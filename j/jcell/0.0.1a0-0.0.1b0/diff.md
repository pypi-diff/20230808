# Comparing `tmp/jcell-0.0.1a0-py3-none-any.whl.zip` & `tmp/jcell-0.0.1b0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,90 +1,93 @@
-Zip file size: 91120 bytes, number of entries: 88
+Zip file size: 95118 bytes, number of entries: 91
 -rw-rw-r--  2.0 unx      253 b- defN 21-Jun-13 13:21 jcell/__init__.py
--rw-rw-r--  2.0 unx     4344 b- defN 21-Jan-29 15:32 jcell/main.py
+-rw-rw-r--  2.0 unx     4344 b- defN 23-Aug-08 14:58 jcell/main.py
 -rw-rw-r--  2.0 unx     7351 b- defN 21-Jun-11 15:54 jcell/update.py
--rw-rw-r--  2.0 unx    10452 b- defN 21-Jun-03 18:07 jcell/.vscode/launch.json
--rw-rw-r--  2.0 unx      538 b- defN 20-Dec-02 16:05 jcell/.vscode/settings.json
--rw-rw-r--  2.0 unx      485 b- defN 20-Dec-02 15:53 jcell/.vscode/tasks.json
--rw-rw-r--  2.0 unx      254 b- defN 21-Apr-21 13:36 jcell/dataset_utils/__init__.py
--rw-rw-r--  2.0 unx    18999 b- defN 21-Apr-21 13:49 jcell/dataset_utils/data_proc.py
--rw-rw-r--  2.0 unx     6186 b- defN 21-Jan-29 15:40 jcell/dataset_utils/imageutl.py
--rw-rw-r--  2.0 unx        0 b- defN 20-Oct-27 13:17 jcell/dataset_utils/proc2d/__init__.py
--rw-rw-r--  2.0 unx     4171 b- defN 21-Apr-21 12:43 jcell/dataset_utils/proc2d/augmentation.py
--rw-rw-r--  2.0 unx     2440 b- defN 20-Dec-02 22:55 jcell/dataset_utils/proc2d/inst2sem.py
--rw-rw-r--  2.0 unx        0 b- defN 20-Oct-27 13:17 jcell/dataset_utils/proc3d/__init__.py
--rw-rw-r--  2.0 unx     6074 b- defN 20-Dec-10 16:16 jcell/dataset_utils/proc3d/augmentation.py
--rw-rw-r--  2.0 unx     2416 b- defN 20-Dec-15 21:37 jcell/dataset_utils/proc3d/inst2sem.py
--rw-rw-r--  2.0 unx       30 b- defN 21-Apr-21 12:09 jcell/evaluation/__init__.py
+-rw-rw-r--  2.0 unx    10060 b- defN 23-Aug-08 14:58 jcell/.vscode/launch.json
+-rw-rw-r--  2.0 unx      538 b- defN 23-Aug-08 14:58 jcell/.vscode/settings.json
+-rw-rw-r--  2.0 unx      485 b- defN 23-Aug-08 14:58 jcell/.vscode/tasks.json
+-rw-rw-r--  2.0 unx      254 b- defN 23-Aug-08 14:58 jcell/dataset_utils/__init__.py
+-rw-rw-r--  2.0 unx    18999 b- defN 23-Aug-08 14:58 jcell/dataset_utils/data_proc.py
+-rw-rw-r--  2.0 unx     6186 b- defN 23-Aug-08 14:58 jcell/dataset_utils/imageutl.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc2d/__init__.py
+-rw-rw-r--  2.0 unx     4171 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc2d/augmentation.py
+-rw-rw-r--  2.0 unx     2440 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc2d/inst2sem.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc3d/__init__.py
+-rw-rw-r--  2.0 unx     6074 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc3d/augmentation.py
+-rw-rw-r--  2.0 unx     2416 b- defN 23-Aug-08 14:58 jcell/dataset_utils/proc3d/inst2sem.py
+-rw-rw-r--  2.0 unx       30 b- defN 23-Aug-08 14:58 jcell/evaluation/__init__.py
 -rw-rw-r--  2.0 unx    14513 b- defN 21-Jun-11 19:16 jcell/evaluation/run.py
--rw-rw-r--  2.0 unx     4500 b- defN 21-Apr-21 12:30 jcell/evaluation/src/__init__.py
--rw-rw-r--  2.0 unx     1251 b- defN 21-Feb-24 15:19 jcell/evaluation/src/iou_mat.py
+-rw-rw-r--  2.0 unx     4500 b- defN 23-Aug-08 14:58 jcell/evaluation/src/__init__.py
+-rw-rw-r--  2.0 unx     1251 b- defN 23-Aug-08 14:58 jcell/evaluation/src/iou_mat.py
 -rw-rw-r--  2.0 unx    23079 b- defN 21-Jun-28 16:59 jcell/evaluation/src/test.py
--rw-rw-r--  2.0 unx      593 b- defN 21-Feb-09 13:37 jcell/evaluation/src/dataloaders/__init__.py
--rw-rw-r--  2.0 unx     6302 b- defN 21-Jan-29 15:40 jcell/evaluation/src/dataloaders/imageutl.py
--rw-rw-r--  2.0 unx      104 b- defN 21-Feb-09 13:38 jcell/evaluation/src/dataloaders/segdataset/__init__.py
+-rw-rw-r--  2.0 unx      593 b- defN 23-Aug-08 14:58 jcell/evaluation/src/dataloaders/__init__.py
+-rw-rw-r--  2.0 unx     6302 b- defN 23-Aug-08 14:58 jcell/evaluation/src/dataloaders/imageutl.py
+-rw-rw-r--  2.0 unx      104 b- defN 23-Aug-08 14:58 jcell/evaluation/src/dataloaders/segdataset/__init__.py
 -rw-rw-r--  2.0 unx     9533 b- defN 21-Jun-11 19:28 jcell/evaluation/src/dataloaders/segdataset/ctransforms.py
 -rw-rw-r--  2.0 unx     4028 b- defN 21-Jun-11 19:27 jcell/evaluation/src/models/__init__.py
--rw-rw-r--  2.0 unx     3746 b- defN 21-Apr-27 18:17 jcell/evaluation/src/models/unet.py
--rw-rw-r--  2.0 unx     3453 b- defN 21-Apr-27 18:17 jcell/evaluation/src/models/unet3pad.py
--rw-rw-r--  2.0 unx     3223 b- defN 21-Apr-27 18:17 jcell/evaluation/src/models/unet3pad3.py
--rw-rw-r--  2.0 unx     3866 b- defN 21-Apr-27 18:17 jcell/evaluation/src/models/unetpad.py
--rw-rw-r--  2.0 unx       62 b- defN 20-Nov-03 14:08 jcell/evaluation/src/post/__init__.py
--rw-rw-r--  2.0 unx     7970 b- defN 21-Apr-27 18:17 jcell/evaluation/src/post/post_processing_func.py
--rw-rw-r--  2.0 unx      191 b- defN 21-Mar-15 12:08 jcell/evaluation/src/utils/__init__.py
+-rw-rw-r--  2.0 unx     3746 b- defN 23-Aug-08 14:58 jcell/evaluation/src/models/unet.py
+-rw-rw-r--  2.0 unx     3453 b- defN 23-Aug-08 14:58 jcell/evaluation/src/models/unet3pad.py
+-rw-rw-r--  2.0 unx     3223 b- defN 23-Aug-08 14:58 jcell/evaluation/src/models/unet3pad3.py
+-rw-rw-r--  2.0 unx     3866 b- defN 23-Aug-08 14:58 jcell/evaluation/src/models/unetpad.py
+-rw-rw-r--  2.0 unx       62 b- defN 23-Aug-08 14:58 jcell/evaluation/src/post/__init__.py
+-rw-rw-r--  2.0 unx     7970 b- defN 23-Aug-08 14:58 jcell/evaluation/src/post/post_processing_func.py
+-rw-rw-r--  2.0 unx      191 b- defN 23-Aug-08 14:58 jcell/evaluation/src/utils/__init__.py
 -rw-rw-r--  2.0 unx     4761 b- defN 21-Jun-11 19:24 jcell/evaluation/src/utils/utils.py
--rw-rw-r--  2.0 unx     4058 b- defN 21-Mar-15 14:29 jcell/evaluation/src/utils/visualization.py
--rw-rw-r--  2.0 unx       37 b- defN 20-Nov-30 14:27 jcell/train/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 21-Apr-19 14:18 jcell/train/src/__init__.py
+-rw-rw-r--  2.0 unx     4058 b- defN 23-Aug-08 14:58 jcell/evaluation/src/utils/visualization.py
+-rw-rw-r--  2.0 unx       37 b- defN 23-Aug-08 14:58 jcell/train/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/__init__.py
 -rw-rw-r--  2.0 unx     2513 b- defN 21-Jun-11 17:41 jcell/train/src/train.py
 -rw-rw-r--  2.0 unx       41 b- defN 21-Jun-11 17:47 jcell/train/src/dataloaders/__init__.py
--rw-rw-r--  2.0 unx      223 b- defN 21-Feb-09 13:43 jcell/train/src/dataloaders/segdataset/__init__.py
+-rw-rw-r--  2.0 unx      223 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset/__init__.py
 -rw-rw-r--  2.0 unx    13952 b- defN 21-Jun-11 17:45 jcell/train/src/dataloaders/segdataset/ctransforms.py
--rw-rw-r--  2.0 unx     3859 b- defN 21-May-03 11:57 jcell/train/src/dataloaders/segdataset/dataset.py
--rw-rw-r--  2.0 unx      434 b- defN 20-Oct-26 15:14 jcell/train/src/dataloaders/segdataset/grid_sample.py
--rw-rw-r--  2.0 unx     3632 b- defN 20-Nov-17 20:49 jcell/train/src/dataloaders/segdataset/tps_grid_gen.py
--rw-rw-r--  2.0 unx      208 b- defN 21-Feb-22 13:55 jcell/train/src/dataloaders/segdataset_all/__init__.py
+-rw-rw-r--  2.0 unx     4197 b- defN 23-Feb-13 22:42 jcell/train/src/dataloaders/segdataset/dataset.py
+-rw-rw-r--  2.0 unx      434 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset/grid_sample.py
+-rw-rw-r--  2.0 unx     3632 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset/tps_grid_gen.py
+-rw-rw-r--  2.0 unx      208 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset_all/__init__.py
 -rw-rw-r--  2.0 unx    13952 b- defN 21-Jun-11 17:46 jcell/train/src/dataloaders/segdataset_all/ctransforms.py
--rw-rw-r--  2.0 unx     3975 b- defN 21-Apr-19 15:20 jcell/train/src/dataloaders/segdataset_all/dataset.py
--rw-rw-r--  2.0 unx      434 b- defN 20-Oct-26 15:14 jcell/train/src/dataloaders/segdataset_all/grid_sample.py
--rw-rw-r--  2.0 unx     3632 b- defN 20-Nov-17 20:49 jcell/train/src/dataloaders/segdataset_all/tps_grid_gen.py
--rw-r--r--  2.0 unx      553 b- defN 21-Mar-22 14:07 jcell/train/src/defaults/dataconfig_dev.json
--rw-r--r--  2.0 unx      642 b- defN 21-Mar-22 14:07 jcell/train/src/defaults/dataconfig_train.json
--rw-rw-r--  2.0 unx     1384 b- defN 21-Jun-11 17:48 jcell/train/src/defaults/loss_definition.json
--rw-r--r--  2.0 unx        3 b- defN 19-Oct-31 22:10 jcell/train/src/defaults/metrics.json
--rw-r--r--  2.0 unx      449 b- defN 20-Dec-18 14:57 jcell/train/src/defaults/metrics_definition.json
--rw-r-----  2.0 unx      562 b- defN 21-Jun-11 17:48 jcell/train/src/defaults/modelconfig.json
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/loss/__init__.py
+-rw-rw-r--  2.0 unx     4341 b- defN 23-Feb-13 22:42 jcell/train/src/dataloaders/segdataset_all/dataset.py
+-rw-rw-r--  2.0 unx      434 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset_all/grid_sample.py
+-rw-rw-r--  2.0 unx     3632 b- defN 23-Aug-08 14:58 jcell/train/src/dataloaders/segdataset_all/tps_grid_gen.py
+-rw-rw-r--  2.0 unx      553 b- defN 23-Aug-08 14:58 jcell/train/src/defaults/dataconfig_dev.json
+-rw-rw-r--  2.0 unx      642 b- defN 23-Aug-08 14:58 jcell/train/src/defaults/dataconfig_train.json
+-rwxrwxrwx  2.0 unx     1384 b- defN 21-Jun-11 17:48 jcell/train/src/defaults/loss_definition.json
+-rw-rw-r--  2.0 unx        3 b- defN 23-Aug-08 14:58 jcell/train/src/defaults/metrics.json
+-rw-rw-r--  2.0 unx      449 b- defN 23-Aug-08 14:58 jcell/train/src/defaults/metrics_definition.json
+-rwxrwxrwx  2.0 unx      562 b- defN 21-Jun-11 17:48 jcell/train/src/defaults/modelconfig.json
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/loss/__init__.py
 -rw-rw-r--  2.0 unx    29390 b- defN 21-Jun-11 17:51 jcell/train/src/loss/lossfunc.py
--rw-rw-r--  2.0 unx     3837 b- defN 21-Apr-19 15:23 jcell/train/src/loss/metrics.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/models/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 20-Oct-26 15:15 jcell/train/src/models/arch/__init__.py
--rw-rw-r--  2.0 unx     3229 b- defN 21-Apr-19 15:24 jcell/train/src/models/arch/unet3pad3.py
--rw-rw-r--  2.0 unx     3456 b- defN 21-Apr-19 15:25 jcell/train/src/models/arch/unetpad_4.py
--rw-rw-r--  2.0 unx     4030 b- defN 21-Apr-21 12:09 jcell/train/src/netframework/__init__.py
--rw-rw-r--  2.0 unx        2 b- defN 19-Oct-31 22:10 jcell/train/src/netframework/dataloaders/__init__.py
--rw-rw-r--  2.0 unx     6820 b- defN 21-Apr-21 13:51 jcell/train/src/netframework/dataloaders/imageutl.py
--rw-rw-r--  2.0 unx     3971 b- defN 21-Jun-11 17:59 jcell/train/src/netframework/dataloaders/loaddataset.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/netframework/loss/__init__.py
--rw-rw-r--  2.0 unx     1558 b- defN 21-Jun-11 17:59 jcell/train/src/netframework/loss/selectloss.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/netframework/models/__init__.py
+-rw-rw-r--  2.0 unx     3837 b- defN 23-Aug-08 14:58 jcell/train/src/loss/metrics.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/models/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/models/arch/__init__.py
+-rw-rw-r--  2.0 unx     3700 b- defN 23-Aug-08 14:58 jcell/train/src/models/arch/unet.py
+-rw-rw-r--  2.0 unx     3229 b- defN 23-Aug-08 14:58 jcell/train/src/models/arch/unet3pad3.py
+-rw-rw-r--  2.0 unx     3226 b- defN 23-Aug-08 14:58 jcell/train/src/models/arch/unetpad_3.py
+-rw-rw-r--  2.0 unx     3456 b- defN 23-Aug-08 14:58 jcell/train/src/models/arch/unetpad_4.py
+-rw-rw-r--  2.0 unx     4030 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/__init__.py
+-rw-rw-r--  2.0 unx        2 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/dataloaders/__init__.py
+-rw-rw-r--  2.0 unx     5484 b- defN 23-Feb-14 20:57 jcell/train/src/netframework/dataloaders/dataloader.py
+-rw-rw-r--  2.0 unx     6820 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/dataloaders/imageutl.py
+-rw-rw-r--  2.0 unx     4384 b- defN 23-Feb-13 23:50 jcell/train/src/netframework/dataloaders/loaddataset.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/loss/__init__.py
+-rw-rw-r--  2.0 unx     1558 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/loss/selectloss.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/models/__init__.py
 -rw-rw-r--  2.0 unx     3299 b- defN 21-Jun-11 17:59 jcell/train/src/netframework/models/loadmodel.py
--rw-rw-r--  2.0 unx    33986 b- defN 21-Jun-11 18:03 jcell/train/src/netframework/netutil/NetFramework.py
--rw-rw-r--  2.0 unx        0 b- defN 20-Jun-23 15:09 jcell/train/src/netframework/netutil/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/netframework/optimizers/__init__.py
--rw-rw-r--  2.0 unx     1274 b- defN 21-Feb-19 20:02 jcell/train/src/netframework/optimizers/selectopt.py
--rw-rw-r--  2.0 unx      660 b- defN 20-Oct-26 15:16 jcell/train/src/netframework/optimizers/selectschedule.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/netframework/utils/__init__.py
--rw-rw-r--  2.0 unx     6845 b- defN 20-Nov-30 19:25 jcell/train/src/netframework/utils/graphics.py
+-rw-rw-r--  2.0 unx    33430 b- defN 23-Feb-13 23:47 jcell/train/src/netframework/netutil/NetFramework.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/netutil/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/optimizers/__init__.py
+-rw-rw-r--  2.0 unx     1274 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/optimizers/selectopt.py
+-rw-rw-r--  2.0 unx      660 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/optimizers/selectschedule.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/utils/__init__.py
+-rw-rw-r--  2.0 unx     6845 b- defN 23-Aug-08 14:58 jcell/train/src/netframework/utils/graphics.py
 -rw-rw-r--  2.0 unx     4245 b- defN 21-Jun-11 18:02 jcell/train/src/netframework/utils/utils.py
--rw-rw-r--  2.0 unx     3015 b- defN 21-Jun-11 17:54 jcell/train/src/netutil/SegmentNet.py
--rw-rw-r--  2.0 unx        0 b- defN 19-Oct-31 22:10 jcell/train/src/netutil/__init__.py
--rwxrwxr-x  2.0 unx       31 b- defN 21-Jan-06 12:33 jcell-0.0.1a0.data/scripts/jcell
--rwxrwxr-x  2.0 unx      244 b- defN 21-Jan-06 12:34 jcell-0.0.1a0.data/scripts/jcell-config
--rwxrwxr-x  2.0 unx       50 b- defN 21-Jan-06 12:34 jcell-0.0.1a0.data/scripts/jcell-dataproc
--rwxrwxr-x  2.0 unx       26 b- defN 21-Jan-29 16:48 jcell-0.0.1a0.data/scripts/jcell-update
--rw-rw-r--  2.0 unx     1074 b- defN 21-Jun-28 17:18 jcell-0.0.1a0.dist-info/LICENSE
--rw-rw-r--  2.0 unx     2973 b- defN 21-Jun-28 17:18 jcell-0.0.1a0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 21-Jun-28 17:18 jcell-0.0.1a0.dist-info/WHEEL
--rw-rw-r--  2.0 unx        6 b- defN 21-Jun-28 17:18 jcell-0.0.1a0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     8402 b- defN 21-Jun-28 17:18 jcell-0.0.1a0.dist-info/RECORD
-88 files, 332226 bytes uncompressed, 77390 bytes compressed:  76.7%
+-rw-rw-r--  2.0 unx     3095 b- defN 23-Feb-13 22:54 jcell/train/src/netutil/SegmentNet.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Aug-08 14:58 jcell/train/src/netutil/__init__.py
+-rwxrwxr-x  2.0 unx       31 b- defN 23-Aug-08 14:58 jcell-0.0.1b0.data/scripts/jcell
+-rwxrwxr-x  2.0 unx      244 b- defN 23-Aug-08 14:58 jcell-0.0.1b0.data/scripts/jcell-config
+-rwxrwxr-x  2.0 unx       50 b- defN 23-Aug-08 14:58 jcell-0.0.1b0.data/scripts/jcell-dataproc
+-rwxrwxr-x  2.0 unx       26 b- defN 23-Aug-08 14:58 jcell-0.0.1b0.data/scripts/jcell-update
+-rw-rw-r--  2.0 unx     1074 b- defN 23-Aug-08 16:08 jcell-0.0.1b0.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3071 b- defN 23-Aug-08 16:08 jcell-0.0.1b0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Aug-08 16:08 jcell-0.0.1b0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        6 b- defN 23-Aug-08 16:08 jcell-0.0.1b0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     8702 b- defN 23-Aug-08 16:08 jcell-0.0.1b0.dist-info/RECORD
+91 files, 345283 bytes uncompressed, 80902 bytes compressed:  76.6%
```

## zipnote {}

```diff
@@ -171,26 +171,35 @@
 
 Filename: jcell/train/src/models/__init__.py
 Comment: 
 
 Filename: jcell/train/src/models/arch/__init__.py
 Comment: 
 
+Filename: jcell/train/src/models/arch/unet.py
+Comment: 
+
 Filename: jcell/train/src/models/arch/unet3pad3.py
 Comment: 
 
+Filename: jcell/train/src/models/arch/unetpad_3.py
+Comment: 
+
 Filename: jcell/train/src/models/arch/unetpad_4.py
 Comment: 
 
 Filename: jcell/train/src/netframework/__init__.py
 Comment: 
 
 Filename: jcell/train/src/netframework/dataloaders/__init__.py
 Comment: 
 
+Filename: jcell/train/src/netframework/dataloaders/dataloader.py
+Comment: 
+
 Filename: jcell/train/src/netframework/dataloaders/imageutl.py
 Comment: 
 
 Filename: jcell/train/src/netframework/dataloaders/loaddataset.py
 Comment: 
 
 Filename: jcell/train/src/netframework/loss/__init__.py
@@ -231,35 +240,35 @@
 
 Filename: jcell/train/src/netutil/SegmentNet.py
 Comment: 
 
 Filename: jcell/train/src/netutil/__init__.py
 Comment: 
 
-Filename: jcell-0.0.1a0.data/scripts/jcell
+Filename: jcell-0.0.1b0.data/scripts/jcell
 Comment: 
 
-Filename: jcell-0.0.1a0.data/scripts/jcell-config
+Filename: jcell-0.0.1b0.data/scripts/jcell-config
 Comment: 
 
-Filename: jcell-0.0.1a0.data/scripts/jcell-dataproc
+Filename: jcell-0.0.1b0.data/scripts/jcell-dataproc
 Comment: 
 
-Filename: jcell-0.0.1a0.data/scripts/jcell-update
+Filename: jcell-0.0.1b0.data/scripts/jcell-update
 Comment: 
 
-Filename: jcell-0.0.1a0.dist-info/LICENSE
+Filename: jcell-0.0.1b0.dist-info/LICENSE
 Comment: 
 
-Filename: jcell-0.0.1a0.dist-info/METADATA
+Filename: jcell-0.0.1b0.dist-info/METADATA
 Comment: 
 
-Filename: jcell-0.0.1a0.dist-info/WHEEL
+Filename: jcell-0.0.1b0.dist-info/WHEEL
 Comment: 
 
-Filename: jcell-0.0.1a0.dist-info/top_level.txt
+Filename: jcell-0.0.1b0.dist-info/top_level.txt
 Comment: 
 
-Filename: jcell-0.0.1a0.dist-info/RECORD
+Filename: jcell-0.0.1b0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## jcell/.vscode/launch.json

```diff
@@ -26,19 +26,18 @@
             "name": "Python: dataproc inst2sem",
             "type": "python",
             "request": "launch",
             "program": "/media/fillo/_home/work/caltech/caltus_deploy/caltus/jcell/dataset_utils/data_proc.py",
             "console": "integratedTerminal",
             "args": [
                 "inst2sem",
-                "--input=/media/fillo/_home/work/caltech/nature_methods/man_seg101_025.tif",
+                "--input=pclv3_16.tif",
                 // "--output=_%3",
                 // "--output=/media/fillo/_home/work/caltech/caltus_deploy/caltus/caltus/unit_test/data/test1/output/",
-                "--se1=1",
-                "--se2=7"
+                // "--se1=1"
             ]
         },
         {
             "name": "Python: dataproc augment",
             "type": "python",
             "request": "launch",
             "program": "/media/fillo/_home/work/caltech/caltus_deploy/caltus/jcell/dataset_utils/data_proc.py",
@@ -69,41 +68,40 @@
             "request": "launch",
             "program": "/media/fillo/_home/work/caltech/caltus_deploy/caltus/jcell/main.py",
             "console": "integratedTerminal",
             "args": [
                 "train",
                 // "-h"
                 // "--listdatasets",
-                "--experiment=cellpose",
-                "--dataset_folder=/media/fillo/_home/work/caltech/nature_methods/datasets",
+                "--experiment=cityscape",
                 // "--dataset_param={'dataset_folder':'/media/fillo/_home/work/caltech/ISBI_datasets/Fluo-N2DL-HeLa1'}",
                 // "--configuration_path=/media/fillo/_home/jcell1/datasets/configuration",
                 // "--output_path=/media/fillo/_home/work/caltech/caltus_deploy/dataset/mer/out",
                 "--use_gpu=1",
                 "--visdom",
                 // "--batch_size=1",
                 // "--batch_acc=8",
                 "--save_rate=100",
                 // "--show_rate=20",
-                "--train_worker=2",
-                "--dev_worker=2",
-                "--loss=jinst",
+                // "--train_worker=4",
+                // "--dev_worker=2",
+                // "--loss=jinst",
                 // "--loss_param",
                 // "{\"lambda_vect\":[1, 0.05, 0.05, 0.05, 1, 0.05, 0.05, 1, 0.05, 1]}",
                 // "--optimizer_param",
                 // "{\"lr\": 0.001}",
                 // "--3D",
                 // "--resume",
                 "--epochs=2",
-                "--optimizer=AdaBelief",
-                // "--model_param",
-                // "{\"init\":\"/media/fillo/_home/work/caltech/nature_methods/models/epoch40model.t7\"}",
-                // "--continual_learning",
-                // "{\"dataset_path\": \"/media/fillo/_home/work/caltech/ISBI_datasets/ALL_DATA_EWC\"}",
-                // "--dataset=tcells",
+                "--optimizer=Adam",
+                "--model_param",
+                "{\"init\":\"/media/fillo/_home/work/caltech/final_ISBI_data/models/17-try_15_epoch100model(GENERALIST OK).t7\"}",
+                "--continual_learning",
+                "{\"dataset_path\": \"/media/fillo/_home/work/caltech/ISBI_datasets/ALL_DATA_EWC\"}",
+                "--dataset=tcells",
                 "/media/fillo/_home/work/caltech/caltus_deploy/",
             ]
         },
         {
             "name": "Python: Evaluation",
             "type": "python",
             "request": "launch",
@@ -122,44 +120,39 @@
                 // "--model=/media/fillo/_home/work/caltech/ISBIC/SW/models/GENERALIST_v0.t7",
                 // "--probability=/media/fillo/_home/work/caltech/caltus_deploy/caltus/unit_test/data/test2/output/squares_prob.tif",
                 // "--input=/media/fillo/_home/work/caltech/ISBI_datasets/original_data/PhC-C2DH-U373/train/02/",
                 // "--input=/media/fillo/_home/work/caltech/ISBIC/Fluo-N2DL-HeLa/01/mask013.tif",
                 // "--input=/media/fillo/_home/work/caltech/final_ISBI_data/test_all/",
                 // "--input=/media/fillo/_home/work/caltech/caltus_deploy/caltus/unit_test/output/squares.tif",
                 // "--probability=/media/fillo/_home/work/caltech/caltus_deploy/caltus/unit_test/output/squares_prob.tif",
-                "--input=/media/fillo/_home/work/caltech/nature_methods/train_val/Fluo-N3DH-CE/01/t194.tif",
-                "--output=/media/fillo/_home/work/caltech/nature_methods/images_server/Fluo-N3DH-CE/",
-                "--model=/media/fillo/_home/work/caltech/nature_methods/models/allGT+ST.t7",
+                "--input=/media/fillo/_home/work/caltech/ISBIC/PhC-C2DL-PSC/01",
+                "--output=/media/fillo/_home/work/caltech/ISBIC/PhC-C2DL-PSC/our_results1/",
+                "--model=generalist",
                 // "--post=MAP",
                 // "--post_param",
                 // "{\"min_area\":126}",
                 "--output_type",
-                // "object_overlay",
-                "instances_rgb",
-                "image",
-                "--3D",
+                "object_overlay",
+                // "--3D",
                 // "--output=/media/fillo/_home/work/caltech/ISBIC/Fluo-N2DL-HeLa/01_RES/",
                 // "--output=/media/fillo/_home/work/caltech/final_ISBI_data/res1/",
                 // "--overwrite",
                 "--use_gpu",
-                // "1",
-                // "--use_gpu",
-                // "2",
-                // "--crop_size=16",
+                "1",
                 // "--post=WTS",
                 // "--post_param",
                 // "{\"thresh_foreground\":0.99}",
                 // "--output_type",
                 // "instances_rgb",
                 // "classification",
-                "--confidence=0.9",
+                // "--confidence=0.85",
                 // "--3D",
                 // "--verbose",
                 // "--percentile_norm",
-                "--sequence",
+                // "--sequence",
                 "/media/fillo/_home/work/caltech/models/"
             ]
             // "args": [
             //     "eval",
             //     "--input=/media/fillo/_home/work/caltech/ISBIC/Fluo-N2DH-SIM+/01/",
             //     "--model=/media/fillo/_home/work/caltech/models/fluosim2.pt",
             //     "--output=/media/fillo/_home/work/caltech/ISBIC/Fluo-N2DH-SIM+/01_newmodel/",
```

## jcell/train/src/dataloaders/segdataset/dataset.py

```diff
@@ -64,17 +64,20 @@
         self.rep = rep
         self.is_3D = is_3D
 
         load_weight = False if weight_folder == "" else True
 
         self.load_weight = load_weight
         if self.load_weight:
-            self.weightprov = matProvider(
-                os.path.join(self.root, split, weight_folder)
-            )
+            self.weightprov = matProvider(os.path.join(self.root, split, weight_folder))
+
+        self.normalization = "max_norm"
+        if self.transform_param is not None:
+            if "NormalizePercentile" in repr(self.transform_param):
+                self.normalization = "percentile_norm"
 
     def __len__(self):
         return self.dataprov._num * self.rep
 
     def __getitem__(self, index):
         img, lbl = self.dataprov[index % self.dataprov._num]
 
@@ -86,50 +89,61 @@
             img = np.repeat(img, 3, axis=2)
         elif self.is_3D and img.ndim == 4 and img.shape[3] == 1:
             img = np.repeat(img, 3, axis=3)
 
         if self.is_3D and img.ndim == 4 and img.shape[2] > img.shape[3]:
             img = img.transpose((0, 1, 3, 2))
 
-        if (not self.is_3D and lbl.ndim == 3) or (
-            self.is_3D and lbl.ndim == 4
-        ):
+        if (not self.is_3D and lbl.ndim == 3) or (self.is_3D and lbl.ndim == 4):
             lbl = lbl[..., 0].squeeze()
 
         sample = {"image": img, "label": lbl}
 
         if self.load_weight:
             wht = self.weightprov[index % self.dataprov.num]
             if not self.is_3D and wht.ndim == 3:
                 wht = np.squeeze(wht[..., 0], axis=2)
             elif self.is_3D and wht.ndim == 4:
                 wht = np.squeeze(wht[..., 0], axis=3)
             sample["weight"] = wht
 
-        normalization = "max_norm"
         if self.transform_param is not None:
             sample = self.transform_param(sample)
-            if "NormalizePercentile" in repr(self.transform_param):
-                normalization = "percentile_norm"
 
         sample["idx"] = index
-        sample["normalization"] = normalization
         return sample
 
 
+# def warp_Variable(sample, device):
+#     images, labels = sample["image"], sample["label"]
+#     images = images.to(device)
+#     labels = labels.to(device)
+
+#     output = {
+#         "image": images,
+#         "label": labels,
+#         "idx": sample["idx"],
+#     }
+
+#     if "weight" in sample:
+#         weight = sample["weight"]
+#         weight = weight.to(device)
+#         output["weight"] = weight
+
+
+#     return output
 def warp_Variable(sample, device):
-    images, labels = sample["image"], sample["label"]
+    idx, images, labels, weights = sample
     images = images.to(device)
     labels = labels.to(device)
 
     output = {
         "image": images,
         "label": labels,
-        "idx": sample["idx"],
+        "idx": idx,
     }
 
-    if "weight" in sample:
-        weight = sample["weight"]
-        weight = weight.to(device)
-        output["weight"] = weight
+    if weights.shape[1] != 1:
+        weights = weights.to(device)
+        output["weight"] = weights
 
     return output
```

## jcell/train/src/dataloaders/segdataset_all/dataset.py

```diff
@@ -68,19 +68,24 @@
             else:
                 self.len = max(self.len, len(self.dataprov[i]))
         self.rep = rep
         self.is_3D = is_3D
         self.pattern = 0
         self.accesing_dataset = np.ones((self.number_datasets,))
 
+        self.normalization = "max_norm"
+        if self.transform_param is not None:
+            if "NormalizePercentile" in repr(self.transform_param):
+                self.normalization = "percentile_norm"
+
     def __len__(self):
         return self.len * self.rep
 
     def __getitem__(self, index):
-        np.random.seed(random.randint(0, 2 ** 32))
+        np.random.seed(random.randint(0, 2**32))
         current_pattern = index % self.number_datasets
 
         len_dataset = len(self.dataprov[current_pattern])
         index = random.randint(0, len_dataset)
 
         img, lbl = self.dataprov[current_pattern][index % len_dataset]
 
@@ -92,42 +97,53 @@
             img = np.repeat(img, 3, axis=2)
         elif self.is_3D and img.ndim == 4 and img.shape[3] == 1:
             img = np.repeat(img, 3, axis=3)
 
         if self.is_3D and img.ndim == 4 and img.shape[2] > img.shape[3]:
             img = img.transpose((0, 1, 3, 2))
 
-        if (not self.is_3D and lbl.ndim == 3) or (
-            self.is_3D and lbl.ndim == 4
-        ):
+        if (not self.is_3D and lbl.ndim == 3) or (self.is_3D and lbl.ndim == 4):
             lbl = lbl[..., 0].squeeze()
 
         sample = {"image": img, "label": lbl}
 
-        normalization = "max_norm"
         if self.transform_param is not None:
             sample = self.transform_param(sample)
-            if "NormalizePercentile" in repr(self.transform_param):
-                normalization = "percentile_norm"
 
         sample["idx"] = index
-        sample["normalization"] = normalization
         return sample
 
 
+# def warp_Variable(sample, device):
+#     images, labels = sample["image"], sample["label"]
+#     images = images.to(device)
+#     labels = labels.to(device)
+
+#     output = {
+#         "image": images,
+#         "label": labels,
+#         "idx": sample["idx"],
+#     }
+
+#     if "weight" in sample:
+#         weight = sample["weight"]
+#         weight = weight.to(device)
+#         output["weight"] = weight
+
+
+#     return output
 def warp_Variable(sample, device):
-    images, labels = sample["image"], sample["label"]
+    idx, images, labels, weights = sample
     images = images.to(device)
     labels = labels.to(device)
 
     output = {
         "image": images,
         "label": labels,
-        "idx": sample["idx"],
+        "idx": idx,
     }
 
-    if "weight" in sample:
-        weight = sample["weight"]
-        weight = weight.to(device)
-        output["weight"] = weight
+    if weights.shape[1] != 1:
+        weights = weights.to(device)
+        output["weight"] = weights
 
     return output
```

## jcell/train/src/netframework/dataloaders/loaddataset.py

```diff
@@ -1,26 +1,29 @@
 import json
 import os
 import numpy as np
 from ..utils.utils import Decoder
 from ..utils.utils import get_class
 from importlib import import_module
-from torch.utils.data import DataLoader, random_split
+from torch.utils.data import random_split
 import torchvision.transforms as transforms
 from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler
 import torch
+from .dataloader import DataLoader
 
 
 def loaddataset(
     datasetname,
     experimentparam,
     batch_size=1,
     worker=1,
     is_3D=False,
     config_file="defaults/dataconfig_train.json",
+    loaderlib="torch",
+    file_name="",
 ):
     # load dataset configuration (json)
     if datasetname == "" and not os.path.isabs(config_file):
         datasetname = "data3d" if is_3D else "data2d"
 
     path_config, config_file_name = os.path.split(config_file)
     automatic_split_required = False
@@ -67,18 +70,22 @@
     # dataset
     ddatasets = cdataset(**data_props, transform_parameter=transform)
 
     # loader
     tsampler = SubsetRandomSampler(np.random.permutation(len(ddatasets)))
     dloader = DataLoader(
         ddatasets,
+        loaderlib,
         batch_size=batch_size,
         sampler=tsampler,
         num_workers=worker,
         pin_memory=True,
+        file_name="{}/{}{}.beton".format(
+            file_name, datasetname + "." if datasetname != "" else "", config_file_name
+        ),
     )
 
     if automatic_split_required:
         val_len = max(min(int(len(ddatasets) * 0.1), 100), 1)
         train_len = len(ddatasets) - val_len
         ddatasets = random_split(
             ddatasets,
@@ -86,27 +93,31 @@
             generator=torch.Generator().manual_seed(1),
         )
 
         dloader = list()
         dloader.append(
             DataLoader(
                 ddatasets[0],
+                loaderlib,
                 batch_size=batch_size,
                 num_workers=worker,
                 pin_memory=True,
                 shuffle=True,
+                file_name="{}/train.beton".format(file_name),
             )
         )
         dloader.append(
             DataLoader(
                 ddatasets[1],
+                loaderlib,
                 batch_size=batch_size,
                 num_workers=worker,
                 pin_memory=True,
                 shuffle=False,
+                file_name="{}/valid.beton".format(file_name),
             )
         )
 
     return ddatasets, dloader, module, data_props["number_classes"]
 
 
 def get_data_path(name, config_file="defaults/dataconfig_train.json"):
```

## jcell/train/src/netframework/netutil/NetFramework.py

```diff
@@ -56,17 +56,15 @@
             default="",
             help="Output path for saving the experiments (default: ../out).",
         )
         parser.add_argument(
             "--configuration_path",
             type=str,
             default="",
-            help="Configuration path (default: {}).".format(
-                self.defaults_path
-            ),
+            help="Configuration path (default: {}).".format(self.defaults_path),
             dest="json_path",
         )
         parser.add_argument(
             "--dataset_folder",
             type=str,
             default="",
             help="Path to a dataset (default: '')",
@@ -253,14 +251,20 @@
         parser.add_argument(
             "--verbose",
             action="store_true",
             help=argparse.SUPPRESS,
         )
 
         parser.add_argument(
+            "--fIO",
+            action="store_true",
+            help=argparse.SUPPRESS,
+        )
+
+        parser.add_argument(
             "--continual_learning",
             type=str,
             default="{}",
             nargs="+",
             help=argparse.SUPPRESS,
         )
 
@@ -272,18 +276,15 @@
             len(not_know_args) == 1 and not os.path.exists(not_know_args[0])
         ):
             print("Parameters {} not recognized.".format(not_know_args[:-1]))
 
         if (
             args.help
             or len(not_know_args) > 1
-            or (
-                len(not_know_args) == 1
-                and not os.path.exists(not_know_args[0])
-            )
+            or (len(not_know_args) == 1 and not os.path.exists(not_know_args[0]))
         ):
             parser.print_help()
             exit(0)
 
         if custom_folder is None and os.path.exists(not_know_args[0]):
             custom_folder = not_know_args[0]
 
@@ -319,46 +320,40 @@
             "model_path": os.path.join(experimentpath, "model"),
             "images_path": os.path.join(experimentpath, "images"),
         }
 
         for _, path in folders.items():
             create_folders(path)
 
-        json.dump(
-            vars(args), open(os.path.join(experimentpath, "args.json"), "w")
-        )
+        json.dump(vars(args), open(os.path.join(experimentpath, "args.json"), "w"))
         args.folders = folders
 
+        args.loaderlib = "ffcv" if args.fIO else "torch"
+
         args.loss_param = " ".join(args.loss_param)
-        args.lossparam = json.loads(
-            args.loss_param.replace("'", '"'), cls=Decoder
-        )
+        args.lossparam = json.loads(args.loss_param.replace("'", '"'), cls=Decoder)
         args.dataset_param = " ".join(args.dataset_param)
         args.datasetparam = json.loads(
             args.dataset_param.replace("'", '"'), cls=Decoder
         )
         args.model_param = " ".join(args.model_param)
-        args.modelparam = json.loads(
-            args.model_param.replace("'", '"'), cls=Decoder
-        )
+        args.modelparam = json.loads(args.model_param.replace("'", '"'), cls=Decoder)
         args.optimizer_param = " ".join(args.optimizer_param)
         args.optimizerparam = json.loads(
             args.optimizer_param.replace("'", '"'), cls=Decoder
         )
         args.continual_learning = " ".join(args.continual_learning)
         args.continual_learning = json.loads(
             args.continual_learning.replace("'", '"'), cls=Decoder
         )
 
         if args.json_path == "":
             args.json_path = "defaults"
         elif args.json_path == "JCELL_RESOURCES":
-            resource_file = os.path.expanduser(
-                os.path.join("~", ".jcell", "jcellrc")
-            )
+            resource_file = os.path.expanduser(os.path.join("~", ".jcell", "jcellrc"))
             if os.path.exists(resource_file):
                 f = open(resource_file, "r")
                 resource_line = f.read()
                 f.close()
                 args.json_path = os.path.join(
                     resource_line, "datasets", "configuration"
                 )
@@ -398,30 +393,22 @@
 
         # Visdom visualization
         self.visdom = args.visdom
         if self.visdom:
             try:
                 from visdom import Visdom
 
-                self.vis = Visdom(
-                    use_incoming_socket=False, raise_exceptions=True
-                )
+                self.vis = Visdom(use_incoming_socket=False, raise_exceptions=True)
                 self.vis.close(env=args.experiment)
                 self.visplotter = gph.VisdomLinePlotter(
                     self.vis, env_name=args.experiment
                 )
-                self.visheatmap = gph.HeatMapVisdom(
-                    self.vis, env_name=args.experiment
-                )
-                self.visimshow = gph.ImageVisdom(
-                    self.vis, env_name=args.experiment
-                )
-                self.vistext = gph.TextVisdom(
-                    self.vis, env_name=args.experiment
-                )
+                self.visheatmap = gph.HeatMapVisdom(self.vis, env_name=args.experiment)
+                self.visimshow = gph.ImageVisdom(self.vis, env_name=args.experiment)
+                self.vistext = gph.TextVisdom(self.vis, env_name=args.experiment)
             except Exception:
                 print("Visdom server can't be reached")
                 self.visdom = False
 
         # Showing results rate
         self.print_rate = args.print_rate
         self.show_rate = args.show_rate
@@ -461,35 +448,39 @@
         ) = loaddataset(
             datasetname=args.dataset,
             experimentparam=args.datasetparam,
             batch_size=args.batch_size,
             worker=args.train_worker,
             is_3D=args.is_3D,
             config_file=os.path.join(defaults_path, "dataconfig_train.json"),
+            loaderlib=args.loaderlib,
+            file_name=os.path.join(args.output_path, "data"),
         )
 
         if isinstance(self.traindataset, list):
             self.traindataset, self.testdataset = self.traindataset
             self.train_loader, self.test_loader = self.train_loader
         else:
             self.testdataset, self.test_loader, _, _ = loaddataset(
                 datasetname=args.dataset,
                 experimentparam=args.datasetparam,
                 batch_size=args.batch_size,
                 worker=args.dev_worker,
                 is_3D=args.is_3D,
                 config_file=os.path.join(defaults_path, "dataconfig_dev.json"),
+                loaderlib=args.loaderlib,
+                file_name=os.path.join(args.output_path, "data"),
             )
 
         # Automatic detection of the number of channels and classes
         sample = self.traindataset[0]
         c = sample["image"].shape
         args.modelparam["in_channels"] = c[0]
         args.modelparam["n_classes"] = n_classes
-        self.normalization_type = sample["normalization"]
+        self.normalization_type = self.traindataset.normalization
 
         self.warp_var_mod = import_module(self.dmodule + ".dataset")
 
         # Setup model
         if args.list_models:
             data = json.load(
                 open(os.path.join(self.defaults_path, "modelconfig.json")),
@@ -508,24 +499,20 @@
             experimentparams=args.modelparam,
             is_3D=args.is_3D,
             config_file=os.path.join(self.defaults_path, "modelconfig.json"),
         )
 
         self.net.to(self.device)
         if self.use_parallel:
-            self.net = torch.nn.DataParallel(
-                self.net, device_ids=self.use_parallel
-            )
+            self.net = torch.nn.DataParallel(self.net, device_ids=self.use_parallel)
             cudnn.benchmark = False
 
         # Setup Optimizer
         print("Selecting optimizer: ", end="")
-        self.optimizer = selectoptimizer(
-            args.optimizer, self.net, args.optimizerparam
-        )
+        self.optimizer = selectoptimizer(args.optimizer, self.net, args.optimizerparam)
 
         # Setup Loss criterion
         if args.list_loss:
             data = json.load(
                 open(os.path.join(self.defaults_path, "loss_definition.json")),
                 cls=Decoder,
             )
@@ -536,39 +523,33 @@
             val = int(input("Select a loss: "))
             args.loss = list(data.keys())[val]
 
         print("Selecting loss function: ", end="")
         self.criterion, self.losseval = selectloss(
             lossname=args.loss,
             parameter=args.lossparam,
-            config_file=os.path.join(
-                self.defaults_path, "loss_definition.json"
-            ),
+            config_file=os.path.join(self.defaults_path, "loss_definition.json"),
         )
         self.criterion.to(self.device)
         self.trlossavg = AverageMeter()
         self.vdlossavg = AverageMeter()
 
         # Others evaluation metrics
         print("Selecting metrics functions:")
-        metrics_dict = get_metric_path(
-            os.path.join(defaults_path, "metrics.json")
-        )
+        metrics_dict = get_metric_path(os.path.join(defaults_path, "metrics.json"))
         self.metrics = dict()
         self.metrics_eval = dict()
         self.trmetrics_avg = dict()
         self.vdmetrics_avg = dict()
 
         for key, value in metrics_dict.items():
             self.metrics[key], self.metrics_eval[key] = selectloss(
                 lossname=value["metric"],
                 parameter=value.pop("param", {}),
-                config_file=os.path.join(
-                    self.defaults_path, "metrics_definition.json"
-                ),
+                config_file=os.path.join(self.defaults_path, "metrics_definition.json"),
             )
             self.metrics[key].to(self.device)
             self.trmetrics_avg[key] = AverageMeter()
             self.vdmetrics_avg[key] = AverageMeter()
 
         self.plogger = print_logger()
 
@@ -586,31 +567,28 @@
                 "device": self.device,
             }
             for key, val in self.args.continual_learning.items():
                 parameters[key] = val
             self.EWC, _ = selectloss(
                 "ewc",
                 parameter=parameters,
-                config_file=os.path.join(
-                    self.defaults_path, "loss_definition.json"
-                ),
+                config_file=os.path.join(self.defaults_path, "loss_definition.json"),
             )
 
     def do_train(self):
         for current_epoch in range(self.init_epoch, self.epochs):
             # print("epoch ", current_epoch)
             self.current_epoch = current_epoch
 
             # Forward over validation set
             avgloss, avgmetric = self.validation(current_epoch)
 
             save_ = (
                 True
-                if self.save_rate != 0
-                and (current_epoch % self.save_rate) == 0
+                if self.save_rate != 0 and (current_epoch % self.save_rate) == 0
                 else False
             )
             # Save netowrk after self.save_rate epochs
             if save_:
                 print("Saving checkpoint epoch {}\n".format(current_epoch))
                 self.savemodel(
                     os.path.join(
@@ -620,17 +598,15 @@
                 )
 
             # Forward and backward over training set
             self.train(current_epoch)
             self.valid_visualization(current_epoch, 0)
 
         # Save last model network
-        self.savemodel(
-            os.path.join(self.folders["model_path"], "lastmodel.t7")
-        )
+        self.savemodel(os.path.join(self.folders["model_path"], "lastmodel.t7"))
 
     # Train function
     def train(self, current_epoch):
         data_time = AverageMeter()
         batch_time = AverageMeter()
 
         self.trlossavg.new_local()
@@ -666,23 +642,19 @@
             if (i + 1) % self.batch_acc == 0 or (i + 1) == total_train:
                 self.optimizer.zero_grad()
 
             batch_time.update(time.time() - end)
             end = time.time()
 
             if (i % self.print_rate) == 0 or (i + 1 == total_train):
-                prefix = "Train [{0}/{1}]".format(
-                    current_epoch + 1, self.args.epochs
-                )
+                prefix = "Train [{0}/{1}]".format(current_epoch + 1, self.args.epochs)
 
                 print_dict = dict()
                 for key, value in self.trmetrics_avg.items():
-                    print_dict[key] = "{:.3f} ({:.3f})".format(
-                        value.val, value.avg
-                    )
+                    print_dict[key] = "{:.3f} ({:.3f})".format(value.val, value.avg)
 
                 print_dict["loss"] = "{:.3f} ({:.3f})".format(
                     self.trlossavg.val, self.trlossavg.avg
                 )
 
                 self.plogger.print(i + 1, total_train, prefix, print_dict)
 
@@ -692,17 +664,15 @@
                 info = {"loss": self.trlossavg}
 
                 for key, value in self.trmetrics_avg.items():
                     info[key] = value
 
                 for tag, value in info.items():
                     self.visplotter.show(tag, "train", iteration, value.avg)
-                    self.visplotter.show(
-                        tag, "train_mean", iteration, value.total_avg
-                    )
+                    self.visplotter.show(tag, "train_mean", iteration, value.total_avg)
 
     def validation(self, current_epoch):
         data_time = AverageMeter()
         batch_time = AverageMeter()
 
         self.vdlossavg.new_local()
         for key, value in self.vdmetrics_avg.items():
@@ -723,63 +693,54 @@
                 kwarg = eval(self.losseval)
                 loss = self.criterion(**kwarg)
 
                 self.vdlossavg.update(loss.item(), images.size(0))
                 for key, value in self.metrics_eval.items():
                     kwarg = eval(self.metrics_eval[key])
                     metric = self.metrics[key](**kwarg)
-                    self.vdmetrics_avg[key].update(
-                        metric.item(), images.size(0)
-                    )
+                    self.vdmetrics_avg[key].update(metric.item(), images.size(0))
 
                 batch_time.update(time.time() - end)
                 end = time.time()
 
                 if i % self.print_rate == 0 or (i + 1 == total_valid):
                     prefix = "Valid [{0}/{1}]".format(
                         current_epoch + 1, self.args.epochs
                     )
 
                     print_dict = dict()
                     for key, value in self.vdmetrics_avg.items():
-                        print_dict[key] = "{:.3f} ({:.3f})".format(
-                            value.val, value.avg
-                        )
+                        print_dict[key] = "{:.3f} ({:.3f})".format(value.val, value.avg)
 
                     print_dict["loss"] = "{:.3f} ({:.3f})".format(
                         self.vdlossavg.val, self.vdlossavg.avg
                     )
 
                     self.plogger.print(i + 1, total_valid, prefix, print_dict)
 
                 if (
                     self.visdom
                     and current_epoch != self.init_epoch
                     and (
-                        ((i + 1) % self.show_rate) == 0
-                        or ((i + 1) % total_valid) == 0
+                        ((i + 1) % self.show_rate) == 0 or ((i + 1) % total_valid) == 0
                     )
                 ):
                     info = {"loss": self.vdlossavg}
 
                     for key, value in self.vdmetrics_avg.items():
                         info[key] = value
 
                     for tag, value in info.items():
-                        self.visplotter.show(
-                            tag, "valid", iteration, value.avg
-                        )
+                        self.visplotter.show(tag, "valid", iteration, value.avg)
                         self.visplotter.show(
                             tag, "valid_mean", iteration, value.total_avg
                         )
 
         if list(self.vdmetrics_avg.keys()):
-            watch_metric = self.vdmetrics_avg[
-                list(self.vdmetrics_avg.keys())[0]
-            ]
+            watch_metric = self.vdmetrics_avg[list(self.vdmetrics_avg.keys())[0]]
         else:
             watch_metric = self.vdlossavg
 
         return self.vdlossavg.avg, watch_metric.avg
 
     def valid_visualization(self, current_epoch, index=0, save=False):
         with torch.no_grad():
@@ -961,20 +922,15 @@
                     "loss_definition.json",
                 )
             ),
             cls=Decoder,
         )
         dl = ""
         for elem in data.keys():
-            dl += (
-                data[elem].pop("name", "unknown loss function")
-                + "("
-                + elem
-                + "),"
-            )
+            dl += data[elem].pop("name", "unknown loss function") + "(" + elem + "),"
         dl = dl[:-2]
         return str(dl)
 
     def list_optimizer(self):
         import inspect
 
         data = inspect.getmembers(sys.modules["torch.optim"], inspect.isclass)
```

## jcell/train/src/netutil/SegmentNet.py

```diff
@@ -21,15 +21,18 @@
     @load_defaults
     def valid_visualization(self, current_epoch, index=0, save=False):
         with torch.no_grad():
             sample = self.testdataset[index]
             sample["image"].unsqueeze_(0)
             sample["label"].unsqueeze_(0)
 
-            sample = self.warp_var_mod.warp_Variable(sample, self.device)
+            sample = self.warp_var_mod.warp_Variable(
+                (sample["idx"], sample["image"], sample["label"], torch.ones((1, 1))),
+                self.device,
+            )
             images = sample["image"]
             labels = sample["label"]
 
             outputs = self.net(images)
             prob = F.softmax(outputs, dim=1)
             prob = prob.detach()[0]
             _, maxprob = torch.max(prob, 0)
@@ -74,17 +77,15 @@
                 self.visheatmap.show(
                     "Image",
                     images.detach().cpu().numpy(),
                     colormap="Greys",
                     scale=scale,
                 )
 
-            if (self.saveim_rate != 0) and (
-                ((current_epoch) % self.saveim_rate) == 0
-            ):
+            if (self.saveim_rate != 0) and (((current_epoch) % self.saveim_rate) == 0):
                 saveimage(
                     prob.cpu().numpy(),
                     os.path.join(
                         self.folders["images_path"],
                         "image-{:d}-{:03d}.tif".format(index, current_epoch),
                     ),
                 )
```

## Comparing `jcell-0.0.1a0.dist-info/LICENSE` & `jcell-0.0.1b0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `jcell-0.0.1a0.dist-info/METADATA` & `jcell-0.0.1b0.dist-info/METADATA`

 * *Files 13% similar despite different names*

```diff
@@ -1,43 +1,41 @@
 Metadata-Version: 2.1
 Name: jcell
-Version: 0.0.1a0
+Version: 0.0.1b0
 Summary: Software package for training and testing deep learning based method applied to image segmentation
 Home-page: http://jcell.org
 Author: Fidel Guerrero Pena
-Author-email: fagp@cin.ufpe.br
-License: UNKNOWN
-Platform: UNKNOWN
+Author-email: fillo8985@gmail.com
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: POSIX :: Linux
 Requires-Python: >=3.6
 Description-Content-Type: text/markdown
+License-File: LICENSE
 Requires-Dist: numpy
 Requires-Dist: Pillow
 Requires-Dist: scikit-image
 Requires-Dist: scipy
-Requires-Dist: torch (>=1.7.1)
-Requires-Dist: torchvision (>=0.8.2)
-Requires-Dist: visdom (>=0.1.8.9)
+Requires-Dist: torch
+Requires-Dist: torchvision
+Requires-Dist: visdom
 Requires-Dist: numba
 Requires-Dist: llc
 Requires-Dist: imageio
-Requires-Dist: imagecodecs
 Requires-Dist: wget
 Requires-Dist: requests
 Requires-Dist: tqdm
 
+[![Python package](https://github.com/fagp/caltus/actions/workflows/python-package.yml/badge.svg)](https://github.com/fagp/caltus/actions/workflows/python-package.yml)
 # JCELL
 
 ``jcell`` is an image segmentation software primarily dedicated to biological cells. The software is an implementation of our latest developments in cell segmentation using deep learning approaches specially aimed at segmenting clustered cells. We pioneered the use of multiclass segmentation to improve segmenting tightly packed cells (see ICIP2018) and recently introduced a combination of Youden's J Statistics and cross entropy as a robust loss working in tandem to promote a sharp classification of pixels/voxels (see ISBI2020). Due to *J*, highly imbalanced data can be directly trained bypassing the need of complicated data balancing strategies.  This is the software used for winning DIC-C2DH-Hela and PhC-C2DH-U373 Cell segmentation challenges (http://celltrackingchallenge.net/latest-csb-results/).
 
 For an in depth understading how the methods work check our publications [ICIP2018], [MICCAIW2019], [ISBI2020].
 
 See documentation for more details on how to use this software.
 
 [ISBI2020] **J Regularization Improves Imbalanced Multiclass Segmentation**. *Fidel A. Guerrero Peña, Pedro D. Marrero Fernandez, Paul T. Tarr, Tsang Ing Ren, Elliot M. Meyerowitz, Alexandre Cunha*. IEEE 17th International Symposium on Biomedical Imaging (ISBI). 2020. https://ieeexplore.ieee.org/abstract/document/9098550. Arxiv https://arxiv.org/abs/1910.09783.
 
 [MICCAIW2019] **A Weakly Supervised Method for Instance Segmentation of Biological Cells**. *Fidel A. Guerrero Pena, Pedro D. Marrero Fernandez, Tsang Ing Ren, Alexandre Cunha*. Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data. Springer. 2019. https://link.springer.com/chapter/10.1007/978-3-030-33391-1_25. Arxiv https://arxiv.org/abs/1908.09891.
 
 [ICIP2018] **Multiclass Weighted Loss for Instance Segmentation of Cluttered Cells**. *Fidel A. Guerrero Pena, Pedro D. Marrero Fernandez, Tsang Ing Ren, Mary Yui, Ellen Rothenberg, Alexandre Cunha*. IEEE International Conference on Image Processing (ICIP). 2018. https://ieeexplore.ieee.org/abstract/document/8451187/. Arxiv https://arxiv.org/abs/1802.07465.
-
```

## Comparing `jcell-0.0.1a0.dist-info/RECORD` & `jcell-0.0.1b0.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 jcell/__init__.py,sha256=F7vreqBuFypQu0hwCnp3rsbc6YSq0a5JAyEVXKGiwgY,253
 jcell/main.py,sha256=RB8mMlTWKlYVLIT37ubeHwcKH4PAmXKr8q7yl_GNWHA,4344
 jcell/update.py,sha256=8gCCoSLkyecuzpMBczrPFvUIAh4AiaqXAJ2aF4m2gYQ,7351
-jcell/.vscode/launch.json,sha256=26Kcd9rqTfqfHqDNlVXD7HDHZFnYbg5pvTD4IaI0vyo,10452
+jcell/.vscode/launch.json,sha256=Qq3m0x5WPc83_Uw8OU8U8JzweANX0w1jAF0hmziHrkM,10060
 jcell/.vscode/settings.json,sha256=nTcARu5DepxWRMlFfS0Jit1kAQQ0BmWnW-hPKaoxyjk,538
 jcell/.vscode/tasks.json,sha256=_QfBLLDF7SedGur0z7M14dRFatsQEBvCe2Uyj7ZvCto,485
 jcell/dataset_utils/__init__.py,sha256=SqIKdlAEXWRkcGFhHnznkJFJ3GWWyY26Dxyb3pec47A,254
 jcell/dataset_utils/data_proc.py,sha256=ZbXc5BS64n1wixsx8QjHlF2NJ-hfo_UaSSiou1JhqU0,18999
 jcell/dataset_utils/imageutl.py,sha256=Lju-YWP1LXGYt7pvXYL8-YDj3qhVvDBxbVoDg8VTbSA,6186
 jcell/dataset_utils/proc2d/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/dataset_utils/proc2d/augmentation.py,sha256=CXN4NY6CMgoffWVHbqzS64-yZ-cMHeH7cAG1Xjeau8A,4171
@@ -34,55 +34,58 @@
 jcell/evaluation/src/utils/visualization.py,sha256=YvyfWpdpVcvX2sa6A3wPGpLD4hwfYNGhWL2-B6sHEBY,4058
 jcell/train/__init__.py,sha256=svfTHDIfBiNTQh5q8t2EPndpSAykqVPNxCmWR79kx-U,37
 jcell/train/src/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/train.py,sha256=lPNdf8eSrr-MZSEXH-pgMSRd91kUxqblItQ8uCshcSA,2513
 jcell/train/src/dataloaders/__init__.py,sha256=Odv6sF_mmRIgWV2GHTU3wegPUmRscmgEoOar7e8yshk,41
 jcell/train/src/dataloaders/segdataset/__init__.py,sha256=T452YB52w3n6zXiemmT2EL39IIYBkvizLqUEXkTtGXM,223
 jcell/train/src/dataloaders/segdataset/ctransforms.py,sha256=tHkxYoiluohVhTpdlFNgglNVQfnqSUsb7mAGuNYr2TI,13952
-jcell/train/src/dataloaders/segdataset/dataset.py,sha256=RkxoviT74NwpKxWGcmF2WhwZugmpv8CaEH1AUMDGd7Y,3859
+jcell/train/src/dataloaders/segdataset/dataset.py,sha256=qsJhGa-r_ZywRQjKdYjGETAKLsvsPYXC5jkyM0Bkw7c,4197
 jcell/train/src/dataloaders/segdataset/grid_sample.py,sha256=0cG3ZovXLKaCPU1YhuQDdSHep5a7F1I4QdtfA5g3ORk,434
 jcell/train/src/dataloaders/segdataset/tps_grid_gen.py,sha256=pEFx2yx26FjHCbuzJ0ZhuQasQAEQdf5PQbyb96iK32E,3632
 jcell/train/src/dataloaders/segdataset_all/__init__.py,sha256=E7rUD0acSYNm6CYP-Bjb0ywSR8hPFA5hK4gQYVf8ay8,208
 jcell/train/src/dataloaders/segdataset_all/ctransforms.py,sha256=ETvix9MKcoeV56aKvCL6Xghyt-H_TBZWpukVr3-eFx0,13952
-jcell/train/src/dataloaders/segdataset_all/dataset.py,sha256=JJ-7j-No3hgjjgoNWFwtsjMGaYDucxZV71i-CdoXFec,3975
+jcell/train/src/dataloaders/segdataset_all/dataset.py,sha256=domuiAqWMP_g-bFMaD1q3Y4kd4Mz-xOOlLB0VlBzYIY,4341
 jcell/train/src/dataloaders/segdataset_all/grid_sample.py,sha256=0cG3ZovXLKaCPU1YhuQDdSHep5a7F1I4QdtfA5g3ORk,434
 jcell/train/src/dataloaders/segdataset_all/tps_grid_gen.py,sha256=pEFx2yx26FjHCbuzJ0ZhuQasQAEQdf5PQbyb96iK32E,3632
 jcell/train/src/defaults/dataconfig_dev.json,sha256=iJPkOfr-mtnroPxVrTMpxXW2QhlgcLLb7TpV-KzcnDo,553
 jcell/train/src/defaults/dataconfig_train.json,sha256=wyLWQ6hF9_s-PEJmubiK8as6dTPM7VaNizJR8m0y8vg,642
 jcell/train/src/defaults/loss_definition.json,sha256=cVO87j48koeoJtGhLnUygpbPGI2xZD7u22grkXtMQcw,1384
 jcell/train/src/defaults/metrics.json,sha256=yj0WO6sFU4GCciYUBWjzvvfqrBh869doeOC2Pp5EI1Y,3
 jcell/train/src/defaults/metrics_definition.json,sha256=ng1bB48jjq50WZcSeEXXuDzSWxdJMOlbq7zeKFckiw8,449
 jcell/train/src/defaults/modelconfig.json,sha256=TZ-xGhcRMG7TngYPxaC99QFBPSlxY0ub1SgH4hTcuDI,562
 jcell/train/src/loss/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/loss/lossfunc.py,sha256=BP6xD1Qk-sP_JoHL5NhPc5-jW5ePM4SaIdeWhM_T3Qw,29390
 jcell/train/src/loss/metrics.py,sha256=Y_2fs8PFVhHmFqjk8X-fWeqJzxOrwRXZX_jYmGFx1tE,3837
 jcell/train/src/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/models/arch/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+jcell/train/src/models/arch/unet.py,sha256=wrkJ2mN_aH3qGA9qnoeli9UUDJDDQl0oykn-TPR0V_8,3700
 jcell/train/src/models/arch/unet3pad3.py,sha256=Yy1zPeFtX--HquO7RFw--odqyim3UBiwNYqHnduHd1s,3229
+jcell/train/src/models/arch/unetpad_3.py,sha256=kYF6DL_BEtWTZTE2K2agQHLppiSpFzaNLMOhouA2ew8,3226
 jcell/train/src/models/arch/unetpad_4.py,sha256=8NafYrJqBC1QcNtQ70ZXnu5RjNS2bCDYdTwTGoxJuNY,3456
 jcell/train/src/netframework/__init__.py,sha256=YO-W8lRGTZdxvGXgEdMnFp5gSzQgXvgJyKWZ6IYXm58,4030
 jcell/train/src/netframework/dataloaders/__init__.py,sha256=daEdpEyAJIa8b2VkCqSKcw8PaExcB6Qro80XNes_sHA,2
+jcell/train/src/netframework/dataloaders/dataloader.py,sha256=Nej-58aQZOsfn3WWEYIljKr8DX2VWw4bFxNn1HikC74,5484
 jcell/train/src/netframework/dataloaders/imageutl.py,sha256=x_Cot-yUOr9X1jPaFXEDmzKfI1BnLT2g4IsemDzUy6k,6820
-jcell/train/src/netframework/dataloaders/loaddataset.py,sha256=2on42RpPpIzwloGj1g5OShSIB7dXUFjHB25iPpeC7_s,3971
+jcell/train/src/netframework/dataloaders/loaddataset.py,sha256=wsCeysCAdDXD-Z_N4Zn1REfOIlpU707oRPV1dBj76lw,4384
 jcell/train/src/netframework/loss/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/netframework/loss/selectloss.py,sha256=GWNYUHR82n0J1x9Ep--fxFgIyaGDnpwWa35mXjGUnHU,1558
 jcell/train/src/netframework/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/netframework/models/loadmodel.py,sha256=de59RZOzod6ATkAA1Ac3OnhDcwL_doQOoteRCZb48qg,3299
-jcell/train/src/netframework/netutil/NetFramework.py,sha256=2Dez5EDggkOCcEuEqd0B2MSuB468yTGyZUmJa74TzQg,33986
+jcell/train/src/netframework/netutil/NetFramework.py,sha256=XuzGA-RtbHNs3oetfDAtiq7-XFLjfBwENJ1XFWioR2o,33430
 jcell/train/src/netframework/netutil/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/netframework/optimizers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/netframework/optimizers/selectopt.py,sha256=XllM-dFnIKIgOtz-gvAqv5APCKtHIYkBI6GYZEmOxe8,1274
 jcell/train/src/netframework/optimizers/selectschedule.py,sha256=LV48x69m1fYNnDFT0jSOMuyDE0nb3FXOI54-yuwsj7A,660
 jcell/train/src/netframework/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 jcell/train/src/netframework/utils/graphics.py,sha256=J_EwmllC0lgPQ3nrAhqN7XhGuEEPnXWTvVJHfmEzCYQ,6845
 jcell/train/src/netframework/utils/utils.py,sha256=5k3QwmkNRWJyrBm8j7UbfgYDFXmaujBchi8TgN0TzjI,4245
-jcell/train/src/netutil/SegmentNet.py,sha256=sXRZv7JsKaefkGdGJoLjbGooQv8kZJoB5j6KRZjrMUo,3015
+jcell/train/src/netutil/SegmentNet.py,sha256=NOyo7zpQ6V53SZLnaWD4HpYDH3XwPtNvvdTsbigmNIY,3095
 jcell/train/src/netutil/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-jcell-0.0.1a0.data/scripts/jcell,sha256=Uf9OzJk2lpMCn5IBdVMTUQsTif_H5_o2nXwcx9g7nRM,31
-jcell-0.0.1a0.data/scripts/jcell-config,sha256=7J1CjwgAFP-nbr-69-tPYSgUOCLS4VEL32haPqRJ8ys,244
-jcell-0.0.1a0.data/scripts/jcell-dataproc,sha256=mrOXJ3b9_pvZAtU9Y6VPIHcnIGO1BJEJNiO9eYzvqk0,50
-jcell-0.0.1a0.data/scripts/jcell-update,sha256=V1893O3B1nKCgMVmOLZhLHZ-R2wqlHmTLxtBtSYfP5s,26
-jcell-0.0.1a0.dist-info/LICENSE,sha256=7EI8xVBu6h_7_JlVw-yPhhOZlpY9hP8wal7kHtqKT_E,1074
-jcell-0.0.1a0.dist-info/METADATA,sha256=5d_I2M5BpwIkt72-hqoVrDVHvybwVkOc2KXn8o1FkzA,2973
-jcell-0.0.1a0.dist-info/WHEEL,sha256=p46_5Uhzqz6AzeSosiOnxK-zmFja1i22CrQCjmYe8ec,92
-jcell-0.0.1a0.dist-info/top_level.txt,sha256=PWy4aUFjrtGOtE3unkRgo6t6BmvzGig9853po1NMLec,6
-jcell-0.0.1a0.dist-info/RECORD,,
+jcell-0.0.1b0.data/scripts/jcell,sha256=Uf9OzJk2lpMCn5IBdVMTUQsTif_H5_o2nXwcx9g7nRM,31
+jcell-0.0.1b0.data/scripts/jcell-config,sha256=7J1CjwgAFP-nbr-69-tPYSgUOCLS4VEL32haPqRJ8ys,244
+jcell-0.0.1b0.data/scripts/jcell-dataproc,sha256=mrOXJ3b9_pvZAtU9Y6VPIHcnIGO1BJEJNiO9eYzvqk0,50
+jcell-0.0.1b0.data/scripts/jcell-update,sha256=V1893O3B1nKCgMVmOLZhLHZ-R2wqlHmTLxtBtSYfP5s,26
+jcell-0.0.1b0.dist-info/LICENSE,sha256=7EI8xVBu6h_7_JlVw-yPhhOZlpY9hP8wal7kHtqKT_E,1074
+jcell-0.0.1b0.dist-info/METADATA,sha256=F5wMSWy34HCKyDcntZPBwSLSp7BN2jKcvI_Vrjd1nFU,3071
+jcell-0.0.1b0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+jcell-0.0.1b0.dist-info/top_level.txt,sha256=PWy4aUFjrtGOtE3unkRgo6t6BmvzGig9853po1NMLec,6
+jcell-0.0.1b0.dist-info/RECORD,,
```

