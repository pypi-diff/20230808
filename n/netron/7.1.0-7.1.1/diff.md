# Comparing `tmp/netron-7.1.0-py3-none-any.whl.zip` & `tmp/netron-7.1.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,146 +1,148 @@
-Zip file size: 1591254 bytes, number of entries: 144
--rw-r--r--  2.0 unx     1526 b- defN 23-Aug-01 04:04 netron/__init__.py
--rw-r--r--  2.0 unx    57889 b- defN 23-Aug-01 04:04 netron/acuity-metadata.json
--rw-r--r--  2.0 unx    24150 b- defN 23-Aug-01 04:04 netron/acuity.js
--rw-r--r--  2.0 unx    11340 b- defN 23-Aug-01 04:04 netron/armnn-metadata.json
--rw-r--r--  2.0 unx   108710 b- defN 23-Aug-01 04:04 netron/armnn-schema.js
--rw-r--r--  2.0 unx    13793 b- defN 23-Aug-01 04:04 netron/armnn.js
--rwxr-xr-x  2.0 unx    16571 b- defN 23-Aug-01 04:04 netron/barracuda.js
--rw-r--r--  2.0 unx    38139 b- defN 23-Aug-01 04:04 netron/base.js
--rw-r--r--  2.0 unx     2017 b- defN 23-Aug-01 04:04 netron/bigdl-metadata.json
--rw-r--r--  2.0 unx    24356 b- defN 23-Aug-01 04:04 netron/bigdl-proto.js
--rw-r--r--  2.0 unx    12745 b- defN 23-Aug-01 04:04 netron/bigdl.js
--rw-r--r--  2.0 unx    34678 b- defN 23-Aug-01 04:04 netron/browser.js
--rw-r--r--  2.0 unx     9505 b- defN 23-Aug-01 04:04 netron/caffe-metadata.json
--rw-r--r--  2.0 unx   188897 b- defN 23-Aug-01 04:04 netron/caffe-proto.js
--rw-r--r--  2.0 unx    25529 b- defN 23-Aug-01 04:04 netron/caffe.js
--rw-r--r--  2.0 unx   863689 b- defN 23-Aug-01 04:04 netron/caffe2-metadata.json
--rw-r--r--  2.0 unx    61210 b- defN 23-Aug-01 04:04 netron/caffe2-proto.js
--rw-r--r--  2.0 unx    22617 b- defN 23-Aug-01 04:04 netron/caffe2.js
--rw-r--r--  2.0 unx      889 b- defN 23-Aug-01 04:04 netron/cambricon.js
--rw-r--r--  2.0 unx    13245 b- defN 23-Aug-01 04:04 netron/circle-metadata.json
--rw-r--r--  2.0 unx    99313 b- defN 23-Aug-01 04:04 netron/circle-schema.js
--rw-r--r--  2.0 unx    24420 b- defN 23-Aug-01 04:04 netron/circle.js
--rw-r--r--  2.0 unx    14193 b- defN 23-Aug-01 04:04 netron/cntk-metadata.json
--rw-r--r--  2.0 unx    11578 b- defN 23-Aug-01 04:04 netron/cntk-proto.js
--rw-r--r--  2.0 unx    43790 b- defN 23-Aug-01 04:04 netron/cntk.js
--rw-r--r--  2.0 unx    15775 b- defN 23-Aug-01 04:04 netron/coreml-metadata.json
--rw-r--r--  2.0 unx   415701 b- defN 23-Aug-01 04:04 netron/coreml-proto.js
--rw-r--r--  2.0 unx    68028 b- defN 23-Aug-01 04:04 netron/coreml.js
--rw-r--r--  2.0 unx   102117 b- defN 23-Aug-01 04:04 netron/dagre.js
--rw-r--r--  2.0 unx    20570 b- defN 23-Aug-01 04:04 netron/darknet-metadata.json
--rw-r--r--  2.0 unx    54886 b- defN 23-Aug-01 04:04 netron/darknet.js
--rw-r--r--  2.0 unx     1417 b- defN 23-Aug-01 04:04 netron/dl4j-metadata.json
--rw-r--r--  2.0 unx    16955 b- defN 23-Aug-01 04:04 netron/dl4j.js
--rw-r--r--  2.0 unx     2309 b- defN 23-Aug-01 04:04 netron/dlc-metadata.json
--rw-r--r--  2.0 unx     8706 b- defN 23-Aug-01 04:04 netron/dlc-schema.js
--rw-r--r--  2.0 unx    26954 b- defN 23-Aug-01 04:04 netron/dlc.js
--rw-r--r--  2.0 unx     1777 b- defN 23-Aug-01 04:04 netron/dnn-metadata.json
--rw-r--r--  2.0 unx    11533 b- defN 23-Aug-01 04:04 netron/dnn-proto.js
--rw-r--r--  2.0 unx    10594 b- defN 23-Aug-01 04:04 netron/dnn.js
--rw-r--r--  2.0 unx    34494 b- defN 23-Aug-01 04:04 netron/favicon.ico
--rw-r--r--  2.0 unx    11358 b- defN 23-Aug-01 04:04 netron/flatbuffers.js
--rw-r--r--  2.0 unx     7734 b- defN 23-Aug-01 04:04 netron/flax.js
--rw-r--r--  2.0 unx     7568 b- defN 23-Aug-01 04:04 netron/flexbuffers.js
--rw-r--r--  2.0 unx        3 b- defN 23-Aug-01 04:04 netron/flux-metadata.json
--rw-r--r--  2.0 unx     2409 b- defN 23-Aug-01 04:04 netron/flux.js
--rw-r--r--  2.0 unx     6061 b- defN 23-Aug-01 04:04 netron/grapher.css
--rw-r--r--  2.0 unx    25602 b- defN 23-Aug-01 04:04 netron/grapher.js
--rw-r--r--  2.0 unx    29456 b- defN 23-Aug-01 04:04 netron/hailo-metadata.json
--rw-r--r--  2.0 unx    11521 b- defN 23-Aug-01 04:04 netron/hailo.js
--rwxr-xr-x  2.0 unx    57289 b- defN 23-Aug-01 04:04 netron/hdf5.js
--rw-r--r--  2.0 unx     6789 b- defN 23-Aug-01 04:04 netron/hickle.js
--rw-r--r--  2.0 unx    58106 b- defN 23-Aug-01 04:04 netron/icon.png
--rw-r--r--  2.0 unx     1392 b- defN 23-Aug-01 04:04 netron/imgdnn.js
--rw-r--r--  2.0 unx    44057 b- defN 23-Aug-01 04:07 netron/index.html
--rw-r--r--  2.0 unx     4113 b- defN 23-Aug-01 04:04 netron/index.js
--rwxr-xr-x  2.0 unx    18643 b- defN 23-Aug-01 04:04 netron/json.js
--rw-r--r--  2.0 unx   254682 b- defN 23-Aug-01 04:04 netron/keras-metadata.json
--rw-r--r--  2.0 unx    54531 b- defN 23-Aug-01 04:04 netron/keras.js
--rw-r--r--  2.0 unx    64052 b- defN 23-Aug-01 04:04 netron/kmodel.js
--rw-r--r--  2.0 unx      244 b- defN 23-Aug-01 04:04 netron/lasagne-metadata.json
--rw-r--r--  2.0 unx     7050 b- defN 23-Aug-01 04:04 netron/lasagne.js
--rw-r--r--  2.0 unx     5172 b- defN 23-Aug-01 04:04 netron/lightgbm.js
--rw-r--r--  2.0 unx    10385 b- defN 23-Aug-01 04:04 netron/mediapipe.js
--rw-r--r--  2.0 unx    91710 b- defN 23-Aug-01 04:04 netron/megengine-metadata.json
--rw-r--r--  2.0 unx    82284 b- defN 23-Aug-01 04:04 netron/megengine-schema.js
--rw-r--r--  2.0 unx    30574 b- defN 23-Aug-01 04:04 netron/megengine.js
--rw-r--r--  2.0 unx    44765 b- defN 23-Aug-01 04:04 netron/mlir.js
--rw-r--r--  2.0 unx     3423 b- defN 23-Aug-01 04:04 netron/mlnet-metadata.json
--rw-r--r--  2.0 unx    78350 b- defN 23-Aug-01 04:04 netron/mlnet.js
--rw-r--r--  2.0 unx    10058 b- defN 23-Aug-01 04:04 netron/mnn-metadata.json
--rw-r--r--  2.0 unx    62342 b- defN 23-Aug-01 04:04 netron/mnn-schema.js
--rw-r--r--  2.0 unx    17641 b- defN 23-Aug-01 04:04 netron/mnn.js
--rw-r--r--  2.0 unx    85458 b- defN 23-Aug-01 04:04 netron/mslite-metadata.json
--rw-r--r--  2.0 unx   171745 b- defN 23-Aug-01 04:04 netron/mslite-schema.js
--rw-r--r--  2.0 unx    14997 b- defN 23-Aug-01 04:04 netron/mslite.js
--rw-r--r--  2.0 unx    11884 b- defN 23-Aug-01 04:04 netron/mxnet-metadata.json
--rw-r--r--  2.0 unx    37803 b- defN 23-Aug-01 04:04 netron/mxnet.js
--rw-r--r--  2.0 unx    30899 b- defN 23-Aug-01 04:04 netron/ncnn-metadata.json
--rw-r--r--  2.0 unx    37976 b- defN 23-Aug-01 04:04 netron/ncnn.js
--rw-r--r--  2.0 unx   290482 b- defN 23-Aug-01 04:04 netron/nnabla-metadata.json
--rw-r--r--  2.0 unx   434215 b- defN 23-Aug-01 04:04 netron/nnabla-proto.js
--rw-r--r--  2.0 unx    11418 b- defN 23-Aug-01 04:04 netron/nnabla.js
--rw-r--r--  2.0 unx     2224 b- defN 23-Aug-01 04:04 netron/nnef.js
--rw-r--r--  2.0 unx    15163 b- defN 23-Aug-01 04:04 netron/numpy.js
--rw-r--r--  2.0 unx    53079 b- defN 23-Aug-01 04:04 netron/om-metadata.json
--rw-r--r--  2.0 unx    37006 b- defN 23-Aug-01 04:04 netron/om-proto.js
--rw-r--r--  2.0 unx    29164 b- defN 23-Aug-01 04:04 netron/om.js
--rw-r--r--  2.0 unx     6818 b- defN 23-Aug-01 04:04 netron/onednn-metadata.json
--rw-r--r--  2.0 unx    11961 b- defN 23-Aug-01 04:04 netron/onednn.js
--rw-r--r--  2.0 unx  2912056 b- defN 23-Aug-01 04:04 netron/onnx-metadata.json
--rw-r--r--  2.0 unx    59899 b- defN 23-Aug-01 04:04 netron/onnx-proto.js
--rw-r--r--  2.0 unx    15717 b- defN 23-Aug-01 04:04 netron/onnx-schema.js
--rw-r--r--  2.0 unx    88981 b- defN 23-Aug-01 04:04 netron/onnx.js
--rw-r--r--  2.0 unx     9053 b- defN 23-Aug-01 04:04 netron/onnx.py
--rw-r--r--  2.0 unx    84585 b- defN 23-Aug-01 04:04 netron/openvino-metadata.json
--rw-r--r--  2.0 unx    44560 b- defN 23-Aug-01 04:04 netron/openvino.js
--rw-r--r--  2.0 unx     2894 b- defN 23-Aug-01 04:04 netron/paddle-metadata.json
--rw-r--r--  2.0 unx    60111 b- defN 23-Aug-01 04:04 netron/paddle-proto.js
--rw-r--r--  2.0 unx    19797 b- defN 23-Aug-01 04:04 netron/paddle-schema.js
--rw-r--r--  2.0 unx    37551 b- defN 23-Aug-01 04:04 netron/paddle.js
--rw-r--r--  2.0 unx     5527 b- defN 23-Aug-01 04:04 netron/pickle.js
--rw-r--r--  2.0 unx    42713 b- defN 23-Aug-01 04:04 netron/protobuf.js
--rw-r--r--  2.0 unx   303716 b- defN 23-Aug-01 04:04 netron/python.js
--rwxr-xr-x  2.0 unx   411132 b- defN 23-Aug-01 04:04 netron/pytorch-metadata.json
--rw-r--r--  2.0 unx    13170 b- defN 23-Aug-01 04:04 netron/pytorch-schema.js
--rw-r--r--  2.0 unx   182294 b- defN 23-Aug-01 04:04 netron/pytorch.js
--rw-r--r--  2.0 unx    24259 b- defN 23-Aug-01 04:04 netron/pytorch.py
--rw-r--r--  2.0 unx     5473 b- defN 23-Aug-01 04:04 netron/rknn-metadata.json
--rw-r--r--  2.0 unx     4263 b- defN 23-Aug-01 04:04 netron/rknn-schema.js
--rw-r--r--  2.0 unx    24805 b- defN 23-Aug-01 04:04 netron/rknn.js
--rw-r--r--  2.0 unx     4571 b- defN 23-Aug-01 04:04 netron/safetensors.js
--rw-r--r--  2.0 unx     5865 b- defN 23-Aug-01 04:04 netron/server.js
--rw-r--r--  2.0 unx    11874 b- defN 23-Aug-01 04:07 netron/server.py
--rw-r--r--  2.0 unx   160693 b- defN 23-Aug-01 04:04 netron/sklearn-metadata.json
--rw-r--r--  2.0 unx    14746 b- defN 23-Aug-01 04:04 netron/sklearn.js
--rw-r--r--  2.0 unx     4901 b- defN 23-Aug-01 04:04 netron/tar.js
--rwxr-xr-x  2.0 unx    27914 b- defN 23-Aug-01 04:04 netron/tengine-metadata.json
--rwxr-xr-x  2.0 unx    28094 b- defN 23-Aug-01 04:04 netron/tengine.js
--rw-r--r--  2.0 unx     5278 b- defN 23-Aug-01 04:04 netron/tensorrt.js
--rw-r--r--  2.0 unx    11077 b- defN 23-Aug-01 04:04 netron/text.js
--rw-r--r--  2.0 unx  2221556 b- defN 23-Aug-01 04:04 netron/tf-metadata.json
--rw-r--r--  2.0 unx   363531 b- defN 23-Aug-01 04:04 netron/tf-proto.js
--rw-r--r--  2.0 unx   106578 b- defN 23-Aug-01 04:04 netron/tf.js
--rw-r--r--  2.0 unx    29824 b- defN 23-Aug-01 04:04 netron/tflite-metadata.json
--rw-r--r--  2.0 unx   110995 b- defN 23-Aug-01 04:04 netron/tflite-schema.js
--rw-r--r--  2.0 unx    25098 b- defN 23-Aug-01 04:04 netron/tflite.js
--rw-r--r--  2.0 unx    20380 b- defN 23-Aug-01 04:04 netron/tnn-metadata.json
--rw-r--r--  2.0 unx    26868 b- defN 23-Aug-01 04:04 netron/tnn.js
--rw-r--r--  2.0 unx    12510 b- defN 23-Aug-01 04:04 netron/torch-metadata.json
--rw-r--r--  2.0 unx    41535 b- defN 23-Aug-01 04:04 netron/torch.js
--rw-r--r--  2.0 unx     2333 b- defN 23-Aug-01 04:04 netron/uff-metadata.json
--rw-r--r--  2.0 unx    30910 b- defN 23-Aug-01 04:04 netron/uff-proto.js
--rw-r--r--  2.0 unx    12710 b- defN 23-Aug-01 04:04 netron/uff.js
--rw-r--r--  2.0 unx   237224 b- defN 23-Aug-01 04:04 netron/view.js
--rw-r--r--  2.0 unx     8023 b- defN 23-Aug-01 04:04 netron/weka.js
--rw-r--r--  2.0 unx    64034 b- defN 23-Aug-01 04:04 netron/xml.js
--rw-r--r--  2.0 unx    55685 b- defN 23-Aug-01 04:04 netron/xmodel-proto.js
--rw-r--r--  2.0 unx    13916 b- defN 23-Aug-01 04:04 netron/xmodel.js
--rw-r--r--  2.0 unx    30921 b- defN 23-Aug-01 04:04 netron/zip.js
--rw-r--r--  2.0 unx     1447 b- defN 23-Aug-01 04:07 netron-7.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Aug-01 04:07 netron-7.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       39 b- defN 23-Aug-01 04:07 netron-7.1.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        7 b- defN 23-Aug-01 04:07 netron-7.1.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    11132 b- defN 23-Aug-01 04:07 netron-7.1.0.dist-info/RECORD
-144 files, 12963178 bytes uncompressed, 1574562 bytes compressed:  87.9%
+Zip file size: 1599944 bytes, number of entries: 146
+-rw-r--r--  2.0 unx     1526 b- defN 23-Aug-07 07:33 netron/__init__.py
+-rw-r--r--  2.0 unx    57889 b- defN 23-Aug-07 07:33 netron/acuity-metadata.json
+-rw-r--r--  2.0 unx    22497 b- defN 23-Aug-07 07:33 netron/acuity.js
+-rw-r--r--  2.0 unx    11340 b- defN 23-Aug-07 07:33 netron/armnn-metadata.json
+-rw-r--r--  2.0 unx   108710 b- defN 23-Aug-07 07:33 netron/armnn-schema.js
+-rw-r--r--  2.0 unx    12340 b- defN 23-Aug-07 07:33 netron/armnn.js
+-rwxr-xr-x  2.0 unx    16571 b- defN 23-Aug-07 07:33 netron/barracuda.js
+-rw-r--r--  2.0 unx    38139 b- defN 23-Aug-07 07:33 netron/base.js
+-rw-r--r--  2.0 unx     2017 b- defN 23-Aug-07 07:33 netron/bigdl-metadata.json
+-rw-r--r--  2.0 unx    24356 b- defN 23-Aug-07 07:33 netron/bigdl-proto.js
+-rw-r--r--  2.0 unx    12745 b- defN 23-Aug-07 07:33 netron/bigdl.js
+-rw-r--r--  2.0 unx    34678 b- defN 23-Aug-07 07:33 netron/browser.js
+-rw-r--r--  2.0 unx     9505 b- defN 23-Aug-07 07:33 netron/caffe-metadata.json
+-rw-r--r--  2.0 unx   188897 b- defN 23-Aug-07 07:33 netron/caffe-proto.js
+-rw-r--r--  2.0 unx    25529 b- defN 23-Aug-07 07:33 netron/caffe.js
+-rw-r--r--  2.0 unx   863689 b- defN 23-Aug-07 07:33 netron/caffe2-metadata.json
+-rw-r--r--  2.0 unx    61210 b- defN 23-Aug-07 07:33 netron/caffe2-proto.js
+-rw-r--r--  2.0 unx    22617 b- defN 23-Aug-07 07:33 netron/caffe2.js
+-rw-r--r--  2.0 unx      889 b- defN 23-Aug-07 07:33 netron/cambricon.js
+-rw-r--r--  2.0 unx    13245 b- defN 23-Aug-07 07:33 netron/circle-metadata.json
+-rw-r--r--  2.0 unx    99313 b- defN 23-Aug-07 07:33 netron/circle-schema.js
+-rw-r--r--  2.0 unx    24420 b- defN 23-Aug-07 07:33 netron/circle.js
+-rw-r--r--  2.0 unx    14193 b- defN 23-Aug-07 07:33 netron/cntk-metadata.json
+-rw-r--r--  2.0 unx    11578 b- defN 23-Aug-07 07:33 netron/cntk-proto.js
+-rw-r--r--  2.0 unx    43790 b- defN 23-Aug-07 07:33 netron/cntk.js
+-rw-r--r--  2.0 unx    15775 b- defN 23-Aug-07 07:33 netron/coreml-metadata.json
+-rw-r--r--  2.0 unx   415701 b- defN 23-Aug-07 07:33 netron/coreml-proto.js
+-rw-r--r--  2.0 unx    68028 b- defN 23-Aug-07 07:33 netron/coreml.js
+-rw-r--r--  2.0 unx   102117 b- defN 23-Aug-07 07:33 netron/dagre.js
+-rw-r--r--  2.0 unx    20570 b- defN 23-Aug-07 07:33 netron/darknet-metadata.json
+-rw-r--r--  2.0 unx    54886 b- defN 23-Aug-07 07:33 netron/darknet.js
+-rw-r--r--  2.0 unx     1417 b- defN 23-Aug-07 07:33 netron/dl4j-metadata.json
+-rw-r--r--  2.0 unx    16955 b- defN 23-Aug-07 07:33 netron/dl4j.js
+-rw-r--r--  2.0 unx     2309 b- defN 23-Aug-07 07:33 netron/dlc-metadata.json
+-rw-r--r--  2.0 unx     8706 b- defN 23-Aug-07 07:33 netron/dlc-schema.js
+-rw-r--r--  2.0 unx    26986 b- defN 23-Aug-07 07:33 netron/dlc.js
+-rw-r--r--  2.0 unx     1777 b- defN 23-Aug-07 07:33 netron/dnn-metadata.json
+-rw-r--r--  2.0 unx    11533 b- defN 23-Aug-07 07:33 netron/dnn-proto.js
+-rw-r--r--  2.0 unx    10594 b- defN 23-Aug-07 07:33 netron/dnn.js
+-rw-r--r--  2.0 unx    34494 b- defN 23-Aug-07 07:33 netron/favicon.ico
+-rw-r--r--  2.0 unx    11358 b- defN 23-Aug-07 07:33 netron/flatbuffers.js
+-rw-r--r--  2.0 unx     7734 b- defN 23-Aug-07 07:33 netron/flax.js
+-rw-r--r--  2.0 unx     7568 b- defN 23-Aug-07 07:33 netron/flexbuffers.js
+-rw-r--r--  2.0 unx        3 b- defN 23-Aug-07 07:33 netron/flux-metadata.json
+-rw-r--r--  2.0 unx     2409 b- defN 23-Aug-07 07:33 netron/flux.js
+-rw-r--r--  2.0 unx     6061 b- defN 23-Aug-07 07:33 netron/grapher.css
+-rw-r--r--  2.0 unx    25602 b- defN 23-Aug-07 07:33 netron/grapher.js
+-rw-r--r--  2.0 unx    29456 b- defN 23-Aug-07 07:33 netron/hailo-metadata.json
+-rw-r--r--  2.0 unx    11521 b- defN 23-Aug-07 07:33 netron/hailo.js
+-rwxr-xr-x  2.0 unx    57289 b- defN 23-Aug-07 07:33 netron/hdf5.js
+-rw-r--r--  2.0 unx     6789 b- defN 23-Aug-07 07:33 netron/hickle.js
+-rw-r--r--  2.0 unx    58106 b- defN 23-Aug-07 07:33 netron/icon.png
+-rw-r--r--  2.0 unx     1392 b- defN 23-Aug-07 07:33 netron/imgdnn.js
+-rw-r--r--  2.0 unx    44059 b- defN 23-Aug-07 07:37 netron/index.html
+-rw-r--r--  2.0 unx     4113 b- defN 23-Aug-07 07:33 netron/index.js
+-rwxr-xr-x  2.0 unx    18643 b- defN 23-Aug-07 07:33 netron/json.js
+-rw-r--r--  2.0 unx   254682 b- defN 23-Aug-07 07:33 netron/keras-metadata.json
+-rw-r--r--  2.0 unx    54531 b- defN 23-Aug-07 07:33 netron/keras.js
+-rw-r--r--  2.0 unx    64052 b- defN 23-Aug-07 07:33 netron/kmodel.js
+-rw-r--r--  2.0 unx      244 b- defN 23-Aug-07 07:33 netron/lasagne-metadata.json
+-rw-r--r--  2.0 unx     7050 b- defN 23-Aug-07 07:33 netron/lasagne.js
+-rw-r--r--  2.0 unx     5172 b- defN 23-Aug-07 07:33 netron/lightgbm.js
+-rw-r--r--  2.0 unx    10385 b- defN 23-Aug-07 07:33 netron/mediapipe.js
+-rw-r--r--  2.0 unx    91710 b- defN 23-Aug-07 07:33 netron/megengine-metadata.json
+-rw-r--r--  2.0 unx    82284 b- defN 23-Aug-07 07:33 netron/megengine-schema.js
+-rw-r--r--  2.0 unx    30574 b- defN 23-Aug-07 07:33 netron/megengine.js
+-rw-r--r--  2.0 unx    44765 b- defN 23-Aug-07 07:33 netron/mlir.js
+-rw-r--r--  2.0 unx     3423 b- defN 23-Aug-07 07:33 netron/mlnet-metadata.json
+-rw-r--r--  2.0 unx    78350 b- defN 23-Aug-07 07:33 netron/mlnet.js
+-rw-r--r--  2.0 unx    10058 b- defN 23-Aug-07 07:33 netron/mnn-metadata.json
+-rw-r--r--  2.0 unx    62342 b- defN 23-Aug-07 07:33 netron/mnn-schema.js
+-rw-r--r--  2.0 unx    17641 b- defN 23-Aug-07 07:33 netron/mnn.js
+-rw-r--r--  2.0 unx    85458 b- defN 23-Aug-07 07:33 netron/mslite-metadata.json
+-rw-r--r--  2.0 unx   171745 b- defN 23-Aug-07 07:33 netron/mslite-schema.js
+-rw-r--r--  2.0 unx    14997 b- defN 23-Aug-07 07:33 netron/mslite.js
+-rw-r--r--  2.0 unx    11884 b- defN 23-Aug-07 07:33 netron/mxnet-metadata.json
+-rw-r--r--  2.0 unx    37803 b- defN 23-Aug-07 07:33 netron/mxnet.js
+-rw-r--r--  2.0 unx    30899 b- defN 23-Aug-07 07:33 netron/ncnn-metadata.json
+-rw-r--r--  2.0 unx    37976 b- defN 23-Aug-07 07:33 netron/ncnn.js
+-rw-r--r--  2.0 unx   295328 b- defN 23-Aug-07 07:33 netron/nnabla-metadata.json
+-rw-r--r--  2.0 unx   441665 b- defN 23-Aug-07 07:33 netron/nnabla-proto.js
+-rw-r--r--  2.0 unx    11418 b- defN 23-Aug-07 07:33 netron/nnabla.js
+-rw-r--r--  2.0 unx     2224 b- defN 23-Aug-07 07:33 netron/nnef.js
+-rw-r--r--  2.0 unx    14205 b- defN 23-Aug-07 07:33 netron/numpy.js
+-rw-r--r--  2.0 unx    53079 b- defN 23-Aug-07 07:33 netron/om-metadata.json
+-rw-r--r--  2.0 unx    37006 b- defN 23-Aug-07 07:33 netron/om-proto.js
+-rw-r--r--  2.0 unx    29188 b- defN 23-Aug-07 07:33 netron/om.js
+-rw-r--r--  2.0 unx     6818 b- defN 23-Aug-07 07:33 netron/onednn-metadata.json
+-rw-r--r--  2.0 unx    11961 b- defN 23-Aug-07 07:33 netron/onednn.js
+-rw-r--r--  2.0 unx  2961943 b- defN 23-Aug-07 07:33 netron/onnx-metadata.json
+-rw-r--r--  2.0 unx    59899 b- defN 23-Aug-07 07:33 netron/onnx-proto.js
+-rw-r--r--  2.0 unx    15717 b- defN 23-Aug-07 07:33 netron/onnx-schema.js
+-rw-r--r--  2.0 unx    88981 b- defN 23-Aug-07 07:33 netron/onnx.js
+-rw-r--r--  2.0 unx     9053 b- defN 23-Aug-07 07:33 netron/onnx.py
+-rw-r--r--  2.0 unx    84585 b- defN 23-Aug-07 07:33 netron/openvino-metadata.json
+-rw-r--r--  2.0 unx    44560 b- defN 23-Aug-07 07:33 netron/openvino.js
+-rw-r--r--  2.0 unx     2894 b- defN 23-Aug-07 07:33 netron/paddle-metadata.json
+-rw-r--r--  2.0 unx    60111 b- defN 23-Aug-07 07:33 netron/paddle-proto.js
+-rw-r--r--  2.0 unx    19797 b- defN 23-Aug-07 07:33 netron/paddle-schema.js
+-rw-r--r--  2.0 unx    37551 b- defN 23-Aug-07 07:33 netron/paddle.js
+-rw-r--r--  2.0 unx     6596 b- defN 23-Aug-07 07:33 netron/pickle.js
+-rw-r--r--  2.0 unx    42713 b- defN 23-Aug-07 07:33 netron/protobuf.js
+-rw-r--r--  2.0 unx   304361 b- defN 23-Aug-07 07:33 netron/python.js
+-rwxr-xr-x  2.0 unx   411132 b- defN 23-Aug-07 07:33 netron/pytorch-metadata.json
+-rw-r--r--  2.0 unx    13170 b- defN 23-Aug-07 07:33 netron/pytorch-schema.js
+-rw-r--r--  2.0 unx   182294 b- defN 23-Aug-07 07:33 netron/pytorch.js
+-rw-r--r--  2.0 unx    24259 b- defN 23-Aug-07 07:33 netron/pytorch.py
+-rw-r--r--  2.0 unx     6136 b- defN 23-Aug-07 07:33 netron/rknn-metadata.json
+-rw-r--r--  2.0 unx     4263 b- defN 23-Aug-07 07:33 netron/rknn-schema.js
+-rw-r--r--  2.0 unx    25066 b- defN 23-Aug-07 07:33 netron/rknn.js
+-rw-r--r--  2.0 unx     4571 b- defN 23-Aug-07 07:33 netron/safetensors.js
+-rw-r--r--  2.0 unx    25814 b- defN 23-Aug-07 07:33 netron/sentencepiece-proto.js
+-rw-r--r--  2.0 unx     2182 b- defN 23-Aug-07 07:33 netron/sentencepiece.js
+-rw-r--r--  2.0 unx     5865 b- defN 23-Aug-07 07:33 netron/server.js
+-rw-r--r--  2.0 unx    11874 b- defN 23-Aug-07 07:37 netron/server.py
+-rw-r--r--  2.0 unx   160693 b- defN 23-Aug-07 07:33 netron/sklearn-metadata.json
+-rw-r--r--  2.0 unx    11185 b- defN 23-Aug-07 07:33 netron/sklearn.js
+-rw-r--r--  2.0 unx     4901 b- defN 23-Aug-07 07:33 netron/tar.js
+-rwxr-xr-x  2.0 unx    27914 b- defN 23-Aug-07 07:33 netron/tengine-metadata.json
+-rwxr-xr-x  2.0 unx    28094 b- defN 23-Aug-07 07:33 netron/tengine.js
+-rw-r--r--  2.0 unx     5278 b- defN 23-Aug-07 07:33 netron/tensorrt.js
+-rw-r--r--  2.0 unx    11077 b- defN 23-Aug-07 07:33 netron/text.js
+-rw-r--r--  2.0 unx  2221556 b- defN 23-Aug-07 07:33 netron/tf-metadata.json
+-rw-r--r--  2.0 unx   363531 b- defN 23-Aug-07 07:33 netron/tf-proto.js
+-rw-r--r--  2.0 unx   106578 b- defN 23-Aug-07 07:33 netron/tf.js
+-rw-r--r--  2.0 unx    29824 b- defN 23-Aug-07 07:33 netron/tflite-metadata.json
+-rw-r--r--  2.0 unx   110995 b- defN 23-Aug-07 07:33 netron/tflite-schema.js
+-rw-r--r--  2.0 unx    25098 b- defN 23-Aug-07 07:33 netron/tflite.js
+-rw-r--r--  2.0 unx    20380 b- defN 23-Aug-07 07:33 netron/tnn-metadata.json
+-rw-r--r--  2.0 unx    26868 b- defN 23-Aug-07 07:33 netron/tnn.js
+-rw-r--r--  2.0 unx    12510 b- defN 23-Aug-07 07:33 netron/torch-metadata.json
+-rw-r--r--  2.0 unx    41535 b- defN 23-Aug-07 07:33 netron/torch.js
+-rw-r--r--  2.0 unx     2333 b- defN 23-Aug-07 07:33 netron/uff-metadata.json
+-rw-r--r--  2.0 unx    30910 b- defN 23-Aug-07 07:33 netron/uff-proto.js
+-rw-r--r--  2.0 unx    12710 b- defN 23-Aug-07 07:33 netron/uff.js
+-rw-r--r--  2.0 unx   242983 b- defN 23-Aug-07 07:33 netron/view.js
+-rw-r--r--  2.0 unx     8023 b- defN 23-Aug-07 07:33 netron/weka.js
+-rw-r--r--  2.0 unx    64034 b- defN 23-Aug-07 07:33 netron/xml.js
+-rw-r--r--  2.0 unx    55685 b- defN 23-Aug-07 07:33 netron/xmodel-proto.js
+-rw-r--r--  2.0 unx    13916 b- defN 23-Aug-07 07:33 netron/xmodel.js
+-rw-r--r--  2.0 unx    30921 b- defN 23-Aug-07 07:33 netron/zip.js
+-rw-r--r--  2.0 unx     1447 b- defN 23-Aug-07 07:37 netron-7.1.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Aug-07 07:37 netron-7.1.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       39 b- defN 23-Aug-07 07:37 netron-7.1.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        7 b- defN 23-Aug-07 07:37 netron-7.1.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    11299 b- defN 23-Aug-07 07:37 netron-7.1.1.dist-info/RECORD
+146 files, 13054354 bytes uncompressed, 1582996 bytes compressed:  87.9%
```

## zipnote {}

```diff
@@ -327,14 +327,20 @@
 
 Filename: netron/rknn.js
 Comment: 
 
 Filename: netron/safetensors.js
 Comment: 
 
+Filename: netron/sentencepiece-proto.js
+Comment: 
+
+Filename: netron/sentencepiece.js
+Comment: 
+
 Filename: netron/server.js
 Comment: 
 
 Filename: netron/server.py
 Comment: 
 
 Filename: netron/sklearn-metadata.json
@@ -411,23 +417,23 @@
 
 Filename: netron/xmodel.js
 Comment: 
 
 Filename: netron/zip.js
 Comment: 
 
-Filename: netron-7.1.0.dist-info/METADATA
+Filename: netron-7.1.1.dist-info/METADATA
 Comment: 
 
-Filename: netron-7.1.0.dist-info/WHEEL
+Filename: netron-7.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: netron-7.1.0.dist-info/entry_points.txt
+Filename: netron-7.1.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: netron-7.1.0.dist-info/top_level.txt
+Filename: netron-7.1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: netron-7.1.0.dist-info/RECORD
+Filename: netron-7.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## netron/acuity.js

### js-beautify {}

```diff
@@ -18,322 +18,203 @@
         return new acuity.Model(metadata, target);
     }
 };
 
 acuity.Model = class {
 
     constructor(metadata, model, data, quantization) {
-        this._name = model.MetaData.Name;
-        this._format = 'Acuity ' + 'v' + model.MetaData.AcuityVersion;
-        this._runtime = model.MetaData.Platform;
-        this._graphs = [new acuity.Graph(metadata, model, data, quantization)];
-    }
-
-    get format() {
-        return this._format;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get runtime() {
-        return this._runtime;
-    }
-
-    get graphs() {
-        return this._graphs;
+        this.name = model.MetaData.Name;
+        this.format = 'Acuity ' + 'v' + model.MetaData.AcuityVersion;
+        this.runtime = model.MetaData.Platform;
+        this.graphs = [new acuity.Graph(metadata, model, data, quantization)];
     }
 };
 
 acuity.Graph = class {
 
     constructor(metadata, model) {
-        this._nodes = [];
-        this._inputs = [];
-        this._outputs = [];
-        const args = new Map();
-        const arg = (name) => {
-            if (!args.has(name)) {
-                args.set(name, {
+        this.nodes = [];
+        this.inputs = [];
+        this.outputs = [];
+        const values = new Map();
+        const value = (name) => {
+            if (!values.has(name)) {
+                values.set(name, {
                     name: name,
                     shape: null
                 });
             }
-            return args.get(name);
+            return values.get(name);
         };
-
         for (const layerName of Object.keys(model.Layers)) {
             const layer = model.Layers[layerName];
             layer.inputs = layer.inputs.map((input) => {
-                return arg(input);
+                return value(input);
             });
             layer.outputs = layer.outputs.map((port) => {
-                const value = arg("@" + layerName + ":" + port);
+                const output = value("@" + layerName + ":" + port);
                 let shape = null;
                 if (layer.op.toLowerCase() == 'input' ||
                     layer.op.toLowerCase() == 'variable') {
                     if (Object.prototype.hasOwnProperty.call(layer.parameters, 'shape') && layer.parameters.shape.length > 0) {
                         shape = layer.parameters.shape;
                     } else if (Object.prototype.hasOwnProperty.call(layer.parameters, 'size') && Object.prototype.hasOwnProperty.call(layer.parameters, 'channels')) {
                         const sizes = layer.parameters.size.split(' ');
                         shape = [0, parseInt(sizes[0]), parseInt(sizes[1]), layer.parameters.channels];
                     }
                     if (shape && shape.length === 4 && shape[0] === 0) {
                         shape[0] = 1;
                     }
                 }
-                value.shape = shape;
-                return value;
+                output.shape = shape;
+                return output;
             });
         }
-
         acuity.Inference.infer(model.Layers);
-
-        for (const pair of args) {
-            const type = new acuity.TensorType(null, new acuity.TensorShape(pair[1].shape));
-            const arg = new acuity.Value(pair[0], type, null, null);
-            args.set(pair[0], arg);
+        for (const entry of values) {
+            const type = new acuity.TensorType(null, new acuity.TensorShape(entry[1].shape));
+            const value = new acuity.Value(entry[0], type, null, null);
+            values.set(entry[0], value);
         }
-
         for (const layerName of Object.keys(model.Layers)) {
             const layer = model.Layers[layerName];
             switch (layer.op.toLowerCase()) {
                 case 'input': {
-                    this._inputs.push(new acuity.Argument(layerName, [
-                        args.get(layer.outputs[0].name)
+                    this.inputs.push(new acuity.Argument(layerName, [
+                        values.get(layer.outputs[0].name)
                     ]));
                     break;
                 }
                 case 'output': {
-                    this._outputs.push(new acuity.Argument(layerName, [
-                        args.get(layer.inputs[0].name)
+                    this.outputs.push(new acuity.Argument(layerName, [
+                        values.get(layer.inputs[0].name)
                     ]));
                     break;
                 }
                 default: {
-                    this._nodes.push(new acuity.Node(metadata, layerName, layer, args));
+                    this.nodes.push(new acuity.Node(metadata, layerName, layer, values));
                     break;
                 }
             }
         }
     }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get nodes() {
-        return this._nodes;
-    }
 };
 
 acuity.Node = class {
 
-    constructor(metadata, name, layer, args) {
-        this._name = name;
-        this._type = metadata.type(layer.op) || {
+    constructor(metadata, name, layer, values) {
+        this.name = name;
+        this.type = metadata.type(layer.op) || {
             name: layer.op
         };
-        this._inputs = [];
-        this._outputs = [];
-        this._attributes = [];
-        this._layer = layer;
-        if (this._type) {
+        this.inputs = [];
+        this.outputs = [];
+        this.attributes = [];
+        if (this.type) {
             if (layer.parameters) {
                 for (const key of Object.keys(layer.parameters)) {
-                    const attribute = new acuity.Attribute(metadata.attribute(this._type.name, key), key, layer.parameters[key]);
-                    this._attributes.push(attribute);
+                    const attribute = new acuity.Attribute(metadata.attribute(this.type.name, key), key, layer.parameters[key]);
+                    this.attributes.push(attribute);
                 }
             }
         }
         for (let i = 0; i < layer.inputs.length; i++) {
             const input = layer.inputs[i];
-            const arg = args.get(input.name);
-            const name = this._type && this._type.inputs && i < this._type.inputs.length ? this._type.inputs[i].name : 'input' + i.toString();
-            this._inputs.push(new acuity.Argument(name, [arg]));
+            const value = values.get(input.name);
+            const name = this.type && this.type.inputs && i < this.type.inputs.length ? this.type.inputs[i].name : 'input' + i.toString();
+            this.inputs.push(new acuity.Argument(name, [value]));
         }
 
-        if (this._type && this._type.constants) {
-            for (const constant of this._type.constants) {
-                // const name = "@" + this._name + ":" + constant.name;
+        if (this.type && this.type.constants) {
+            for (const constant of this.type.constants) {
+                // const name = "@" + this.name + ":" + constant.name;
                 const type = new acuity.TensorType(null, new acuity.TensorShape(null));
                 const value = new acuity.Value('', type, null, new acuity.Tensor(type));
-                this._inputs.push(new acuity.Argument(constant.name, [value]));
+                this.inputs.push(new acuity.Argument(constant.name, [value]));
             }
         }
 
         for (let i = 0; i < layer.outputs.length; i++) {
             const output = layer.outputs[i];
-            const arg = args.get(output.name);
-            const name = this._type && this._type.outputs && i < this._type.outputs.length ? this._type.outputs[i].name : 'output' + i.toString();
-            this._outputs.push(new acuity.Argument(name, [arg]));
+            const value = values.get(output.name);
+            const name = this.type && this.type.outputs && i < this.type.outputs.length ? this.type.outputs[i].name : 'output' + i.toString();
+            this.outputs.push(new acuity.Argument(name, [value]));
         }
     }
-
-    get type() {
-        return this._type;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get attributes() {
-        return this._attributes;
-    }
 };
 
 acuity.Attribute = class {
 
     constructor(metadata, name, value) {
-        this._type = null;
-        this._name = name;
-        this._value = value;
+        this.type = null;
+        this.name = name;
+        this.value = value;
         if (metadata) {
-            this._type = metadata.type || null;
+            this.type = metadata.type || null;
             if (Object.prototype.hasOwnProperty.call(metadata, 'default')) {
                 if (metadata.default === value) {
-                    this._visible = false;
+                    this.visible = false;
                 }
             }
         }
     }
-
-    get name() {
-        return this._name;
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get value() {
-        return this._value;
-    }
-
-    get visible() {
-        return this._visible == false ? false : true;
-    }
 };
 
 acuity.Argument = class {
 
     constructor(name, value) {
-        this._name = name;
-        this._value = value;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get value() {
-        return this._value;
+        this.name = name;
+        this.value = value;
     }
 };
 
 acuity.Value = class {
 
     constructor(name, type, quantization, initializer) {
         if (typeof name !== 'string') {
             throw new acuity.Error("Invalid value identifier '" + JSON.stringify(name) + "'.");
         }
-        this._name = name;
-        this._type = type || null;
-        this._quantization = quantization || null;
-        this._initializer = initializer || null;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get quantization() {
-        return this._quantization;
-    }
-
-    get initializer() {
-        return this._initializer;
+        this.name = name;
+        this.type = type || null;
+        this.quantization = quantization || null;
+        this.initializer = initializer || null;
     }
 };
 
 acuity.TensorType = class {
 
     constructor(dataType, shape) {
-        this._dataType = dataType || '?';
-        this._shape = shape;
-    }
-
-    get dataType() {
-        return this._dataType;
-    }
-
-    set dataType(dataType) {
-        this._dataType = dataType;
-    }
-
-    get shape() {
-        return this._shape;
+        this.dataType = dataType || '?';
+        this.shape = shape;
     }
 
     toString() {
-        return (this.dataType || '?') + this._shape.toString();
+        return (this.dataType || '?') + this.shape.toString();
     }
 };
 
 acuity.TensorShape = class {
 
     constructor(dimensions) {
-        this._dimensions = dimensions || null;
-    }
-
-    get dimensions() {
-        if (Array.isArray(this._dimensions) && this._dimensions.length == 1 && this._dimensions[0] == 0) {
-            return [];
-        }
-        return this._dimensions;
+        this.dimensions = Array.isArray(dimensions) && dimensions.length == 1 && dimensions[0] == 0 ? [] : dimensions;
     }
 
     toString() {
-        if (!Array.isArray(this._dimensions) || this._dimensions.length == 0 || (this._dimensions.length == 1 && this._dimensions[0] == 0)) {
+        if (!Array.isArray(this.dimensions) || this.dimensions.length == 0 || (this.dimensions.length == 1 && this.dimensions[0] == 0)) {
             return '';
         }
-        return '[' + this._dimensions.map((dimension) => dimension ? dimension.toString() : '?').join(',') + ']';
+        return '[' + this.dimensions.map((dimension) => dimension ? dimension.toString() : '?').join(',') + ']';
     }
 };
 
 acuity.Tensor = class {
 
     constructor(type) {
-        this._type = type;
-    }
-
-    get category() {
-        return 'Constant';
-    }
-
-    get type() {
-        return this._type;
+        this.type = type;
+        this.Category = 'Constant';
     }
 };
 
 acuity.Inference = class {
 
     static infer(layers) {
         const outputs = new Map();
```

## netron/armnn.js

### js-beautify {}

```diff
@@ -54,376 +54,273 @@
         return new armnn.Model(metadata, model);
     }
 };
 
 armnn.Model = class {
 
     constructor(metadata, model) {
-        this._graphs = [];
-        this._graphs.push(new armnn.Graph(metadata, model));
-    }
-
-    get format() {
-        return 'Arm NN';
-    }
-
-    get graphs() {
-        return this._graphs;
+        this.format = 'Arm NN';
+        this.graphs = [new armnn.Graph(metadata, model)];
     }
 };
 
 armnn.Graph = class {
 
     constructor(metadata, graph) {
-        this._name = '';
-        this._nodes = [];
-        this._inputs = [];
-        this._outputs = [];
+        this.name = '';
+        this.nodes = [];
+        this.inputs = [];
+        this.outputs = [];
         const counts = new Map();
         for (const layer of graph.layers) {
             const base = armnn.Node.getBase(layer);
             for (const slot of base.inputSlots) {
                 const name = slot.connection.sourceLayerIndex.toString() + ':' + slot.connection.outputSlotIndex.toString();
                 counts.set(name, counts.has(name) ? counts.get(name) + 1 : 1);
             }
         }
-        const args = new Map();
-        const arg = (layerIndex, slotIndex, tensor) => {
+        const values = new Map();
+        const value = (layerIndex, slotIndex, tensor) => {
             const name = layerIndex.toString() + ':' + slotIndex.toString();
-            if (!args.has(name)) {
+            if (!values.has(name)) {
                 const layer = graph.layers[layerIndex];
                 const base = layerIndex < graph.layers.length ? armnn.Node.getBase(layer) : null;
                 const tensorInfo = base && slotIndex < base.outputSlots.length ? base.outputSlots[slotIndex].tensorInfo : null;
-                args.set(name, new armnn.Value(name, tensorInfo, tensor));
+                values.set(name, new armnn.Value(name, tensorInfo, tensor));
             }
-            return args.get(name);
+            return values.get(name);
         };
         const layers = graph.layers.filter((layer) => {
             const base = armnn.Node.getBase(layer);
             if (base.layerType == armnn.schema.LayerType.Constant && base.outputSlots.length === 1 && layer.layer.input) {
                 const slot = base.outputSlots[0];
                 const name = base.index.toString() + ':' + slot.index.toString();
                 if (counts.get(name) === 1) {
                     const tensor = new armnn.Tensor(layer.layer.input, 'Constant');
-                    arg(base.index, slot.index, tensor);
+                    value(base.index, slot.index, tensor);
                     return false;
                 }
             }
             return true;
         });
         for (const layer of layers) {
             const base = armnn.Node.getBase(layer);
             for (const slot of base.inputSlots) {
-                arg(slot.connection.sourceLayerIndex, slot.connection.outputSlotIndex);
+                value(slot.connection.sourceLayerIndex, slot.connection.outputSlotIndex);
             }
         }
         for (const layer of layers) {
             const base = armnn.Node.getBase(layer);
             switch (base.layerType) {
                 case armnn.schema.LayerType.Input: {
                     const name = base ? base.layerName : '';
                     for (const slot of base.outputSlots) {
-                        const value = arg(base.index, slot.index);
-                        this._inputs.push(new armnn.Argument(name, [value]));
+                        const argument = new armnn.Argument(name, [value(base.index, slot.index)]);
+                        this.inputs.push(argument);
                     }
                     break;
                 }
                 case armnn.schema.LayerType.Output: {
                     const base = armnn.Node.getBase(layer);
                     const name = base ? base.layerName : '';
                     for (const slot of base.inputSlots) {
-                        const value = arg(slot.connection.sourceLayerIndex, slot.connection.outputSlotIndex);
-                        this._outputs.push(new armnn.Argument(name, [value]));
+                        const argument = new armnn.Argument(name, [value(slot.connection.sourceLayerIndex, slot.connection.outputSlotIndex)]);
+                        this.outputs.push(argument);
                     }
                     break;
                 }
                 default:
-                    this._nodes.push(new armnn.Node(metadata, layer, arg));
+                    this.nodes.push(new armnn.Node(metadata, layer, value));
                     break;
             }
         }
     }
-
-    get name() {
-        return this._name;
-    }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get nodes() {
-        return this._nodes;
-    }
 };
 
 armnn.Node = class {
 
-    constructor(metadata, layer, arg) {
+    constructor(metadata, layer, value) {
         const type = layer.layer.constructor.name;
-        this._type = Object.assign({}, metadata.type(type) || {
+        this.type = Object.assign({}, metadata.type(type) || {
             name: type
         });
-        this._type.name = this._type.name.replace(/Layer$/, '');
-        this._name = '';
-        this._outputs = [];
-        this._inputs = [];
-        this._attributes = [];
-        const inputSchemas = (this._type && this._type.inputs) ? [...this._type.inputs] : [{
+        this.type.name = this.type.name.replace(/Layer$/, '');
+        this.name = '';
+        this.outputs = [];
+        this.inputs = [];
+        this.attributes = [];
+        const inputSchemas = (this.type && this.type.inputs) ? [...this.type.inputs] : [{
             name: 'input'
         }];
-        const outputSchemas = (this._type && this._type.outputs) ? [...this._type.outputs] : [{
+        const outputSchemas = (this.type && this.type.outputs) ? [...this.type.outputs] : [{
             name: 'output'
         }];
         const base = armnn.Node.getBase(layer);
         if (base) {
-            this._name = base.layerName;
-            const inputSlots = [...base.inputSlots];
-            while (inputSlots.length > 0) {
+            this.name = base.layerName;
+            const inputs = [...base.inputSlots];
+            while (inputs.length > 0) {
                 const inputSchema = inputSchemas.length > 0 ? inputSchemas.shift() : {
                     name: '?'
                 };
-                const inputCount = inputSchema.list ? inputSlots.length : 1;
-                this._inputs.push(new armnn.Argument(inputSchema.name, inputSlots.splice(0, inputCount).map((inputSlot) => {
-                    return arg(inputSlot.connection.sourceLayerIndex, inputSlot.connection.outputSlotIndex);
-                })));
+                const count = inputSchema.list ? inputs.length : 1;
+                const argument = new armnn.Argument(inputSchema.name, inputs.splice(0, count).map((inputSlot) => {
+                    return value(inputSlot.connection.sourceLayerIndex, inputSlot.connection.outputSlotIndex);
+                }));
+                this.inputs.push(argument);
             }
-            const outputSlots = [...base.outputSlots];
-            while (outputSlots.length > 0) {
+            const outputs = [...base.outputSlots];
+            while (outputs.length > 0) {
                 const outputSchema = outputSchemas.length > 0 ? outputSchemas.shift() : {
                     name: '?'
                 };
-                const outputCount = outputSchema.list ? outputSlots.length : 1;
-                this._outputs.push(new armnn.Argument(outputSchema.name, outputSlots.splice(0, outputCount).map((outputSlot) => {
-                    return arg(base.index, outputSlot.index);
+                const count = outputSchema.list ? outputs.length : 1;
+                this.outputs.push(new armnn.Argument(outputSchema.name, outputs.splice(0, count).map((outputSlot) => {
+                    return value(base.index, outputSlot.index);
                 })));
             }
         }
-        if (layer.layer && layer.layer.descriptor && this._type.attributes) {
-            for (const pair of Object.entries(layer.layer.descriptor)) {
-                const name = pair[0];
-                const value = pair[1];
-                const attribute = new armnn.Attribute(metadata.attribute(type, name), name, value);
-                this._attributes.push(attribute);
-            }
-        }
         if (layer.layer) {
+            if (layer.layer.descriptor && this.type.attributes) {
+                for (const entry of Object.entries(layer.layer.descriptor)) {
+                    const name = entry[0];
+                    const value = entry[1];
+                    const attribute = new armnn.Attribute(metadata.attribute(type, name), name, value);
+                    this.attributes.push(attribute);
+                }
+            }
             for (const entry of Object.entries(layer.layer).filter((entry) => entry[1] instanceof armnn.schema.ConstTensor)) {
                 const name = entry[0];
                 const tensor = entry[1];
                 const value = new armnn.Value('', tensor.info, new armnn.Tensor(tensor));
-                this._inputs.push(new armnn.Argument(name, [value]));
+                this.inputs.push(new armnn.Argument(name, [value]));
             }
         }
     }
 
-    get type() {
-        return this._type;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get attributes() {
-        return this._attributes;
-    }
-
     static getBase(layer) {
         return layer.layer.base.base ? layer.layer.base.base : layer.layer.base;
     }
 
     static makeKey(layer_id, index) {
         return layer_id.toString() + "_" + index.toString();
     }
 };
 
 armnn.Attribute = class {
 
     constructor(metadata, name, value) {
-        this._name = name;
-        this._type = metadata ? metadata.type : null;
-        this._value = ArrayBuffer.isView(value) ? Array.from(value) : value;
-        if (armnn.schema[this._type]) {
-            this._value = armnn.Utility.enum(this._type, this._value);
+        this.name = name;
+        this.type = metadata ? metadata.type : null;
+        this.value = ArrayBuffer.isView(value) ? Array.from(value) : value;
+        if (armnn.schema[this.type]) {
+            this.value = armnn.Utility.enum(this.type, this.value);
         }
     }
-
-    get name() {
-        return this._name;
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get value() {
-        return this._value;
-    }
-
-    get visible() {
-        return this._visible == false ? false : true;
-    }
 };
 
 armnn.Argument = class {
 
     constructor(name, value) {
-        this._name = name;
-        this._value = value;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get value() {
-        return this._value;
+        this.name = name;
+        this.value = value;
     }
 };
 
 armnn.Value = class {
 
     constructor(name, tensorInfo, initializer) {
         if (typeof name !== 'string') {
             throw new armnn.Error("Invalid value identifier '" + JSON.stringify(name) + "'.");
         }
-        this._name = name;
-        this._type = new armnn.TensorType(tensorInfo);
-        this._initializer = initializer;
+        this.name = name;
+        this.type = new armnn.TensorType(tensorInfo);
+        this.initializer = initializer;
 
-        if (this._type.dataType.startsWith('q') && tensorInfo) {
+        if (this.type.dataType.startsWith('q') && tensorInfo) {
             this._scale = tensorInfo.quantizationScale;
             this._zeroPoint = tensorInfo.quantizationOffset;
         }
     }
 
-    get name() {
-        return this._name;
-    }
-
-    get type() {
-        return this._type;
-    }
-
     get quantization() {
         if (this._scale !== undefined && this._zeroPoint !== undefined) {
             return this._scale.toString() + ' * ' + (this._zeroPoint == 0 ? 'q' : ('(q - ' + this._zeroPoint.toString() + ')'));
         }
         return undefined;
     }
-
-    get initializer() {
-        return this._initializer;
-    }
 };
 
 armnn.Tensor = class {
 
     constructor(tensor, category) {
-        this._type = new armnn.TensorType(tensor.info);
-        this._category = category || '';
+        this.type = new armnn.TensorType(tensor.info);
+        this.category = category || '';
         const data = tensor.data.data.slice(0);
-        this._values = new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
-    }
-
-    get category() {
-        return this._category;
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get values() {
-        return this._values;
+        this.values = new Uint8Array(data.buffer, data.byteOffset, data.byteLength);
     }
 };
 
 armnn.TensorType = class {
 
     constructor(tensorInfo) {
         const dataType = tensorInfo.dataType;
         switch (dataType) {
             case 0:
-                this._dataType = 'float16';
+                this.dataType = 'float16';
                 break;
             case 1:
-                this._dataType = 'float32';
+                this.dataType = 'float32';
                 break;
             case 2:
-                this._dataType = 'quint8';
+                this.dataType = 'quint8';
                 break; // QuantisedAsymm8
             case 3:
-                this._dataType = 'int32';
+                this.dataType = 'int32';
                 break;
             case 4:
-                this._dataType = 'boolean';
+                this.dataType = 'boolean';
                 break;
             case 5:
-                this._dataType = 'qint16';
+                this.dataType = 'qint16';
                 break; // QuantisedSymm16
             case 6:
-                this._dataType = 'quint8';
+                this.dataType = 'quint8';
                 break; // QAsymmU8
             case 7:
-                this._dataType = 'qint16';
+                this.dataType = 'qint16';
                 break; // QSymmS16
             case 8:
-                this._dataType = 'qint8';
+                this.dataType = 'qint8';
                 break; // QAsymmS8
             case 9:
-                this._dataType = 'qint8';
+                this.dataType = 'qint8';
                 break; // QSymmS8
             default:
                 throw new armnn.Error("Unsupported data type '" + JSON.stringify(dataType) + "'.");
         }
-        this._shape = new armnn.TensorShape(tensorInfo.dimensions);
-    }
-
-    get dataType() {
-        return this._dataType;
-    }
-
-    get shape() {
-        return this._shape;
+        this.shape = new armnn.TensorShape(tensorInfo.dimensions);
     }
 
     toString() {
-        return this.dataType + this._shape.toString();
+        return this.dataType + this.shape.toString();
     }
 };
 
 armnn.TensorShape = class {
 
     constructor(dimensions) {
-        this._dimensions = Array.from(dimensions);
-    }
-
-    get dimensions() {
-        return this._dimensions;
+        this.dimensions = Array.from(dimensions);
     }
 
     toString() {
-        if (!this._dimensions || this._dimensions.length == 0) {
+        if (!this.dimensions || this.dimensions.length == 0) {
             return '';
         }
-        return '[' + this._dimensions.map((dimension) => dimension.toString()).join(',') + ']';
+        return '[' + this.dimensions.map((dimension) => dimension.toString()).join(',') + ']';
     }
 };
 
 armnn.Utility = class {
 
     static enum(name, value) {
         const type = name && armnn.schema ? armnn.schema[name] : undefined;
```

## netron/dlc.js

### js-beautify {}

```diff
@@ -44,14 +44,15 @@
         }
     }
 };
 
 dlc.Graph = class {
 
     constructor(metadata, version, graph) {
+        this.name = graph.name;
         this.inputs = [];
         this.outputs = [];
         const values = new Map();
         switch (version) {
             case 3: {
                 for (const node of graph.nodes) {
                     for (const name of node.inputs) {
```

## netron/index.html

```diff
@@ -1,15 +1,15 @@
 <!DOCTYPE html>
 <html lang="en">
 <head>
 <meta charset="utf-8">
 <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
 <meta http-equiv="Content-Security-Policy" content="script-src 'self' www.google-analytics.com;">
-<meta name="version" content="7.1.0">
-<meta name="date" content="2023-08-01 04:04:15">
+<meta name="version" content="7.1.1">
+<meta name="date" content="2023-08-07 07:33:23">
 <title>Netron</title>
 <link rel="stylesheet" type="text/css" href="grapher.css">
 <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
 <link rel="icon" type="image/png" href="icon.png">
 <link rel="apple-touch-icon" type="image/png" href="icon.png">
 <link rel="apple-touch-icon-precomposed" type="image/png" href="icon.png">
 <link rel="fluid-icon" type="image/png" href="icon.png">
@@ -175,15 +175,15 @@
 }
 .sidebar { display: flex; flex-direction: column; font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif; font-size: 12px; height: 100%; right: -100%; position: fixed; transition: 0.1s; top: 0; background-color: #ececec; color: #242424; overflow: hidden; border-left: 1px solid rgba(255, 255, 255, 0.5); opacity: 0; }
 .sidebar-title { font-weight: bold; font-size: 12px; letter-spacing: 0.5px; text-transform: uppercase; height: 20px; margin: 0; padding: 20px; user-select: none; -webkit-user-select: none; -moz-user-select: none; }
 .sidebar-closebutton { padding: 8px 8px 8px 32px; text-decoration: none; font-size: 25px; color: #777777; opacity: 1.0; display: block; transition: 0.2s; position: absolute; top: 0; right: 15px; margin-left: 50px; user-select: none; -webkit-user-select: none; -moz-user-select: none; }
 .sidebar-closebutton:hover { color: #242424; }
 .sidebar-content { display: flex; flex-direction: column; flex-grow: 1; height: 0; }
 .sidebar-header { font-weight: bold; font-size: 11px; text-transform: uppercase; line-height: 1.25; margin-top: 16px; margin-bottom: 16px; border-bottom: 1px solid #ececec; display: block; user-select: none; -webkit-user-select: none; -moz-user-select: none; cursor: default; }
-.sidebar-node { flex-grow: 1; padding: 0px 20px 20px 20px; overflow-y: auto; }
+.sidebar-object { flex-grow: 1; padding: 0px 20px 20px 20px; overflow-y: auto; }
 .sidebar-item { margin-bottom: 0px; display: block; }
 .sidebar-item-name { float: left; font-size: 11px; min-width: 95px; max-width: 95px; padding-right: 5px; padding-top: 7px; display: block; }
 .sidebar-item-name input { color: #777; font-family: inherit; font-size: inherit; color: inherit; background-color: inherit; width: 100%; text-align: right; margin: 0; padding: 0; border: 0; outline: none; text-overflow: ellipsis; }
 .sidebar-item-value-list { margin: 0; margin-left: 105px; overflow: hidden; display: block; padding: 0; }
 .sidebar-item-value { font-size: 11px; background-color: #fcfcfc; border-radius: 2px; border: 1px solid #fcfcfc; margin-top: 3px; margin-bottom: 3px; overflow: auto; }
 .sidebar-item-value-dark { background-color: #f8f8f8; border: 1px solid #f8f8f8; }
 .sidebar-item-value b { font-weight: bold; }
```

## netron/nnabla-metadata.json

### Pretty-printed

 * *Similarity: 0.9823008849557522%*

 * *Differences: {'insert': "[(222, OrderedDict([('name', 'Unique'), ('description', 'Find the unique elements of "*

 * *           "input array.'), ('inputs', [OrderedDict([('name', 'x'), ('type', 'nnabla.Variable'), "*

 * *           "('description', 'A N-D array.')])]), ('attributes', [OrderedDict([('name', 'flatten'), "*

 * *           "('type', 'boolean'), ('default', True), ('description', 'If True, unique values of the "*

 * *           "flatten input array are returned.')]), OrderedDict([('name', 'axis'), ('type', "*

 * *           "'int64' […]*

```diff
@@ -7787,9 +7787,168 @@
         "outputs": [
             {
                 "description": "N-D array with shape :math:`(N, C_y, C_x, H_o, W_o)`.\n\nA spatial size of the output is calculated as\n\n.. math::\n\n  H_o = \\frac{H + (top\\_pad + bottom\\_pad) - patch_v }{patch\\_step_v} + 1.\n\nA channel size of the output is calculated as\n\n.. math::\n\n  C_y = \\frac{2 \\times shift_v}{shift\\_step_v} + 1.\n\n:math:`W_o` and :math:`C_x` are the same calculation with differenct components.",
                 "name": "y",
                 "type": "nnabla.Variable"
             }
         ]
+    },
+    {
+        "attributes": [
+            {
+                "default": true,
+                "description": "If True, unique values of the flatten input array are returned.",
+                "name": "flatten",
+                "type": "boolean"
+            },
+            {
+                "default": "None",
+                "description": "If flatten is True and axis is specified, unique slices along axis are returned.",
+                "name": "axis",
+                "type": "int64"
+            },
+            {
+                "default": true,
+                "description": "If True, unique values/slices sorted in ascending order are returned.",
+                "name": "sorted",
+                "type": "boolean"
+            },
+            {
+                "default": false,
+                "description": "If True, `indices` is returned.",
+                "name": "with_index",
+                "type": "boolean"
+            },
+            {
+                "default": false,
+                "description": "If True, `inverse_indices` is returned.",
+                "name": "with_inverse",
+                "type": "boolean"
+            },
+            {
+                "default": false,
+                "description": "If True, `counts` is returned.",
+                "name": "with_counts",
+                "type": "boolean"
+            }
+        ],
+        "description": "Find the unique elements of input array.",
+        "inputs": [
+            {
+                "description": "A N-D array.",
+                "name": "x",
+                "type": "nnabla.Variable"
+            }
+        ],
+        "name": "Unique",
+        "outputs": [
+            {
+                "description": "A N-D array.",
+                "name": "y",
+                "type": "nnabla.Variable"
+            },
+            {
+                "description": "A 1-D array. It's indices of `y` elements first occurance in `x`. If `flatten` is True, it contains indices to flattend input array `x`. If `flatten` is False and `axis` is specified, it contains indices to input array `x` on `axis`.",
+                "name": "indices",
+                "type": "nnabla.Variable"
+            },
+            {
+                "description": "A 1-D array. It's indices of `x` elements corresponding to `y`. If `flatten` is True, it contains indices to output array `y`. If `flatten` is False and `axis` is specified, it contains indices to output array `y` on `axis`.",
+                "name": "inverse_indices",
+                "type": "nnabla.Variable"
+            },
+            {
+                "description": "A 1-D array. It's the count of each element of 'y' in input array `x`.",
+                "name": "counts",
+                "type": "nnabla.Variable"
+            }
+        ]
+    },
+    {
+        "attributes": [
+            {
+                "default": 0,
+                "description": "Index of the diagonal. The default value 0 means the main diagonal, a positive value means an upper diagonal, and a negative value means a lower diagonal.",
+                "name": "k",
+                "type": "int64"
+            }
+        ],
+        "description": "Generate a 2-D array with ones on the diagonal, specified by `k`, and zeros elsewhere.\nThe shape of the output array is the same as the input array.",
+        "inputs": [
+            {
+                "description": "A 2-D array.",
+                "name": "x",
+                "type": "nnabla.Variable"
+            }
+        ],
+        "name": "EyeLike",
+        "outputs": [
+            {
+                "description": "A 2-D array.",
+                "name": "y",
+                "type": "nnabla.Variable"
+            }
+        ]
+    },
+    {
+        "attributes": [
+            {
+                "default": false,
+                "description": "If True, this operator behaves like numpy.fmod, otherwise it behaves like numpy.mod.",
+                "name": "fmod",
+                "type": "boolean"
+            }
+        ],
+        "description": "Element-wise remainder function.\nThe behavior of this opeator is determined by x0's dtype and the `fmod` argument:\n\n.. math::\n    y_i = \\left\\{\n    \\begin{array}{ll}\n      \\text{numpy.fmod}(x_{0,i}, x_{1,i})\n        & (x_{0} \\text{has a floating-point type or fmod is True})\\\\\n      \\text{numpy.mod}(x_{0,i}, x_{1,i})\n        & (\\text{otherwise})\n    \\end{array} \\right..",
+        "inputs": [
+            {
+                "description": "A N-D array.",
+                "name": "x0",
+                "type": "nnabla.Variable"
+            },
+            {
+                "description": "A N-D array.",
+                "name": "x1",
+                "type": "nnabla.Variable"
+            }
+        ],
+        "name": "Mod2",
+        "outputs": [
+            {
+                "description": "A N-D array.",
+                "name": "y",
+                "type": "nnabla.Variable"
+            }
+        ]
+    },
+    {
+        "attributes": [
+            {
+                "default": "LEFT",
+                "description": "Direction of bit shift.",
+                "name": "direction",
+                "type": "string"
+            }
+        ],
+        "description": "Element-wise bit shift function.",
+        "inputs": [
+            {
+                "description": "A N-D array. Its dtype must be one of the unsigned integer types.",
+                "name": "x",
+                "type": "nnabla.Variable"
+            },
+            {
+                "description": "A N-D array. Its dtype is casted to x's dtype at run-time.",
+                "name": "shift",
+                "type": "nnabla.Variable"
+            }
+        ],
+        "name": "BitShift",
+        "outputs": [
+            {
+                "description": "A N-D array.",
+                "name": "y",
+                "type": "nnabla.Variable"
+            }
+        ]
     }
 ]
```

## netron/nnabla-proto.js

### js-beautify {}

```diff
@@ -3240,15 +3240,15 @@
     constructor() {
         this.repeat_id = [];
         this.input = [];
         this.output = [];
     }
 
     get parameter() {
-        $root.nnabla.Function.parameterSet = $root.nnabla.Function.parameterSet || new Set(["affine_param", "rnn_param", "lstm_param", "gru_param", "convolution_param", "fused_convolution_param", "depthwise_convolution_param", "deconvolution_param", "depthwise_deconvolution_param", "deformable_convolution_param", "max_pooling_param", "average_pooling_param", "sum_pooling_param", "unpooling_param", "roi_align_param", "relu_param", "leaky_relu_param", "softmax_param", "log_softmax_param", "elu_param", "selu_param", "crelu_param", "celu_param", "prelu_param", "softplus_param", "fused_batch_normalization_param", "batch_normalization_param", "group_normalization_param", "instance_normalization_param", "layer_normalization_param", "norm_normalization_param", "sync_batch_normalization_param", "tensor_normalization_param", "weight_normalization_param", "weight_standardization_param", "spectral_norm_param", "mean_subtraction_param", "clip_grad_by_norm_param", "sum_param", "cumsum_param", "mean_param", "max_param", "min_param", "norm_param", "prod_param", "cumprod_param", "add2_param", "bc_add2_param", "sub2_param", "mul2_param", "div2_param", "pow2_param", "add_scalar_param", "mul_scalar_param", "pow_scalar_param", "r_sub_scalar_param", "r_div_scalar_param", "r_pow_scalar_param", "sign_param", "minimum_scalar_param", "maximum_scalar_param", "searchsorted_param", "logical_and_scalar_param", "logical_or_scalar_param", "logical_xor_scalar_param", "equal_scalar_param", "not_equal_scalar_param", "greater_equal_scalar_param", "greater_scalar_param", "less_equal_scalar_param", "less_scalar_param", "reset_nan_param", "reset_inf_param", "constant_param", "arange_param", "linspace_param", "batch_matmul_param", "round_param", "ceil_param", "floor_param", "concatenate_param", "split_param", "stack_param", "slice_param", "pad_param", "transpose_param", "broadcast_param", "broadcast_to_param", "tile_param", "one_hot_param", "flip_param", "shift_param", "sort_param", "reshape_param", "shape_param", "meshgrid_param", "batch_cholesky_param", "gather_param", "scatter_nd_param", "scatter_add_param", "bool_fill_param", "pack_padded_sequence_param", "pad_packed_sequence_param", "interpolate_param", "onnx_resize_param", "fft_param", "ifft_param", "stft_param", "istft_param", "dropout_param", "top_k_data_param", "top_k_grad_param", "rand_param", "randint_param", "randn_param", "rand_binomial_param", "rand_beta_param", "rand_gamma_param", "random_choice_param", "random_crop_param", "random_flip_param", "random_shift_param", "random_erase_param", "image_augmentation_param", "softmax_cross_entropy_param", "categorical_cross_entropy_param", "huber_loss_param", "epsilon_insensitive_loss_param", "kl_multinomial_param", "affine_grid_param", "warp_by_grid_param", "binary_connect_affine_param", "binary_connect_convolution_param", "binary_weight_affine_param", "binary_weight_convolution_param", "inq_affine_param", "inq_convolution_param", "fixed_point_quantize_param", "min_max_quantize_param", "pow2_quantize_param", "prune_param", "quantize_linear_param", "top_n_error_param", "confusion_matrix_param", "vat_noise_param", "sink_param", "nms_detection2d_param", "onnx_non_max_suppression_param", "max_pooling_backward_param", "patch_correlation_param"]);
+        $root.nnabla.Function.parameterSet = $root.nnabla.Function.parameterSet || new Set(["affine_param", "rnn_param", "lstm_param", "gru_param", "convolution_param", "fused_convolution_param", "depthwise_convolution_param", "deconvolution_param", "depthwise_deconvolution_param", "deformable_convolution_param", "max_pooling_param", "average_pooling_param", "sum_pooling_param", "unpooling_param", "roi_align_param", "relu_param", "leaky_relu_param", "softmax_param", "log_softmax_param", "elu_param", "selu_param", "crelu_param", "celu_param", "prelu_param", "softplus_param", "fused_batch_normalization_param", "batch_normalization_param", "group_normalization_param", "instance_normalization_param", "layer_normalization_param", "norm_normalization_param", "sync_batch_normalization_param", "tensor_normalization_param", "weight_normalization_param", "weight_standardization_param", "spectral_norm_param", "mean_subtraction_param", "clip_grad_by_norm_param", "sum_param", "cumsum_param", "mean_param", "max_param", "min_param", "norm_param", "prod_param", "cumprod_param", "add2_param", "bc_add2_param", "sub2_param", "mul2_param", "div2_param", "pow2_param", "add_scalar_param", "mul_scalar_param", "pow_scalar_param", "r_sub_scalar_param", "r_div_scalar_param", "r_pow_scalar_param", "sign_param", "minimum_scalar_param", "maximum_scalar_param", "searchsorted_param", "logical_and_scalar_param", "logical_or_scalar_param", "logical_xor_scalar_param", "equal_scalar_param", "not_equal_scalar_param", "greater_equal_scalar_param", "greater_scalar_param", "less_equal_scalar_param", "less_scalar_param", "reset_nan_param", "reset_inf_param", "constant_param", "arange_param", "linspace_param", "batch_matmul_param", "round_param", "ceil_param", "floor_param", "concatenate_param", "split_param", "stack_param", "slice_param", "pad_param", "transpose_param", "broadcast_param", "broadcast_to_param", "tile_param", "one_hot_param", "flip_param", "shift_param", "sort_param", "reshape_param", "shape_param", "meshgrid_param", "batch_cholesky_param", "gather_param", "scatter_nd_param", "scatter_add_param", "bool_fill_param", "pack_padded_sequence_param", "pad_packed_sequence_param", "interpolate_param", "onnx_resize_param", "fft_param", "ifft_param", "stft_param", "istft_param", "dropout_param", "top_k_data_param", "top_k_grad_param", "rand_param", "randint_param", "randn_param", "rand_binomial_param", "rand_beta_param", "rand_gamma_param", "random_choice_param", "random_crop_param", "random_flip_param", "random_shift_param", "random_erase_param", "image_augmentation_param", "softmax_cross_entropy_param", "categorical_cross_entropy_param", "huber_loss_param", "epsilon_insensitive_loss_param", "kl_multinomial_param", "affine_grid_param", "warp_by_grid_param", "binary_connect_affine_param", "binary_connect_convolution_param", "binary_weight_affine_param", "binary_weight_convolution_param", "inq_affine_param", "inq_convolution_param", "fixed_point_quantize_param", "min_max_quantize_param", "pow2_quantize_param", "prune_param", "quantize_linear_param", "top_n_error_param", "confusion_matrix_param", "vat_noise_param", "sink_param", "nms_detection2d_param", "onnx_non_max_suppression_param", "max_pooling_backward_param", "patch_correlation_param", "unique_param", "eye_like_param", "mod2_param", "bit_shift_param"]);
         return Object.keys(this).find((key) => $root.nnabla.Function.parameterSet.has(key) && this[key] != null);
     }
 
     static decode(reader, length) {
         const message = new $root.nnabla.Function();
         const end = length !== undefined ? reader.position + length : reader.length;
         while (reader.position < end) {
@@ -3718,14 +3718,26 @@
                     break;
                 case 1221:
                     message.max_pooling_backward_param = $root.nnabla.MaxPoolingBackwardParameter.decode(reader, reader.uint32());
                     break;
                 case 1222:
                     message.patch_correlation_param = $root.nnabla.PatchCorrelationParameter.decode(reader, reader.uint32());
                     break;
+                case 1223:
+                    message.unique_param = $root.nnabla.UniqueParameter.decode(reader, reader.uint32());
+                    break;
+                case 1224:
+                    message.eye_like_param = $root.nnabla.EyeLikeParameter.decode(reader, reader.uint32());
+                    break;
+                case 1225:
+                    message.mod2_param = $root.nnabla.Mod2Parameter.decode(reader, reader.uint32());
+                    break;
+                case 1226:
+                    message.bit_shift_param = $root.nnabla.BitShiftParameter.decode(reader, reader.uint32());
+                    break;
                 case 100:
                     message.repeat_param = $root.nnabla.RepeatParameter.decode(reader, reader.uint32());
                     break;
                 case 101:
                     message.recurrent_param = $root.nnabla.RecurrentParameter.decode(reader, reader.uint32());
                     break;
                 default:
@@ -4206,14 +4218,26 @@
                     break;
                 case "max_pooling_backward_param":
                     message.max_pooling_backward_param = $root.nnabla.MaxPoolingBackwardParameter.decodeText(reader);
                     break;
                 case "patch_correlation_param":
                     message.patch_correlation_param = $root.nnabla.PatchCorrelationParameter.decodeText(reader);
                     break;
+                case "unique_param":
+                    message.unique_param = $root.nnabla.UniqueParameter.decodeText(reader);
+                    break;
+                case "eye_like_param":
+                    message.eye_like_param = $root.nnabla.EyeLikeParameter.decodeText(reader);
+                    break;
+                case "mod2_param":
+                    message.mod2_param = $root.nnabla.Mod2Parameter.decodeText(reader);
+                    break;
+                case "bit_shift_param":
+                    message.bit_shift_param = $root.nnabla.BitShiftParameter.decodeText(reader);
+                    break;
                 case "repeat_param":
                     message.repeat_param = $root.nnabla.RepeatParameter.decodeText(reader);
                     break;
                 case "recurrent_param":
                     message.recurrent_param = $root.nnabla.RecurrentParameter.decodeText(reader);
                     break;
                 default:
@@ -12395,8 +12419,207 @@
     }
 };
 
 $root.nnabla.PatchCorrelationParameter.prototype.patch = null;
 $root.nnabla.PatchCorrelationParameter.prototype.shift = null;
 $root.nnabla.PatchCorrelationParameter.prototype.patch_step = null;
 $root.nnabla.PatchCorrelationParameter.prototype.shift_step = null;
-$root.nnabla.PatchCorrelationParameter.prototype.padding = null;
+$root.nnabla.PatchCorrelationParameter.prototype.padding = null;
+
+$root.nnabla.UniqueParameter = class UniqueParameter {
+
+    constructor() {}
+
+    static decode(reader, length) {
+        const message = new $root.nnabla.UniqueParameter();
+        const end = length !== undefined ? reader.position + length : reader.length;
+        while (reader.position < end) {
+            const tag = reader.uint32();
+            switch (tag >>> 3) {
+                case 1:
+                    message.flatten = reader.bool();
+                    break;
+                case 2:
+                    message.axis = reader.int64();
+                    break;
+                case 3:
+                    message.sorted = reader.bool();
+                    break;
+                case 4:
+                    message.with_index = reader.bool();
+                    break;
+                case 5:
+                    message.with_inverse = reader.bool();
+                    break;
+                case 6:
+                    message.with_counts = reader.bool();
+                    break;
+                default:
+                    reader.skipType(tag & 7);
+                    break;
+            }
+        }
+        return message;
+    }
+
+    static decodeText(reader) {
+        const message = new $root.nnabla.UniqueParameter();
+        reader.start();
+        while (!reader.end()) {
+            const tag = reader.tag();
+            switch (tag) {
+                case "flatten":
+                    message.flatten = reader.bool();
+                    break;
+                case "axis":
+                    message.axis = reader.int64();
+                    break;
+                case "sorted":
+                    message.sorted = reader.bool();
+                    break;
+                case "with_index":
+                    message.with_index = reader.bool();
+                    break;
+                case "with_inverse":
+                    message.with_inverse = reader.bool();
+                    break;
+                case "with_counts":
+                    message.with_counts = reader.bool();
+                    break;
+                default:
+                    reader.field(tag, message);
+                    break;
+            }
+        }
+        return message;
+    }
+};
+
+$root.nnabla.UniqueParameter.prototype.flatten = false;
+$root.nnabla.UniqueParameter.prototype.axis = protobuf.Int64.create(0);
+$root.nnabla.UniqueParameter.prototype.sorted = false;
+$root.nnabla.UniqueParameter.prototype.with_index = false;
+$root.nnabla.UniqueParameter.prototype.with_inverse = false;
+$root.nnabla.UniqueParameter.prototype.with_counts = false;
+
+$root.nnabla.EyeLikeParameter = class EyeLikeParameter {
+
+    constructor() {}
+
+    static decode(reader, length) {
+        const message = new $root.nnabla.EyeLikeParameter();
+        const end = length !== undefined ? reader.position + length : reader.length;
+        while (reader.position < end) {
+            const tag = reader.uint32();
+            switch (tag >>> 3) {
+                case 1:
+                    message.k = reader.int64();
+                    break;
+                default:
+                    reader.skipType(tag & 7);
+                    break;
+            }
+        }
+        return message;
+    }
+
+    static decodeText(reader) {
+        const message = new $root.nnabla.EyeLikeParameter();
+        reader.start();
+        while (!reader.end()) {
+            const tag = reader.tag();
+            switch (tag) {
+                case "k":
+                    message.k = reader.int64();
+                    break;
+                default:
+                    reader.field(tag, message);
+                    break;
+            }
+        }
+        return message;
+    }
+};
+
+$root.nnabla.EyeLikeParameter.prototype.k = protobuf.Int64.create(0);
+
+$root.nnabla.Mod2Parameter = class Mod2Parameter {
+
+    constructor() {}
+
+    static decode(reader, length) {
+        const message = new $root.nnabla.Mod2Parameter();
+        const end = length !== undefined ? reader.position + length : reader.length;
+        while (reader.position < end) {
+            const tag = reader.uint32();
+            switch (tag >>> 3) {
+                case 1:
+                    message.fmod = reader.bool();
+                    break;
+                default:
+                    reader.skipType(tag & 7);
+                    break;
+            }
+        }
+        return message;
+    }
+
+    static decodeText(reader) {
+        const message = new $root.nnabla.Mod2Parameter();
+        reader.start();
+        while (!reader.end()) {
+            const tag = reader.tag();
+            switch (tag) {
+                case "fmod":
+                    message.fmod = reader.bool();
+                    break;
+                default:
+                    reader.field(tag, message);
+                    break;
+            }
+        }
+        return message;
+    }
+};
+
+$root.nnabla.Mod2Parameter.prototype.fmod = false;
+
+$root.nnabla.BitShiftParameter = class BitShiftParameter {
+
+    constructor() {}
+
+    static decode(reader, length) {
+        const message = new $root.nnabla.BitShiftParameter();
+        const end = length !== undefined ? reader.position + length : reader.length;
+        while (reader.position < end) {
+            const tag = reader.uint32();
+            switch (tag >>> 3) {
+                case 1:
+                    message.direction = reader.string();
+                    break;
+                default:
+                    reader.skipType(tag & 7);
+                    break;
+            }
+        }
+        return message;
+    }
+
+    static decodeText(reader) {
+        const message = new $root.nnabla.BitShiftParameter();
+        reader.start();
+        while (!reader.end()) {
+            const tag = reader.tag();
+            switch (tag) {
+                case "direction":
+                    message.direction = reader.string();
+                    break;
+                default:
+                    reader.field(tag, message);
+                    break;
+            }
+        }
+        return message;
+    }
+};
+
+$root.nnabla.BitShiftParameter.prototype.direction = "";
```

## netron/numpy.js

### js-beautify {}

```diff
@@ -214,87 +214,46 @@
         return new numpy.Model(format, graphs);
     }
 };
 
 numpy.Model = class {
 
     constructor(format, graphs) {
-        this._format = format;
-        this._graphs = graphs.map((graph) => new numpy.Graph(graph));
-    }
-
-    get format() {
-        return this._format;
-    }
-
-    get graphs() {
-        return this._graphs;
+        this.format = format;
+        this.graphs = graphs.map((graph) => new numpy.Graph(graph));
     }
 };
 
 numpy.Graph = class {
 
     constructor(graph) {
-        this._name = graph.name || '';
-        this._nodes = graph.layers.map((layer) => new numpy.Node(layer));
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get inputs() {
-        return [];
-    }
-
-    get outputs() {
-        return [];
-    }
-
-    get nodes() {
-        return this._nodes;
+        this.name = graph.name || '';
+        this.nodes = graph.layers.map((layer) => new numpy.Node(layer));
+        this.inputs = [];
+        this.outputs = [];
     }
 };
 
 numpy.Argument = class {
 
     constructor(name, value) {
-        this._name = name;
-        this._value = value;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get value() {
-        return this._value;
+        this.name = name;
+        this.value = value;
     }
 };
 
 numpy.Value = class {
 
     constructor(name, initializer) {
         if (typeof name !== 'string') {
             throw new numpy.Error("Invalid value identifier '" + JSON.stringify(name) + "'.");
         }
-        this._name = name;
-        this._initializer = initializer || null;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get type() {
-        return this._initializer.type;
-    }
-
-    get initializer() {
-        return this._initializer;
+        this.name = name;
+        this.type = initializer.type;
+        this.initializer = initializer || null;
     }
 };
 
 numpy.Node = class {
 
     constructor(layer) {
         this._name = layer.name || '';
@@ -330,71 +289,40 @@
         return [];
     }
 };
 
 numpy.Tensor = class {
 
     constructor(array) {
-        this._type = new numpy.TensorType(array.dtype.__name__, new numpy.TensorShape(array.shape));
-        this._byteorder = array.dtype.byteorder;
-        this._data = this._type.dataType == 'string' || this._type.dataType == 'object' ? array.flatten().tolist() : array.tobytes();
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get category() {
-        return 'NumPy Array';
-    }
-
-    get layout() {
-        return this._type.dataType == 'string' || this._type.dataType == 'object' ? '|' : this._byteorder;
-    }
-
-    get values() {
-        return this._data;
+        this.type = new numpy.TensorType(array.dtype.__name__, new numpy.TensorShape(array.shape));
+        this.values = this.type.dataType == 'string' || this.type.dataType == 'object' ? array.flatten().tolist() : array.tobytes();
+        this.layout = this.type.dataType == 'string' || this.type.dataType == 'object' ? '|' : array.dtype.byteorder;
     }
 };
 
 numpy.TensorType = class {
 
     constructor(dataType, shape) {
-        this._dataType = dataType;
-        this._shape = shape;
-    }
-
-    get dataType() {
-        return this._dataType || '?';
-    }
-
-    get shape() {
-        return this._shape;
+        this.dataType = dataType || '?';
+        this.shape = shape;
     }
 
     toString() {
-        return this.dataType + this._shape.toString();
+        return this.dataType + this.shape.toString();
     }
 };
 
 numpy.TensorShape = class {
 
     constructor(dimensions) {
-        this._dimensions = dimensions;
-    }
-
-    get dimensions() {
-        return this._dimensions;
+        this.dimensions = dimensions;
     }
 
     toString() {
-        if (!this._dimensions || this._dimensions.length == 0) {
-            return '';
-        }
-        return '[' + this._dimensions.join(',') + ']';
+        return this.dimensions && this.dimensions.length > 0 ? '[' + this.dimensions.join(',') + ']' : '';
     }
 };
 
 numpy.Utility = class {
 
     static isTensor(obj) {
         return obj && obj.__class__ &&
```

## netron/om.js

### js-beautify {}

```diff
@@ -297,15 +297,15 @@
         return this.dataType + this.shape.toString();
     }
 };
 
 om.TensorShape = class {
 
     constructor(dimensions) {
-        this.dimensions = dimensions.map((dim) => Number.isInteger(dim) ? dim : dim.toNumber());
+        this.dimensions = dimensions.map((dim) => !Number.isInteger(dim) && dim && dim.toNumber ? dim.toNumber() : dim);
     }
 
     equals(obj) {
         if (obj && Array.isArray(obj.dimensions) && Array.isArray(this.dimensions)) {
             if (this.dimensions.length === obj.dimensions.length) {
                 return obj.dimensions.every((value, index) => this.dimensions[index] === value);
             }
```

## netron/onnx-metadata.json

### Pretty-printed

 * *Similarity: 0.9955927144249512%*

 * *Differences: {'225': '{\'examples\': {0: {\'code\': \'"""\\ninput_shape: [1, 3, 32]\\noutput_shape: [1, 3, '*

 * *        '31]\\n"""\\np = 3\\nkernel_shape = [2]\\nstrides = [1]\\nnode = '*

 * *        'onnx.helper.make_node(\\n    "LpPool",\\n    inputs=["x"],\\n    outputs=["y"],\\n    '*

 * *        'kernel_shape=kernel_shape,\\n    strides=strides,\\n    p=p,\\n)\\nx = np.random.randn(1, '*

 * *        '3, 32).astype(np.float32)\\nx_shape = np.shape(x)\\npads = None\\nout_shape, _ = '*

 * *        'get_output_shape_explicit_padding(\\n    p […]*

```diff
@@ -1977,35 +1977,35 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements exclude pad.\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
                 "summary": "averagepool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[6, 7.5], [12, 13.5]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_ceil\")",
                 "summary": "averagepool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
                 "summary": "averagepool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[6, 7], [10, 11]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_dilations\")",
                 "summary": "averagepool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
                 "summary": "averagepool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    pad_shape,\n    \"AVG\",\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\ndilations = (1, 1)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, dilations, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    \"AVG\",\n    pads,\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
                 "summary": "averagepool_2d_pads_count_include_pad"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [7, 7.5, 8, 8.5, 9],\n                [9.5, 10, 10.5, 11, 11.5],\n                [12, 12.5, 13, 13.5, 14],\n                [14.5, 15, 15.5, 16, 16.5],\n                [17, 17.5, 18, 18.5, 19],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_precomputed_pads\"\n)",
                 "summary": "averagepool_2d_precomputed_pads"
             },
             {
@@ -2017,28 +2017,36 @@
                 "summary": "averagepool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[4, 6], [14, 16]]]]).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_precomputed_strides\",\n)",
                 "summary": "averagepool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
                 "summary": "averagepool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
                 "summary": "averagepool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET)\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
                 "summary": "averagepool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
                 "summary": "averagepool_3d_default"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[[6, 7], [10, 11]], [[6, 7], [10, 11]]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_dilations_small\"\n)",
+                "summary": "averagepool_3d_dilations"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\ncount_include_pad = 0\n\nfor count_include_pad in (0, 1):\n    for ceil_mode in (True, False):\n        node = onnx.helper.make_node(\n            \"AveragePool\",\n            inputs=[\"x\"],\n            outputs=[\"y\"],\n            kernel_shape=kernel_shape,\n            strides=strides,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n            ceil_mode=ceil_mode,\n        )\n\n        x = np.random.randn(1, 1, *x_shape).astype(np.float32)\n        out_shape, pads = get_output_shape_explicit_padding(\n            None,\n            x_shape,\n            kernel_shape,\n            strides,\n            dilations=dilations,\n            ceil_mode=ceil_mode,\n        )\n        padded = np.pad(\n            x,\n            (\n                (0, 0),\n                (0, 0),\n                (pads[0], pads[3]),\n                (pads[1], pads[4]),\n                (pads[2], pads[5]),\n            ),\n            mode=\"constant\",\n            constant_values=0 if count_include_pad == 1 else np.nan,\n        )\n        y = pool(\n            padded,\n            (1, 1, *x_shape),\n            kernel_shape,\n            strides,\n            out_shape,\n            \"AVG\",\n            pads=pads,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n        )\n\n        test_name = f\"test_averagepool_3d_dilations_large_count_include_pad_is_{count_include_pad}_ceil_mode_is_{ceil_mode}\"\n        expect(node, inputs=[x], outputs=[y], name=test_name)",
+                "summary": "averagepool_3d_dilations_large"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].",
                 "name": "X",
                 "type": "T"
@@ -2105,35 +2113,35 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
                 "summary": "averagepool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[6, 7.5], [12, 13.5]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_ceil\")",
                 "summary": "averagepool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
                 "summary": "averagepool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[6, 7], [10, 11]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_dilations\")",
                 "summary": "averagepool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
                 "summary": "averagepool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    pad_shape,\n    \"AVG\",\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\ndilations = (1, 1)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, dilations, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    \"AVG\",\n    pads,\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
                 "summary": "averagepool_2d_pads_count_include_pad"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [7, 7.5, 8, 8.5, 9],\n                [9.5, 10, 10.5, 11, 11.5],\n                [12, 12.5, 13, 13.5, 14],\n                [14.5, 15, 15.5, 16, 16.5],\n                [17, 17.5, 18, 18.5, 19],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_precomputed_pads\"\n)",
                 "summary": "averagepool_2d_precomputed_pads"
             },
             {
@@ -2145,28 +2153,36 @@
                 "summary": "averagepool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[4, 6], [14, 16]]]]).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_precomputed_strides\",\n)",
                 "summary": "averagepool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
                 "summary": "averagepool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
                 "summary": "averagepool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET)\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
                 "summary": "averagepool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
                 "summary": "averagepool_3d_default"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[[6, 7], [10, 11]], [[6, 7], [10, 11]]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_dilations_small\"\n)",
+                "summary": "averagepool_3d_dilations"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\ncount_include_pad = 0\n\nfor count_include_pad in (0, 1):\n    for ceil_mode in (True, False):\n        node = onnx.helper.make_node(\n            \"AveragePool\",\n            inputs=[\"x\"],\n            outputs=[\"y\"],\n            kernel_shape=kernel_shape,\n            strides=strides,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n            ceil_mode=ceil_mode,\n        )\n\n        x = np.random.randn(1, 1, *x_shape).astype(np.float32)\n        out_shape, pads = get_output_shape_explicit_padding(\n            None,\n            x_shape,\n            kernel_shape,\n            strides,\n            dilations=dilations,\n            ceil_mode=ceil_mode,\n        )\n        padded = np.pad(\n            x,\n            (\n                (0, 0),\n                (0, 0),\n                (pads[0], pads[3]),\n                (pads[1], pads[4]),\n                (pads[2], pads[5]),\n            ),\n            mode=\"constant\",\n            constant_values=0 if count_include_pad == 1 else np.nan,\n        )\n        y = pool(\n            padded,\n            (1, 1, *x_shape),\n            kernel_shape,\n            strides,\n            out_shape,\n            \"AVG\",\n            pads=pads,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n        )\n\n        test_name = f\"test_averagepool_3d_dilations_large_count_include_pad_is_{count_include_pad}_ceil_mode_is_{ceil_mode}\"\n        expect(node, inputs=[x], outputs=[y], name=test_name)",
+                "summary": "averagepool_3d_dilations_large"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].",
                 "name": "X",
                 "type": "T"
@@ -2239,35 +2255,35 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled\n\n ```\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
                 "summary": "averagepool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[6, 7.5], [12, 13.5]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_ceil\")",
                 "summary": "averagepool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
                 "summary": "averagepool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[6, 7], [10, 11]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_dilations\")",
                 "summary": "averagepool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
                 "summary": "averagepool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    pad_shape,\n    \"AVG\",\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\ndilations = (1, 1)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, dilations, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    \"AVG\",\n    pads,\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
                 "summary": "averagepool_2d_pads_count_include_pad"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [7, 7.5, 8, 8.5, 9],\n                [9.5, 10, 10.5, 11, 11.5],\n                [12, 12.5, 13, 13.5, 14],\n                [14.5, 15, 15.5, 16, 16.5],\n                [17, 17.5, 18, 18.5, 19],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_precomputed_pads\"\n)",
                 "summary": "averagepool_2d_precomputed_pads"
             },
             {
@@ -2279,28 +2295,36 @@
                 "summary": "averagepool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[4, 6], [14, 16]]]]).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_precomputed_strides\",\n)",
                 "summary": "averagepool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
                 "summary": "averagepool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
                 "summary": "averagepool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET)\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
                 "summary": "averagepool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
                 "summary": "averagepool_3d_default"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[[6, 7], [10, 11]], [[6, 7], [10, 11]]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_dilations_small\"\n)",
+                "summary": "averagepool_3d_dilations"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\ncount_include_pad = 0\n\nfor count_include_pad in (0, 1):\n    for ceil_mode in (True, False):\n        node = onnx.helper.make_node(\n            \"AveragePool\",\n            inputs=[\"x\"],\n            outputs=[\"y\"],\n            kernel_shape=kernel_shape,\n            strides=strides,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n            ceil_mode=ceil_mode,\n        )\n\n        x = np.random.randn(1, 1, *x_shape).astype(np.float32)\n        out_shape, pads = get_output_shape_explicit_padding(\n            None,\n            x_shape,\n            kernel_shape,\n            strides,\n            dilations=dilations,\n            ceil_mode=ceil_mode,\n        )\n        padded = np.pad(\n            x,\n            (\n                (0, 0),\n                (0, 0),\n                (pads[0], pads[3]),\n                (pads[1], pads[4]),\n                (pads[2], pads[5]),\n            ),\n            mode=\"constant\",\n            constant_values=0 if count_include_pad == 1 else np.nan,\n        )\n        y = pool(\n            padded,\n            (1, 1, *x_shape),\n            kernel_shape,\n            strides,\n            out_shape,\n            \"AVG\",\n            pads=pads,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n        )\n\n        test_name = f\"test_averagepool_3d_dilations_large_count_include_pad_is_{count_include_pad}_ceil_mode_is_{ceil_mode}\"\n        expect(node, inputs=[x], outputs=[y], name=test_name)",
+                "summary": "averagepool_3d_dilations_large"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].",
                 "name": "X",
                 "type": "T"
@@ -2373,35 +2397,35 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled\n\n ```\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following when ceil_mode is enabled:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\nor when ceil_mode is disabled:\n ```\n VALID: output_spatial_shape[i] = floor((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = floor(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
                 "summary": "averagepool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[6, 7.5], [12, 13.5]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_ceil\")",
                 "summary": "averagepool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
                 "summary": "averagepool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[6, 7], [10, 11]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_dilations\")",
                 "summary": "averagepool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
                 "summary": "averagepool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    pad_shape,\n    \"AVG\",\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\ndilations = (1, 1)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, dilations, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    \"AVG\",\n    pads,\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
                 "summary": "averagepool_2d_pads_count_include_pad"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [7, 7.5, 8, 8.5, 9],\n                [9.5, 10, 10.5, 11, 11.5],\n                [12, 12.5, 13, 13.5, 14],\n                [14.5, 15, 15.5, 16, 16.5],\n                [17, 17.5, 18, 18.5, 19],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_precomputed_pads\"\n)",
                 "summary": "averagepool_2d_precomputed_pads"
             },
             {
@@ -2413,28 +2437,36 @@
                 "summary": "averagepool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[4, 6], [14, 16]]]]).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_precomputed_strides\",\n)",
                 "summary": "averagepool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
                 "summary": "averagepool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
                 "summary": "averagepool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET)\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
                 "summary": "averagepool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
                 "summary": "averagepool_3d_default"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[[6, 7], [10, 11]], [[6, 7], [10, 11]]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_dilations_small\"\n)",
+                "summary": "averagepool_3d_dilations"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\ncount_include_pad = 0\n\nfor count_include_pad in (0, 1):\n    for ceil_mode in (True, False):\n        node = onnx.helper.make_node(\n            \"AveragePool\",\n            inputs=[\"x\"],\n            outputs=[\"y\"],\n            kernel_shape=kernel_shape,\n            strides=strides,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n            ceil_mode=ceil_mode,\n        )\n\n        x = np.random.randn(1, 1, *x_shape).astype(np.float32)\n        out_shape, pads = get_output_shape_explicit_padding(\n            None,\n            x_shape,\n            kernel_shape,\n            strides,\n            dilations=dilations,\n            ceil_mode=ceil_mode,\n        )\n        padded = np.pad(\n            x,\n            (\n                (0, 0),\n                (0, 0),\n                (pads[0], pads[3]),\n                (pads[1], pads[4]),\n                (pads[2], pads[5]),\n            ),\n            mode=\"constant\",\n            constant_values=0 if count_include_pad == 1 else np.nan,\n        )\n        y = pool(\n            padded,\n            (1, 1, *x_shape),\n            kernel_shape,\n            strides,\n            out_shape,\n            \"AVG\",\n            pads=pads,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n        )\n\n        test_name = f\"test_averagepool_3d_dilations_large_count_include_pad_is_{count_include_pad}_ceil_mode_is_{ceil_mode}\"\n        expect(node, inputs=[x], outputs=[y], name=test_name)",
+                "summary": "averagepool_3d_dilations_large"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].",
                 "name": "X",
                 "type": "T"
@@ -2510,38 +2542,38 @@
                 "description": "Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.",
                 "name": "strides",
                 "required": false,
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
-        "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following when ceil_mode is enabled:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n or when ceil_mode is disabled:\n ```\n VALID: output_spatial_shape[i] = floor((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = floor(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n ",
+        "description": "AveragePool consumes an input tensor X and applies average pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n average pooling consisting of computing the average on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape is calculated differently\n depending on whether explicit padding is used, where pads is employed, or auto padding is used, where auto_pad is utilized.\n With explicit padding (https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d):\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - dilation[i] * (kernel_shape[i] - 1) - 1) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - dilation[i] * (kernel_shape[i] - 1) - 1) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled. `pad_shape[i]` is the sum of pads along axis `i`.\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following when ceil_mode is enabled:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n or when ceil_mode is disabled (https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D):\n ```\n VALID: output_spatial_shape[i] = floor((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i]) + 1\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = floor((input_spatial_shape[i] - 1) / strides_spatial_shape[i]) + 1\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_1d_default\")",
                 "summary": "averagepool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[6, 7.5], [12, 13.5]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_ceil\")",
                 "summary": "averagepool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_default\")",
                 "summary": "averagepool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[6, 7], [10, 11]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_dilations\")",
                 "summary": "averagepool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_pads\")",
                 "summary": "averagepool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    pad_shape,\n    \"AVG\",\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    count_include_pad=1,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\ndilations = (1, 1)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = 2\npad_top = 2\npad_right = 2\npad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides, dilations, ceil_mode=False\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pads[0], pads[2]), (pads[1], pads[3])),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    x_shape,\n    kernel_shape,\n    strides,\n    out_shape,\n    \"AVG\",\n    pads,\n    count_include_pad=1,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_pads_count_include_pad\",\n)",
                 "summary": "averagepool_2d_pads_count_include_pad"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [7, 7.5, 8, 8.5, 9],\n                [9.5, 10, 10.5, 11, 11.5],\n                [12, 12.5, 13, 13.5, 14],\n                [14.5, 15, 15.5, 16, 16.5],\n                [17, 17.5, 18, 18.5, 19],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_precomputed_pads\"\n)",
                 "summary": "averagepool_2d_precomputed_pads"
             },
             {
@@ -2553,28 +2585,36 @@
                 "summary": "averagepool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[4, 6], [14, 16]]]]).astype(np.float32)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_averagepool_2d_precomputed_strides\",\n)",
                 "summary": "averagepool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_lower\")",
                 "summary": "averagepool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = (pad_top, pad_left, pad_bottom, pad_right)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_same_upper\")",
                 "summary": "averagepool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET)\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape[2:], kernel_shape, strides, ceil_mode=False\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_2d_strides\")",
                 "summary": "averagepool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"AVG\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_default\")",
                 "summary": "averagepool_3d_default"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"AveragePool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n    ceil_mode=True,\n)\n\n# input shape: [1, 1, 4, 4, 4]\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array([[[[[6, 7], [10, 11]], [[6, 7], [10, 11]]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_averagepool_3d_dilations_small\"\n)",
+                "summary": "averagepool_3d_dilations"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\ncount_include_pad = 0\n\nfor count_include_pad in (0, 1):\n    for ceil_mode in (True, False):\n        node = onnx.helper.make_node(\n            \"AveragePool\",\n            inputs=[\"x\"],\n            outputs=[\"y\"],\n            kernel_shape=kernel_shape,\n            strides=strides,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n            ceil_mode=ceil_mode,\n        )\n\n        x = np.random.randn(1, 1, *x_shape).astype(np.float32)\n        out_shape, pads = get_output_shape_explicit_padding(\n            None,\n            x_shape,\n            kernel_shape,\n            strides,\n            dilations=dilations,\n            ceil_mode=ceil_mode,\n        )\n        padded = np.pad(\n            x,\n            (\n                (0, 0),\n                (0, 0),\n                (pads[0], pads[3]),\n                (pads[1], pads[4]),\n                (pads[2], pads[5]),\n            ),\n            mode=\"constant\",\n            constant_values=0 if count_include_pad == 1 else np.nan,\n        )\n        y = pool(\n            padded,\n            (1, 1, *x_shape),\n            kernel_shape,\n            strides,\n            out_shape,\n            \"AVG\",\n            pads=pads,\n            dilations=dilations,\n            count_include_pad=count_include_pad,\n        )\n\n        test_name = f\"test_averagepool_3d_dilations_large_count_include_pad_is_{count_include_pad}_ceil_mode_is_{ceil_mode}\"\n        expect(node, inputs=[x], outputs=[y], name=test_name)",
+                "summary": "averagepool_3d_dilations_large"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].",
                 "name": "X",
                 "type": "T"
@@ -18102,43 +18142,43 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "LpPool consumes an input tensor X and applies Lp pooling across the\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n Lp pooling consisting of computing the Lp norm on all values of a subset\n of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing.",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
                 "summary": "lppool_1d_default"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
                 "summary": "lppool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    p=p,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array(\n    [\n        [\n            [\n                [14.560219778561036, 16.24807680927192],\n                [21.633307652783937, 23.49468024894146],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_dilations\")",
                 "summary": "lppool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
                 "summary": "lppool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
                 "summary": "lppool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
                 "summary": "lppool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
                 "summary": "lppool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
                 "summary": "lppool_3d_default"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.",
                 "name": "X",
@@ -18207,43 +18247,43 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "LpPool consumes an input tensor X and applies Lp pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n Lp pooling consisting of computing the Lp norm on all values of a subset\n of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing.",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
                 "summary": "lppool_1d_default"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
                 "summary": "lppool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    p=p,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array(\n    [\n        [\n            [\n                [14.560219778561036, 16.24807680927192],\n                [21.633307652783937, 23.49468024894146],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_dilations\")",
                 "summary": "lppool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
                 "summary": "lppool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
                 "summary": "lppool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
                 "summary": "lppool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
                 "summary": "lppool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
                 "summary": "lppool_3d_default"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.",
                 "name": "X",
@@ -18312,43 +18352,43 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "LpPool consumes an input tensor X and applies Lp pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n Lp pooling consisting of computing the Lp norm on all values of a subset\n of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing.",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
                 "summary": "lppool_1d_default"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
                 "summary": "lppool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    p=p,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array(\n    [\n        [\n            [\n                [14.560219778561036, 16.24807680927192],\n                [21.633307652783937, 23.49468024894146],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_dilations\")",
                 "summary": "lppool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
                 "summary": "lppool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
                 "summary": "lppool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
                 "summary": "lppool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
                 "summary": "lppool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
                 "summary": "lppool_3d_default"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.",
                 "name": "X",
@@ -18429,43 +18469,43 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "LpPool consumes an input tensor X and applies Lp pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n Lp pooling consisting of computing the Lp norm on all values of a subset\n of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - {kernelSpatialShape}) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - {kernelSpatialShape} + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + {kernelSpatialShape} - input_spatial_shape[i]\n ```",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\np = 3\nkernel_shape = [2]\nstrides = [1]\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    p=p,\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_1d_default\")",
                 "summary": "lppool_1d_default"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_default\")",
                 "summary": "lppool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n    p=p,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\ny = np.array(\n    [\n        [\n            [\n                [14.560219778561036, 16.24807680927192],\n                [21.633307652783937, 23.49468024894146],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_dilations\")",
                 "summary": "lppool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_pads\")",
                 "summary": "lppool_2d_pads"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\np = 4\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_lower\")",
                 "summary": "lppool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=0,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", pads, p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_same_upper\")",
                 "summary": "lppool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\np = 2\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    strides=[3, 3],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_2d_strides\")",
                 "summary": "lppool_2d_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(\n    padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"LPPOOL\", p=p\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\np = 3\nnode = onnx.helper.make_node(\n    \"LpPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    p=p,\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"LPPOOL\", p=p)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_lppool_3d_default\")",
                 "summary": "lppool_3d_default"
             }
         ],
         "inputs": [
             {
                 "description": "Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.",
                 "name": "X",
@@ -19016,31 +19056,31 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad.\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
                 "summary": "maxpool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_ceil\")",
                 "summary": "maxpool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
                 "summary": "maxpool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_dilations\")",
                 "summary": "maxpool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\n\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
                 "summary": "maxpool_2d_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_pads\")",
                 "summary": "maxpool_2d_precomputed_pads"
             },
             {
@@ -19048,34 +19088,46 @@
                 "summary": "maxpool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[2, 2], strides=[2, 2]\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_strides\"\n)",
                 "summary": "maxpool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
                 "summary": "maxpool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
                 "summary": "maxpool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
                 "summary": "maxpool_2d_strides"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_uint8\")",
                 "summary": "maxpool_2d_uint8"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
                 "summary": "maxpool_3d_default"
             },
             {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[[11, 12], [15, 16]], [[11, 12], [15, 16]]]]]).astype(\n    np.float32\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations\")",
+                "summary": "maxpool_3d_dilations"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\ndilations = [2, 2, 2]\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nceil_mode = False\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=dilations,\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nx_shape = x.shape[2:]\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = x\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations_use_ref_impl\"\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\nceil_mode = True\n\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    dilations=dilations,\n    ceil_mode=ceil_mode,\n)\n\nx = np.random.randn(1, 1, *x_shape).astype(np.float32)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = np.pad(\n    x,\n    (\n        (0, 0),\n        (0, 0),\n        (pads[0], pads[3]),\n        (pads[1], pads[4]),\n        (pads[2], pads[5]),\n    ),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_maxpool_3d_dilations_use_ref_impl_large\",\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl_large"
+            },
+            {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\nz = np.array(\n    [\n        [\n            [\n                [12, 13, 14, 14, 14],\n                [17, 18, 19, 19, 19],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n            ]\n        ]\n    ]\n).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_pads\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n    storage_order=1,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\nz = np.array([[[[6, 16], [8, 18]]]]).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_strides\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_strides"
             }
@@ -19148,31 +19200,31 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - kernel_spatial_shape[i]) / strides_spatial_shape[i] + 1)\n\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - kernel_spatial_shape[i] + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + kernel_spatial_shape[i] - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad.\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
                 "summary": "maxpool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_ceil\")",
                 "summary": "maxpool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
                 "summary": "maxpool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_dilations\")",
                 "summary": "maxpool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\n\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
                 "summary": "maxpool_2d_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_pads\")",
                 "summary": "maxpool_2d_precomputed_pads"
             },
             {
@@ -19180,34 +19232,46 @@
                 "summary": "maxpool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[2, 2], strides=[2, 2]\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_strides\"\n)",
                 "summary": "maxpool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
                 "summary": "maxpool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
                 "summary": "maxpool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
                 "summary": "maxpool_2d_strides"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_uint8\")",
                 "summary": "maxpool_2d_uint8"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
                 "summary": "maxpool_3d_default"
             },
             {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[[11, 12], [15, 16]], [[11, 12], [15, 16]]]]]).astype(\n    np.float32\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations\")",
+                "summary": "maxpool_3d_dilations"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\ndilations = [2, 2, 2]\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nceil_mode = False\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=dilations,\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nx_shape = x.shape[2:]\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = x\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations_use_ref_impl\"\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\nceil_mode = True\n\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    dilations=dilations,\n    ceil_mode=ceil_mode,\n)\n\nx = np.random.randn(1, 1, *x_shape).astype(np.float32)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = np.pad(\n    x,\n    (\n        (0, 0),\n        (0, 0),\n        (pads[0], pads[3]),\n        (pads[1], pads[4]),\n        (pads[2], pads[5]),\n    ),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_maxpool_3d_dilations_use_ref_impl_large\",\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl_large"
+            },
+            {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\nz = np.array(\n    [\n        [\n            [\n                [12, 13, 14, 14, 14],\n                [17, 18, 19, 19, 19],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n            ]\n        ]\n    ]\n).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_pads\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n    storage_order=1,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\nz = np.array([[[[6, 16], [8, 18]]]]).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_strides\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_strides"
             }
@@ -19306,31 +19370,31 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled\n\n ```\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad.\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
                 "summary": "maxpool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_ceil\")",
                 "summary": "maxpool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
                 "summary": "maxpool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_dilations\")",
                 "summary": "maxpool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\n\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
                 "summary": "maxpool_2d_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_pads\")",
                 "summary": "maxpool_2d_precomputed_pads"
             },
             {
@@ -19338,34 +19402,46 @@
                 "summary": "maxpool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[2, 2], strides=[2, 2]\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_strides\"\n)",
                 "summary": "maxpool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
                 "summary": "maxpool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
                 "summary": "maxpool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
                 "summary": "maxpool_2d_strides"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_uint8\")",
                 "summary": "maxpool_2d_uint8"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
                 "summary": "maxpool_3d_default"
             },
             {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[[11, 12], [15, 16]], [[11, 12], [15, 16]]]]]).astype(\n    np.float32\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations\")",
+                "summary": "maxpool_3d_dilations"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\ndilations = [2, 2, 2]\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nceil_mode = False\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=dilations,\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nx_shape = x.shape[2:]\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = x\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations_use_ref_impl\"\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\nceil_mode = True\n\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    dilations=dilations,\n    ceil_mode=ceil_mode,\n)\n\nx = np.random.randn(1, 1, *x_shape).astype(np.float32)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = np.pad(\n    x,\n    (\n        (0, 0),\n        (0, 0),\n        (pads[0], pads[3]),\n        (pads[1], pads[4]),\n        (pads[2], pads[5]),\n    ),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_maxpool_3d_dilations_use_ref_impl_large\",\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl_large"
+            },
+            {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\nz = np.array(\n    [\n        [\n            [\n                [12, 13, 14, 14, 14],\n                [17, 18, 19, 19, 19],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n            ]\n        ]\n    ]\n).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_pads\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n    storage_order=1,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\nz = np.array([[[[6, 16], [8, 18]]]]).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_strides\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_strides"
             }
@@ -19464,31 +19540,31 @@
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
         "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled\n\n ```\n * pad_shape[i] is sum of pads along axis i\n ```\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad.\n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
                 "summary": "maxpool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_ceil\")",
                 "summary": "maxpool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
                 "summary": "maxpool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_dilations\")",
                 "summary": "maxpool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\n\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
                 "summary": "maxpool_2d_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_pads\")",
                 "summary": "maxpool_2d_precomputed_pads"
             },
             {
@@ -19496,34 +19572,46 @@
                 "summary": "maxpool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[2, 2], strides=[2, 2]\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_strides\"\n)",
                 "summary": "maxpool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
                 "summary": "maxpool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
                 "summary": "maxpool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
                 "summary": "maxpool_2d_strides"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_uint8\")",
                 "summary": "maxpool_2d_uint8"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
                 "summary": "maxpool_3d_default"
             },
             {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[[11, 12], [15, 16]], [[11, 12], [15, 16]]]]]).astype(\n    np.float32\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations\")",
+                "summary": "maxpool_3d_dilations"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\ndilations = [2, 2, 2]\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nceil_mode = False\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=dilations,\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nx_shape = x.shape[2:]\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = x\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations_use_ref_impl\"\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\nceil_mode = True\n\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    dilations=dilations,\n    ceil_mode=ceil_mode,\n)\n\nx = np.random.randn(1, 1, *x_shape).astype(np.float32)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = np.pad(\n    x,\n    (\n        (0, 0),\n        (0, 0),\n        (pads[0], pads[3]),\n        (pads[1], pads[4]),\n        (pads[2], pads[5]),\n    ),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_maxpool_3d_dilations_use_ref_impl_large\",\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl_large"
+            },
+            {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\nz = np.array(\n    [\n        [\n            [\n                [12, 13, 14, 14, 14],\n                [17, 18, 19, 19, 19],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n            ]\n        ]\n    ]\n).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_pads\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n    storage_order=1,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\nz = np.array([[[[6, 16], [8, 18]]]]).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_strides\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_strides"
             }
@@ -19619,34 +19707,34 @@
                 "description": "Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.",
                 "name": "strides",
                 "required": false,
                 "type": "int64[]"
             }
         ],
         "category": "Pool",
-        "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape will be following:\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled `pad_shape[i]` is the sum of pads along axis `i`.\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following when ceil_mode is enabled:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n or when ceil_mode is disabled:\n ```\n VALID: output_spatial_shape[i] = floor((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = floor(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad. \n ",
+        "description": "MaxPool consumes an input tensor X and applies max pooling across\n the tensor according to kernel sizes, stride sizes, and pad lengths.\n max pooling consisting of computing the max on all values of a\n subset of the input tensor according to the kernel size and downsampling the\n data into the output tensor Y for further processing. The output spatial shape is calculated differently\n depending on whether explicit padding is used, where pads is employed, or auto padding is used, where auto_pad is utilized.\n With explicit padding (https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html?highlight=maxpool#torch.nn.MaxPool2d):\n ```\n output_spatial_shape[i] = floor((input_spatial_shape[i] + pad_shape[i] - dilation[i] * (kernel_shape[i] - 1) - 1) / strides_spatial_shape[i] + 1)\n ```\n or\n ```\n output_spatial_shape[i] = ceil((input_spatial_shape[i] + pad_shape[i] - dilation[i] * (kernel_shape[i] - 1) - 1) / strides_spatial_shape[i] + 1)\n ```\n if ceil_mode is enabled. `pad_shape[i]` is the sum of pads along axis `i`.\n\n `auto_pad` is a DEPRECATED attribute. If you are using them currently, the output spatial shape will be following when ceil_mode is enabled:\n ```\n VALID: output_spatial_shape[i] = ceil((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) + 1) / strides_spatial_shape[i])\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides_spatial_shape[i])\n ```\n or when ceil_mode is disabled (https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D):\n ```\n VALID: output_spatial_shape[i] = floor((input_spatial_shape[i] - ((kernel_spatial_shape[i] - 1) * dilations[i] + 1)) / strides_spatial_shape[i]) + 1\n SAME_UPPER or SAME_LOWER: output_spatial_shape[i] = floor((input_spatial_shape[i] - 1) / strides_spatial_shape[i]) + 1\n ```\n And pad shape will be following if `SAME_UPPER` or `SAME_LOWER`:\n ```\n pad_shape[i] = (output_spatial_shape[i] - 1) * strides_spatial_shape[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]\n ```\n The output of each pooling window is maximum number of elements exclude pad. \n ",
         "examples": [
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2]\nstrides = [1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32]\noutput_shape: [1, 3, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2],\n)\nx = np.random.randn(1, 3, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2]\nstrides = [1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_1d_default\")",
                 "summary": "maxpool_1d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    strides=[2, 2],\n    ceil_mode=True,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_ceil\")",
                 "summary": "maxpool_2d_ceil"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_default\")",
                 "summary": "maxpool_2d_default"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 4, 4]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    strides=[1, 1],\n    dilations=[2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12],\n                [13, 14, 15, 16],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[11, 12], [15, 16]]]]).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_dilations\")",
                 "summary": "maxpool_2d_dilations"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npad_shape = [pad_top + pad_bottom, pad_left + pad_right]\nout_shape = get_output_shape(\n    \"NOTSET\", np.add(x_shape[2:], pad_shape), kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 28, 28]\noutput_shape: [1, 3, 30, 30]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[3, 3],\n    pads=[2, 2, 2, 2],\n)\nx = np.random.randn(1, 3, 28, 28).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (3, 3)\nstrides = (1, 1)\npad_bottom = pad_top = pad_right = pad_left = 2\npads = [pad_top, pad_left, pad_bottom, pad_right]\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\n\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_pads\")",
                 "summary": "maxpool_2d_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_pads\")",
                 "summary": "maxpool_2d_precomputed_pads"
             },
             {
@@ -19654,34 +19742,46 @@
                 "summary": "maxpool_2d_precomputed_same_upper"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[2, 2], strides=[2, 2]\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_precomputed_strides\"\n)",
                 "summary": "maxpool_2d_precomputed_strides"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_LOWER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [1, 0, 1, 0] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_LOWER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_LOWER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_bottom = pad_shape[0] // 2\npad_top = pad_shape[0] - pad_bottom\npad_right = pad_shape[1] // 2\npad_left = pad_shape[1] - pad_right\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_lower\")",
                 "summary": "maxpool_2d_same_lower"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape(\"SAME_UPPER\", x_shape[2:], kernel_shape, strides)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, pad_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 32, 32]\npad_shape: [1, 1] -> [0, 1, 0, 1] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2],\n    auto_pad=\"SAME_UPPER\",\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (2, 2)\nstrides = (1, 1)\nout_shape = get_output_shape_auto_pad(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides\n)\npad_shape = get_pad_shape(\n    \"SAME_UPPER\", x_shape[2:], kernel_shape, strides, out_shape\n)\npad_top = pad_shape[0] // 2\npad_bottom = pad_shape[0] - pad_top\npad_left = pad_shape[1] // 2\npad_right = pad_shape[1] - pad_left\npadded = np.pad(\n    x,\n    ((0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)),\n    mode=\"constant\",\n    constant_values=np.nan,\n)\npads = [pad_top, pad_left, pad_bottom, pad_right]\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\", pads)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_same_upper\")",
                 "summary": "maxpool_2d_same_upper"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, (0, 0), \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32]\noutput_shape: [1, 3, 10, 10]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\", inputs=[\"x\"], outputs=[\"y\"], kernel_shape=[5, 5], strides=[3, 3]\n)\nx = np.random.randn(1, 3, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = (5, 5)\nstrides = (3, 3)\nout_shape, pads = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_strides\")",
                 "summary": "maxpool_2d_strides"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.uint8)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_2d_uint8\")",
                 "summary": "maxpool_2d_uint8"
             },
             {
-                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape = get_output_shape(\"NOTSET\", x_shape[2:], kernel_shape, strides)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, [0, 0, 0], \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
+                "code": "\"\"\"\ninput_shape: [1, 3, 32, 32, 32]\noutput_shape: [1, 3, 31, 31, 31]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n)\nx = np.random.randn(1, 3, 32, 32, 32).astype(np.float32)\nx_shape = np.shape(x)\npads = None\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nout_shape, _ = get_output_shape_explicit_padding(\n    pads, x_shape[2:], kernel_shape, strides\n)\npadded = x\ny = pool(padded, x_shape, kernel_shape, strides, out_shape, \"MAX\")\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_default\")",
                 "summary": "maxpool_3d_default"
             },
             {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=[2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[[11, 12], [15, 16]], [[11, 12], [15, 16]]]]]).astype(\n    np.float32\n)\n\nexpect(node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations\")",
+                "summary": "maxpool_3d_dilations"
+            },
+            {
+                "code": "\"\"\"\ninput_shape: [1, 1, 4, 4, 4]\noutput_shape: [1, 1, 2, 2, 2]\n\"\"\"\ndilations = [2, 2, 2]\nkernel_shape = [2, 2, 2]\nstrides = [1, 1, 1]\nceil_mode = False\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=[2, 2, 2],\n    strides=[1, 1, 1],\n    dilations=dilations,\n)\nx = np.array(\n    [\n        [\n            [\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n                [\n                    [1, 2, 3, 4],\n                    [5, 6, 7, 8],\n                    [9, 10, 11, 12],\n                    [13, 14, 15, 16],\n                ],\n            ]\n        ]\n    ]\n).astype(np.float32)\n\nx_shape = x.shape[2:]\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = x\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node, inputs=[x], outputs=[y], name=\"test_maxpool_3d_dilations_use_ref_impl\"\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl"
+            },
+            {
+                "code": "x_shape = (32, 32, 32)\ndilations = (2, 2, 2)\nkernel_shape = (5, 5, 5)\nstrides = (3, 3, 3)\nceil_mode = True\n\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\"],\n    kernel_shape=kernel_shape,\n    strides=strides,\n    dilations=dilations,\n    ceil_mode=ceil_mode,\n)\n\nx = np.random.randn(1, 1, *x_shape).astype(np.float32)\nout_shape, pads = get_output_shape_explicit_padding(\n    None, x_shape, kernel_shape, strides, dilations, ceil_mode=ceil_mode\n)\npadded = np.pad(\n    x,\n    (\n        (0, 0),\n        (0, 0),\n        (pads[0], pads[3]),\n        (pads[1], pads[4]),\n        (pads[2], pads[5]),\n    ),\n    mode=\"constant\",\n    constant_values=0,\n)\ny = pool(\n    padded,\n    (1, 1, *x_shape),\n    kernel_shape,\n    strides,\n    out_shape,\n    \"MAX\",\n    pads,\n    dilations=dilations,\n)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y],\n    name=\"test_maxpool_3d_dilations_use_ref_impl_large\",\n)",
+                "summary": "maxpool_3d_dilations_use_ref_impl_large"
+            },
+            {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 5, 5]\npad_shape: [4, 4] -> [2, 2, 2, 2] by axis\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[5, 5],\n    pads=[2, 2, 2, 2],\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array(\n    [\n        [\n            [\n                [13, 14, 15, 15, 15],\n                [18, 19, 20, 20, 20],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n                [23, 24, 25, 25, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\nz = np.array(\n    [\n        [\n            [\n                [12, 13, 14, 14, 14],\n                [17, 18, 19, 19, 19],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n                [22, 23, 24, 24, 24],\n            ]\n        ]\n    ]\n).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_pads\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_pads"
             },
             {
                 "code": "\"\"\"\ninput_shape: [1, 1, 5, 5]\noutput_shape: [1, 1, 2, 2]\n\"\"\"\nnode = onnx.helper.make_node(\n    \"MaxPool\",\n    inputs=[\"x\"],\n    outputs=[\"y\", \"z\"],\n    kernel_shape=[2, 2],\n    strides=[2, 2],\n    storage_order=1,\n)\nx = np.array(\n    [\n        [\n            [\n                [1, 2, 3, 4, 5],\n                [6, 7, 8, 9, 10],\n                [11, 12, 13, 14, 15],\n                [16, 17, 18, 19, 20],\n                [21, 22, 23, 24, 25],\n            ]\n        ]\n    ]\n).astype(np.float32)\ny = np.array([[[[7, 9], [17, 19]]]]).astype(np.float32)\nz = np.array([[[[6, 16], [8, 18]]]]).astype(np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[y, z],\n    name=\"test_maxpool_with_argmax_2d_precomputed_strides\",\n)",
                 "summary": "maxpool_with_argmax_2d_precomputed_strides"
             }
@@ -28790,14 +28890,77 @@
             }
         ],
         "version": 18
     },
     {
         "attributes": [
             {
+                "description": "Regex pattern to match on. This must be valid RE2 syntax.",
+                "name": "pattern",
+                "required": false,
+                "type": "string"
+            }
+        ],
+        "description": "RegexFullMatch performs a full regex match on each element of the input tensor. If an element fully matches the regex pattern specified as an attribute, the corresponding element in the output is True and it is False otherwise. [RE2](https://github.com/google/re2/wiki/Syntax) regex syntax is used.",
+        "examples": [
+            {
+                "code": "node = onnx.helper.make_node(\n    \"RegexFullMatch\",\n    inputs=[\"X\"],\n    outputs=[\"Y\"],\n    pattern=r\"www\\.[\\w.-]+\\.\\bcom\\b\",\n)\n\nx = np.array([\"www.google.com\", \"www.facebook.com\", \"www.bbc.co.uk\"]).astype(\n    object\n)\nresult = np.array([True, True, False])\nexpect(node, inputs=[x], outputs=[result], name=\"test_regex_full_match_basic\")",
+                "summary": "basic"
+            },
+            {
+                "code": "node = onnx.helper.make_node(\n    \"RegexFullMatch\",\n    inputs=[\"X\"],\n    outputs=[\"Y\"],\n    pattern=r\"(\\W|^)[\\w.\\-]{0,25}@(yahoo|gmail)\\.com(\\W|$)\",\n)\n\nx = np.array(\n    [\n        [\"account@gmail.com\", \"account@hotmail.com\"],\n        [\"not email\", \"account2@yahoo.com\"],\n    ]\n).astype(object)\nresult = np.array([[True, False], [False, True]])\nexpect(\n    node,\n    inputs=[x],\n    outputs=[result],\n    name=\"test_regex_full_match_email_domain\",\n)",
+                "summary": "match_email_domain"
+            },
+            {
+                "code": "node = onnx.helper.make_node(\n    \"RegexFullMatch\",\n    inputs=[\"X\"],\n    outputs=[\"Y\"],\n    pattern=r\"(\\W|^)[\\w.\\-]{0,25}@(yahoo|gmail)\\.com(\\W|$)\",\n)\n\nx = np.array([[], []]).astype(object)\nresult = np.array([[], []]).astype(bool)\nexpect(\n    node,\n    inputs=[x],\n    outputs=[result],\n    name=\"test_regex_full_match_empty\",\n)",
+                "summary": "match_empty"
+            }
+        ],
+        "inputs": [
+            {
+                "description": "Tensor with strings to match on.",
+                "name": "X",
+                "type": "T1"
+            }
+        ],
+        "max_input": 1,
+        "max_output": 1,
+        "min_input": 1,
+        "min_output": 1,
+        "module": "ai.onnx",
+        "name": "RegexFullMatch",
+        "outputs": [
+            {
+                "description": "Tensor of bools indicating if each input string fully matches the regex pattern specified.",
+                "name": "Y",
+                "type": "T2"
+            }
+        ],
+        "support_level": "common",
+        "type_constraints": [
+            {
+                "allowed_type_strs": [
+                    "tensor(string)"
+                ],
+                "description": "Inputs must be UTF-8 strings",
+                "type_param_str": "T1"
+            },
+            {
+                "allowed_type_strs": [
+                    "tensor(bool)"
+                ],
+                "description": "Outputs are bools and are True where there is a full regex match and False otherwise.",
+                "type_param_str": "T2"
+            }
+        ],
+        "version": 20
+    },
+    {
+        "attributes": [
+            {
                 "description": "legacy optimization attribute.",
                 "name": "consumed_inputs",
                 "required": false,
                 "type": "int64[]"
             }
         ],
         "category": "Activation",
@@ -36690,14 +36853,103 @@
         ],
         "support_level": "common",
         "version": 10
     },
     {
         "attributes": [
             {
+                "description": "Delimiter to split on. If left unset or set to the empty string (\"\"), the input is split on consecutive whitespace.",
+                "name": "delimiter",
+                "required": false,
+                "type": "string"
+            },
+            {
+                "description": "Maximum number of splits (from left to right). If left unset (or if the number of possible splits are less than maxsplit), it will make as many splits as possible. Note that the maximum possible number of substrings returned with `maxsplit` specified is `maxsplit+1` since the remaining suffix after the `maxsplit`th split is included in the output.",
+                "name": "maxsplit",
+                "required": false,
+                "type": "int64"
+            }
+        ],
+        "description": "StringSplit splits a string tensor's elements into substrings based on a delimiter attribute and a maxsplit attribute.\n\nThe first output of this operator is a tensor of strings representing the substrings from splitting each input string on the `delimiter` substring. This tensor has one additional rank compared to the input tensor in order to store the substrings for each input element (where the input tensor is not empty). Note that, in order to ensure the same number of elements are present in the final dimension, this tensor will pad empty strings as illustrated in the examples below. Consecutive delimiters are not grouped together and are deemed to delimit empty strings, except if the `delimiter` is unspecified or is the empty string (\"\"). In the case where the `delimiter` is unspecified or the empty string, consecutive whitespace characters are regarded as a single separator and leading or trailing whitespace is removed in the output.\n\nThe second output tensor represents the number of substrings generated. `maxsplit` can be used to limit the number of splits performed - after the `maxsplit`th split if the string is not fully split, the trailing suffix of input string after the final split point is also added. For elements where fewer splits are possible than specified in `maxsplit`, it has no effect.",
+        "examples": [
+            {
+                "code": "node = onnx.helper.make_node(\n    \"StringSplit\",\n    inputs=[\"x\"],\n    outputs=[\"substrings\", \"length\"],\n    delimiter=\".\",\n    maxsplit=None,\n)\n\nx = np.array([\"abc.com\", \"def.net\"]).astype(object)\n\nsubstrings = np.array([[\"abc\", \"com\"], [\"def\", \"net\"]]).astype(object)\n\nlength = np.array([2, 2], dtype=np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[substrings, length],\n    name=\"test_string_split_basic\",\n)",
+                "summary": "basic"
+            },
+            {
+                "code": "node = onnx.helper.make_node(\n    \"StringSplit\",\n    inputs=[\"x\"],\n    outputs=[\"substrings\", \"length\"],\n    delimiter=\"-\",\n    maxsplit=None,\n)\n\nx = np.array([\"o-n-n--x-\", \"o-n----nx\"]).astype(object)\n\nsubstrings = np.array(\n    [[\"o\", \"n\", \"n\", \"\", \"x\", \"\"], [\"o\", \"n\", \"\", \"\", \"\", \"nx\"]]\n).astype(object)\n\nlength = np.array([6, 6], dtype=np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[substrings, length],\n    name=\"test_string_split_consecutive_delimiters\",\n)",
+                "summary": "consecutive_delimiters"
+            },
+            {
+                "code": "for delimiter, test_name in (\n    (\"\", \"test_string_split_empty_string_delimiter\"),\n    (None, \"test_string_split_no_delimiter\"),\n):\n    node = onnx.helper.make_node(\n        \"StringSplit\",\n        inputs=[\"x\"],\n        outputs=[\"substrings\", \"length\"],\n        delimiter=delimiter,\n        maxsplit=None,\n    )\n\n    x = np.array(\n        [\"hello world !\", \"  hello   world !\", \" hello world   ! \"]\n    ).astype(object)\n\n    substrings = np.array(\n        [\n            [\"hello\", \"world\", \"!\"],\n            [\"hello\", \"world\", \"!\"],\n            [\"hello\", \"world\", \"!\"],\n        ]\n    ).astype(object)\n\n    length = np.array([3, 3, 3], dtype=np.int64)\n\n    expect(\n        node,\n        inputs=[x],\n        outputs=[substrings, length],\n        name=test_name,\n    )",
+                "summary": "empty_string_delimiter"
+            },
+            {
+                "code": "node = onnx.helper.make_node(\n    \"StringSplit\",\n    inputs=[\"x\"],\n    outputs=[\"substrings\", \"length\"],\n    delimiter=None,\n    maxsplit=None,\n)\n\nx = np.array([]).astype(object)\n\nsubstrings = np.array([]).astype(object).reshape(0, 0)\n\nlength = np.array([], dtype=np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[substrings, length],\n    name=\"test_string_split_empty_tensor\",\n    output_type_protos=[\n        onnx.helper.make_tensor_type_proto(onnx.TensorProto.STRING, (0, None)),\n        None,\n    ],\n)",
+                "summary": "empty_string_split"
+            },
+            {
+                "code": "node = onnx.helper.make_node(\n    \"StringSplit\",\n    inputs=[\"x\"],\n    outputs=[\"substrings\", \"length\"],\n    maxsplit=2,\n)\n\nx = np.array(\n    [[\"hello world\", \"def.net\"], [\"o n n x\", \"the quick brown fox\"]]\n).astype(object)\n\nsubstrings = np.array(\n    [\n        [[\"hello\", \"world\", \"\"], [\"def.net\", \"\", \"\"]],\n        [[\"o\", \"n\", \"n x\"], [\"the\", \"quick\", \"brown fox\"]],\n    ]\n).astype(object)\n\nlength = np.array([[2, 1], [3, 3]], np.int64)\n\nexpect(\n    node,\n    inputs=[x],\n    outputs=[substrings, length],\n    name=\"test_string_split_maxsplit\",\n)",
+                "summary": "maxsplit"
+            }
+        ],
+        "inputs": [
+            {
+                "description": "Tensor of strings to split.",
+                "name": "X",
+                "type": "T1"
+            }
+        ],
+        "max_input": 1,
+        "max_output": 2,
+        "min_input": 1,
+        "min_output": 2,
+        "module": "ai.onnx",
+        "name": "StringSplit",
+        "outputs": [
+            {
+                "description": "Tensor of substrings representing the outcome of splitting the strings in the input on the delimiter. Note that to ensure the same number of elements are present in the final rank, this tensor will pad any necessary empty strings.",
+                "name": "Y",
+                "type": "T2"
+            },
+            {
+                "description": "The number of substrings generated for each input element.",
+                "name": "Z",
+                "type": "T3"
+            }
+        ],
+        "support_level": "common",
+        "type_constraints": [
+            {
+                "allowed_type_strs": [
+                    "tensor(string)"
+                ],
+                "description": "The input must be a UTF-8 string tensor",
+                "type_param_str": "T1"
+            },
+            {
+                "allowed_type_strs": [
+                    "tensor(string)"
+                ],
+                "description": "Tensor of substrings.",
+                "type_param_str": "T2"
+            },
+            {
+                "allowed_type_strs": [
+                    "tensor(int64)"
+                ],
+                "description": "The number of substrings generated.",
+                "type_param_str": "T3"
+            }
+        ],
+        "version": 20
+    },
+    {
+        "attributes": [
+            {
                 "description": "If set, defines the broadcast dimensions. See doc for details.",
                 "name": "axis",
                 "required": false,
                 "type": "int64"
             },
             {
                 "description": "Pass 1 to enable broadcasting",
```

## netron/pickle.js

### js-beautify {}

```diff
@@ -49,129 +49,125 @@
         return new pickle.Model(obj, format);
     }
 };
 
 pickle.Model = class {
 
     constructor(value, format) {
-        this._format = format;
-        this._graphs = [new pickle.Graph(value)];
-    }
-
-    get format() {
-        return this._format;
-    }
-
-    get graphs() {
-        return this._graphs;
+        this.format = format;
+        this.graphs = [new pickle.Graph(value)];
     }
 };
 
 pickle.Graph = class {
 
     constructor(obj) {
-        this._inputs = [];
-        this._outputs = [];
-        this._nodes = [];
-
+        this.inputs = [];
+        this.outputs = [];
+        this.nodes = [];
         if (Array.isArray(obj) && (obj.every((item) => item.__class__) || (obj.every((item) => Array.isArray(item))))) {
             for (const item of obj) {
-                this._nodes.push(new pickle.Node(item));
+                this.nodes.push(new pickle.Node(item));
             }
         } else if (obj && obj instanceof Map && !Array.from(obj.values()).some((value) => typeof value === 'string' || typeof value === 'number')) {
             for (const entry of obj) {
-                this._nodes.push(new pickle.Node(entry[1], entry[0]));
+                this.nodes.push(new pickle.Node(entry[1], entry[0]));
             }
         } else if (obj && obj.__class__) {
-            this._nodes.push(new pickle.Node(obj));
+            this.nodes.push(new pickle.Node(obj));
         } else if (obj && Object(obj) === obj) {
-            this._nodes.push(new pickle.Node(obj));
+            this.nodes.push(new pickle.Node(obj));
         }
     }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get nodes() {
-        return this._nodes;
-    }
 };
 
 pickle.Node = class {
 
     constructor(obj, name) {
-        this._name = name || '';
-        this._inputs = [];
-        this._outputs = [];
-        this._attributes = [];
+        this.name = name || '';
+        this.inputs = [];
+        this.outputs = [];
+        this.attributes = [];
+        const isArray = (obj) => {
+            return obj && obj.__class__ && obj.__class__.__module__ === 'numpy' && obj.__class__.__name__ === 'ndarray';
+        };
         if (Array.isArray(obj)) {
-            this._type = {
+            this.type = {
                 name: 'List'
             };
-            this._attributes.push(new pickle.Attribute('value', obj));
+            const attribute = new pickle.Attribute('value', obj);
+            this.attributes.push(attribute);
         } else {
             const type = obj.__class__ ? obj.__class__.__module__ + '.' + obj.__class__.__name__ : 'Object';
-            this._type = {
+            this.type = {
                 name: type
             };
             const entries = obj instanceof Map ? Array.from(obj.entries()) : Object.entries(obj);
             for (const entry of entries) {
                 const name = entry[0];
                 const value = entry[1];
-                this._attributes.push(new pickle.Attribute(name, value));
+                if (value && isArray(value)) {
+                    const tensor = new pickle.Tensor(value);
+                    const attribute = new pickle.Attribute(name, 'tensor', tensor);
+                    this.attributes.push(attribute);
+                } else if (Array.isArray(value) && value.length > 0 && value.every((obj) => isArray(obj))) {
+                    const values = value.map((value) => new pickle.Tensor(value));
+                    const attribute = new pickle.Attribute(name, 'tensor[]', values);
+                    this.attributes.push(attribute);
+                } else {
+                    const attribute = new pickle.Attribute(name, null, value);
+                    this.attributes.push(attribute);
+                }
+
             }
         }
     }
+};
 
-    get type() {
-        return this._type;
-    }
-
-    get name() {
-        return this._name;
-    }
+pickle.Attribute = class {
 
-    get inputs() {
-        return this._inputs;
+    constructor(name, type, value) {
+        this.name = name;
+        this.type = type;
+        this.value = value;
+        if (!type && value && value.__class__) {
+            this.type = value.__class__.__module__ + '.' + value.__class__.__name__;
+        }
     }
+};
 
-    get outputs() {
-        return this._outputs;
-    }
+pickle.Tensor = class {
 
-    get attributes() {
-        return this._attributes;
+    constructor(array) {
+        this.type = new pickle.TensorType(array.dtype.__name__, new pickle.TensorShape(array.shape));
+        this.layout = this.type.dataType == 'string' || this.type.dataType == 'object' ? '|' : array.dtype.byteorder;
+        this.values = this.type.dataType == 'string' || this.type.dataType == 'object' ? array.tolist() : array.tobytes();
     }
 };
 
-pickle.Attribute = class {
+pickle.TensorType = class {
 
-    constructor(name, value) {
-        this._name = name;
-        this._value = value;
-        if (value && value.__class__) {
-            this._type = value.__class__.__module__ + '.' + value.__class__.__name__;
-        }
+    constructor(dataType, shape) {
+        this.dataType = dataType;
+        this.shape = shape;
     }
 
-    get name() {
-        return this._name;
+    toString() {
+        return this.dataType + this.shape.toString();
     }
+};
+
+pickle.TensorShape = class {
 
-    get value() {
-        return this._value;
+    constructor(dimensions) {
+        this.dimensions = dimensions;
     }
 
-    get type() {
-        return this._type;
+    toString() {
+        return this.dimensions ? ('[' + this.dimensions.map((dimension) => dimension.toString()).join(',') + ']') : '';
     }
 };
 
 pickle.Error = class extends Error {
 
     constructor(message) {
         super(message);
```

## netron/python.js

### js-beautify {}

```diff
@@ -1818,15 +1818,15 @@
                     }
                 }
             }
         });
         this.registerFunction('builtins.long', this.builtins.int);
         this.registerFunction('builtins.print', function() {});
         this.registerFunction('builtins.unicode', function( /* value */ ) {
-            throw new python.Error('Not implemented.');
+            throw new python.Error("'builtins.unicode' not implemented.");
         });
         this.registerType('builtins.Warning', class {});
         this.registerType('builtins.FutureWarning', class extends this._builtins.Warning {});
         this.registerType('typing._Final', class {});
         this.registerType('typing._SpecialForm', class extends this._typing._Final {});
         this.registerType('typing._BaseGenericAlias', class extends this._typing._Final {});
         this.registerType('typing._GenericAlias', class extends this._typing._BaseGenericAlias {});
@@ -2224,14 +2224,17 @@
         this.registerType('gensim.models.keyedvectors.Word2VecKeyedVectors', class {});
         this.registerType('gensim.models.phrases.Phrases', class {});
         this.registerType('gensim.models.tfidfmodel.TfidfModel', class {});
         this.registerType('gensim.models.word2vec.Vocab', class {});
         this.registerType('gensim.models.word2vec.Word2Vec', class {});
         this.registerType('gensim.models.word2vec.Word2VecTrainables', class {});
         this.registerType('gensim.models.word2vec.Word2VecVocab', class {});
+        this.registerFunction('gensim.utils.call_on_class_only', function() {
+            throw new python.Error('This method should be called on a class object.');
+        });
         this.registerType('google3.learning.deepmind.research.nbr.pbl_jax.clean_jaxline.utils.optimizers.ScaleByLarsState', class {
             constructor(obj) {
                 Object.assign(this, obj);
             }
         });
         this.registerType('joblib.numpy_pickle.NumpyArrayWrapper', class {
             constructor( /* subtype, shape, dtype */ ) {}
@@ -3534,14 +3537,17 @@
         });
         this.registerFunction('builtins.set', function(iterable) {
             return iterable ? iterable : [];
         });
         this.registerFunction('builtins.slice', function(start, stop, step) {
             return [start, stop, step];
         });
+        this.registerFunction('builtins.hash', function( /* obj */ ) {
+            throw new python.Error("'builtins.hash' not implemented.");
+        });
         this.registerFunction('cloudpickle.cloudpickle._builtin_type', function(name) {
             return name;
         });
         this.registerFunction('collections.Counter', function( /* iterable */ ) {
             return {
                 __module__: 'collections',
                 __name__: 'Counter'
@@ -3887,15 +3893,15 @@
             }
             const buffer = new Uint8Array([0, 0, 0, 0]);
             buffer.set(file.read(major >= 2 ? 4 : 2), 0);
             const header_length = buffer[3] << 24 | buffer[2] << 16 | buffer[1] << 8 | buffer[0];
             let header = file.read(header_length);
             const decoder = new TextDecoder(major >= 3 ? 'utf-8' : 'ascii');
             header = decoder.decode(header);
-            header = JSON.parse(header.replace(/\(/, '[').replace(/\)/, ']').replace('[,', '[1,]').replace(',]', ',1]').replace(/'/g, '"').replace(/:\s*False\s*,/, ':false,').replace(/:\s*True\s*,/, ':true,').replace(/,\s*\}/, ' }'));
+            header = JSON.parse(header.replace(/\(/, '[').replace(/\)/, ']').replace('[,', '[1,]').replace(',]', ']').replace(/'/g, '"').replace(/:\s*False\s*,/, ':false,').replace(/:\s*True\s*,/, ':true,').replace(/,\s*\}/, ' }'));
             if (!header.descr || header.descr.length < 2) {
                 throw new python.Error("Missing property 'descr'.");
             }
             if (!header.shape) {
                 throw new python.Error("Missing property 'shape'.");
             }
             const shape = header.shape;
@@ -4043,15 +4049,14 @@
                 littleendian: dtype.str[0],
                 shape: shape,
                 data: new Uint8Array(size)
             };
             context.view = new DataView(context.data.buffer, context.data.byteOffset, size);
             encode(context, a, 0);
             return self.invoke('numpy.ndarray', [shape, dtype, context.data]);
-
         });
         this.registerFunction('numpy.ma.core._mareconstruct', function(subtype, baseclass, baseshape, basetype) {
             const data = self.invoke(baseclass, [baseshape, basetype]);
             // = ndarray.__new__(ndarray, baseshape, make_mask_descr(basetype))
             const mask = self.invoke('numpy.ndarray', [baseshape, '']);
             return self.invoke(subtype, [data, mask, basetype]);
         });
@@ -5143,14 +5148,20 @@
         });
         this.registerFunction('torch.neg', function(value) {
             if (typeof value === 'number') {
                 return -value;
             }
             throw new python.Error("Unsupported 'torch.neg' expression type.");
         });
+        this.registerFunction('torch.pow', function(left, right) {
+            if (typeof left === 'number' && typeof right === 'number') {
+                return Math.pow(left, right);
+            }
+            throw new python.Error("Unsupported 'torch.pow' expression type.");
+        });
         this.registerFunction('torch.q_scale', function( /* tensor */ ) {
             return -1; // TODO
         });
         this.registerFunction('torch.t', function(tensor) {
             return tensor;
         });
         this.registerFunction('torch.size', function(tensor, dim) {
@@ -6437,15 +6448,15 @@
     get length() {
         return this._length;
     }
 
     seek(position) {
         this._position = position >= 0 ? position : this._length + position;
         if (this._position > this._buffer.length) {
-            throw new Error('Expected ' + (this._position - this._buffer.length) + ' more bytes. The file might be corrupted. Unexpected end of file.');
+            throw new python.Error('Expected ' + (this._position - this._buffer.length) + ' more bytes. The file might be corrupted. Unexpected end of file.');
         }
     }
 
     skip(offset) {
         this._position += offset;
         if (this._position > this._buffer.length) {
             throw new python.Error('Expected ' + (this._position - this._buffer.length) + ' more bytes. The file might be corrupted. Unexpected end of file.');
```

## netron/rknn-metadata.json

### Pretty-printed

 * *Similarity: 0.9310344827586207%*

 * *Differences: {'insert': "[(27, OrderedDict([('name', 'ConvReluAdd'), ('category', 'Layer'), ('inputs', "*

 * *           "[OrderedDict([('name', 'input')]), OrderedDict([('name', 'weights')]), "*

 * *           "OrderedDict([('name', 'bias')])])])), (28, OrderedDict([('name', 'ConvLeakyRelu'), "*

 * *           "('category', 'Layer'), ('inputs', [OrderedDict([('name', 'input')]), "*

 * *           "OrderedDict([('name', 'weights')]), OrderedDict([('name', 'bias')])])])), (29, "*

 * *           "OrderedDict([('name', 'ConvLeakyReluAdd'), ('categ […]*

```diff
@@ -242,14 +242,74 @@
             {
                 "name": "weights"
             },
             {
                 "name": "bias"
             }
         ],
+        "name": "ConvReluAdd"
+    },
+    {
+        "category": "Layer",
+        "inputs": [
+            {
+                "name": "input"
+            },
+            {
+                "name": "weights"
+            },
+            {
+                "name": "bias"
+            }
+        ],
+        "name": "ConvLeakyRelu"
+    },
+    {
+        "category": "Layer",
+        "inputs": [
+            {
+                "name": "input"
+            },
+            {
+                "name": "weights"
+            },
+            {
+                "name": "bias"
+            }
+        ],
+        "name": "ConvLeakyReluAdd"
+    },
+    {
+        "category": "Layer",
+        "inputs": [
+            {
+                "name": "input"
+            },
+            {
+                "name": "weights"
+            },
+            {
+                "name": "bias"
+            }
+        ],
+        "name": "ConvExSwish"
+    },
+    {
+        "category": "Layer",
+        "inputs": [
+            {
+                "name": "input"
+            },
+            {
+                "name": "weights"
+            },
+            {
+                "name": "bias"
+            }
+        ],
         "name": "ConvTranspose"
     },
     {
         "category": "Layer",
         "inputs": [
             {
                 "name": "input"
```

## netron/rknn.js

### js-beautify {}

```diff
@@ -10,51 +10,46 @@
         return rknn.Container.open(context);
     }
 
     async open(context, target) {
         await context.require('./rknn-schema');
         rknn.schema = flatbuffers.get('rknn').rknn;
         const metadata = await context.metadata('rknn-metadata.json');
-        const container = target;
-        const type = container.type;
-        switch (type) {
-            case 'json': {
-                const buffer = container.value;
-                const reader = json.TextReader.open(buffer);
-                const model = reader.read();
-                return new rknn.Model(metadata, type, model, container.next);
-            }
-            case 'flatbuffers': {
-                const buffer = container.value;
-                const reader = flatbuffers.BinaryReader.open(buffer);
-                const model = rknn.schema.Model.create(reader);
-                return new rknn.Model(metadata, type, model, null);
-            }
-            case 'openvx': {
-                const buffer = container.value;
-                const model = new openvx.Model(buffer);
-                return new rknn.Model(metadata, type, model, null);
-            }
-            default: {
-                throw new rknn.Error("Unsupported RKNN format '" + container.type + "'.");
-            }
+        target.read();
+        if (target.has('json')) {
+            const buffer = target.get('json');
+            const reader = json.TextReader.open(buffer);
+            const model = reader.read();
+            return new rknn.Model(metadata, 'json', model, target);
+        }
+        if (target.has('flatbuffers')) {
+            const buffer = target.get('flatbuffers');
+            const reader = flatbuffers.BinaryReader.open(buffer);
+            const model = rknn.schema.Model.create(reader);
+            return new rknn.Model(metadata, 'flatbuffers', model, null);
+        }
+        if (target.has('openvx')) {
+            const buffer = target.get('openvx');
+            const model = new openvx.Model(buffer);
+            return new rknn.Model(metadata, 'openvx', model, null);
         }
+        throw new rknn.Error("Unsupported RKNN format.");
     }
 };
 
 rknn.Model = class {
 
-    constructor(metadata, type, model, next) {
+    constructor(metadata, type, model, container) {
         switch (type) {
             case 'json': {
                 this._format = 'RKNN v' + model.version.split('-').shift();
                 this._name = model.name || '';
                 this._producer = model.ori_network_platform || model.network_platform || '';
                 this._runtime = model.target_platform ? model.target_platform.join(',') : '';
-                this._graphs = [new rknn.Graph(metadata, type, model.name || '', model, next)];
+                this._graphs = [new rknn.Graph(metadata, type, model.name || '', model, container)];
                 break;
             }
             case 'flatbuffers': {
                 const version = model.compiler.split('-').shift();
                 this._format = 'RKNN Lite' + (version ? ' v' + version : '');
                 this._runtime = model.runtime;
                 this._name = model.name || '';
@@ -65,15 +60,15 @@
                     value: model.source
                 });
                 break;
             }
             case 'openvx': {
                 this._format = 'RKNN OpenVX';
                 this._name = model.name || '';
-                this._graphs = [new rknn.Graph(metadata, type, '', model, next)];
+                this._graphs = [new rknn.Graph(metadata, type, '', model, container)];
                 break;
             }
             default: {
                 throw new rknn.Error("Unsupported RKNN model type '" + type + "'.");
             }
         }
     }
@@ -101,15 +96,15 @@
     get graphs() {
         return this._graphs;
     }
 };
 
 rknn.Graph = class {
 
-    constructor(metadata, type, name, obj, next) {
+    constructor(metadata, type, name, obj, container) {
         this._name = name;
         this._inputs = [];
         this._outputs = [];
         this._nodes = [];
         switch (type) {
             case 'json': {
                 const dataType = (value) => {
@@ -129,40 +124,40 @@
                             if (value.vx_type !== '') {
                                 throw new rknn.Error("Invalid data type '" + JSON.stringify(dataType) + "'.");
                             }
                             return '?';
                     }
                 };
                 const model = obj;
-                const args = new Map();
+                const values = new Map();
                 for (const const_tensor of model.const_tensor) {
                     const name = 'const_tensor:' + const_tensor.tensor_id.toString();
                     const shape = new rknn.TensorShape(const_tensor.size);
                     const type = new rknn.TensorType(dataType(const_tensor.dtype), shape);
-                    const tensor = new rknn.Tensor(type, const_tensor.offset, next.value);
+                    const tensor = new rknn.Tensor(type, const_tensor.offset, null);
                     const value = new rknn.Value(name, type, tensor);
-                    args.set(name, value);
+                    values.set(name, value);
                 }
                 for (const virtual_tensor of model.virtual_tensor) {
                     const name = virtual_tensor.node_id.toString() + ':' + virtual_tensor.output_port.toString();
                     const value = new rknn.Value(name, null, null);
-                    args.set(name, value);
+                    values.set(name, value);
                 }
                 for (const norm_tensor of model.norm_tensor) {
                     const name = 'norm_tensor:' + norm_tensor.tensor_id.toString();
                     const shape = new rknn.TensorShape(norm_tensor.size);
                     const type = new rknn.TensorType(dataType(norm_tensor.dtype), shape);
                     const value = new rknn.Value(name, type, null);
-                    args.set(name, value);
+                    values.set(name, value);
                 }
-                const arg = (name) => {
-                    if (!args.has(name)) {
-                        args.set(name, new rknn.Value(name, null, null));
+                const value = (name) => {
+                    if (!values.has(name)) {
+                        values.set(name, new rknn.Value(name, null, null));
                     }
-                    return args.get(name);
+                    return values.get(name);
                 };
                 for (const node of model.nodes) {
                     node.input = [];
                     node.output = [];
                 }
                 for (const connection of model.connection) {
                     switch (connection.left) {
@@ -177,29 +172,28 @@
                             break;
                         default:
                             throw new rknn.Error("Unsupported left connection '" + connection.left + "'.");
                     }
                 }
                 for (const graph of model.graph) {
                     const key = graph.right + ':' + graph.right_tensor_id.toString();
-                    const value = arg(key);
                     const name = graph.left + (graph.left_tensor_id === 0 ? '' : graph.left_tensor_id.toString());
-                    const argument = new rknn.Argument(name, [value]);
+                    const argument = new rknn.Argument(name, [value(key)]);
                     switch (graph.left) {
                         case 'input':
                             this._inputs.push(argument);
                             break;
                         case 'output':
                             this._outputs.push(argument);
                             break;
                         default:
                             throw new rknn.Error("Unsupported left graph connection '" + graph.left + "'.");
                     }
                 }
-                this._nodes = model.nodes.map((node) => new rknn.Node(metadata, type, node, arg, next));
+                this._nodes = model.nodes.map((node) => new rknn.Node(metadata, type, node, value, container));
                 break;
             }
             case 'flatbuffers': {
                 const graph = obj;
                 const dataTypes = ['unk0', 'int32', '?', 'int8', '?', 'int16', 'float32', 'int64', '?', '?', 'float16', '?', '?', 'unk13'];
                 const args = graph.tensors.map((tensor) => {
                     const shape = new rknn.TensorShape(Array.from(tensor.shape));
@@ -213,20 +207,20 @@
                 });
                 const arg = (index) => {
                     if (index >= args.length) {
                         throw new rknn.Error("Invalid tensor index '" + index.toString() + "'.");
                     }
                     return args[index];
                 };
-                this._nodes = graph.nodes.map((node) => new rknn.Node(metadata, type, node, arg, next));
+                this._nodes = graph.nodes.map((node) => new rknn.Node(metadata, type, node, arg, container));
                 break;
             }
             case 'openvx': {
                 const model = obj;
-                this._nodes = model.nodes.map((node) => new rknn.Node(metadata, type, node, null, next));
+                this._nodes = model.nodes.map((node) => new rknn.Node(metadata, type, node, null, container));
                 break;
             }
             default: {
                 throw new rknn.Error("Unsupported RKNN graph type '" + type + "'.");
             }
         }
     }
@@ -286,30 +280,30 @@
     get initializer() {
         return this._initializer;
     }
 };
 
 rknn.Node = class {
 
-    constructor(metadata, type, node, arg, next) {
+    constructor(metadata, type, node, value, container) {
         this._inputs = [];
         this._outputs = [];
         this._attributes = [];
         switch (type) {
             case 'json': {
                 this._name = node.name || '';
-                if (node.op === 'VSI_NN_OP_NBG' && next && next.type === 'openvx') {
-                    const buffer = next.value;
+                if (node.op === 'VSI_NN_OP_NBG' && container && container.has('openvx')) {
+                    const buffer = container.get('openvx');
                     const model = new openvx.Model(buffer);
-                    this._type = new rknn.Graph(metadata, next.type, 'NBG', model, null);
-                } else if (node.op === 'RKNN_OP_NNBG' && next && next.type === 'flatbuffers') {
-                    const buffer = next.value;
+                    this._type = new rknn.Graph(metadata, 'openvx', 'NBG', model, null);
+                } else if (node.op === 'RKNN_OP_NNBG' && container && container.has('flatbuffers')) {
+                    const buffer = container.get('flatbuffers');
                     const reader = flatbuffers.BinaryReader.open(buffer);
                     const model = rknn.schema.Model.create(reader);
-                    this._type = new rknn.Graph(metadata, next.type, 'NNBG', model.graphs[0], null);
+                    this._type = new rknn.Graph(metadata, 'flatbuffers', 'NNBG', model.graphs[0], null);
                 } else {
                     this._type = Object.assign({}, metadata.type(node.op) || {
                         name: node.op
                     });
                     for (const prefix of ['VSI_NN_OP_', 'RKNN_OP_']) {
                         this._type.name = this._type.name.startsWith(prefix) ? this._type.name.substring(prefix.length) : this._type.name;
                     }
@@ -318,36 +312,36 @@
                 for (let i = 0; i < node.input.length;) {
                     const input = this._type && this._type.inputs && i < this._type.inputs.length ? this._type.inputs[i] : {
                         name: i === 0 ? 'input' : i.toString()
                     };
                     const count = input.list ? node.input.length - i : 1;
                     const list = node.input.slice(i, i + count).map((input) => {
                         if (input.right_tensor) {
-                            return arg(input.right_tensor.type + ':' + input.right_tensor.tensor_id.toString());
+                            return value(input.right_tensor.type + ':' + input.right_tensor.tensor_id.toString());
                         }
                         if (input.right_node) {
-                            return arg(input.right_node.node_id.toString() + ':' + input.right_node.tensor_id.toString());
+                            return value(input.right_node.node_id.toString() + ':' + input.right_node.tensor_id.toString());
                         }
                         throw new rknn.Error('Invalid input argument.');
                     });
                     this._inputs.push(new rknn.Argument(input.name, list));
                     i += count;
                 }
                 node.output = node.output || [];
                 for (let i = 0; i < node.output.length;) {
                     const output = this._metadata && this._metadata.outputs && i < this._metadata.outputs.length ? this._metadata.outputs[i] : {
                         name: i === 0 ? 'output' : i.toString()
                     };
                     const count = output.list ? node.output.length - i : 1;
                     const list = node.output.slice(i, i + count).map((output) => {
                         if (output.right_tensor) {
-                            return arg(output.right_tensor.type + ':' + output.right_tensor.tensor_id.toString());
+                            return value(output.right_tensor.type + ':' + output.right_tensor.tensor_id.toString());
                         }
                         if (output.right_node) {
-                            return arg(output.right_node.node_id.toString() + ':' + output.right_node.tensor_id.toString());
+                            return value(output.right_node.node_id.toString() + ':' + output.right_node.tensor_id.toString());
                         }
                         throw new rknn.Error('Invalid output argument.');
                     });
                     this._outputs.push(new rknn.Argument(output.name, list));
                     i += count;
                 }
                 if (node.nn) {
@@ -369,35 +363,35 @@
                     const inputs = this._type.inputs || (node.inputs.length === 1 ? [{
                         name: "input"
                     }] : [{
                         name: "inputs",
                         list: true
                     }]);
                     if (Array.isArray(inputs) && inputs.length > 0 && inputs[0].list === true) {
-                        this._inputs = [new rknn.Argument(inputs[0].name, Array.from(node.inputs).map((input) => arg(input)))];
+                        this._inputs = [new rknn.Argument(inputs[0].name, Array.from(node.inputs).map((input) => value(input)))];
                     } else {
                         this._inputs = Array.from(node.inputs).map((input, index) => {
-                            const value = arg(input);
-                            return new rknn.Argument(index < inputs.length ? inputs[index].name : index.toString(), [value]);
+                            return new rknn.Argument(index < inputs.length ? inputs[index].name : index.toString(), [value(input)]);
                         });
                     }
                 }
                 if (node.outputs.length > 0) {
                     const outputs = this._type.outputs || (node.outputs.length === 1 ? [{
                         name: "output"
                     }] : [{
                         name: "outputs",
                         list: true
                     }]);
                     if (Array.isArray(outputs) && outputs.length > 0 && outputs[0].list === true) {
-                        this._outputs = [new rknn.Argument(outputs[0].name, Array.from(node.outputs).map((output) => arg(output)))];
+                        const values = Array.from(node.outputs).map((output) => value(output));
+                        const argument = new rknn.Argument(outputs[0].name, values);
+                        this._outputs = [argument];
                     } else {
                         this._outputs = Array.from(node.outputs).map((output, index) => {
-                            const value = arg(output);
-                            return new rknn.Argument(index < outputs.length ? outputs[index].name : index.toString(), [value]);
+                            return new rknn.Argument(index < outputs.length ? outputs[index].name : index.toString(), [value(output)]);
                         });
                     }
                 }
                 break;
             }
             case 'openvx': {
                 this._name = '';
@@ -536,128 +530,140 @@
         if (!this._dimensions || this._dimensions.length == 0) {
             return '';
         }
         return '[' + this._dimensions.join(',') + ']';
     }
 };
 
-rknn.Container = class {
+rknn.Container = class extends Map {
 
     static open(context) {
         const stream = context.stream;
         if (stream) {
-            const container = new rknn.Container(stream, stream.length);
-            if (container.type) {
-                return container;
+            const signature = rknn.Container.signature(stream);
+            switch (signature) {
+                case 'rknn':
+                case 'openvx':
+                case 'flatbuffers':
+                    return new rknn.Container(stream);
+                default:
+                    break;
+            }
+            const obj = context.open('json');
+            if (obj && obj.version && Array.isArray(obj.nodes) && obj.network_platform) {
+                const entries = new Map();
+                entries.set('json', stream);
+                return new rknn.Container(null, entries);
             }
         }
         return null;
     }
 
-    constructor(stream, length) {
+    constructor(stream, entries) {
+        super(entries);
         this._stream = stream;
-        this._length = length;
-        this._type = '';
-        if ((stream.position + 16) <= this._length) {
-            const signature = [0x52, 0x4B, 0x4E, 0x4E]; // RKNN
-            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
-                this._type = 'json';
-            }
-        }
-        if ((stream.position + 16) <= this._length) {
-            const signature = [0x43, 0x59, 0x50, 0x54, 0x52, 0x4B, 0x4E, 0x4E]; // CYPTRKNN
-            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
-                this._type = 'crypt';
-            }
-        }
-        if ((stream.position + 8) <= this._length) {
-            const signature = [0x52, 0x4B, 0x4E, 0x4E]; // RKNN
-            if (stream.peek(8).subarray(4, 8).every((value, index) => value === signature[index])) {
-                this._type = 'flatbuffers';
-            }
-        }
-        if ((stream.position + 8) <= this._length) {
-            const signature = [0x56, 0x50, 0x4D, 0x4E]; // VPMN
-            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
-                this._type = 'openvx';
-            }
-        }
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get value() {
-        this.read();
-        return this._value;
-    }
-
-    get next() {
-        this.read();
-        return this._next;
     }
 
     read() {
         if (this._stream) {
             const stream = this._stream;
             delete this._stream;
-            switch (this._type) {
-                case 'crypt': {
-                    throw new rknn.Error('Invalid file content. File contains undocumented encrypted RKNN data.');
-                }
-                case 'json': {
+            const signature = rknn.Container.signature(stream);
+            switch (signature) {
+                case 'rknn': {
                     const uint64 = () => {
                         const buffer = stream.read(8);
                         const reader = new base.BinaryReader(buffer);
                         return reader.uint64();
                     };
                     stream.skip(8);
                     const version = uint64();
                     const data_size = uint64();
                     switch (version) {
                         case 0x0001:
                         case 0x1001:
                             break;
                         case 0x0002:
+                        case 0x1002:
+                        case 0x1003:
                         case 0x0004:
                             if (data_size > 0) {
                                 stream.skip(40);
                             }
                             break;
+                        case 0x0003:
+                        case 0x0005:
+                        case 0x0006:
                         default:
                             throw new rknn.Error("Unsupported RKNN container version '" + version + "'.");
                     }
-                    this._next = new rknn.Container(stream, data_size);
-                    this._next.read();
-                    const value_size = uint64();
-                    this._value = stream.read(value_size);
+                    const signature = rknn.Container.signature(stream, data_size);
+                    const data = stream.read(data_size);
+                    const json_size = uint64();
+                    const json = stream.read(json_size);
+                    this.set('json', json);
+                    if (signature) {
+                        this.set(signature, data);
+                    }
                     break;
                 }
+                case 'openvx':
                 case 'flatbuffers': {
-                    this._value = stream.read(this._length);
-                    this._next = null;
+                    this.set(signature, stream.peek());
                     break;
                 }
-                case 'openvx': {
-                    this._value = stream.read(this._length);
-                    this._next = null;
-                    break;
-                }
-                case '': {
-                    this._value = stream.read(this._length);
-                    this._next = null;
-                    break;
+                case 'cyptrknn': {
+                    throw new rknn.Error('Invalid file content. File contains undocumented encrypted RKNN data.');
                 }
                 default: {
-                    throw new rknn.Error("Unsupported container type '" + this._format + "'.");
+                    break;
                 }
             }
         }
     }
+
+    static signature(stream, length) {
+        length = length || stream.length;
+        if (stream && (stream.position + 16) <= length) {
+            const signature = [0x52, 0x4B, 0x4E, 0x4E]; // RKNN
+            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
+                return 'rknn';
+            }
+        }
+        if (stream && (stream.position + 16) <= length) {
+            const signature = [0x43, 0x59, 0x50, 0x54, 0x52, 0x4B, 0x4E, 0x4E]; // CYPTRKNN
+            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
+                return 'cyptrknn';
+            }
+        }
+        if (stream && (stream.position + 8) <= length) {
+            const signature = [0x52, 0x4B, 0x4E, 0x4E]; // RKNN
+            if (stream.peek(8).subarray(4, 8).every((value, index) => value === signature[index])) {
+                return 'flatbuffers';
+            }
+        }
+        if (stream && (stream.position + 8) <= length) {
+            const signature = [0x56, 0x50, 0x4D, 0x4E]; // VPMN
+            if (stream.peek(signature.length).every((value, index) => value === signature[index])) {
+                return 'openvx';
+            }
+        }
+        return undefined;
+    }
+};
+
+openvx.BinaryReader = class extends base.BinaryReader {
+
+    string(length) {
+        const buffer = this.read(length);
+        const index = buffer.indexOf(0);
+        const data = index === -1 ? buffer : buffer.subarray(0, index);
+        this._decoder = this._decoder || new TextDecoder('ascii');
+        return this._decoder.decode(data);
+    }
 };
 
 openvx.Model = class {
 
     constructor(buffer) {
         const reader = new openvx.BinaryReader(buffer);
         reader.skip(4); // signature
@@ -705,25 +711,14 @@
     }
 
     get nodes() {
         return this._nodes;
     }
 };
 
-openvx.BinaryReader = class extends base.BinaryReader {
-
-    string(length) {
-        const buffer = this.read(length);
-        const index = buffer.indexOf(0);
-        const data = index === -1 ? buffer : buffer.subarray(0, index);
-        this._decoder = this._decoder || new TextDecoder('ascii');
-        return this._decoder.decode(data);
-    }
-};
-
 rknn.Error = class extends Error {
 
     constructor(message) {
         super(message);
         this.name = 'Error loading RKNN model.';
     }
 };
```

## netron/server.py

```diff
@@ -11,15 +11,15 @@
 import socketserver
 import sys
 import threading
 import time
 import webbrowser
 import urllib.parse
 
-__version__ = '7.1.0'
+__version__ = '7.1.1'
 
 class _ContentProvider: # pylint: disable=too-few-public-methods
     data = bytearray()
     base_dir = ''
     base = ''
     identifier = ''
     def __init__(self, data, path, file):
```

## netron/sklearn.js

### js-beautify {}

```diff
@@ -57,412 +57,247 @@
 
     constructor(metadata, target, obj) {
         const formats = new Map([
             ['sklearn', 'scikit-learn'],
             ['scipy', 'SciPy'],
             ['hmmlearn', 'hmmlearn']
         ]);
-        this._format = formats.get(target.split('.').shift());
-        this._graphs = [];
+        this.format = formats.get(target.split('.').shift());
+        this.graphs = [];
         const version = [];
         switch (target) {
             case 'sklearn':
             case 'scipy':
             case 'hmmlearn': {
                 if (obj._sklearn_version) {
                     version.push(' v' + obj._sklearn_version.toString());
                 }
-                this._graphs.push(new sklearn.Graph(metadata, '', obj));
+                this.graphs.push(new sklearn.Graph(metadata, '', obj));
                 break;
             }
             case 'sklearn.list':
             case 'scipy.list': {
                 const list = obj;
                 for (let i = 0; i < list.length; i++) {
                     const obj = list[i];
-                    this._graphs.push(new sklearn.Graph(metadata, i.toString(), obj));
+                    this.graphs.push(new sklearn.Graph(metadata, i.toString(), obj));
                     if (obj._sklearn_version) {
                         version.push(' v' + obj._sklearn_version.toString());
                     }
                 }
                 break;
             }
             case 'sklearn.map':
             case 'scipy.map': {
                 for (const entry of Object.entries(obj)) {
                     const obj = entry[1];
-                    this._graphs.push(new sklearn.Graph(metadata, entry[0], obj));
+                    this.graphs.push(new sklearn.Graph(metadata, entry[0], obj));
                     if (obj._sklearn_version) {
                         version.push(' v' + obj._sklearn_version.toString());
                     }
                 }
                 break;
             }
             default: {
                 throw new sklearn.Error("Unsupported scikit-learn format '" + target + "'.");
             }
         }
         if (version.length > 0 && version.every((value) => value === version[0])) {
-            this._format += version[0];
+            this.format += version[0];
         }
     }
-
-    get format() {
-        return this._format;
-    }
-
-    get graphs() {
-        return this._graphs;
-    }
 };
 
 sklearn.Graph = class {
 
     constructor(metadata, name, obj) {
-        this._name = name || '';
-        this._metadata = metadata;
-        this._nodes = [];
-        this._groups = false;
+        this.name = name || '';
+        this.nodes = [];
+        this.inputs = [];
+        this.outputs = [];
+        this.groups = false;
         const values = new Map();
         const value = (name) => {
             if (!values.has(name)) {
                 values.set(name, new sklearn.Value(name, null, null));
             }
             return values.get(name);
         };
         const concat = (parent, name) => {
             return (parent === '' ? name : `${parent}/${name}`);
         };
         const process = (group, name, obj, inputs) => {
             const type = obj.__class__.__module__ + '.' + obj.__class__.__name__;
             switch (type) {
                 case 'sklearn.pipeline.Pipeline': {
-                    this._groups = true;
+                    this.groups = true;
                     name = name || 'pipeline';
                     const childGroup = concat(group, name);
                     for (const step of obj.steps) {
                         inputs = process(childGroup, step[0], step[1], inputs);
                     }
                     return inputs;
                 }
                 case 'sklearn.pipeline.FeatureUnion': {
-                    this._groups = true;
+                    this.groups = true;
                     const outputs = [];
                     name = name || 'union';
                     const output = concat(group, name);
                     const subgroup = concat(group, name);
-                    this._nodes.push(new sklearn.Node(this._metadata, subgroup, output, obj, inputs, [output], value));
+                    this.nodes.push(new sklearn.Node(metadata, subgroup, output, obj, inputs, [output], value));
                     for (const transformer of obj.transformer_list) {
                         outputs.push(...process(subgroup, transformer[0], transformer[1], [output]));
                     }
                     return outputs;
                 }
                 case 'sklearn.compose._column_transformer.ColumnTransformer': {
-                    this._groups = true;
+                    this.groups = true;
                     name = name || 'transformer';
                     const output = concat(group, name);
                     const subgroup = concat(group, name);
                     const outputs = [];
-                    this._nodes.push(new sklearn.Node(this._metadata, subgroup, output, obj, inputs, [output], value));
+                    this.nodes.push(new sklearn.Node(metadata, subgroup, output, obj, inputs, [output], value));
                     for (const transformer of obj.transformers) {
                         if (transformer[1] !== 'passthrough') {
                             outputs.push(...process(subgroup, transformer[0], transformer[1], [output]));
                         }
                     }
                     return outputs;
                 }
                 default: {
                     const output = concat(group, name);
-                    this._nodes.push(new sklearn.Node(this._metadata, group, output, obj, inputs, output === '' ? [] : [output], value));
+                    this.nodes.push(new sklearn.Node(metadata, group, output, obj, inputs, output === '' ? [] : [output], value));
                     return [output];
                 }
             }
         };
         process('', '', obj, ['data']);
     }
-
-    get name() {
-        return this._name;
-    }
-
-    get groups() {
-        return this._groups;
-    }
-
-    get inputs() {
-        return [];
-    }
-
-    get outputs() {
-        return [];
-    }
-
-    get nodes() {
-        return this._nodes;
-    }
 };
 
 sklearn.Argument = class {
 
     constructor(name, value) {
-        this._name = name;
-        this._value = value;
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get value() {
-        return this._value;
+        this.name = name;
+        this.value = value;
     }
 };
 
 sklearn.Value = class {
 
     constructor(name, type, initializer) {
         if (typeof name !== 'string') {
             throw new sklearn.Error("Invalid value identifier '" + JSON.stringify(name) + "'.");
         }
-        this._name = name;
+        this.name = name;
         this._type = type || null;
-        this._initializer = initializer || null;
-    }
-
-    get name() {
-        return this._name;
+        this.initializer = initializer || null;
     }
 
     get type() {
-        if (this._initializer) {
-            return this._initializer.type;
+        if (this.initializer) {
+            return this.initializer.type;
         }
         return this._type;
     }
-
-    get initializer() {
-        return this._initializer;
-    }
 };
 
 sklearn.Node = class {
 
     constructor(metadata, group, name, obj, inputs, outputs, value) {
-        this._group = group || '';
-        this._name = name || '';
+        this.group = group || null;
+        this.name = name || '';
         const type = obj.__class__ ? obj.__class__.__module__ + '.' + obj.__class__.__name__ : 'Object';
-        this._type = metadata.type(type) || {
+        this.type = metadata.type(type) || {
             name: type
         };
-        this._inputs = inputs.map((input) => new sklearn.Argument(input, [value(input)]));
-        this._outputs = outputs.map((output) => new sklearn.Argument(output, [value(output)]));
-        this._attributes = [];
-
+        this.inputs = inputs.map((input) => new sklearn.Argument(input, [value(input)]));
+        this.outputs = outputs.map((output) => new sklearn.Argument(output, [value(output)]));
+        this.attributes = [];
+        const isArray = (obj) => {
+            return obj && obj.__class__ && obj.__class__.__module__ === 'numpy' && obj.__class__.__name__ === 'ndarray';
+        };
         for (const entry of Object.entries(obj)) {
             const name = entry[0];
             const value = entry[1];
-            if (value && sklearn.Utility.isTensor(value)) {
+            if (value && isArray(value)) {
                 const argument = new sklearn.Argument(name, [new sklearn.Value('', null, new sklearn.Tensor(value))]);
-                this._inputs.push(argument);
-            } else if (Array.isArray(value) && value.every((obj) => sklearn.Utility.isTensor(obj))) {
+                this.inputs.push(argument);
+            } else if (Array.isArray(value) && value.length > 0 && value.every((obj) => isArray(obj))) {
                 const argument = new sklearn.Argument(name, value.map((obj) => new sklearn.Value('', null, new sklearn.Tensor(obj))));
-                this._inputs.push(argument);
+                this.inputs.push(argument);
             } else if (!name.startsWith('_')) {
                 const attribute = new sklearn.Attribute(metadata.attribute(type, name), name, value);
-                this._attributes.push(attribute);
+                this.attributes.push(attribute);
             }
         }
     }
-
-    get type() {
-        return this._type; // .split('.').pop();
-    }
-
-    get name() {
-        return this._name;
-    }
-
-    get group() {
-        return this._group ? this._group : null;
-    }
-
-    get inputs() {
-        return this._inputs;
-    }
-
-    get outputs() {
-        return this._outputs;
-    }
-
-    get attributes() {
-        return this._attributes;
-    }
 };
 
 sklearn.Attribute = class {
 
     constructor(metadata, name, value) {
-        this._name = name;
-        this._value = value;
+        this.name = name;
+        this.value = value;
         if (metadata) {
-            if (metadata.optional && this._value == null) {
-                this._visible = false;
+            if (metadata.optional && this.value == null) {
+                this.visible = false;
             } else if (metadata.visible === false) {
-                this._visible = false;
+                this.visible = false;
             } else if (metadata.default !== undefined) {
                 if (Array.isArray(value)) {
                     if (Array.isArray(metadata.default)) {
-                        this._visible = value.length !== metadata.default || !this.value.every((item, index) => item == metadata.default[index]);
+                        this.visible = value.length !== metadata.default || !this.value.every((item, index) => item == metadata.default[index]);
                     } else {
-                        this._visible = !this.value.every((item) => item == metadata.default);
+                        this.visible = !this.value.every((item) => item == metadata.default);
                     }
                 } else {
-                    this._visible = this.value !== metadata.default;
+                    this.visible = this.value !== metadata.default;
                 }
             }
         }
         if (value) {
             if (Array.isArray(value) && value.length > 0 && value.every((obj) => obj.__class__ && obj.__class__.__module__ === value[0].__class__.__module__ && obj.__class__.__name__ === value[0].__class__.__name__)) {
-                this._type = value[0].__class__.__module__ + '.' + value[0].__class__.__name__ + '[]';
+                this.type = value[0].__class__.__module__ + '.' + value[0].__class__.__name__ + '[]';
             } else if (value.__class__) {
-                this._type = value.__class__.__module__ + '.' + value.__class__.__name__;
+                this.type = value.__class__.__module__ + '.' + value.__class__.__name__;
             }
         }
     }
-
-    get name() {
-        return this._name;
-    }
-
-    get value() {
-        return this._value;
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get visible() {
-        return this._visible == false ? false : true;
-    }
 };
 
 sklearn.Tensor = class {
 
     constructor(array) {
-        if (!sklearn.Utility.isTensor(array)) {
-            const type = array.__class__.__module__ + '.' + array.__class__.__name__;
-            throw new sklearn.Error("Unsupported tensor type '" + type + "'.");
-        }
-        this._type = new sklearn.TensorType(array.dtype.__name__, new sklearn.TensorShape(array.shape));
-        this._byteorder = array.dtype.byteorder;
-        this._data = this._type.dataType == 'string' || this._type.dataType == 'object' ? array.tolist() : array.tobytes();
-    }
-
-    get type() {
-        return this._type;
-    }
-
-    get category() {
-        return 'NumPy Array';
-    }
-
-    get layout() {
-        return this._type.dataType == 'string' || this._type.dataType == 'object' ? '|' : this._byteorder;
-    }
-
-    get values() {
-        return this._data;
+        this.type = new sklearn.TensorType(array.dtype.__name__, new sklearn.TensorShape(array.shape));
+        this.layout = this.type.dataType == 'string' || this.type.dataType == 'object' ? '|' : array.dtype.byteorder;
+        this.values = this.type.dataType == 'string' || this.type.dataType == 'object' ? array.tolist() : array.tobytes();
     }
 };
 
 sklearn.TensorType = class {
 
     constructor(dataType, shape) {
-        this._dataType = dataType;
-        this._shape = shape;
-    }
-
-    get dataType() {
-        return this._dataType;
-    }
-
-    get shape() {
-        return this._shape;
+        this.dataType = dataType;
+        this.shape = shape;
     }
 
     toString() {
-        return this.dataType + this._shape.toString();
+        return this.dataType + this.shape.toString();
     }
 };
 
 sklearn.TensorShape = class {
 
     constructor(dimensions) {
-        this._dimensions = dimensions;
-    }
-
-    get dimensions() {
-        return this._dimensions;
+        this.dimensions = dimensions;
     }
 
     toString() {
-        return this._dimensions ? ('[' + this._dimensions.map((dimension) => dimension.toString()).join(',') + ']') : '';
-    }
-};
-
-sklearn.Utility = class {
-
-    static isTensor(obj) {
-        return obj && obj.__class__ && obj.__class__.__module__ === 'numpy' && obj.__class__.__name__ === 'ndarray';
-    }
-
-    static findWeights(obj) {
-        const keys = ['', 'blobs'];
-        for (const key of keys) {
-            const dict = key === '' ? obj : obj[key];
-            if (dict) {
-                const weights = new Map();
-                if (dict instanceof Map) {
-                    for (const pair of dict) {
-                        if (!sklearn.Utility.isTensor(pair[1])) {
-                            return null;
-                        }
-                        weights.set(pair[0], pair[1]);
-                    }
-                    return weights;
-                } else if (!Array.isArray(dict)) {
-                    for (const key in dict) {
-                        const value = dict[key];
-                        if (key != 'weight_order' && key != 'lr') {
-                            if (!key || !sklearn.Utility.isTensor(value)) {
-                                return null;
-                            }
-                            weights.set(key, value);
-                        }
-                    }
-                    return weights;
-                }
-            }
-        }
-        for (const key of keys) {
-            const list = key === '' ? obj : obj[key];
-            if (list && Array.isArray(list)) {
-                const weights = new Map();
-                for (let i = 0; i < list.length; i++) {
-                    const value = list[i];
-                    if (!sklearn.Utility.isTensor(value, 'numpy.ndarray')) {
-                        return null;
-                    }
-                    weights.set(i.toString(), value);
-                }
-                return weights;
-            }
-        }
-        return null;
+        return this.dimensions ? ('[' + this.dimensions.map((dimension) => dimension.toString()).join(',') + ']') : '';
     }
 };
 
 sklearn.Error = class extends Error {
 
     constructor(message) {
         super(message);
```

## netron/view.js

### js-beautify {}

```diff
@@ -1089,36 +1089,48 @@
                 });
                 nodeSidebar.on('error', (sender, error) => {
                     if (this._model) {
                         error.context = this._model.identifier;
                     }
                     this.error(error, null, null);
                 });
-                nodeSidebar.on('activate', (sender, argument) => {
-                    this._graph.select([argument]);
+                nodeSidebar.on('activate', (sender, value) => {
+                    this._graph.select([value]);
                 });
                 nodeSidebar.on('deactivate', () => {
                     this._graph.select(null);
                 });
+                nodeSidebar.on('select', (sender, value) => {
+                    this.scrollTo(this._graph.activate(value));
+                });
                 this._sidebar.open(nodeSidebar.render(), 'Node Properties');
             } catch (error) {
                 if (error) {
                     error.context = this._model.identifier;
                 }
                 this.error(error, 'Error showing node properties.', null);
             }
         }
     }
 
-    showConnectionProperties(argument) {
+    showConnectionProperties(value, from, to) {
         try {
             if (this._menu) {
                 this._menu.close();
             }
-            const connectionSidebar = new view.ConnectionSidebar(this._host, argument);
+            const connectionSidebar = new view.ConnectionSidebar(this._host, value, from, to);
+            connectionSidebar.on('activate', (sender, value) => {
+                this._graph.select([value]);
+            });
+            connectionSidebar.on('deactivate', () => {
+                this._graph.select(null);
+            });
+            connectionSidebar.on('select', (sender, value) => {
+                this.scrollTo(this._graph.activate(value));
+            });
             connectionSidebar.on('error', (sender, error) => {
                 if (this._model) {
                     error.context = this._model.identifier;
                 }
                 this.error(error, null, null);
             });
             this._sidebar.open(connectionSidebar.render(), 'Connection Properties');
@@ -1758,24 +1770,24 @@
                     }
                 }
             }
         }
         for (const input of graph.inputs) {
             const viewInput = this.createInput(input);
             for (const value of input.value) {
-                this.createValue(value).from(viewInput);
+                this.createValue(value).from = viewInput;
             }
         }
         for (const node of graph.nodes) {
             const viewNode = this.createNode(node);
             const inputs = node.inputs;
             for (const input of inputs) {
                 for (const value of input.value) {
                     if (value.name != '' && !value.initializer) {
-                        this.createValue(value).to(viewNode);
+                        this.createValue(value).to.push(viewNode);
                     }
                 }
             }
             let outputs = node.outputs;
             if (node.chain && node.chain.length > 0) {
                 const chainOutputs = node.chain[node.chain.length - 1].outputs;
                 if (chainOutputs.length > 0) {
@@ -1786,22 +1798,22 @@
                 for (const value of output.value) {
                     if (!value) {
                         const error = new view.Error('Invalid null argument.');
                         error.context = this.model.identifier;
                         throw error;
                     }
                     if (value.name != '') {
-                        this.createValue(value).from(viewNode);
+                        this.createValue(value).from = viewNode;
                     }
                 }
             }
 
             if (node.controlDependencies && node.controlDependencies.length > 0) {
                 for (const value of node.controlDependencies) {
-                    this.createValue(value).to(viewNode, true);
+                    this.createValue(value).controlDependency(viewNode);
                 }
             }
             const createCluster = (name) => {
                 if (!clusters.has(name)) {
                     this.setNode({
                         name: name,
                         rx: 5,
@@ -1835,42 +1847,55 @@
                     }
                 }
             }
         }
         for (const output of graph.outputs) {
             const viewOutput = this.createOutput(output);
             for (const value of output.value) {
-                this.createValue(value).to(viewOutput);
+                this.createValue(value).to.push(viewOutput);
             }
         }
     }
 
     build(document, origin) {
         for (const value of this._values.values()) {
             value.build();
         }
         super.build(document, origin);
     }
 
     select(selection) {
-        for (const element of this._selection) {
-            element.deselect();
+        if (this._selection.size > 0) {
+            for (const element of this._selection) {
+                element.deselect();
+            }
+            this._selection.clear();
         }
-        this._selection.clear();
-        let array = [];
         if (selection) {
+            let array = [];
             for (const value of selection) {
                 if (this._table.has(value)) {
                     const element = this._table.get(value);
                     array = array.concat(element.select());
                     this._selection.add(element);
                 }
             }
+            return array;
         }
-        return array;
+        return null;
+    }
+
+    activate(value) {
+        if (this._table.has(value)) {
+            this.select(null);
+            const element = this._table.get(value);
+            element.activate();
+            return this.select([value]);
+        }
+        return [];
     }
 
     focus(selection) {
         for (const value of selection) {
             const element = this._table.get(value);
             if (element && !this._selection.has(element)) {
                 element.select();
@@ -1925,15 +1950,15 @@
                 error.context = this.context.model.identifier;
             }
             throw error;
         }
         const content = this.context.view.options.names && (node.name || node.location) ? (node.name || node.location) : type.name.split('.').pop();
         const tooltip = this.context.view.options.names && (node.name || node.location) ? type.name : (node.name || node.location);
         const title = header.add(null, styles, content, tooltip);
-        title.on('click', () => this.context.view.showNodeProperties(node));
+        title.on('click', () => this.context.activate(node));
         if (node.type.nodes && node.type.nodes.length > 0) {
             const definition = header.add(null, styles, '\u0192', 'Show Function Definition');
             definition.on('click', () => this.context.view.pushGraph(node.type));
         }
         if (node.nodes) {
             // this._expand = header.add(null, styles, '+', null);
             // this._expand.on('click', () => this.toggle());
@@ -1959,15 +1984,15 @@
         sortedAttributes.sort((a, b) => {
             const au = a.name.toUpperCase();
             const bu = b.name.toUpperCase();
             return (au < bu) ? -1 : (au > bu) ? 1 : 0;
         });
         if (initializers.length > 0 || hiddenInitializers || sortedAttributes.length > 0) {
             const list = this.list();
-            list.on('click', () => this.context.view.showNodeProperties(node));
+            list.on('click', () => this.context.activate(node));
             for (const initializer of initializers) {
                 const value = initializer.value[0];
                 const type = value.type;
                 let shape = '';
                 let separator = '';
                 if (type && type.shape && type.shape.dimensions && Array.isArray(type.shape.dimensions)) {
                     shape = '\u3008' + type.shape.dimensions.map((d) => (d !== null && d !== undefined) ? d : '?').join('\u00D7') + '\u3009';
@@ -2035,14 +2060,18 @@
         // this._graph.build(document, parent);
         // this._graph.update();
         this.canvas.width = 300;
         this.canvas.height = 300;
         this.layout();
         this.context.update();
     }
+
+    activate() {
+        this.context.view.showNodeProperties(this.value);
+    }
 };
 
 view.Input = class extends grapher.Node {
 
     constructor(context, value) {
         super();
         this.context = context;
@@ -2066,14 +2095,18 @@
     get inputs() {
         return [];
     }
 
     get outputs() {
         return [this.value];
     }
+
+    activate() {
+        this.context.view.showModelProperties();
+    }
 };
 
 view.Output = class extends grapher.Node {
 
     constructor(context, value) {
         super();
         this.context = context;
@@ -2091,56 +2124,55 @@
     get inputs() {
         return [this.value];
     }
 
     get outputs() {
         return [];
     }
+
+    activate() {
+        this.context.view.showModelProperties();
+    }
 };
 
 view.Value = class {
 
     constructor(context, argument) {
         this.context = context;
         this.value = argument;
+        this.from = null;
+        this.to = [];
     }
 
-    from(node) {
-        this._from = node;
-    }
-
-    to(node, controlDependency) {
-        this._to = this._to || [];
-        if (controlDependency) {
-            this._controlDependencies = this._controlDependencies || new Set();
-            this._controlDependencies.add(this._to.length);
-        }
-        this._to.push(node);
+    controlDependency(node) {
+        this._controlDependencies = this._controlDependencies || new Set();
+        this._controlDependencies.add(this.to.length);
+        this.to.push(node);
     }
 
     build() {
         this._edges = this._edges || [];
-        if (this._from && this._to) {
-            for (let i = 0; i < this._to.length; i++) {
-                const to = this._to[i];
+        if (this.from && Array.isArray(this.to)) {
+            for (let i = 0; i < this.to.length; i++) {
+                const to = this.to[i];
                 let content = '';
                 const type = this.value.type;
                 if (type &&
                     type.shape &&
                     type.shape.dimensions &&
                     type.shape.dimensions.length > 0 &&
                     type.shape.dimensions.every((dim) => !dim || Number.isInteger(dim) || dim instanceof base.Int64 || (typeof dim === 'string'))) {
                     content = type.shape.dimensions.map((dim) => (dim !== null && dim !== undefined) ? dim : '?').join('\u00D7');
                     content = content.length > 16 ? '' : content;
                 }
                 if (this.context.view.options.names) {
                     content = this.value.name.split('\n').shift(); // custom argument id
                 }
-                const edge = new view.Edge(this, this._from, to);
-                edge.v = this._from.name;
+                const edge = new view.Edge(this, this.from, to);
+                edge.v = this.from.name;
                 edge.w = to.name;
                 if (content) {
                     edge.label = content;
                 }
                 edge.id = 'edge-' + this.value.name;
                 if (this._controlDependencies && this._controlDependencies.has(i)) {
                     edge.class = 'edge-path-control-dependency';
@@ -2160,14 +2192,21 @@
     }
 
     deselect() {
         for (const edge of this._edges) {
             edge.deselect();
         }
     }
+
+    activate() {
+        const value = this.value;
+        const from = this.from.value;
+        const to = this.to.map((node) => node.value);
+        this.context.view.showConnectionProperties(value, from, to);
+    }
 };
 
 view.Edge = class extends grapher.Edge {
 
     constructor(value, from, to) {
         super(from, to);
         this.value = value;
@@ -2178,23 +2217,26 @@
             return 2;
         }
         return 1;
     }
 
     emit(event) {
         switch (event) {
-            case 'pointerover':
+            case 'pointerover': {
                 this.value.context.focus([this.value.value]);
                 break;
-            case 'pointerleave':
+            }
+            case 'pointerleave': {
                 this.value.context.blur([this.value.value]);
                 break;
-            case 'click':
-                // this.value.context.view.showConnectionProperties(this.value.value);
+            }
+            case 'click': {
+                this.value.context.activate(this.value.value);
                 break;
+            }
             default:
                 break;
         }
     }
 };
 
 view.Sidebar = class {
@@ -2280,14 +2322,26 @@
             container.focus();
         }
     }
 };
 
 view.Control = class {
 
+    constructor(host) {
+        this._host = host;
+    }
+
+    createElement(tagName, className) {
+        const element = this._host.document.createElement(tagName);
+        if (className) {
+            element.setAttribute('class', className);
+        }
+        return element;
+    }
+
     on(event, callback) {
         this._events = this._events || {};
         this._events[event] = this._events[event] || [];
         this._events[event].push(callback);
     }
 
     emit(event, data) {
@@ -2295,183 +2349,188 @@
             for (const callback of this._events[event]) {
                 callback(this, data);
             }
         }
     }
 };
 
-view.NodeSidebar = class extends view.Control {
+view.ObjectSidebar = class extends view.Control {
+
+    constructor(host) {
+        super(host);
+        this._container = this.createElement('div', 'sidebar-object');
+    }
+
+    add(name, item) {
+        const entry = new view.NameValueView(this._host, name, item);
+        const element = entry.render();
+        this._container.appendChild(element);
+    }
+
+    addProperty(name, value, style) {
+        const item = new view.ValueTextView(this._host, value, style);
+        this.add(name, item);
+        return item;
+    }
+
+    addHeader(title) {
+        const element = this.createElement('div', 'sidebar-header');
+        element.innerText = title;
+        this._container.appendChild(element);
+    }
+
+    render() {
+        return [this._container];
+    }
+};
+
+view.NodeSidebar = class extends view.ObjectSidebar {
 
     constructor(host, node) {
-        super();
-        this._host = host;
+        super(host);
         this._node = node;
-        this._elements = [];
         this._attributes = [];
         this._inputs = [];
         this._outputs = [];
-
-        const container = this._host.document.createElement('div');
-        container.className = 'sidebar-node';
-        this._elements.push(container);
-
         if (node.type) {
-            let showDocumentation = null;
             const type = node.type;
+            const item = this.addProperty('type', node.type.identifier || node.type.name);
             if (type && (type.description || type.inputs || type.outputs || type.attributes)) {
-                showDocumentation = {};
-                showDocumentation.text = type.nodes ? '\u0192' : '?';
-                showDocumentation.callback = () => {
+                item.action(type.nodes ? '\u0192' : '?', () => {
                     this.emit('show-documentation', null);
-                };
+                });
             }
-            this._addProperty('type', new view.ValueTextView(this._host, node.type.identifier || node.type.name, showDocumentation));
             if (node.type.module) {
-                this._addProperty('module', new view.ValueTextView(this._host, node.type.module));
+                this.addProperty('module', node.type.module);
             }
         }
-
         if (node.name) {
-            this._addProperty('name', new view.ValueTextView(this._host, node.name));
+            this.addProperty('name', node.name);
         }
-
         if (node.location) {
-            this._addProperty('location', new view.ValueTextView(this._host, node.location));
+            this.addProperty('location', node.location);
         }
-
         if (node.description) {
-            this._addProperty('description', new view.ValueTextView(this._host, node.description));
+            this.addProperty('description', node.description);
         }
-
         if (node.device) {
-            this._addProperty('device', new view.ValueTextView(this._host, node.device));
+            this.addProperty('device', node.device);
         }
-
         const attributes = node.attributes;
         if (attributes && attributes.length > 0) {
+            this.addHeader('Attributes');
             const sortedAttributes = node.attributes.slice();
             sortedAttributes.sort((a, b) => {
                 const au = a.name.toUpperCase();
                 const bu = b.name.toUpperCase();
                 return (au < bu) ? -1 : (au > bu) ? 1 : 0;
             });
-            this._addHeader('Attributes');
             for (const attribute of sortedAttributes) {
                 this._addAttribute(attribute.name, attribute);
             }
         }
-
         const inputs = node.inputs;
         if (inputs && inputs.length > 0) {
-            this._addHeader('Inputs');
+            this.addHeader('Inputs');
             for (const input of inputs) {
                 this._addInput(input.name, input);
             }
         }
-
         const outputs = node.outputs;
         if (outputs && outputs.length > 0) {
-            this._addHeader('Outputs');
+            this.addHeader('Outputs');
             for (const output of outputs) {
                 this._addOutput(output.name, output);
             }
         }
     }
 
-    render() {
-        return this._elements;
-    }
-
-    _addHeader(title) {
-        const element = this._host.document.createElement('div');
-        element.className = 'sidebar-header';
-        element.innerText = title;
-        this._elements[0].appendChild(element);
-    }
-
-    _addProperty(name, value) {
-        const item = new view.NameValueView(this._host, name, value);
-        this._elements[0].appendChild(item.render());
-    }
-
     _addAttribute(name, attribute) {
-        const value = new view.AttributeView(this._host, attribute);
-        value.on('show-graph', (sender, graph) => {
-            this.emit('show-graph', graph);
-        });
+        let value = null;
+        switch (attribute.type) {
+            case 'tensor': {
+                value = new view.ValueView(this._host, {
+                    type: attribute.value.type,
+                    initializer: attribute.value
+                }, '');
+                value.on('export-tensor', (sender, value) => this.emit('export-tensor', value));
+                value.on('error', (sender, value) => this.emit('error', value));
+                break;
+            }
+            case 'tensor[]': {
+                const values = attribute.value.map((value) => {
+                    return {
+                        type: value.type,
+                        initializer: value
+                    };
+                });
+                value = new view.ArgumentView(this._host, {
+                    value: values
+                }, '');
+                break;
+            }
+            default: {
+                value = new view.AttributeView(this._host, attribute);
+                value.on('show-graph', (sender, graph) => {
+                    this.emit('show-graph', graph);
+                });
+                break;
+            }
+        }
         const item = new view.NameValueView(this._host, name, value);
         this._attributes.push(item);
-        this._elements[0].appendChild(item.render());
+        this._container.appendChild(item.render());
     }
 
     _addInput(name, input) {
         if (input.value.length > 0) {
-            const value = new view.ParameterView(this._host, input);
+            const value = new view.ArgumentView(this._host, input);
             value.on('export-tensor', (sender, value) => this.emit('export-tensor', value));
             value.on('error', (sender, value) => this.emit('error', value));
             value.on('activate', (sender, value) => this.emit('activate', value));
             value.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            value.on('select', (sender, value) => this.emit('select', value));
             const item = new view.NameValueView(this._host, name, value);
             this._inputs.push(item);
-            this._elements[0].appendChild(item.render());
+            this._container.appendChild(item.render());
         }
     }
 
     _addOutput(name, output) {
         if (output.value.length > 0) {
-            const value = new view.ParameterView(this._host, output);
+            const value = new view.ArgumentView(this._host, output);
             value.on('activate', (sender, value) => this.emit('activate', value));
             value.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            value.on('select', (sender, value) => this.emit('select', value));
             const item = new view.NameValueView(this._host, name, value);
             this._outputs.push(item);
-            this._elements[0].appendChild(item.render());
+            this._container.appendChild(item.render());
         }
     }
 };
 
-view.ConnectionSidebar = class extends view.Control {
-
-    constructor(host, argument) {
-        super();
-        this._host = host;
-        this._argument = argument;
-        this._elements = [];
-    }
-
-    render() {
-        return this._elements;
-    }
-};
-
-view.NameValueView = class {
+view.NameValueView = class extends view.Control {
 
     constructor(host, name, value) {
+        super(host);
         this._host = host;
         this._name = name;
         this._value = value;
-
-        const nameElement = this._host.document.createElement('div');
-        nameElement.className = 'sidebar-item-name';
-
-        const nameInputElement = this._host.document.createElement('input');
-        nameInputElement.setAttribute('type', 'text');
-        nameInputElement.setAttribute('value', name);
-        nameInputElement.setAttribute('title', name);
-        nameInputElement.setAttribute('readonly', 'true');
-        nameElement.appendChild(nameInputElement);
-
-        const valueElement = this._host.document.createElement('div');
-        valueElement.className = 'sidebar-item-value-list';
-
+        const nameElement = this.createElement('div', 'sidebar-item-name');
+        const input = this.createElement('input');
+        input.setAttribute('type', 'text');
+        input.setAttribute('value', name);
+        input.setAttribute('title', name);
+        input.setAttribute('readonly', 'true');
+        nameElement.appendChild(input);
+        const valueElement = this.createElement('div', 'sidebar-item-value-list');
         for (const element of value.render()) {
             valueElement.appendChild(element);
         }
-
-        this._element = this._host.document.createElement('div');
-        this._element.className = 'sidebar-item';
+        this._element = this.createElement('div', 'sidebar-item');
         this._element.appendChild(nameElement);
         this._element.appendChild(valueElement);
     }
 
     get name() {
         return this._name;
     }
@@ -2513,451 +2572,538 @@
     render() {
         return this._elements;
     }
 };
 
 view.ValueTextView = class {
 
-    constructor(host, value, action) {
+    constructor(host, value, style) {
         this._host = host;
-        this._elements = [];
-        const element = this._host.document.createElement('div');
-        element.className = 'sidebar-item-value';
-        this._elements.push(element);
-
-        if (action) {
-            this._action = this._host.document.createElement('div');
-            this._action.className = 'sidebar-item-value-expander';
-            this._action.innerHTML = action.text;
-            this._action.addEventListener('click', () => {
-                action.callback();
-            });
-            element.appendChild(this._action);
+        this._element = this._host.document.createElement('div');
+        this._element.className = 'sidebar-item-value';
+        if (value) {
+            const list = Array.isArray(value) ? value : [value];
+            let className = 'sidebar-item-value-line';
+            for (const item of list) {
+                const line = this._host.document.createElement('div');
+                line.className = className;
+                switch (style) {
+                    case 'code':
+                        line.innerHTML = '<code>' + item + '<code>';
+                        break;
+                    case 'bold':
+                        line.innerHTML = '<b>' + item + '<b>';
+                        break;
+                    default:
+                        line.innerText = item;
+                        break;
+                }
+                this._element.appendChild(line);
+                className = 'sidebar-item-value-line-border';
+            }
         }
+    }
 
-        const list = Array.isArray(value) ? value : [value];
-        let className = 'sidebar-item-value-line';
-        for (const item of list) {
-            const line = this._host.document.createElement('div');
-            line.className = className;
-            line.innerText = item;
-            element.appendChild(line);
-            className = 'sidebar-item-value-line-border';
-        }
+    action(text, callback) {
+        this._action = this._host.document.createElement('div');
+        this._action.className = 'sidebar-item-value-expander';
+        this._action.innerHTML = text;
+        this._action.addEventListener('click', () => {
+            callback();
+        });
+        this._element.insertBefore(this._action, this._element.childNodes[0]);
     }
 
     render() {
-        return this._elements;
+        return [this._element];
     }
 
     toggle() {}
 };
 
-view.ValueView = class extends view.Control {
-
-    _bold(name, value) {
-        const line = this._host.document.createElement('div');
-        line.innerHTML = name + ': ' + '<b>' + value + '</b>';
-        this._add(line);
-    }
-
-    _code(name, value) {
-        const line = this._host.document.createElement('div');
-        line.innerHTML = name + ': ' + '<code><b>' + value + '</b></code>';
-        this._add(line);
-    }
-
-    _add(child) {
-        child.className = this._element.childNodes.length < 2 ? 'sidebar-item-value-line' : 'sidebar-item-value-line-border';
-        this._element.appendChild(child);
-    }
-
-    _tensor(value) {
-        const contentLine = this._host.document.createElement('pre');
-        try {
-            const tensor = new view.Tensor(value);
-            const layout = tensor.layout;
-            if (layout) {
-                const layouts = new Map([
-                    ['sparse', 'Sparse'],
-                    ['sparse.coo', 'Sparse COO'],
-                    ['sparse.csr', 'Sparse CSR'],
-                    ['sparse.csc', 'Sparse CSC'],
-                    ['sparse.bsr', 'Sparse BSR'],
-                    ['sparse.bsc', 'Sparse BSC']
-                ]);
-                if (layouts.has(layout)) {
-                    this._bold('layout', layouts.get(layout));
-                }
-            }
-            if (Array.isArray(tensor.stride) && tensor.stride.length > 0) {
-                this._code('stride', tensor.stride.join(','));
-            }
-            if (tensor.layout !== '<' && tensor.layout !== '>' && tensor.layout !== '|' && tensor.layout !== 'sparse' && tensor.layout !== 'sparse.coo') {
-                contentLine.innerHTML = "Tensor layout '" + tensor.layout + "' is not implemented.";
-            } else if (tensor.empty) {
-                contentLine.innerHTML = 'Tensor data is empty.';
-            } else if (tensor.type && tensor.type.dataType === '?') {
-                contentLine.innerHTML = 'Tensor data type is not defined.';
-            } else if (tensor.type && !tensor.type.shape) {
-                contentLine.innerHTML = 'Tensor shape is not defined.';
-            } else {
-                contentLine.innerHTML = tensor.toString();
-
-                if (this._host.save &&
-                    value.type.shape && value.type.shape.dimensions &&
-                    value.type.shape.dimensions.length > 0) {
-                    this._saveButton = this._host.document.createElement('div');
-                    this._saveButton.className = 'sidebar-item-value-expander';
-                    this._saveButton.innerHTML = '&#x1F4BE;';
-                    this._saveButton.addEventListener('click', () => {
-                        this.emit('export-tensor', tensor);
-                    });
-                    this._element.appendChild(this._saveButton);
-                }
-            }
-        } catch (err) {
-            contentLine.innerHTML = err.toString();
-            this.emit('error', err);
-        }
-        const valueLine = this._host.document.createElement('div');
-        valueLine.className = 'sidebar-item-value-line-border';
-        valueLine.appendChild(contentLine);
-        this._element.appendChild(valueLine);
-    }
-};
-
-view.AttributeView = class extends view.ValueView {
+view.AttributeView = class extends view.Control {
 
     constructor(host, attribute) {
-        super();
-        this._host = host;
+        super(host);
         this._attribute = attribute;
-        this._element = this._host.document.createElement('div');
-        this._element.className = 'sidebar-item-value';
-
+        this._element = this.createElement('div', 'sidebar-item-value');
         const type = this._attribute.type;
-        if (type) {
-            this._expander = this._host.document.createElement('div');
-            this._expander.className = 'sidebar-item-value-expander';
+        if (type && type !== 'tensor') {
+            this._expander = this.createElement('div', 'sidebar-item-value-expander');
             this._expander.innerText = '+';
             this._expander.addEventListener('click', () => {
                 this.toggle();
             });
             this._element.appendChild(this._expander);
         }
         const value = this._attribute.value;
         switch (type) {
             case 'graph': {
-                const line = this._host.document.createElement('div');
-                line.className = 'sidebar-item-value-line-link';
+                const line = this.createElement('div', 'sidebar-item-value-line-link');
                 line.innerHTML = value.name;
                 line.addEventListener('click', () => {
                     this.emit('show-graph', value);
                 });
                 this._element.appendChild(line);
                 break;
             }
             case 'function': {
-                const line = this._host.document.createElement('div');
-                line.className = 'sidebar-item-value-line-link';
+                const line = this.createElement('div', 'sidebar-item-value-line-link');
                 line.innerHTML = value.type.name;
                 line.addEventListener('click', () => {
                     this.emit('show-graph', value.type);
                 });
                 this._element.appendChild(line);
                 break;
             }
+            case 'tensor': {
+                throw new view.Error('Attribute view tensor not implemented.');
+            }
             default: {
                 let content = new view.Formatter(value, type).toString();
                 if (content && content.length > 1000) {
                     content = content.substring(0, 1000) + '\u2026';
                 }
                 if (content && typeof content === 'string') {
                     content = content.split('<').join('&lt;').split('>').join('&gt;');
                 }
-                const line = this._host.document.createElement('div');
-                line.className = 'sidebar-item-value-line';
+                const line = this.createElement('div', 'sidebar-item-value-line');
                 line.innerHTML = content ? content : '&nbsp;';
                 this._element.appendChild(line);
             }
         }
     }
 
     render() {
         return [this._element];
     }
 
     toggle() {
         if (this._expander.innerText == '+') {
             this._expander.innerText = '-';
-
             const type = this._attribute.type;
             const value = this._attribute.value;
             const content = type == 'tensor' && value && value.type ? value.type.toString() : this._attribute.type;
-            const typeLine = this._host.document.createElement('div');
-            typeLine.className = 'sidebar-item-value-line-border';
+            const typeLine = this.createElement('div', 'sidebar-item-value-line-border');
             typeLine.innerHTML = 'type: ' + '<code><b>' + content + '</b></code>';
             this._element.appendChild(typeLine);
-
             const description = this._attribute.description;
             if (description) {
-                const descriptionLine = this._host.document.createElement('div');
-                descriptionLine.className = 'sidebar-item-value-line-border';
+                const descriptionLine = this.createElement('div', 'sidebar-item-value-line-border');
                 descriptionLine.innerHTML = description;
                 this._element.appendChild(descriptionLine);
             }
-
-            if (this._attribute.type == 'tensor' && value) {
-                this._tensor(value);
-            }
         } else {
             this._expander.innerText = '+';
             while (this._element.childElementCount > 2) {
                 this._element.removeChild(this._element.lastChild);
             }
         }
     }
 };
 
-view.ParameterView = class extends view.Control {
+view.ArgumentView = class extends view.Control {
 
-    constructor(host, list) {
+    constructor(host, argument) {
         super();
-        this._list = list;
+        this._argument = argument;
         this._elements = [];
         this._items = [];
-        for (const value of list.value) {
-            const item = new view.ArgumentView(host, value);
+        for (const value of argument.value) {
+            const item = new view.ValueView(host, value);
             item.on('export-tensor', (sender, value) => this.emit('export-tensor', value));
             item.on('error', (sender, value) => this.emit('error', value));
             item.on('activate', (sender, value) => this.emit('activate', value));
             item.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            item.on('select', (sender, value) => this.emit('select', value));
             this._items.push(item);
-            this._elements.push(item.render());
+            for (const element of item.render()) {
+                this._elements.push(element);
+            }
         }
     }
 
     render() {
         return this._elements;
     }
 
     toggle() {
         for (const item of this._items) {
             item.toggle();
         }
     }
 };
 
-view.ArgumentView = class extends view.ValueView {
-
-    constructor(host, argument) {
-        super();
-        this._host = host;
-        this._argument = argument;
-
-        this._element = this._host.document.createElement('div');
-        this._element.className = 'sidebar-item-value';
-
-        const type = this._argument.type;
-        const initializer = this._argument.initializer;
-        const quantization = this._argument.quantization;
-        const location = this._argument.location !== undefined;
+view.ValueView = class extends view.Control {
 
+    constructor(host, value, name) {
+        super(host);
+        this._value = value;
+        this._element = this.createElement('div', 'sidebar-item-value');
+        const type = this._value.type;
+        const initializer = this._value.initializer;
+        const quantization = this._value.quantization;
+        const location = this._value.location !== undefined;
         if (initializer) {
             this._element.classList.add('sidebar-item-value-dark');
         }
-
-        if (type || initializer || quantization || location) {
-            this._expander = this._host.document.createElement('div');
-            this._expander.className = 'sidebar-item-value-expander';
+        if (type || initializer || quantization || location || name === undefined) {
+            this._expander = this.createElement('div', 'sidebar-item-value-expander');
             this._expander.innerText = '+';
             this._expander.addEventListener('click', () => {
                 this.toggle();
             });
             this._element.appendChild(this._expander);
         }
-
-        const name = this._argument.name ? this._argument.name.split('\n').shift() : ''; // custom argument id
-        this._hasId = name ? true : false;
+        const tensor = name !== undefined;
+        name = this._value.name ? this._value.name.split('\n').shift() : ''; // custom argument id
+        this._hasId = name && !tensor ? true : false;
         this._hasCategory = initializer && initializer.category ? true : false;
-        if (this._hasId || (!this._hasCategory && !type)) {
+        if (this._hasId || (!this._hasCategory && !type && !tensor)) {
             this._hasId = true;
-            const nameLine = this._host.document.createElement('div');
-            nameLine.className = 'sidebar-item-value-line';
+            const nameLine = this.createElement('div', 'sidebar-item-value-line');
             if (typeof name !== 'string') {
                 throw new Error("Invalid value identifier '" + JSON.stringify(name) + "'.");
             }
             nameLine.innerHTML = '<span class=\'sidebar-item-value-line-content\'>name: <b>' + (name || ' ') + '</b></span>';
-            nameLine.addEventListener('pointerenter', () => this.emit('activate', this._argument));
-            nameLine.addEventListener('pointerleave', () => this.emit('deactivate', this._argument));
+            nameLine.addEventListener('pointerenter', () => this.emit('activate', this._value));
+            nameLine.addEventListener('pointerleave', () => this.emit('deactivate', this._value));
+            if (!initializer) {
+                nameLine.style.cursor = 'pointer';
+                nameLine.addEventListener('click', () => this.emit('select', this._value));
+            }
             this._element.appendChild(nameLine);
         } else if (this._hasCategory) {
             this._bold('category', initializer.category);
         } else if (type) {
-            this._code('type', type.toString().split('<').join('&lt;').split('>').join('&gt;'));
+            this._code('tensor', type.toString().split('<').join('&lt;').split('>').join('&gt;'));
         }
     }
 
     render() {
-        return this._element;
+        return [this._element];
     }
 
     toggle() {
         if (this._expander) {
             if (this._expander.innerText == '+') {
                 this._expander.innerText = '-';
-
-                const initializer = this._argument.initializer;
+                const initializer = this._value.initializer;
                 if (this._hasId && this._hasCategory) {
                     this._bold('category', initializer.category);
                 }
-
                 let type = null;
                 let denotation = null;
-                if (this._argument.type) {
-                    type = this._argument.type.toString();
-                    denotation = this._argument.type.denotation || null;
+                if (this._value.type) {
+                    type = this._value.type.toString();
+                    denotation = this._value.type.denotation || null;
                 }
                 if (type && (this._hasId || this._hasCategory)) {
-                    this._code('type', type.split('<').join('&lt;').split('>').join('&gt;'));
+                    this._code('tensor', type.split('<').join('&lt;').split('>').join('&gt;'));
                 }
                 if (denotation) {
                     this._code('denotation', denotation);
                 }
-
-                const description = this._argument.description;
+                const description = this._value.description;
                 if (description) {
-                    const descriptionLine = this._host.document.createElement('div');
-                    descriptionLine.className = 'sidebar-item-value-line-border';
+                    const descriptionLine = this.createElement('div', 'sidebar-item-value-line-border');
                     descriptionLine.innerHTML = description;
                     this._element.appendChild(descriptionLine);
                 }
-
-                const quantization = this._argument.quantization;
+                const quantization = this._value.quantization;
                 if (quantization) {
-                    const quantizationLine = this._host.document.createElement('div');
-                    quantizationLine.className = 'sidebar-item-value-line-border';
+                    const quantizationLine = this.createElement('div', 'sidebar-item-value-line-border');
                     const content = !Array.isArray(quantization) ? quantization : '<br><br>' + quantization.map((value) => '  ' + value).join('<br>');
                     quantizationLine.innerHTML = '<span class=\'sidebar-item-value-line-content\'>quantization: ' + '<b>' + content + '</b></span>';
                     this._element.appendChild(quantizationLine);
                 }
-
-                const location = this._argument.location;
+                const location = this._value.location;
                 if (location !== undefined) {
                     this._bold('location', location);
                 }
-
                 if (initializer) {
                     this._tensor(initializer);
                 }
             } else {
                 this._expander.innerText = '+';
                 while (this._element.childElementCount > 2) {
                     this._element.removeChild(this._element.lastChild);
                 }
             }
         }
     }
+
+    _bold(name, value) {
+        const line = this.createElement('div');
+        line.innerHTML = name + ': ' + '<b>' + value + '</b>';
+        this._add(line);
+    }
+
+    _code(name, value) {
+        const line = this.createElement('div');
+        line.innerHTML = name + ': ' + '<code><b>' + value + '</b></code>';
+        this._add(line);
+    }
+
+    _add(child) {
+        child.className = this._element.childNodes.length < 2 ? 'sidebar-item-value-line' : 'sidebar-item-value-line-border';
+        this._element.appendChild(child);
+    }
+
+    _tensor(value) {
+        const contentLine = this.createElement('pre');
+        try {
+            const tensor = new view.Tensor(value);
+            const layout = tensor.layout;
+            if (layout) {
+                const layouts = new Map([
+                    ['sparse', 'Sparse'],
+                    ['sparse.coo', 'Sparse COO'],
+                    ['sparse.csr', 'Sparse CSR'],
+                    ['sparse.csc', 'Sparse CSC'],
+                    ['sparse.bsr', 'Sparse BSR'],
+                    ['sparse.bsc', 'Sparse BSC']
+                ]);
+                if (layouts.has(layout)) {
+                    this._bold('layout', layouts.get(layout));
+                }
+            }
+            if (Array.isArray(tensor.stride) && tensor.stride.length > 0) {
+                this._code('stride', tensor.stride.join(','));
+            }
+            if (tensor.layout !== '<' && tensor.layout !== '>' && tensor.layout !== '|' && tensor.layout !== 'sparse' && tensor.layout !== 'sparse.coo') {
+                contentLine.innerHTML = "Tensor layout '" + tensor.layout + "' is not implemented.";
+            } else if (tensor.empty) {
+                contentLine.innerHTML = 'Tensor data is empty.';
+            } else if (tensor.type && tensor.type.dataType === '?') {
+                contentLine.innerHTML = 'Tensor data type is not defined.';
+            } else if (tensor.type && !tensor.type.shape) {
+                contentLine.innerHTML = 'Tensor shape is not defined.';
+            } else {
+                contentLine.innerHTML = tensor.toString();
+                if (this._host.save &&
+                    value.type.shape && value.type.shape.dimensions &&
+                    value.type.shape.dimensions.length > 0) {
+                    this._saveButton = this.createElement('div', 'sidebar-item-value-expander');
+                    this._saveButton.innerHTML = '&#x1F4BE;';
+                    this._saveButton.addEventListener('click', () => {
+                        this.emit('export-tensor', tensor);
+                    });
+                    this._element.appendChild(this._saveButton);
+                }
+            }
+        } catch (err) {
+            contentLine.innerHTML = err.toString();
+            this.emit('error', err);
+        }
+        const valueLine = this.createElement('div', 'sidebar-item-value-line-border');
+        valueLine.appendChild(contentLine);
+        this._element.appendChild(valueLine);
+    }
 };
 
-view.ModelSidebar = class extends view.Control {
+view.NodeView = class extends view.Control {
 
-    constructor(host, model, graph) {
+    constructor(host, node) {
+        super(host);
+        this._node = node;
+        this._element = this.createElement('div', 'sidebar-item-value');
+        const name = node.name;
+        const type = node.type ? node.type.name : '';
+        if (name && type) {
+            this._expander = this.createElement('div', 'sidebar-item-value-expander');
+            this._expander.innerText = '+';
+            this._expander.addEventListener('click', () => {
+                this.toggle();
+            });
+            this._element.appendChild(this._expander);
+        }
+        if (type) {
+            const type = node.type.name;
+            const element = this.createElement('div', 'sidebar-item-value-line');
+            element.innerHTML = '<span class=\'sidebar-item-value-line-content\'>node: <b>' + (type || ' ') + '</b></span>';
+            element.addEventListener('pointerenter', () => this.emit('activate', this._node));
+            element.addEventListener('pointerleave', () => this.emit('deactivate', this._node));
+            element.addEventListener('click', () => this.emit('select', this._node));
+            element.style.cursor = 'pointer';
+            this._element.appendChild(element);
+        } else {
+            const element = this.createElement('div', 'sidebar-item-value-line');
+            element.innerHTML = '<span class=\'sidebar-item-value-line-content\'>name: <b>' + (name || ' ') + '</b></span>';
+            element.addEventListener('pointerenter', () => this.emit('activate', this._node));
+            element.addEventListener('pointerleave', () => this.emit('deactivate', this._node));
+            element.addEventListener('click', () => this.emit('select', this._node));
+            element.style.cursor = 'pointer';
+            this._element.appendChild(element);
+        }
+    }
+
+    render() {
+        return [this._element];
+    }
+
+    toggle() {
+        if (this._expander) {
+            if (this._expander.innerText == '+') {
+                this._expander.innerText = '-';
+                const name = this._node.name;
+                const element = this.createElement('div', 'sidebar-item-value-line-border');
+                element.innerHTML = '<span class=\'sidebar-item-value-line-content\'>name: <b>' + name + '</b></span>';
+                element.addEventListener('pointerenter', () => this.emit('activate', this._node));
+                element.addEventListener('pointerleave', () => this.emit('deactivate', this._node));
+                element.addEventListener('click', () => this.emit('select', this._node));
+                element.style.cursor = 'pointer';
+                this._element.appendChild(element);
+            } else {
+                this._expander.innerText = '+';
+                while (this._element.childElementCount > 2) {
+                    this._element.removeChild(this._element.lastChild);
+                }
+            }
+        }
+    }
+};
+
+view.NodeListView = class extends view.Control {
+
+    constructor(host, list) {
         super();
         this._host = host;
-        this._model = model;
+        this._elements = [];
+        for (const node of list) {
+            const item = new view.NodeView(host, node);
+            item.on('activate', (sender, value) => this.emit('activate', value));
+            item.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            item.on('select', (sender, value) => this.emit('select', value));
+            item.toggle();
+            for (const element of item.render()) {
+                this._elements.push(element);
+            }
+        }
+    }
+
+    render() {
+        return this._elements;
+    }
+};
+
+view.ConnectionSidebar = class extends view.ObjectSidebar {
 
-        this._container = this._host.document.createElement('div');
-        this._container.className = 'sidebar-node';
+    constructor(host, value, from, to) {
+        super(host);
+        this._host = host;
+        this._value = value;
+        this._from = from;
+        this._to = to;
+        const name = value.name.split('\n')[0];
+        this.addProperty('name', name);
+        if (value.type) {
+            const item = new view.ValueView(this._host, value, '');
+            this.add('type', item);
+            item.toggle();
+        }
+        if (from) {
+            this.addHeader('Inputs');
+            const list = new view.NodeListView(host, [from]);
+            list.on('activate', (sender, value) => this.emit('activate', value));
+            list.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            list.on('select', (sender, value) => this.emit('select', value));
+            const item = new view.NameValueView(this._host, 'from', list);
+            this._container.appendChild(item.render());
+        }
+        if (Array.isArray(to) && to.length > 0) {
+            this.addHeader('Outputs');
+            const list = new view.NodeListView(this._host, to);
+            list.on('activate', (sender, value) => this.emit('activate', value));
+            list.on('deactivate', (sender, value) => this.emit('deactivate', value));
+            list.on('select', (sender, value) => this.emit('select', value));
+            const item = new view.NameValueView(this._host, 'to', list);
+            this._container.appendChild(item.render());
+        }
+    }
+};
+
+view.ModelSidebar = class extends view.ObjectSidebar {
+
+    constructor(host, model, graph) {
+        super(host);
+        this._model = model;
 
         if (model.format) {
-            this._addProperty('format', new view.ValueTextView(this._host, model.format));
+            this.addProperty('format', model.format);
         }
         if (model.producer) {
-            this._addProperty('producer', new view.ValueTextView(this._host, model.producer));
+            this.addProperty('producer', model.producer);
         }
         if (model.name) {
-            this._addProperty('name', new view.ValueTextView(this._host, model.name));
+            this.addProperty('name', model.name);
         }
         if (model.version) {
-            this._addProperty('version', new view.ValueTextView(this._host, model.version));
+            this.addProperty('version', model.version);
         }
         if (model.description) {
-            this._addProperty('description', new view.ValueTextView(this._host, model.description));
+            this.addProperty('description', model.description);
         }
         if (model.domain) {
-            this._addProperty('domain', new view.ValueTextView(this._host, model.domain));
+            this.addProperty('domain', model.domain);
         }
         if (model.imports) {
-            this._addProperty('imports', new view.ValueTextView(this._host, model.imports));
+            this.addProperty('imports', model.imports);
         }
         if (model.runtime) {
-            this._addProperty('runtime', new view.ValueTextView(this._host, model.runtime));
+            this.addProperty('runtime', model.runtime);
         }
         if (model.metadata) {
             for (const entry of model.metadata) {
-                this._addProperty(entry.name, new view.ValueTextView(this._host, entry.value));
+                this.addProperty(entry.name, entry.value);
             }
         }
         const graphs = Array.isArray(model.graphs) ? model.graphs : [];
-        if (graphs.length > 1) {
-            const graphSelector = new view.SelectView(this._host, model.graphs, graph);
-            graphSelector.on('change', (sender, data) => {
+        if (graphs.length > 1 || (graphs.length === 1 && graphs[0].name)) {
+            const selector = new view.SelectView(this._host, model.graphs, graph);
+            selector.on('change', (sender, data) => {
                 this.emit('update-active-graph', data);
             });
-            this._addProperty('subgraph', graphSelector);
+            this.addProperty('graph', selector);
         }
 
         if (graph) {
             if (graph.version) {
-                this._addProperty('version', new view.ValueTextView(this._host, graph.version));
+                this.addProperty('version', graph.version);
             }
             if (graph.type) {
-                this._addProperty('type', new view.ValueTextView(this._host, graph.type));
+                this.addProperty('type', graph.type);
             }
             if (graph.tags) {
-                this._addProperty('tags', new view.ValueTextView(this._host, graph.tags));
+                this.addProperty('tags', graph.tags);
             }
             if (graph.description) {
-                this._addProperty('description', new view.ValueTextView(this._host, graph.description));
+                this.addProperty('description', graph.description);
             }
             if (Array.isArray(graph.inputs) && graph.inputs.length > 0) {
-                this._addHeader('Inputs');
+                this.addHeader('Inputs');
                 for (const input of graph.inputs) {
                     this.addArgument(input.name, input);
                 }
             }
             if (Array.isArray(graph.outputs) && graph.outputs.length > 0) {
-                this._addHeader('Outputs');
+                this.addHeader('Outputs');
                 for (const output of graph.outputs) {
                     this.addArgument(output.name, output);
                 }
             }
         }
     }
 
     render() {
         return [this._container];
     }
 
-    _addHeader(title) {
-        const element = this._host.document.createElement('div');
-        element.className = 'sidebar-header';
-        element.innerText = title;
-        this._container.appendChild(element);
-    }
-
-    _addProperty(name, value) {
-        const item = new view.NameValueView(this._host, name, value);
-        this._container.appendChild(item.render());
-    }
-
     addArgument(name, argument) {
-        const value = new view.ParameterView(this._host, argument);
+        const value = new view.ArgumentView(this._host, argument);
         value.toggle();
         const item = new view.NameValueView(this._host, name, value);
         this._container.appendChild(item.render());
     }
 };
 
 view.DocumentationSidebar = class extends view.Control {
@@ -2967,136 +3113,118 @@
         this._host = host;
         this._type = type;
     }
 
     render() {
         if (!this._elements) {
             this._elements = [];
-
             const type = view.Documentation.format(this._type);
-
-            const element = this._host.document.createElement('div');
-            element.setAttribute('class', 'sidebar-documentation');
-
+            const element = this.createElement('div', 'sidebar-documentation');
             this._append(element, 'h1', type.name);
-
             if (type.summary) {
                 this._append(element, 'p', type.summary);
             }
-
             if (type.description) {
                 this._append(element, 'p', type.description);
             }
-
             if (Array.isArray(type.attributes) && type.attributes.length > 0) {
                 this._append(element, 'h2', 'Attributes');
                 const attributes = this._append(element, 'dl');
                 for (const attribute of type.attributes) {
                     this._append(attributes, 'dt', attribute.name + (attribute.type ? ': <tt>' + attribute.type + '</tt>' : ''));
                     this._append(attributes, 'dd', attribute.description);
                 }
                 element.appendChild(attributes);
             }
-
             if (Array.isArray(type.inputs) && type.inputs.length > 0) {
                 this._append(element, 'h2', 'Inputs' + (type.inputs_range ? ' (' + type.inputs_range + ')' : ''));
                 const inputs = this._append(element, 'dl');
                 for (const input of type.inputs) {
                     this._append(inputs, 'dt', input.name + (input.type ? ': <tt>' + input.type + '</tt>' : '') + (input.option ? ' (' + input.option + ')' : ''));
                     this._append(inputs, 'dd', input.description);
                 }
             }
-
             if (Array.isArray(type.outputs) && type.outputs.length > 0) {
                 this._append(element, 'h2', 'Outputs' + (type.outputs_range ? ' (' + type.outputs_range + ')' : ''));
                 const outputs = this._append(element, 'dl');
                 for (const output of type.outputs) {
                     this._append(outputs, 'dt', output.name + (output.type ? ': <tt>' + output.type + '</tt>' : '') + (output.option ? ' (' + output.option + ')' : ''));
                     this._append(outputs, 'dd', output.description);
                 }
             }
-
             if (Array.isArray(type.type_constraints) && type.type_constraints.length > 0) {
                 this._append(element, 'h2', 'Type Constraints');
                 const type_constraints = this._append(element, 'dl');
                 for (const type_constraint of type.type_constraints) {
                     this._append(type_constraints, 'dt', type_constraint.type_param_str + ': ' + type_constraint.allowed_type_strs.map((item) => '<tt>' + item + '</tt>').join(', '));
                     this._append(type_constraints, 'dd', type_constraint.description);
                 }
             }
-
             if (Array.isArray(type.examples) && type.examples.length > 0) {
                 this._append(element, 'h2', 'Examples');
                 for (const example of type.examples) {
                     this._append(element, 'h3', example.summary);
                     this._append(element, 'pre', example.code);
                 }
             }
-
             if (Array.isArray(type.references) && type.references.length > 0) {
                 this._append(element, 'h2', 'References');
                 const references = this._append(element, 'ul');
                 for (const reference of type.references) {
                     this._append(references, 'li', reference.description);
                 }
             }
-
             if (type.domain && type.version && type.support_level) {
                 this._append(element, 'h2', 'Support');
                 this._append(element, 'dl', 'In domain <tt>' + type.domain + '</tt> since version <tt>' + type.version + '</tt> at support level <tt>' + type.support_level + '</tt>.');
             }
-
             if (this._host.type === 'Electron') {
                 element.addEventListener('click', (e) => {
                     if (e.target && e.target.href) {
                         const url = e.target.href;
                         if (url.startsWith('http://') || url.startsWith('https://')) {
                             e.preventDefault();
                             this.emit('navigate', {
                                 link: url
                             });
                         }
                     }
                 });
             }
-
             this._elements = [element];
         }
         return this._elements;
     }
 
     _append(parent, type, content) {
-        const element = this._host.document.createElement(type);
+        const element = this.createElement(type);
         if (content) {
             element.innerHTML = content;
         }
         parent.appendChild(element);
         return element;
     }
 };
 
 view.FindSidebar = class extends view.Control {
 
     constructor(host, graph) {
-        super();
-        this._host = host;
+        super(host);
         this._graph = graph;
         this._table = new Map();
-        this._searchElement = this._host.document.createElement('input');
-        this._searchElement.setAttribute('class', 'sidebar-find-search');
+        this._searchElement = this.createElement('input', 'sidebar-find-search');
         this._searchElement.setAttribute('id', 'search');
         this._searchElement.setAttribute('type', 'text');
         this._searchElement.setAttribute('spellcheck', 'false');
         this._searchElement.setAttribute('placeholder', 'Search');
         this._searchElement.addEventListener('input', (e) => {
             this.update(e.target.value);
             this.emit('search-text-changed', e.target.value);
         });
-        this._contentElement = this._host.document.createElement('ol');
-        this._contentElement.setAttribute('class', 'sidebar-find-content');
+        this._contentElement = this.createElement('ol', 'sidebar-find-content');
         this._contentElement.addEventListener('click', (e) => {
             const identifier = e.target.getAttribute('data');
             if (this._table.has(identifier)) {
                 this.emit('select', this._table.get(identifier));
             }
         });
     }
@@ -3128,15 +3256,15 @@
         }
         this._table.clear();
         let index = 0;
         const add = (value, content) => {
             const key = index.toString();
             index++;
             this._table.set(key, value);
-            const element = this._host.document.createElement('li');
+            const element = this.createElement('li');
             element.innerText = content;
             element.setAttribute('data', key);
             element.addEventListener('pointerover', (e) => {
                 const identifier = e.target.getAttribute('data');
                 if (this._table.has(identifier)) {
                     this.emit('focus', this._table.get(identifier));
                 }
@@ -5215,15 +5343,15 @@
         this.register('./megengine', ['.tm', '.mge']);
         this.register('./pickle', ['.pkl', '.pickle', '.joblib', '.model', '.meta', '.pb', '.pt', '.h5', '.pkl.z', '.joblib.z', '.pdstates', '.mge']);
         this.register('./cntk', ['.model', '.cntk', '.cmf', '.dnn']);
         this.register('./paddle', ['.pdmodel', '.pdiparams', '.pdparams', '.pdopt', '.paddle', '__model__', '.__model__', '.pbtxt', '.txt', '.tar', '.tar.gz', '.nb']);
         this.register('./bigdl', ['.model', '.bigdl']);
         this.register('./darknet', ['.cfg', '.model', '.txt', '.weights']);
         this.register('./weka', ['.model']);
-        this.register('./rknn', ['.rknn', '.nb', '.onnx']);
+        this.register('./rknn', ['.rknn', '.nb', '.onnx', '.json']);
         this.register('./dlc', ['.dlc', 'model', '.params']);
         this.register('./armnn', ['.armnn', '.json']);
         this.register('./mnn', ['.mnn']);
         this.register('./ncnn', ['.param', '.bin', '.cfg.ncnn', '.weights.ncnn', '.ncnnmodel']);
         this.register('./tnn', ['.tnnproto', '.tnnmodel']);
         this.register('./tengine', ['.tmfile']);
         this.register('./mslite', ['.ms']);
@@ -5241,14 +5369,15 @@
         this.register('./om', ['.om', '.onnx', '.pb', '.engine']);
         this.register('./nnabla', ['.nntxt'], ['.nnp']);
         this.register('./hickle', ['.h5', '.hkl']);
         this.register('./nnef', ['.nnef', '.dat']);
         this.register('./cambricon', ['.cambricon']);
         this.register('./onednn', ['.json']);
         this.register('./mlir', ['.mlir']);
+        this.register('./sentencepiece', ['.model']);
         this.register('./hailo', ['.hn', '.har']);
         this.register('./safetensors', ['.safetensors']);
     }
 
     register(id, factories, containers) {
         for (const extension of factories) {
             this._factories.push({
```

## Comparing `netron-7.1.0.dist-info/METADATA` & `netron-7.1.1.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: netron
-Version: 7.1.0
+Version: 7.1.1
 Summary: Viewer for neural network, deep learning, and machine learning models
 Home-page: https://github.com/lutzroeder/netron
 Author: Lutz Roeder
 Author-email: lutzroeder@users.noreply.github.com
 License: MIT
 Keywords: onnx,keras,tensorflow,tflite,coreml,mxnet,caffe,caffe2,torchscript,pytorch,ncnn,mnn,openvino,darknet,paddlepaddle,chainer,artificial intelligence,machine learning,deep learning,neural network,visualizer,viewer
 Classifier: Intended Audience :: Developers
```

## Comparing `netron-7.1.0.dist-info/RECORD` & `netron-7.1.1.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 netron/__init__.py,sha256=4X_FliRM4GvcwqYDnJ7SHmJoR6u4vdcPBgzfGe62os0,1526
 netron/acuity-metadata.json,sha256=QWN9j-u1qIO3fDekkb81x2htnA2_fBcBza54PmIswYg,57889
-netron/acuity.js,sha256=H5hyUhpLeBEdBh6C6f3D2_ZBTPgZIIfoTbi3_GHV89Q,24150
+netron/acuity.js,sha256=myqxfYzNkhlC91Z9aFJV_YXNsd84OjSqmzdWPz3t9lM,22497
 netron/armnn-metadata.json,sha256=QF244hVPg7xbSSg1EHff8sQCPEKf8-KqGEOHa-AE3io,11340
 netron/armnn-schema.js,sha256=D0drkSXP9KuMls2jd_GipMEgvT2EX_ItpejdUALrCiU,108710
-netron/armnn.js,sha256=bcnJ3H2TdfQlmtDEnvi3H7OPLrWf6E0NDbj9b1MmSn8,13793
+netron/armnn.js,sha256=xCGSzsKfhqSG2YD0huqHSkp71EAgxvFPUfHQqvRsLR0,12340
 netron/barracuda.js,sha256=jTlPAGGYv1x23ftW5Bt2VGIQU_RAwcmgUV9qXTa3VbQ,16571
 netron/base.js,sha256=LIoN0aukoBM2NF1apE3aIPZkdoSfb60mYZ5h2KD-POQ,38139
 netron/bigdl-metadata.json,sha256=TRtkhMaMeFVOIG7C7sB5cdedbGRifKEQFGQKjqikIBM,2017
 netron/bigdl-proto.js,sha256=i9PTO7r9Z0JktlrmY6n8BIcj1E9AJ7Gc0U_FoZvtcXI,24356
 netron/bigdl.js,sha256=on2pXMueLaI-Hc6wYLHDCrVQsRPE40s7iwY6UgUnmcI,12745
 netron/browser.js,sha256=9H48oPrOLVmMy1RuBjXfGB-RK2I1n1-82c-vYKW_qog,34678
 netron/caffe-metadata.json,sha256=PfjdGkv0ND0C_RRZTlBp8xU4dbO7IaRVsJswgfS6l-k,9505
@@ -29,15 +29,15 @@
 netron/dagre.js,sha256=mpY-dfNmzuFCrna4ld50bSM31xd9EhxEohZFG2X8KYI,102117
 netron/darknet-metadata.json,sha256=dw1vThEJwGVlV74G2cvyzQ6v7LWoGdF_LAnUM77JfXk,20570
 netron/darknet.js,sha256=ZGevgBNQdtdzGLpuzpKH83Ow8iNngVtl3RXK5LBo2tc,54886
 netron/dl4j-metadata.json,sha256=wh1OJVSWT2PQtQRq35NanPXfNF8s0bspM2Ww573U8To,1417
 netron/dl4j.js,sha256=5RCP4eaRqHlV8k9M7aO3puMrKcHlrzS6rjNM3oaS96I,16955
 netron/dlc-metadata.json,sha256=VKrDC_pYt3IvHyUMmBb3Rvw6W_UZVl9UV5A3k_FSJqE,2309
 netron/dlc-schema.js,sha256=M2wD-2CaEGkoxwv4-ivwNayP3HLLGsmhnRbpAKG497I,8706
-netron/dlc.js,sha256=etIbzhNNiPs9t_VZW9pw2cZwH_sPxbl8hunT99ERdqA,26954
+netron/dlc.js,sha256=68_wCB0au0nbDUQ2hMWiGzc3COcDwdgfAzOLzhgAqD0,26986
 netron/dnn-metadata.json,sha256=5-48ChRcuDJQ5WA6_c5xOYs66J3XjsPYbrz7LyH_d9E,1777
 netron/dnn-proto.js,sha256=vpoxH8Jw21cerjYxea6AL1EAfcnO-lhqEjAbJWYu5L0,11533
 netron/dnn.js,sha256=qkpCsurI6f-Q2gsCjj3_dmLDKFFJ5rOqrihNuc8XxA0,10594
 netron/favicon.ico,sha256=o3hrI04KVfImdrgo9Ucs1f27tMPVjCiJzGogjeR8pHg,34494
 netron/flatbuffers.js,sha256=2IFTatwF8YRtHR-0dO69W5gGxmKgZMc7L8qzPB7zIzI,11358
 netron/flax.js,sha256=8bNiqG8IluO0Sg3P-eo0X6juZn44kTVceL5SK2XFfeE,7734
 netron/flexbuffers.js,sha256=djGSf33a0wTn_3Ux2i7ZO5kJwESfB7WqnEcS2eXRiEI,7568
@@ -47,15 +47,15 @@
 netron/grapher.js,sha256=PYuEgUOBzt9lSuaY4KPHHV3LS3gPJKYKwZ2hfWKtgzo,25602
 netron/hailo-metadata.json,sha256=RVG-oCGnGid9UOHRdIQ_BINS-GkvG7uyTenguCiKdMs,29456
 netron/hailo.js,sha256=6z49tAAkjcNuV_Uo1BmpmPsZLIEZDjUlVJ-lYyI_1lA,11521
 netron/hdf5.js,sha256=-iS1B7LVP_ogiXwyz0GlKh5rxScT8HWSsHl5YakMNK4,57289
 netron/hickle.js,sha256=R1V48MTME8WhYOTYJa6ijS2tpvbWMeqBRX7qJZO51bw,6789
 netron/icon.png,sha256=8PZX7X6-sLBgonyQTGelX60C661x3YZ13eIGcuXQcHc,58106
 netron/imgdnn.js,sha256=qhg0atOv43eoRVT8d6hIkPgEQOu8Fsu3ANb6QVttQWc,1392
-netron/index.html,sha256=Rmp5x5dJmRGhwLXAJcbaCqJndemirW_EhPWX6-YUedQ,44057
+netron/index.html,sha256=KLPizdGadb7m_-JSP8ExPa9uNVaF3zrNqbzoqzVM5ec,44059
 netron/index.js,sha256=NDSySEu8DFQ0mN00nDOJZXQdXP7nG90INtJ1f6sYx_Q,4113
 netron/json.js,sha256=cor_V2_vWltKePIM5OQMvmZRwyl4wsn9vkejf2i4G2c,18643
 netron/keras-metadata.json,sha256=PExbUAIA4PpP35ARwz8Lp66EKfgIuAEY1b2_yWTZzLQ,254682
 netron/keras.js,sha256=HHJxewX74eI-crOS3IYnYrIdpWf1bGyQonHncjlkH5Y,54531
 netron/kmodel.js,sha256=l0zlbLQY2chZCGbQKQpEomsQo3tD7Vv3j7RsRBQAckA,64052
 netron/lasagne-metadata.json,sha256=UAy5q6DnjJWEav_Vo-G-OncwvHVuytNlTStpDJ8MB2U,244
 netron/lasagne.js,sha256=YMDnlOtC8cqHh_SICDF4E_gRsXJNBnTRnkGHcAZdC4g,7050
@@ -73,50 +73,52 @@
 netron/mslite-metadata.json,sha256=auv76wwLS_Cg4R2t1VXZcUMSUp0louocjSSOXwibMAk,85458
 netron/mslite-schema.js,sha256=-f6KUBaFsKh6q8mJi_8r6ZGK93B6Ih2RKcRRKLsABlA,171745
 netron/mslite.js,sha256=Q1XHky40Y-VaBC-3FxWjCPaZ4GZfYH57losB50-zpCY,14997
 netron/mxnet-metadata.json,sha256=sf1taquijGWKNTAkxVbDMAk4wbkiZ-IYkkYekHxtKfc,11884
 netron/mxnet.js,sha256=IR3XwlDzHpZADr_FJHIGFPSYQqLC2BeY5Y1PlEqbImQ,37803
 netron/ncnn-metadata.json,sha256=uokKe5QeTBOjxVo4jcuSMQAFqsm9SXETwWLZlv67JRU,30899
 netron/ncnn.js,sha256=Pk-t3uOI_5AYRXQ84bAdh8CvKwN0AcMmYF9e1YP3Pfc,37976
-netron/nnabla-metadata.json,sha256=fqBPePVmcKoHTp6YAzEpOaSZBrdEUv-SOEUVGM6fJ50,290482
-netron/nnabla-proto.js,sha256=sWfuD9QEF9nRxNfTo4eQSMu8lV5mpmQRJXUkpPIDlrI,434215
+netron/nnabla-metadata.json,sha256=oqnWeP6fJQ0w8091k7KE5m6pOYx0j2uhDw17LBDQ278,295328
+netron/nnabla-proto.js,sha256=vFAwAnNeEdzM8kJq_IVFMPtoLJ96fGEnp8N2fwEhhJc,441665
 netron/nnabla.js,sha256=lKpVO2UzNuk9ni2CdPQRObAv6twblwHxMfu4hn_Xc6E,11418
 netron/nnef.js,sha256=gOoqFv531ftHkGbC_otlXYE79qAnzkDjDXkCFSGbnt8,2224
-netron/numpy.js,sha256=rFVSNsdTf5NjTCyagrvLgkGhq1Z8X4ElDPf-aZPOn0E,15163
+netron/numpy.js,sha256=vNYzg9OSiXt9ue1fy0PLEqs238PHBnsus80YPhidNLo,14205
 netron/om-metadata.json,sha256=nWz35Zjqfe_JqM9F9mydQnso0k4j3D1YuKgMJpS8_4Y,53079
 netron/om-proto.js,sha256=1SbZHKiX3S0r98-rX8dGl4bsF7x-DrQDbNxseeunpks,37006
-netron/om.js,sha256=BGiqgu75KFRTHSkBLgGqgAJbzbff9F4F5bQxVLMfdRE,29164
+netron/om.js,sha256=zqWWEkUgQ1eRCyLHKDr-TTaK4o_IkpityqLMirtvucY,29188
 netron/onednn-metadata.json,sha256=ZzCrrVEwXx36AWZ_TbOLa6PM-VL4LpEit0u35yj_-LU,6818
 netron/onednn.js,sha256=GN22Xi5q2pKMPxMoIfV9vjojpiRhaz8f0LU5jZedZuM,11961
-netron/onnx-metadata.json,sha256=9CqZ-2b9qbmcGHeOS6V7zUZdCqpCnyuAZc5DLQiuwrA,2912056
+netron/onnx-metadata.json,sha256=YbQEBIBso79c88GycNeTTTjjs9nVqtW3Y38GnGuK8Es,2961943
 netron/onnx-proto.js,sha256=l35_Dhs_wpLvGTuSmWuHsRfXBiJU97JdCA7PzzsvV_s,59899
 netron/onnx-schema.js,sha256=bCJy80ZVAxcNbsa60fBbpJCzOoapMZjf4TnAutaBzqU,15717
 netron/onnx.js,sha256=B5hzPPUE31MlB8B6Qe1nkE7UlALQDjT3HDuneGnDR5o,88981
 netron/onnx.py,sha256=GkNnqLXIZjHMviBblu_XorcDKrNcvmVZ0A-Yxg5l2Hg,9053
 netron/openvino-metadata.json,sha256=heC0fS0DL26NLrlVXcEcs4GldF_LYWDBJp2iI1G8_zo,84585
 netron/openvino.js,sha256=jlRGDsNzIHgcdt9vgT0llqZehJGbPQ0f9UGvssy0wH4,44560
 netron/paddle-metadata.json,sha256=iyV8jUl7AhSOMTVcWLrChsBqS1l8iqGYl99KLYFl93w,2894
 netron/paddle-proto.js,sha256=2vXAa6JSlrxnI7UXYaGwDik4RyaT90QQR7Kc-Kbc5qI,60111
 netron/paddle-schema.js,sha256=DmewWGVK8zHjPz-7GQ6md9WqQsX0sexfw3UizluGedU,19797
 netron/paddle.js,sha256=9_QmEZvgqWCJ2PfObKjgH09cgxhqNNhgNUfLXDO0n9I,37551
-netron/pickle.js,sha256=WOISUM0Q4h3NHu2wE_YciK-n03Qdn2qBKf67MlFpSWY,5527
+netron/pickle.js,sha256=LJBPQWxb3F9bxj7yKzgGZ-pQiLbXLhUkpwb9qpi9seE,6596
 netron/protobuf.js,sha256=ywdCgnvVRrpARySOloWs_P7e9MliActsCYuqgYZvayM,42713
-netron/python.js,sha256=0o_nL66ICpgbP5oPz3N1zjWieByPfmxSr7INPU2TVV4,303716
+netron/python.js,sha256=ksRoZzABBKqs-OztiuPD8IkI9o9ngjJAL9dIVpD-Qv4,304361
 netron/pytorch-metadata.json,sha256=Cxn_zeHPmO4R3I4uh70vKBWlyk8-kMyckPCqECGGPCw,411132
 netron/pytorch-schema.js,sha256=DsFhOphzFGysPeVnnxcqvHgs0zhYy2mTEpBwre8r6IA,13170
 netron/pytorch.js,sha256=-bumsIBab2IDf_9pr9Vee4NzUmpeYOQbiSvKlZEHouw,182294
 netron/pytorch.py,sha256=gkEnA4OGqooxARhnsEZfzDYmAsycMSTkLXIB1hMJm9Y,24259
-netron/rknn-metadata.json,sha256=KaVXz6q_TPrAFBaOaSvHhNDU2m-rmeyIl2NThAa7lxY,5473
+netron/rknn-metadata.json,sha256=QqQPb1-r5J_uFtRE0FX7-nPfDDnnZbncejhy6Oo1Omo,6136
 netron/rknn-schema.js,sha256=i5gzD6mHjr1jFjTv30mHJk13KErOdaX3O4xSWabkLzE,4263
-netron/rknn.js,sha256=7sCaiyVpOvHJspBq0H4-gZ0SLosDa3DLplwj0hAzyik,24805
+netron/rknn.js,sha256=01tNUVN4du1Upe601SkELf_wdIZT4HtT8Ts0AIBAwuY,25066
 netron/safetensors.js,sha256=sNrm4dJlfj5cPKOzMH_IknrxS3juImytbC_2Pl-l9xI,4571
+netron/sentencepiece-proto.js,sha256=YoIksXa3uOhYlJR3P4Jb9dNjpkqvmc0rRVt8ZTf59Ks,25814
+netron/sentencepiece.js,sha256=Ox2et7rSpZW0MVANeYIfHW8lM6INEuVs8OIVNmhuFXA,2182
 netron/server.js,sha256=uo-0Btwxwc2h9E91ANSjwx5YT0Q36FPN5RXP2M9LlDM,5865
-netron/server.py,sha256=ZCWthynMu_W_DTzs6udDhAksGcjMhOz6-OdGSGIiCuU,11874
+netron/server.py,sha256=l2gn8k7kQb8OHYaCKQqzjuoqZy_HEBTRLcBthZMo__g,11874
 netron/sklearn-metadata.json,sha256=L9UWeoEfqkFzZOT4WiupFpVwdDvcuwlXiesuChzqIwc,160693
-netron/sklearn.js,sha256=a_yRJGsbcy67pBI-T6Y9mF2VWTtCrNlPLSyQEZwvfMo,14746
+netron/sklearn.js,sha256=oIALotnNQmUY7U1Q4Jd5Rpe-_9COWxU9LS5Hkn_fj3Q,11185
 netron/tar.js,sha256=ivL2nPokTaMqz9X763EoNzDOS802A4hH2HkLjJYFLoU,4901
 netron/tengine-metadata.json,sha256=v4dIwOf9t_f1bhYkJBORa71SBWlYuwi3LuZZJQjcYGY,27914
 netron/tengine.js,sha256=ZLNFxRmPo4hNLJaFQbBa5ZRIkZxvUnPj7eq9DbkeYiQ,28094
 netron/tensorrt.js,sha256=yi8c89zuTvk_rfHdzgCi0FwALclKWUe0u8KiKABmtGY,5278
 netron/text.js,sha256=RtcaVwGuG3uC0zGcc4MOjV3pqBNG8e3ZVSqtsO_fUKU,11077
 netron/tf-metadata.json,sha256=voCEpb8UnnWZ8LG9MDgbDaMZ3YL3FwBhuv1RfWri6wY,2221556
 netron/tf-proto.js,sha256=MWEi1dbXh0uxz6-yNUvF93YaJaXW-M8nQ6o2oNpK2qE,363531
@@ -127,18 +129,18 @@
 netron/tnn-metadata.json,sha256=Je5JnWH0t4gWsSkj9YbWIzzbcYEoP3XXwVMa7sAH3_A,20380
 netron/tnn.js,sha256=sBCYEleRWan_kJg_r3p8qalT3JM3Xacv9JIv13LpvMo,26868
 netron/torch-metadata.json,sha256=fj2b1n_Ih7eZdst4ohdUEAL5T3XmjTMlkUBmUo3Ogng,12510
 netron/torch.js,sha256=WcrV81ntqURliC20t3YHpd_iF3f_omGyprl1OOUNsns,41535
 netron/uff-metadata.json,sha256=kVCe02DZKfSoTgwqfjh18jQcImre1KcYkg76_WNOagI,2333
 netron/uff-proto.js,sha256=U7-KLsLgvBdSeBEclHE8-xaWMqMN_PjoziTOmH7EK9Y,30910
 netron/uff.js,sha256=lgq1pojhH6rClTEL88hgntJwG6-TrXoW6z4WjcRC5HY,12710
-netron/view.js,sha256=pJgK3fKDV8DrshbNS6SkXfRDPBGsSBKpahn3qoj9YAo,237224
+netron/view.js,sha256=-s-LMImZ3P2uPoK_qcJ1rmeknb-QNDjPoi1-yHHyjk4,242983
 netron/weka.js,sha256=TAiwO3z0KhjtfbHOZrfVSidJlJKy538Uu2aCmyyF3aM,8023
 netron/xml.js,sha256=_zng3WkOrLR4OvBYMs0aD04pbmUq6Q2QJQxtETbi2Rw,64034
 netron/xmodel-proto.js,sha256=mFk07nBgAyXBOWllxg-fw-2EGEaIxF231wXlNLK6v5A,55685
 netron/xmodel.js,sha256=FYHJt1B-Ony6vPc_GiGoq9YIkXZyNqrgCfGD3RQTIHg,13916
 netron/zip.js,sha256=Ji6a_L_wsrMJWJm6xyL-Ld_JFFjFB-e2D8plcW-5GQg,30921
-netron-7.1.0.dist-info/METADATA,sha256=WTa2y5OQzAQXJAvqybTbj-JZ-kWKPF-6ZdoSa9EjjlA,1447
-netron-7.1.0.dist-info/WHEEL,sha256=AtBG6SXL3KF_v0NxLf0ehyVOh0cold-JbJYXNGorC6Q,92
-netron-7.1.0.dist-info/entry_points.txt,sha256=3fHM6H_AIEjt21838iCMZ72hmRqtnNTuL66UnCIOSpU,39
-netron-7.1.0.dist-info/top_level.txt,sha256=qt4XhfLsmugdsjAczetcmraULS1GexprL8Ruo2YQubU,7
-netron-7.1.0.dist-info/RECORD,,
+netron-7.1.1.dist-info/METADATA,sha256=gE9HmVySee7KzRzoqeodPZq7oljB8tzka8H6dKGgLwM,1447
+netron-7.1.1.dist-info/WHEEL,sha256=5sUXSg9e4bi7lTLOHcm6QEYwO5TIF1TNbTSVFVjcJcc,92
+netron-7.1.1.dist-info/entry_points.txt,sha256=3fHM6H_AIEjt21838iCMZ72hmRqtnNTuL66UnCIOSpU,39
+netron-7.1.1.dist-info/top_level.txt,sha256=qt4XhfLsmugdsjAczetcmraULS1GexprL8Ruo2YQubU,7
+netron-7.1.1.dist-info/RECORD,,
```

