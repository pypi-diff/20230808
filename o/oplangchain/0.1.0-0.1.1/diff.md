# Comparing `tmp/oplangchain-0.1.0.tar.gz` & `tmp/oplangchain-0.1.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "oplangchain-0.1.0.tar", max compression
+gzip compressed data, was "oplangchain-0.1.1.tar", max compression
```

## Comparing `oplangchain-0.1.0.tar` & `oplangchain-0.1.1.tar`

### file list

```diff
@@ -1,972 +1,972 @@
--rw-r--r--   0        0        0     3074 2023-08-07 14:51:51.064476 oplangchain-0.1.0/oplangchain/__init__.py
--rw-r--r--   0        0        0     3396 2023-08-07 14:51:51.065474 oplangchain-0.1.0/oplangchain/agents/__init__.py
--rw-r--r--   0        0        0    41297 2023-08-07 14:51:51.065474 oplangchain-0.1.0/oplangchain/agents/agent.py
--rw-r--r--   0        0        0    18325 2023-08-07 14:51:51.066475 oplangchain-0.1.0/oplangchain/agents/agent_iterator.py
--rw-r--r--   0        0        0     3464 2023-08-07 14:51:51.067476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/__init__.py
--rw-r--r--   0        0        0      873 2023-08-07 14:51:51.067476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/amadeus/toolkit.py
--rw-r--r--   0        0        0      919 2023-08-07 14:51:51.068473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/azure_cognitive_services.py
--rw-r--r--   0        0        0      369 2023-08-07 14:51:51.068473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/base.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.069473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/conversational_retrieval/__init__.py
--rw-r--r--   0        0        0     3377 2023-08-07 14:51:51.070474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py
--rw-r--r--   0        0        0      730 2023-08-07 14:51:51.070474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/conversational_retrieval/tool.py
--rw-r--r--   0        0        0       19 2023-08-07 14:51:51.071474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/csv/__init__.py
--rw-r--r--   0        0        0     1148 2023-08-07 14:51:51.071474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/csv/base.py
--rw-r--r--   0        0        0      174 2023-08-07 14:51:51.072475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/file_management/__init__.py
--rw-r--r--   0        0        0     2074 2023-08-07 14:51:51.074475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/file_management/toolkit.py
--rw-r--r--   0        0        0       22 2023-08-07 14:51:51.075476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/github/__init__.py
--rw-r--r--   0        0        0     2484 2023-08-07 14:51:51.075476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/github/toolkit.py
--rw-r--r--   0        0        0       21 2023-08-07 14:51:51.076475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/gmail/__init__.py
--rw-r--r--   0        0        0     1567 2023-08-07 14:51:51.077473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/gmail/toolkit.py
--rw-r--r--   0        0        0       20 2023-08-07 14:51:51.077473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/jira/__init__.py
--rw-r--r--   0        0        0     1919 2023-08-07 14:51:51.078473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/jira/toolkit.py
--rw-r--r--   0        0        0       18 2023-08-07 14:51:51.079473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/__init__.py
--rw-r--r--   0        0        0     1713 2023-08-07 14:51:51.079473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/base.py
--rw-r--r--   0        0        0     1819 2023-08-07 14:51:51.080474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/prompt.py
--rw-r--r--   0        0        0      555 2023-08-07 14:51:51.081474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/toolkit.py
--rw-r--r--   0        0        0       23 2023-08-07 14:51:51.081474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/multion/__init__.py
--rw-r--r--   0        0        0      660 2023-08-07 14:51:51.082473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/multion/toolkit.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.082473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/nla/__init__.py
--rw-r--r--   0        0        0     1937 2023-08-07 14:51:51.083474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/nla/tool.py
--rw-r--r--   0        0        0     3765 2023-08-07 14:51:51.084474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/nla/toolkit.py
--rw-r--r--   0        0        0       25 2023-08-07 14:51:51.084474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/office365/__init__.py
--rw-r--r--   0        0        0     1171 2023-08-07 14:51:51.085475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/office365/toolkit.py
--rw-r--r--   0        0        0       26 2023-08-07 14:51:51.086474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/__init__.py
--rw-r--r--   0        0        0     2140 2023-08-07 14:51:51.086474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/base.py
--rw-r--r--   0        0        0    11233 2023-08-07 14:51:51.087474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/planner.py
--rw-r--r--   0        0        0    10460 2023-08-07 14:51:51.088474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/planner_prompt.py
--rw-r--r--   0        0        0     1743 2023-08-07 14:51:51.088474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/prompt.py
--rw-r--r--   0        0        0     3835 2023-08-07 14:51:51.089476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/spec.py
--rw-r--r--   0        0        0     2374 2023-08-07 14:51:51.090474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/toolkit.py
--rw-r--r--   0        0        0       22 2023-08-07 14:51:51.091474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/pandas/__init__.py
--rw-r--r--   0        0        0    11518 2023-08-07 14:51:51.091474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/pandas/base.py
--rw-r--r--   0        0        0     1113 2023-08-07 14:51:51.092475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/pandas/prompt.py
--rw-r--r--   0        0        0      162 2023-08-07 14:51:51.092475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/playwright/__init__.py
--rw-r--r--   0        0        0     3014 2023-08-07 14:51:51.093473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/playwright/toolkit.py
--rw-r--r--   0        0        0       22 2023-08-07 14:51:51.094473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/__init__.py
--rw-r--r--   0        0        0     2322 2023-08-07 14:51:51.094473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/base.py
--rw-r--r--   0        0        0     2489 2023-08-07 14:51:51.095474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/chat_base.py
--rw-r--r--   0        0        0     2773 2023-08-07 14:51:51.095474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/prompt.py
--rw-r--r--   0        0        0     3217 2023-08-07 14:51:51.096473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/toolkit.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.096473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/python/__init__.py
--rw-r--r--   0        0        0     2200 2023-08-07 14:51:51.097476 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/python/base.py
--rw-r--r--   0        0        0      513 2023-08-07 14:51:51.098475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/python/prompt.py
--rw-r--r--   0        0        0       20 2023-08-07 14:51:51.098475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark/__init__.py
--rw-r--r--   0        0        0     2734 2023-08-07 14:51:51.099473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark/base.py
--rw-r--r--   0        0        0      295 2023-08-07 14:51:51.099473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark/prompt.py
--rw-r--r--   0        0        0       23 2023-08-07 14:51:51.100475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/__init__.py
--rw-r--r--   0        0        0     2072 2023-08-07 14:51:51.100475 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/base.py
--rw-r--r--   0        0        0     1202 2023-08-07 14:51:51.101474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/prompt.py
--rw-r--r--   0        0        0     1034 2023-08-07 14:51:51.101474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/toolkit.py
--rw-r--r--   0        0        0       17 2023-08-07 14:51:51.102474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/__init__.py
--rw-r--r--   0        0        0     3434 2023-08-07 14:51:51.102474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/base.py
--rw-r--r--   0        0        0     1428 2023-08-07 14:51:51.103474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/prompt.py
--rw-r--r--   0        0        0     2816 2023-08-07 14:51:51.103474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/toolkit.py
--rw-r--r--   0        0        0       56 2023-08-07 14:51:51.104474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/__init__.py
--rw-r--r--   0        0        0     2408 2023-08-07 14:51:51.105474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/base.py
--rw-r--r--   0        0        0      834 2023-08-07 14:51:51.105474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/prompt.py
--rw-r--r--   0        0        0     2961 2023-08-07 14:51:51.106474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/toolkit.py
--rw-r--r--   0        0        0       23 2023-08-07 14:51:51.107474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/xorbits/__init__.py
--rw-r--r--   0        0        0     3105 2023-08-07 14:51:51.107474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/xorbits/base.py
--rw-r--r--   0        0        0     1070 2023-08-07 14:51:51.107474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/xorbits/prompt.py
--rw-r--r--   0        0        0       22 2023-08-07 14:51:51.108474 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/zapier/__init__.py
--rw-r--r--   0        0        0     1609 2023-08-07 14:51:51.109473 oplangchain-0.1.0/oplangchain/agents/agent_toolkits/zapier/toolkit.py
--rw-r--r--   0        0        0      688 2023-08-07 14:51:51.109473 oplangchain-0.1.0/oplangchain/agents/agent_types.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.110474 oplangchain-0.1.0/oplangchain/agents/chat/__init__.py
--rw-r--r--   0        0        0     4908 2023-08-07 14:51:51.110474 oplangchain-0.1.0/oplangchain/agents/chat/base.py
--rw-r--r--   0        0        0     1706 2023-08-07 14:51:51.111474 oplangchain-0.1.0/oplangchain/agents/chat/output_parser.py
--rw-r--r--   0        0        0     1158 2023-08-07 14:51:51.111474 oplangchain-0.1.0/oplangchain/agents/chat/prompt.py
--rw-r--r--   0        0        0       75 2023-08-07 14:51:51.112474 oplangchain-0.1.0/oplangchain/agents/conversational/__init__.py
--rw-r--r--   0        0        0     4820 2023-08-07 14:51:51.113475 oplangchain-0.1.0/oplangchain/agents/conversational/base.py
--rw-r--r--   0        0        0     1150 2023-08-07 14:51:51.113475 oplangchain-0.1.0/oplangchain/agents/conversational/output_parser.py
--rw-r--r--   0        0        0     1859 2023-08-07 14:51:51.114475 oplangchain-0.1.0/oplangchain/agents/conversational/prompt.py
--rw-r--r--   0        0        0       75 2023-08-07 14:51:51.114475 oplangchain-0.1.0/oplangchain/agents/conversational_chat/__init__.py
--rw-r--r--   0        0        0     4977 2023-08-07 14:51:51.115474 oplangchain-0.1.0/oplangchain/agents/conversational_chat/base.py
--rw-r--r--   0        0        0     2256 2023-08-07 14:51:51.115474 oplangchain-0.1.0/oplangchain/agents/conversational_chat/output_parser.py
--rw-r--r--   0        0        0     2757 2023-08-07 14:51:51.116474 oplangchain-0.1.0/oplangchain/agents/conversational_chat/prompt.py
--rw-r--r--   0        0        0     2995 2023-08-07 14:51:51.116474 oplangchain-0.1.0/oplangchain/agents/initialize.py
--rw-r--r--   0        0        0    17319 2023-08-07 14:51:51.117475 oplangchain-0.1.0/oplangchain/agents/load_tools.py
--rw-r--r--   0        0        0     4371 2023-08-07 14:51:51.117475 oplangchain-0.1.0/oplangchain/agents/loading.py
--rw-r--r--   0        0        0       86 2023-08-07 14:51:51.118474 oplangchain-0.1.0/oplangchain/agents/mrkl/__init__.py
--rw-r--r--   0        0        0     7097 2023-08-07 14:51:51.119474 oplangchain-0.1.0/oplangchain/agents/mrkl/base.py
--rw-r--r--   0        0        0     2706 2023-08-07 14:51:51.119474 oplangchain-0.1.0/oplangchain/agents/mrkl/output_parser.py
--rw-r--r--   0        0        0      641 2023-08-07 14:51:51.119474 oplangchain-0.1.0/oplangchain/agents/mrkl/prompt.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.120474 oplangchain-0.1.0/oplangchain/agents/openai_functions_agent/__init__.py
--rw-r--r--   0        0        0     2527 2023-08-07 14:51:51.121473 oplangchain-0.1.0/oplangchain/agents/openai_functions_agent/agent_token_buffer_memory.py
--rw-r--r--   0        0        0    11896 2023-08-07 14:51:51.121473 oplangchain-0.1.0/oplangchain/agents/openai_functions_agent/base.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.122475 oplangchain-0.1.0/oplangchain/agents/openai_functions_multi_agent/__init__.py
--rw-r--r--   0        0        0    13337 2023-08-07 14:51:51.122475 oplangchain-0.1.0/oplangchain/agents/openai_functions_multi_agent/base.py
--rw-r--r--   0        0        0       76 2023-08-07 14:51:51.123474 oplangchain-0.1.0/oplangchain/agents/react/__init__.py
--rw-r--r--   0        0        0     5664 2023-08-07 14:51:51.124474 oplangchain-0.1.0/oplangchain/agents/react/base.py
--rw-r--r--   0        0        0     1188 2023-08-07 14:51:51.124474 oplangchain-0.1.0/oplangchain/agents/react/output_parser.py
--rw-r--r--   0        0        0     1901 2023-08-07 14:51:51.125474 oplangchain-0.1.0/oplangchain/agents/react/textworld_prompt.py
--rw-r--r--   0        0        0     6122 2023-08-07 14:51:51.125474 oplangchain-0.1.0/oplangchain/agents/react/wiki_prompt.py
--rw-r--r--   0        0        0     1085 2023-08-07 14:51:51.126475 oplangchain-0.1.0/oplangchain/agents/schema.py
--rw-r--r--   0        0        0      106 2023-08-07 14:51:51.127474 oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/__init__.py
--rw-r--r--   0        0        0     3094 2023-08-07 14:51:51.127474 oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/base.py
--rw-r--r--   0        0        0      962 2023-08-07 14:51:51.128474 oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/output_parser.py
--rw-r--r--   0        0        0     1921 2023-08-07 14:51:51.128474 oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/prompt.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.129475 oplangchain-0.1.0/oplangchain/agents/structured_chat/__init__.py
--rw-r--r--   0        0        0     5144 2023-08-07 14:51:51.129475 oplangchain-0.1.0/oplangchain/agents/structured_chat/base.py
--rw-r--r--   0        0        0     3452 2023-08-07 14:51:51.130474 oplangchain-0.1.0/oplangchain/agents/structured_chat/output_parser.py
--rw-r--r--   0        0        0      992 2023-08-07 14:51:51.130474 oplangchain-0.1.0/oplangchain/agents/structured_chat/prompt.py
--rw-r--r--   0        0        0     1402 2023-08-07 14:51:51.131474 oplangchain-0.1.0/oplangchain/agents/tools.py
--rw-r--r--   0        0        0     1475 2023-08-07 14:51:51.131474 oplangchain-0.1.0/oplangchain/agents/types.py
--rw-r--r--   0        0        0      384 2023-08-07 14:51:51.132475 oplangchain-0.1.0/oplangchain/agents/utils.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.132475 oplangchain-0.1.0/oplangchain/agents/xml/__init__.py
--rw-r--r--   0        0        0     3887 2023-08-07 14:51:51.133474 oplangchain-0.1.0/oplangchain/agents/xml/base.py
--rw-r--r--   0        0        0      749 2023-08-07 14:51:51.133474 oplangchain-0.1.0/oplangchain/agents/xml/prompt.py
--rw-r--r--   0        0        0      218 2023-08-07 14:51:51.134474 oplangchain-0.1.0/oplangchain/base_language.py
--rw-r--r--   0        0        0    24769 2023-08-07 14:51:51.134474 oplangchain-0.1.0/oplangchain/cache.py
--rw-r--r--   0        0        0     2839 2023-08-07 14:51:51.135474 oplangchain-0.1.0/oplangchain/callbacks/__init__.py
--rw-r--r--   0        0        0    14484 2023-08-07 14:51:51.136474 oplangchain-0.1.0/oplangchain/callbacks/aim_callback.py
--rw-r--r--   0        0        0    13719 2023-08-07 14:51:51.136474 oplangchain-0.1.0/oplangchain/callbacks/argilla_callback.py
--rw-r--r--   0        0        0     7503 2023-08-07 14:51:51.137474 oplangchain-0.1.0/oplangchain/callbacks/arize_callback.py
--rw-r--r--   0        0        0    11343 2023-08-07 14:51:51.137474 oplangchain-0.1.0/oplangchain/callbacks/arthur_callback.py
--rw-r--r--   0        0        0    15174 2023-08-07 14:51:51.138475 oplangchain-0.1.0/oplangchain/callbacks/base.py
--rw-r--r--   0        0        0    18496 2023-08-07 14:51:51.139474 oplangchain-0.1.0/oplangchain/callbacks/clearml_callback.py
--rw-r--r--   0        0        0    23238 2023-08-07 14:51:51.139474 oplangchain-0.1.0/oplangchain/callbacks/comet_ml_callback.py
--rw-r--r--   0        0        0     6424 2023-08-07 14:51:51.140475 oplangchain-0.1.0/oplangchain/callbacks/context_callback.py
--rw-r--r--   0        0        0     2561 2023-08-07 14:51:51.140475 oplangchain-0.1.0/oplangchain/callbacks/file.py
--rw-r--r--   0        0        0    13157 2023-08-07 14:51:51.141475 oplangchain-0.1.0/oplangchain/callbacks/flyte_callback.py
--rw-r--r--   0        0        0     1410 2023-08-07 14:51:51.141475 oplangchain-0.1.0/oplangchain/callbacks/human.py
--rw-r--r--   0        0        0     5570 2023-08-07 14:51:51.142475 oplangchain-0.1.0/oplangchain/callbacks/infino_callback.py
--rw-r--r--   0        0        0    53773 2023-08-07 14:51:51.142475 oplangchain-0.1.0/oplangchain/callbacks/manager.py
--rw-r--r--   0        0        0    24163 2023-08-07 14:51:51.143474 oplangchain-0.1.0/oplangchain/callbacks/mlflow_callback.py
--rw-r--r--   0        0        0     5348 2023-08-07 14:51:51.143474 oplangchain-0.1.0/oplangchain/callbacks/openai_info.py
--rw-r--r--   0        0        0     5523 2023-08-07 14:51:51.144475 oplangchain-0.1.0/oplangchain/callbacks/promptlayer_callback.py
--rw-r--r--   0        0        0     8823 2023-08-07 14:51:51.144475 oplangchain-0.1.0/oplangchain/callbacks/sagemaker_callback.py
--rw-r--r--   0        0        0     3203 2023-08-07 14:51:51.145474 oplangchain-0.1.0/oplangchain/callbacks/stdout.py
--rw-r--r--   0        0        0     2436 2023-08-07 14:51:51.145474 oplangchain-0.1.0/oplangchain/callbacks/streaming_aiter.py
--rw-r--r--   0        0        0     3364 2023-08-07 14:51:51.145474 oplangchain-0.1.0/oplangchain/callbacks/streaming_aiter_final_only.py
--rw-r--r--   0        0        0     2170 2023-08-07 14:51:51.146474 oplangchain-0.1.0/oplangchain/callbacks/streaming_stdout.py
--rw-r--r--   0        0        0     3368 2023-08-07 14:51:51.147474 oplangchain-0.1.0/oplangchain/callbacks/streaming_stdout_final_only.py
--rw-r--r--   0        0        0     3190 2023-08-07 14:51:51.147474 oplangchain-0.1.0/oplangchain/callbacks/streamlit/__init__.py
--rw-r--r--   0        0        0     5435 2023-08-07 14:51:51.148474 oplangchain-0.1.0/oplangchain/callbacks/streamlit/mutable_expander.py
--rw-r--r--   0        0        0    15671 2023-08-07 14:51:51.149474 oplangchain-0.1.0/oplangchain/callbacks/streamlit/streamlit_callback_handler.py
--rw-r--r--   0        0        0      502 2023-08-07 14:51:51.150474 oplangchain-0.1.0/oplangchain/callbacks/tracers/__init__.py
--rw-r--r--   0        0        0    17018 2023-08-07 14:51:51.150474 oplangchain-0.1.0/oplangchain/callbacks/tracers/base.py
--rw-r--r--   0        0        0     4858 2023-08-07 14:51:51.151474 oplangchain-0.1.0/oplangchain/callbacks/tracers/evaluation.py
--rw-r--r--   0        0        0     8055 2023-08-07 14:51:51.151474 oplangchain-0.1.0/oplangchain/callbacks/tracers/langchain.py
--rw-r--r--   0        0        0     7362 2023-08-07 14:51:51.152474 oplangchain-0.1.0/oplangchain/callbacks/tracers/langchain_v1.py
--rw-r--r--   0        0        0     1537 2023-08-07 14:51:51.152474 oplangchain-0.1.0/oplangchain/callbacks/tracers/run_collector.py
--rw-r--r--   0        0        0     3456 2023-08-07 14:51:51.152474 oplangchain-0.1.0/oplangchain/callbacks/tracers/schemas.py
--rw-r--r--   0        0        0     6027 2023-08-07 14:51:51.153474 oplangchain-0.1.0/oplangchain/callbacks/tracers/stdout.py
--rw-r--r--   0        0        0    18983 2023-08-07 14:51:51.153474 oplangchain-0.1.0/oplangchain/callbacks/tracers/wandb.py
--rw-r--r--   0        0        0     8505 2023-08-07 14:51:51.154474 oplangchain-0.1.0/oplangchain/callbacks/utils.py
--rw-r--r--   0        0        0    20659 2023-08-07 14:51:51.154474 oplangchain-0.1.0/oplangchain/callbacks/wandb_callback.py
--rw-r--r--   0        0        0     8062 2023-08-07 14:51:51.155475 oplangchain-0.1.0/oplangchain/callbacks/whylabs_callback.py
--rw-r--r--   0        0        0     5294 2023-08-07 14:51:51.156475 oplangchain-0.1.0/oplangchain/chains/__init__.py
--rw-r--r--   0        0        0       84 2023-08-07 14:51:51.157475 oplangchain-0.1.0/oplangchain/chains/api/__init__.py
--rw-r--r--   0        0        0     5334 2023-08-07 14:51:51.158475 oplangchain-0.1.0/oplangchain/chains/api/base.py
--rw-r--r--   0        0        0     2452 2023-08-07 14:51:51.159474 oplangchain-0.1.0/oplangchain/chains/api/news_docs.py
--rw-r--r--   0        0        0     3399 2023-08-07 14:51:51.159474 oplangchain-0.1.0/oplangchain/chains/api/open_meteo_docs.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.160475 oplangchain-0.1.0/oplangchain/chains/api/openapi/__init__.py
--rw-r--r--   0        0        0     8750 2023-08-07 14:51:51.161475 oplangchain-0.1.0/oplangchain/chains/api/openapi/chain.py
--rw-r--r--   0        0        0     1791 2023-08-07 14:51:51.161475 oplangchain-0.1.0/oplangchain/chains/api/openapi/prompts.py
--rw-r--r--   0        0        0     1877 2023-08-07 14:51:51.162474 oplangchain-0.1.0/oplangchain/chains/api/openapi/requests_chain.py
--rw-r--r--   0        0        0     1749 2023-08-07 14:51:51.162474 oplangchain-0.1.0/oplangchain/chains/api/openapi/response_chain.py
--rw-r--r--   0        0        0     1920 2023-08-07 14:51:51.163474 oplangchain-0.1.0/oplangchain/chains/api/podcast_docs.py
--rw-r--r--   0        0        0     1026 2023-08-07 14:51:51.163474 oplangchain-0.1.0/oplangchain/chains/api/prompt.py
--rw-r--r--   0        0        0     1537 2023-08-07 14:51:51.164475 oplangchain-0.1.0/oplangchain/chains/api/tmdb_docs.py
--rw-r--r--   0        0        0    24814 2023-08-07 14:51:51.164475 oplangchain-0.1.0/oplangchain/chains/base.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.165475 oplangchain-0.1.0/oplangchain/chains/chat_vector_db/__init__.py
--rw-r--r--   0        0        0      689 2023-08-07 14:51:51.165475 oplangchain-0.1.0/oplangchain/chains/chat_vector_db/prompts.py
--rw-r--r--   0        0        0       43 2023-08-07 14:51:51.166474 oplangchain-0.1.0/oplangchain/chains/combine_documents/__init__.py
--rw-r--r--   0        0        0     6390 2023-08-07 14:51:51.167474 oplangchain-0.1.0/oplangchain/chains/combine_documents/base.py
--rw-r--r--   0        0        0    11149 2023-08-07 14:51:51.167474 oplangchain-0.1.0/oplangchain/chains/combine_documents/map_reduce.py
--rw-r--r--   0        0        0     8368 2023-08-07 14:51:51.168475 oplangchain-0.1.0/oplangchain/chains/combine_documents/map_rerank.py
--rw-r--r--   0        0        0    11004 2023-08-07 14:51:51.168475 oplangchain-0.1.0/oplangchain/chains/combine_documents/reduce.py
--rw-r--r--   0        0        0     9075 2023-08-07 14:51:51.169474 oplangchain-0.1.0/oplangchain/chains/combine_documents/refine.py
--rw-r--r--   0        0        0     7658 2023-08-07 14:51:51.169474 oplangchain-0.1.0/oplangchain/chains/combine_documents/stuff.py
--rw-r--r--   0        0        0      107 2023-08-07 14:51:51.170474 oplangchain-0.1.0/oplangchain/chains/constitutional_ai/__init__.py
--rw-r--r--   0        0        0     6328 2023-08-07 14:51:51.170474 oplangchain-0.1.0/oplangchain/chains/constitutional_ai/base.py
--rw-r--r--   0        0        0      265 2023-08-07 14:51:51.171474 oplangchain-0.1.0/oplangchain/chains/constitutional_ai/models.py
--rw-r--r--   0        0        0    21738 2023-08-07 14:51:51.171474 oplangchain-0.1.0/oplangchain/chains/constitutional_ai/principles.py
--rw-r--r--   0        0        0     8656 2023-08-07 14:51:51.172475 oplangchain-0.1.0/oplangchain/chains/constitutional_ai/prompts.py
--rw-r--r--   0        0        0       71 2023-08-07 14:51:51.173476 oplangchain-0.1.0/oplangchain/chains/conversation/__init__.py
--rw-r--r--   0        0        0     2174 2023-08-07 14:51:51.173476 oplangchain-0.1.0/oplangchain/chains/conversation/base.py
--rw-r--r--   0        0        0      856 2023-08-07 14:51:51.174476 oplangchain-0.1.0/oplangchain/chains/conversation/memory.py
--rw-r--r--   0        0        0      908 2023-08-07 14:51:51.174476 oplangchain-0.1.0/oplangchain/chains/conversation/prompt.py
--rw-r--r--   0        0        0       49 2023-08-07 14:51:51.175475 oplangchain-0.1.0/oplangchain/chains/conversational_retrieval/__init__.py
--rw-r--r--   0        0        0    16705 2023-08-07 14:51:51.176476 oplangchain-0.1.0/oplangchain/chains/conversational_retrieval/base.py
--rw-r--r--   0        0        0      715 2023-08-07 14:51:51.176476 oplangchain-0.1.0/oplangchain/chains/conversational_retrieval/prompts.py
--rw-r--r--   0        0        0      126 2023-08-07 14:51:51.177475 oplangchain-0.1.0/oplangchain/chains/elasticsearch_database/__init__.py
--rw-r--r--   0        0        0     8166 2023-08-07 14:51:51.177475 oplangchain-0.1.0/oplangchain/chains/elasticsearch_database/base.py
--rw-r--r--   0        0        0     1420 2023-08-07 14:51:51.178474 oplangchain-0.1.0/oplangchain/chains/elasticsearch_database/prompts.py
--rw-r--r--   0        0        0      731 2023-08-07 14:51:51.178474 oplangchain-0.1.0/oplangchain/chains/example_generator.py
--rw-r--r--   0        0        0       51 2023-08-07 14:51:51.179474 oplangchain-0.1.0/oplangchain/chains/flare/__init__.py
--rw-r--r--   0        0        0     8765 2023-08-07 14:51:51.180476 oplangchain-0.1.0/oplangchain/chains/flare/base.py
--rw-r--r--   0        0        0     1453 2023-08-07 14:51:51.180476 oplangchain-0.1.0/oplangchain/chains/flare/prompts.py
--rw-r--r--   0        0        0       49 2023-08-07 14:51:51.181476 oplangchain-0.1.0/oplangchain/chains/graph_qa/__init__.py
--rw-r--r--   0        0        0     7676 2023-08-07 14:51:51.182475 oplangchain-0.1.0/oplangchain/chains/graph_qa/arangodb.py
--rw-r--r--   0        0        0     2970 2023-08-07 14:51:51.182475 oplangchain-0.1.0/oplangchain/chains/graph_qa/base.py
--rw-r--r--   0        0        0     4586 2023-08-07 14:51:51.183475 oplangchain-0.1.0/oplangchain/chains/graph_qa/cypher.py
--rw-r--r--   0        0        0     3019 2023-08-07 14:51:51.183475 oplangchain-0.1.0/oplangchain/chains/graph_qa/hugegraph.py
--rw-r--r--   0        0        0     3019 2023-08-07 14:51:51.184473 oplangchain-0.1.0/oplangchain/chains/graph_qa/kuzu.py
--rw-r--r--   0        0        0     2994 2023-08-07 14:51:51.184473 oplangchain-0.1.0/oplangchain/chains/graph_qa/nebulagraph.py
--rw-r--r--   0        0        0     4479 2023-08-07 14:51:51.185474 oplangchain-0.1.0/oplangchain/chains/graph_qa/neptune_cypher.py
--rw-r--r--   0        0        0    13728 2023-08-07 14:51:51.185474 oplangchain-0.1.0/oplangchain/chains/graph_qa/prompts.py
--rw-r--r--   0        0        0     4771 2023-08-07 14:51:51.186474 oplangchain-0.1.0/oplangchain/chains/graph_qa/sparql.py
--rw-r--r--   0        0        0       75 2023-08-07 14:51:51.187475 oplangchain-0.1.0/oplangchain/chains/hyde/__init__.py
--rw-r--r--   0        0        0     2831 2023-08-07 14:51:51.187475 oplangchain-0.1.0/oplangchain/chains/hyde/base.py
--rw-r--r--   0        0        0     1908 2023-08-07 14:51:51.188474 oplangchain-0.1.0/oplangchain/chains/hyde/prompts.py
--rw-r--r--   0        0        0    12141 2023-08-07 14:51:51.188474 oplangchain-0.1.0/oplangchain/chains/llm.py
--rw-r--r--   0        0        0       88 2023-08-07 14:51:51.189475 oplangchain-0.1.0/oplangchain/chains/llm_bash/__init__.py
--rw-r--r--   0        0        0     4165 2023-08-07 14:51:51.190475 oplangchain-0.1.0/oplangchain/chains/llm_bash/base.py
--rw-r--r--   0        0        0     1937 2023-08-07 14:51:51.191475 oplangchain-0.1.0/oplangchain/chains/llm_bash/prompt.py
--rw-r--r--   0        0        0      139 2023-08-07 14:51:51.191475 oplangchain-0.1.0/oplangchain/chains/llm_checker/__init__.py
--rw-r--r--   0        0        0     6090 2023-08-07 14:51:51.192474 oplangchain-0.1.0/oplangchain/chains/llm_checker/base.py
--rw-r--r--   0        0        0     1120 2023-08-07 14:51:51.192474 oplangchain-0.1.0/oplangchain/chains/llm_checker/prompt.py
--rw-r--r--   0        0        0      143 2023-08-07 14:51:51.193472 oplangchain-0.1.0/oplangchain/chains/llm_math/__init__.py
--rw-r--r--   0        0        0     6372 2023-08-07 14:51:51.194476 oplangchain-0.1.0/oplangchain/chains/llm_math/base.py
--rw-r--r--   0        0        0      863 2023-08-07 14:51:51.194476 oplangchain-0.1.0/oplangchain/chains/llm_math/prompt.py
--rw-r--r--   0        0        0     2877 2023-08-07 14:51:51.195474 oplangchain-0.1.0/oplangchain/chains/llm_requests.py
--rw-r--r--   0        0        0      352 2023-08-07 14:51:51.196474 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/__init__.py
--rw-r--r--   0        0        0     6606 2023-08-07 14:51:51.196474 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/base.py
--rw-r--r--   0        0        0      654 2023-08-07 14:51:51.241473 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/prompts/are_all_true_prompt.txt
--rw-r--r--   0        0        0      377 2023-08-07 14:51:51.242473 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/prompts/check_facts.txt
--rw-r--r--   0        0        0      128 2023-08-07 14:51:51.244473 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/prompts/create_facts.txt
--rw-r--r--   0        0        0      416 2023-08-07 14:51:51.245474 oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/prompts/revise_summary.txt
--rw-r--r--   0        0        0      126 2023-08-07 14:51:51.245474 oplangchain-0.1.0/oplangchain/chains/llm_symbolic_math/__init__.py
--rw-r--r--   0        0        0     5555 2023-08-07 14:51:51.246475 oplangchain-0.1.0/oplangchain/chains/llm_symbolic_math/base.py
--rw-r--r--   0        0        0     1087 2023-08-07 14:51:51.246475 oplangchain-0.1.0/oplangchain/chains/llm_symbolic_math/prompt.py
--rw-r--r--   0        0        0    23945 2023-08-07 14:51:51.277473 oplangchain-0.1.0/oplangchain/chains/loading.py
--rw-r--r--   0        0        0     3715 2023-08-07 14:51:51.278475 oplangchain-0.1.0/oplangchain/chains/mapreduce.py
--rw-r--r--   0        0        0     3050 2023-08-07 14:51:51.279473 oplangchain-0.1.0/oplangchain/chains/moderation.py
--rw-r--r--   0        0        0       96 2023-08-07 14:51:51.279473 oplangchain-0.1.0/oplangchain/chains/natbot/__init__.py
--rw-r--r--   0        0        0     4179 2023-08-07 14:51:51.280474 oplangchain-0.1.0/oplangchain/chains/natbot/base.py
--rw-r--r--   0        0        0    15466 2023-08-07 14:51:51.280474 oplangchain-0.1.0/oplangchain/chains/natbot/crawler.py
--rw-r--r--   0        0        0     4984 2023-08-07 14:51:51.281475 oplangchain-0.1.0/oplangchain/chains/natbot/prompt.py
--rw-r--r--   0        0        0      948 2023-08-07 14:51:51.310473 oplangchain-0.1.0/oplangchain/chains/openai_functions/__init__.py
--rw-r--r--   0        0        0    14608 2023-08-07 14:51:51.311474 oplangchain-0.1.0/oplangchain/chains/openai_functions/base.py
--rw-r--r--   0        0        0     3506 2023-08-07 14:51:51.312483 oplangchain-0.1.0/oplangchain/chains/openai_functions/citation_fuzzy_match.py
--rw-r--r--   0        0        0     3338 2023-08-07 14:51:51.343475 oplangchain-0.1.0/oplangchain/chains/openai_functions/extraction.py
--rw-r--r--   0        0        0    11184 2023-08-07 16:16:46.596551 oplangchain-0.1.0/oplangchain/chains/openai_functions/openapi.py
--rw-r--r--   0        0        0     3709 2023-08-07 14:51:51.344474 oplangchain-0.1.0/oplangchain/chains/openai_functions/qa_with_structure.py
--rw-r--r--   0        0        0     2653 2023-08-07 14:51:51.345474 oplangchain-0.1.0/oplangchain/chains/openai_functions/tagging.py
--rw-r--r--   0        0        0     1257 2023-08-07 14:51:51.345474 oplangchain-0.1.0/oplangchain/chains/openai_functions/utils.py
--rw-r--r--   0        0        0     1961 2023-08-07 14:51:51.346475 oplangchain-0.1.0/oplangchain/chains/prompt_selector.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.346475 oplangchain-0.1.0/oplangchain/chains/qa_generation/__init__.py
--rw-r--r--   0        0        0     2444 2023-08-07 14:51:51.347474 oplangchain-0.1.0/oplangchain/chains/qa_generation/base.py
--rw-r--r--   0        0        0     1865 2023-08-07 14:51:51.347474 oplangchain-0.1.0/oplangchain/chains/qa_generation/prompt.py
--rw-r--r--   0        0        0      173 2023-08-07 14:51:51.348474 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/__init__.py
--rw-r--r--   0        0        0     7717 2023-08-07 14:51:51.348474 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/base.py
--rw-r--r--   0        0        0     6803 2023-08-07 14:51:51.349474 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/loading.py
--rw-r--r--   0        0        0     6966 2023-08-07 14:51:51.350474 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/map_reduce_prompt.py
--rw-r--r--   0        0        0     1313 2023-08-07 14:51:51.377473 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/refine_prompts.py
--rw-r--r--   0        0        0     2344 2023-08-07 14:51:51.378473 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/retrieval.py
--rw-r--r--   0        0        0     6576 2023-08-07 14:51:51.378473 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/stuff_prompt.py
--rw-r--r--   0        0        0     2799 2023-08-07 14:51:51.378473 oplangchain-0.1.0/oplangchain/chains/qa_with_sources/vector_db.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.379473 oplangchain-0.1.0/oplangchain/chains/query_constructor/__init__.py
--rw-r--r--   0        0        0     5808 2023-08-07 14:51:51.380475 oplangchain-0.1.0/oplangchain/chains/query_constructor/base.py
--rw-r--r--   0        0        0     3129 2023-08-07 14:51:51.380475 oplangchain-0.1.0/oplangchain/chains/query_constructor/ir.py
--rw-r--r--   0        0        0     4752 2023-08-07 14:51:51.381474 oplangchain-0.1.0/oplangchain/chains/query_constructor/parser.py
--rw-r--r--   0        0        0     6446 2023-08-07 14:51:51.381474 oplangchain-0.1.0/oplangchain/chains/query_constructor/prompt.py
--rw-r--r--   0        0        0      303 2023-08-07 14:51:51.383473 oplangchain-0.1.0/oplangchain/chains/query_constructor/schema.py
--rw-r--r--   0        0        0     8552 2023-08-07 14:51:51.384474 oplangchain-0.1.0/oplangchain/chains/question_answering/__init__.py
--rw-r--r--   0        0        0     8003 2023-08-07 14:51:51.384474 oplangchain-0.1.0/oplangchain/chains/question_answering/map_reduce_prompt.py
--rw-r--r--   0        0        0     1617 2023-08-07 14:51:51.416474 oplangchain-0.1.0/oplangchain/chains/question_answering/map_rerank_prompt.py
--rw-r--r--   0        0        0     2726 2023-08-07 14:51:51.417476 oplangchain-0.1.0/oplangchain/chains/question_answering/refine_prompts.py
--rw-r--r--   0        0        0     1135 2023-08-07 14:51:51.417476 oplangchain-0.1.0/oplangchain/chains/question_answering/stuff_prompt.py
--rw-r--r--   0        0        0       62 2023-08-07 14:51:51.418473 oplangchain-0.1.0/oplangchain/chains/retrieval_qa/__init__.py
--rw-r--r--   0        0        0     9762 2023-08-07 14:51:51.419475 oplangchain-0.1.0/oplangchain/chains/retrieval_qa/base.py
--rw-r--r--   0        0        0      394 2023-08-07 14:51:51.419475 oplangchain-0.1.0/oplangchain/chains/retrieval_qa/prompt.py
--rw-r--r--   0        0        0      407 2023-08-07 14:51:51.420474 oplangchain-0.1.0/oplangchain/chains/router/__init__.py
--rw-r--r--   0        0        0     4556 2023-08-07 14:51:51.420474 oplangchain-0.1.0/oplangchain/chains/router/base.py
--rw-r--r--   0        0        0     1970 2023-08-07 14:51:51.421474 oplangchain-0.1.0/oplangchain/chains/router/embedding_router.py
--rw-r--r--   0        0        0     4185 2023-08-07 14:51:51.421474 oplangchain-0.1.0/oplangchain/chains/router/llm_router.py
--rw-r--r--   0        0        0     2562 2023-08-07 14:51:51.447474 oplangchain-0.1.0/oplangchain/chains/router/multi_prompt.py
--rw-r--r--   0        0        0     1123 2023-08-07 14:51:51.448481 oplangchain-0.1.0/oplangchain/chains/router/multi_prompt_prompt.py
--rw-r--r--   0        0        0     1079 2023-08-07 14:51:51.449476 oplangchain-0.1.0/oplangchain/chains/router/multi_retrieval_prompt.py
--rw-r--r--   0        0        0     3635 2023-08-07 14:51:51.449476 oplangchain-0.1.0/oplangchain/chains/router/multi_retrieval_qa.py
--rw-r--r--   0        0        0     7481 2023-08-07 14:51:51.450475 oplangchain-0.1.0/oplangchain/chains/sequential.py
--rw-r--r--   0        0        0       47 2023-08-07 14:51:51.450475 oplangchain-0.1.0/oplangchain/chains/sql_database/__init__.py
--rw-r--r--   0        0        0    14202 2023-08-07 14:51:51.451476 oplangchain-0.1.0/oplangchain/chains/sql_database/prompt.py
--rw-r--r--   0        0        0     2066 2023-08-07 14:51:51.451476 oplangchain-0.1.0/oplangchain/chains/sql_database/query.py
--rw-r--r--   0        0        0     5695 2023-08-07 14:51:51.480846 oplangchain-0.1.0/oplangchain/chains/summarize/__init__.py
--rw-r--r--   0        0        0      233 2023-08-07 14:51:51.481847 oplangchain-0.1.0/oplangchain/chains/summarize/map_reduce_prompt.py
--rw-r--r--   0        0        0      805 2023-08-07 14:51:51.481847 oplangchain-0.1.0/oplangchain/chains/summarize/refine_prompts.py
--rw-r--r--   0        0        0      233 2023-08-07 14:51:51.513090 oplangchain-0.1.0/oplangchain/chains/summarize/stuff_prompt.py
--rw-r--r--   0        0        0     2233 2023-08-07 14:51:51.513090 oplangchain-0.1.0/oplangchain/chains/transform.py
--rw-r--r--   0        0        0     1354 2023-08-07 14:51:51.514100 oplangchain-0.1.0/oplangchain/chat_models/__init__.py
--rw-r--r--   0        0        0     6988 2023-08-07 14:51:51.515099 oplangchain-0.1.0/oplangchain/chat_models/anthropic.py
--rw-r--r--   0        0        0     4707 2023-08-07 14:51:51.515099 oplangchain-0.1.0/oplangchain/chat_models/azure_openai.py
--rw-r--r--   0        0        0     5396 2023-08-07 14:51:51.518098 oplangchain-0.1.0/oplangchain/chat_models/azureml_endpoint.py
--rw-r--r--   0        0        0    23270 2023-08-07 14:51:51.519100 oplangchain-0.1.0/oplangchain/chat_models/base.py
--rw-r--r--   0        0        0     1040 2023-08-07 14:51:51.519100 oplangchain-0.1.0/oplangchain/chat_models/fake.py
--rw-r--r--   0        0        0    11127 2023-08-07 14:51:51.520100 oplangchain-0.1.0/oplangchain/chat_models/google_palm.py
--rw-r--r--   0        0        0     4017 2023-08-07 14:51:51.520100 oplangchain-0.1.0/oplangchain/chat_models/human.py
--rw-r--r--   0        0        0    15223 2023-08-07 14:51:51.521099 oplangchain-0.1.0/oplangchain/chat_models/jinachat.py
--rw-r--r--   0        0        0     6855 2023-08-07 14:51:51.521099 oplangchain-0.1.0/oplangchain/chat_models/mlflow_ai_gateway.py
--rw-r--r--   0        0        0    22364 2023-08-07 14:51:51.522100 oplangchain-0.1.0/oplangchain/chat_models/openai.py
--rw-r--r--   0        0        0     5164 2023-08-07 14:51:51.522100 oplangchain-0.1.0/oplangchain/chat_models/promptlayer_openai.py
--rw-r--r--   0        0        0     6006 2023-08-07 14:51:51.523098 oplangchain-0.1.0/oplangchain/chat_models/vertexai.py
--rw-r--r--   0        0        0      685 2023-08-07 14:51:51.523098 oplangchain-0.1.0/oplangchain/docker-compose.yaml
--rw-r--r--   0        0        0      519 2023-08-07 14:51:51.524099 oplangchain-0.1.0/oplangchain/docstore/__init__.py
--rw-r--r--   0        0        0     1071 2023-08-07 14:51:51.524099 oplangchain-0.1.0/oplangchain/docstore/arbitrary_fn.py
--rw-r--r--   0        0        0      836 2023-08-07 14:51:51.525100 oplangchain-0.1.0/oplangchain/docstore/base.py
--rw-r--r--   0        0        0       62 2023-08-07 14:51:51.525100 oplangchain-0.1.0/oplangchain/docstore/document.py
--rw-r--r--   0        0        0     1602 2023-08-07 14:51:51.550662 oplangchain-0.1.0/oplangchain/docstore/in_memory.py
--rw-r--r--   0        0        0     1479 2023-08-07 14:51:51.551661 oplangchain-0.1.0/oplangchain/docstore/wikipedia.py
--rw-r--r--   0        0        0    12884 2023-08-07 14:51:51.552662 oplangchain-0.1.0/oplangchain/document_loaders/__init__.py
--rw-r--r--   0        0        0     2847 2023-08-07 14:51:51.552662 oplangchain-0.1.0/oplangchain/document_loaders/acreom.py
--rw-r--r--   0        0        0      839 2023-08-07 14:51:51.553664 oplangchain-0.1.0/oplangchain/document_loaders/airbyte_json.py
--rw-r--r--   0        0        0     1273 2023-08-07 14:51:51.553664 oplangchain-0.1.0/oplangchain/document_loaders/airtable.py
--rw-r--r--   0        0        0     2716 2023-08-07 14:51:51.582945 oplangchain-0.1.0/oplangchain/document_loaders/apify_dataset.py
--rw-r--r--   0        0        0     1138 2023-08-07 14:51:51.582945 oplangchain-0.1.0/oplangchain/document_loaders/arxiv.py
--rw-r--r--   0        0        0     4861 2023-08-07 14:51:51.583960 oplangchain-0.1.0/oplangchain/document_loaders/async_html.py
--rw-r--r--   0        0        0      576 2023-08-07 14:51:51.583960 oplangchain-0.1.0/oplangchain/document_loaders/azlyrics.py
--rw-r--r--   0        0        0     1612 2023-08-07 14:51:51.584953 oplangchain-0.1.0/oplangchain/document_loaders/azure_blob_storage_container.py
--rw-r--r--   0        0        0     1631 2023-08-07 14:51:51.584953 oplangchain-0.1.0/oplangchain/document_loaders/azure_blob_storage_file.py
--rw-r--r--   0        0        0     3041 2023-08-07 14:51:51.585951 oplangchain-0.1.0/oplangchain/document_loaders/base.py
--rw-r--r--   0        0        0     3928 2023-08-07 14:51:51.585951 oplangchain-0.1.0/oplangchain/document_loaders/bibtex.py
--rw-r--r--   0        0        0     3147 2023-08-07 14:51:51.586951 oplangchain-0.1.0/oplangchain/document_loaders/bigquery.py
--rw-r--r--   0        0        0     2722 2023-08-07 14:51:51.586951 oplangchain-0.1.0/oplangchain/document_loaders/bilibili.py
--rw-r--r--   0        0        0    10089 2023-08-07 14:51:51.587951 oplangchain-0.1.0/oplangchain/document_loaders/blackboard.py
--rw-r--r--   0        0        0      326 2023-08-07 14:51:51.587951 oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/__init__.py
--rw-r--r--   0        0        0     4279 2023-08-07 14:51:51.588952 oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/file_system.py
--rw-r--r--   0        0        0     5765 2023-08-07 14:51:51.588952 oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/schema.py
--rw-r--r--   0        0        0     1506 2023-08-07 14:51:51.615001 oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/youtube_audio.py
--rw-r--r--   0        0        0     5728 2023-08-07 14:51:51.615001 oplangchain-0.1.0/oplangchain/document_loaders/blockchain.py
--rw-r--r--   0        0        0     1068 2023-08-07 14:51:51.616031 oplangchain-0.1.0/oplangchain/document_loaders/brave_search.py
--rw-r--r--   0        0        0     2132 2023-08-07 14:51:51.616031 oplangchain-0.1.0/oplangchain/document_loaders/browserless.py
--rw-r--r--   0        0        0     2026 2023-08-07 14:51:51.617013 oplangchain-0.1.0/oplangchain/document_loaders/chatgpt.py
--rw-r--r--   0        0        0      552 2023-08-07 14:51:51.617013 oplangchain-0.1.0/oplangchain/document_loaders/college_confidential.py
--rw-r--r--   0        0        0     2143 2023-08-07 14:51:51.618013 oplangchain-0.1.0/oplangchain/document_loaders/concurrent.py
--rw-r--r--   0        0        0    25397 2023-08-07 14:51:51.619013 oplangchain-0.1.0/oplangchain/document_loaders/confluence.py
--rw-r--r--   0        0        0     1068 2023-08-07 14:51:51.646792 oplangchain-0.1.0/oplangchain/document_loaders/conllu.py
--rw-r--r--   0        0        0     4195 2023-08-07 14:51:51.646792 oplangchain-0.1.0/oplangchain/document_loaders/csv_loader.py
--rw-r--r--   0        0        0     5901 2023-08-07 14:51:51.647825 oplangchain-0.1.0/oplangchain/document_loaders/cube_semantic.py
--rw-r--r--   0        0        0     4993 2023-08-07 14:51:51.648805 oplangchain-0.1.0/oplangchain/document_loaders/datadog_logs.py
--rw-r--r--   0        0        0     1325 2023-08-07 14:51:51.648805 oplangchain-0.1.0/oplangchain/document_loaders/dataframe.py
--rw-r--r--   0        0        0     2110 2023-08-07 14:51:51.648805 oplangchain-0.1.0/oplangchain/document_loaders/diffbot.py
--rw-r--r--   0        0        0     5094 2023-08-07 14:51:51.649807 oplangchain-0.1.0/oplangchain/document_loaders/directory.py
--rw-r--r--   0        0        0     1261 2023-08-07 14:51:51.649807 oplangchain-0.1.0/oplangchain/document_loaders/discord.py
--rw-r--r--   0        0        0    13216 2023-08-07 14:51:51.650804 oplangchain-0.1.0/oplangchain/document_loaders/docugami.py
--rw-r--r--   0        0        0     6089 2023-08-07 14:51:51.650804 oplangchain-0.1.0/oplangchain/document_loaders/dropbox.py
--rw-r--r--   0        0        0     3181 2023-08-07 14:51:51.651804 oplangchain-0.1.0/oplangchain/document_loaders/duckdb_loader.py
--rw-r--r--   0        0        0     3782 2023-08-07 14:51:51.651804 oplangchain-0.1.0/oplangchain/document_loaders/email.py
--rw-r--r--   0        0        0     8933 2023-08-07 14:51:51.652806 oplangchain-0.1.0/oplangchain/document_loaders/embaas.py
--rw-r--r--   0        0        0     1510 2023-08-07 14:51:51.652806 oplangchain-0.1.0/oplangchain/document_loaders/epub.py
--rw-r--r--   0        0        0     7808 2023-08-07 14:51:51.653805 oplangchain-0.1.0/oplangchain/document_loaders/etherscan.py
--rw-r--r--   0        0        0     5744 2023-08-07 14:51:51.653805 oplangchain-0.1.0/oplangchain/document_loaders/evernote.py
--rw-r--r--   0        0        0     1664 2023-08-07 14:51:51.654807 oplangchain-0.1.0/oplangchain/document_loaders/excel.py
--rw-r--r--   0        0        0     1298 2023-08-07 14:51:51.654807 oplangchain-0.1.0/oplangchain/document_loaders/facebook_chat.py
--rw-r--r--   0        0        0     2241 2023-08-07 14:51:51.655804 oplangchain-0.1.0/oplangchain/document_loaders/fauna.py
--rw-r--r--   0        0        0     1569 2023-08-07 14:51:51.655804 oplangchain-0.1.0/oplangchain/document_loaders/figma.py
--rw-r--r--   0        0        0     1573 2023-08-07 14:51:51.656804 oplangchain-0.1.0/oplangchain/document_loaders/gcs_directory.py
--rw-r--r--   0        0        0     1731 2023-08-07 14:51:51.656804 oplangchain-0.1.0/oplangchain/document_loaders/gcs_file.py
--rw-r--r--   0        0        0     4527 2023-08-07 14:51:51.657804 oplangchain-0.1.0/oplangchain/document_loaders/generic.py
--rw-r--r--   0        0        0     1682 2023-08-07 14:51:51.657804 oplangchain-0.1.0/oplangchain/document_loaders/geodataframe.py
--rw-r--r--   0        0        0     4138 2023-08-07 14:51:51.657804 oplangchain-0.1.0/oplangchain/document_loaders/git.py
--rw-r--r--   0        0        0     3106 2023-08-07 14:51:51.658804 oplangchain-0.1.0/oplangchain/document_loaders/gitbook.py
--rw-r--r--   0        0        0     6868 2023-08-07 14:51:51.658804 oplangchain-0.1.0/oplangchain/document_loaders/github.py
--rw-r--r--   0        0        0    13926 2023-08-07 14:51:51.659804 oplangchain-0.1.0/oplangchain/document_loaders/googledrive.py
--rw-r--r--   0        0        0      969 2023-08-07 14:51:51.660541 oplangchain-0.1.0/oplangchain/document_loaders/gutenberg.py
--rw-r--r--   0        0        0     1559 2023-08-07 14:51:51.660541 oplangchain-0.1.0/oplangchain/document_loaders/helpers.py
--rw-r--r--   0        0        0     2061 2023-08-07 14:51:51.661555 oplangchain-0.1.0/oplangchain/document_loaders/hn.py
--rw-r--r--   0        0        0     1204 2023-08-07 14:51:51.661555 oplangchain-0.1.0/oplangchain/document_loaders/html.py
--rw-r--r--   0        0        0     2118 2023-08-07 14:51:51.661555 oplangchain-0.1.0/oplangchain/document_loaders/html_bs.py
--rw-r--r--   0        0        0     3025 2023-08-07 14:51:51.662553 oplangchain-0.1.0/oplangchain/document_loaders/hugging_face_dataset.py
--rw-r--r--   0        0        0     7648 2023-08-07 14:51:51.662553 oplangchain-0.1.0/oplangchain/document_loaders/ifixit.py
--rw-r--r--   0        0        0     1186 2023-08-07 14:51:51.663554 oplangchain-0.1.0/oplangchain/document_loaders/image.py
--rw-r--r--   0        0        0     3099 2023-08-07 14:51:51.663554 oplangchain-0.1.0/oplangchain/document_loaders/image_captions.py
--rw-r--r--   0        0        0      487 2023-08-07 14:51:51.664553 oplangchain-0.1.0/oplangchain/document_loaders/imsdb.py
--rw-r--r--   0        0        0     1734 2023-08-07 14:51:51.664553 oplangchain-0.1.0/oplangchain/document_loaders/iugu.py
--rw-r--r--   0        0        0     3699 2023-08-07 14:51:51.665554 oplangchain-0.1.0/oplangchain/document_loaders/joplin.py
--rw-r--r--   0        0        0     5487 2023-08-07 14:51:51.665554 oplangchain-0.1.0/oplangchain/document_loaders/json_loader.py
--rw-r--r--   0        0        0     2052 2023-08-07 14:51:51.665554 oplangchain-0.1.0/oplangchain/document_loaders/larksuite.py
--rw-r--r--   0        0        0     1828 2023-08-07 14:51:51.666553 oplangchain-0.1.0/oplangchain/document_loaders/markdown.py
--rw-r--r--   0        0        0     3130 2023-08-07 14:51:51.666553 oplangchain-0.1.0/oplangchain/document_loaders/mastodon.py
--rw-r--r--   0        0        0     3293 2023-08-07 14:51:51.667553 oplangchain-0.1.0/oplangchain/document_loaders/max_compute.py
--rw-r--r--   0        0        0     3479 2023-08-07 14:51:51.667553 oplangchain-0.1.0/oplangchain/document_loaders/mediawikidump.py
--rw-r--r--   0        0        0      838 2023-08-07 14:51:51.668553 oplangchain-0.1.0/oplangchain/document_loaders/merge.py
--rw-r--r--   0        0        0     2600 2023-08-07 14:51:51.668553 oplangchain-0.1.0/oplangchain/document_loaders/mhtml.py
--rw-r--r--   0        0        0     3131 2023-08-07 14:51:51.669553 oplangchain-0.1.0/oplangchain/document_loaders/modern_treasury.py
--rw-r--r--   0        0        0     4287 2023-08-07 14:51:51.669553 oplangchain-0.1.0/oplangchain/document_loaders/news.py
--rw-r--r--   0        0        0     4281 2023-08-07 14:51:51.669553 oplangchain-0.1.0/oplangchain/document_loaders/notebook.py
--rw-r--r--   0        0        0      741 2023-08-07 14:51:51.670553 oplangchain-0.1.0/oplangchain/document_loaders/notion.py
--rw-r--r--   0        0        0     5892 2023-08-07 14:51:51.670553 oplangchain-0.1.0/oplangchain/document_loaders/notiondb.py
--rw-r--r--   0        0        0     1084 2023-08-07 14:51:51.671554 oplangchain-0.1.0/oplangchain/document_loaders/nuclia.py
--rw-r--r--   0        0        0     3594 2023-08-07 14:51:51.671554 oplangchain-0.1.0/oplangchain/document_loaders/obs_directory.py
--rw-r--r--   0        0        0     4745 2023-08-07 14:51:51.672555 oplangchain-0.1.0/oplangchain/document_loaders/obs_file.py
--rw-r--r--   0        0        0     2537 2023-08-07 14:51:51.672555 oplangchain-0.1.0/oplangchain/document_loaders/obsidian.py
--rw-r--r--   0        0        0     1793 2023-08-07 14:51:51.673554 oplangchain-0.1.0/oplangchain/document_loaders/odt.py
--rw-r--r--   0        0        0     8635 2023-08-07 14:51:51.673554 oplangchain-0.1.0/oplangchain/document_loaders/onedrive.py
--rw-r--r--   0        0        0     1108 2023-08-07 14:51:51.674553 oplangchain-0.1.0/oplangchain/document_loaders/onedrive_file.py
--rw-r--r--   0        0        0     1322 2023-08-07 14:51:51.674553 oplangchain-0.1.0/oplangchain/document_loaders/open_city_data.py
--rw-r--r--   0        0        0     1765 2023-08-07 14:51:51.675557 oplangchain-0.1.0/oplangchain/document_loaders/org_mode.py
--rw-r--r--   0        0        0      645 2023-08-07 14:51:51.676554 oplangchain-0.1.0/oplangchain/document_loaders/parsers/__init__.py
--rw-r--r--   0        0        0     6083 2023-08-07 14:51:51.676554 oplangchain-0.1.0/oplangchain/document_loaders/parsers/audio.py
--rw-r--r--   0        0        0     2466 2023-08-07 14:51:51.677553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/generic.py
--rw-r--r--   0        0        0     5759 2023-08-07 14:51:51.677553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/grobid.py
--rw-r--r--   0        0        0       99 2023-08-07 14:51:51.678553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/html/__init__.py
--rw-r--r--   0        0        0     1602 2023-08-07 14:51:51.678553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/html/bs4.py
--rw-r--r--   0        0        0      117 2023-08-07 14:51:51.679553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/__init__.py
--rw-r--r--   0        0        0      499 2023-08-07 14:51:51.679553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/code_segmenter.py
--rw-r--r--   0        0        0     2088 2023-08-07 14:51:51.680556 oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/javascript.py
--rw-r--r--   0        0        0     4670 2023-08-07 14:51:51.680556 oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/language_parser.py
--rw-r--r--   0        0        0     1662 2023-08-07 14:51:51.681553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/python.py
--rw-r--r--   0        0        0     8801 2023-08-07 14:51:51.681553 oplangchain-0.1.0/oplangchain/document_loaders/parsers/pdf.py
--rw-r--r--   0        0        0      912 2023-08-07 14:51:51.682556 oplangchain-0.1.0/oplangchain/document_loaders/parsers/registry.py
--rw-r--r--   0        0        0      476 2023-08-07 14:51:51.682556 oplangchain-0.1.0/oplangchain/document_loaders/parsers/txt.py
--rw-r--r--   0        0        0    20543 2023-08-07 14:51:51.683555 oplangchain-0.1.0/oplangchain/document_loaders/pdf.py
--rw-r--r--   0        0        0     2517 2023-08-07 14:51:51.683555 oplangchain-0.1.0/oplangchain/document_loaders/powerpoint.py
--rw-r--r--   0        0        0     1412 2023-08-07 14:51:51.684554 oplangchain-0.1.0/oplangchain/document_loaders/psychic.py
--rw-r--r--   0        0        0     3418 2023-08-07 14:51:51.684554 oplangchain-0.1.0/oplangchain/document_loaders/pyspark_dataframe.py
--rw-r--r--   0        0        0      525 2023-08-07 14:51:51.684554 oplangchain-0.1.0/oplangchain/document_loaders/python.py
--rw-r--r--   0        0        0     3526 2023-08-07 14:51:51.685553 oplangchain-0.1.0/oplangchain/document_loaders/readthedocs.py
--rw-r--r--   0        0        0    12428 2023-08-07 14:51:51.685553 oplangchain-0.1.0/oplangchain/document_loaders/recursive_url_loader.py
--rw-r--r--   0        0        0     4605 2023-08-07 14:51:51.686554 oplangchain-0.1.0/oplangchain/document_loaders/reddit.py
--rw-r--r--   0        0        0      722 2023-08-07 14:51:51.686554 oplangchain-0.1.0/oplangchain/document_loaders/roam.py
--rw-r--r--   0        0        0     4433 2023-08-07 14:51:51.687553 oplangchain-0.1.0/oplangchain/document_loaders/rocksetdb.py
--rw-r--r--   0        0        0     4930 2023-08-07 14:51:51.687553 oplangchain-0.1.0/oplangchain/document_loaders/rss.py
--rw-r--r--   0        0        0     1821 2023-08-07 14:51:51.688553 oplangchain-0.1.0/oplangchain/document_loaders/rst.py
--rw-r--r--   0        0        0     2050 2023-08-07 14:51:51.688553 oplangchain-0.1.0/oplangchain/document_loaders/rtf.py
--rw-r--r--   0        0        0     1225 2023-08-07 14:51:51.689554 oplangchain-0.1.0/oplangchain/document_loaders/s3_directory.py
--rw-r--r--   0        0        0     1316 2023-08-07 14:51:51.689554 oplangchain-0.1.0/oplangchain/document_loaders/s3_file.py
--rw-r--r--   0        0        0     5008 2023-08-07 14:51:51.690554 oplangchain-0.1.0/oplangchain/document_loaders/sitemap.py
--rw-r--r--   0        0        0     4180 2023-08-07 14:51:51.690554 oplangchain-0.1.0/oplangchain/document_loaders/slack_directory.py
--rw-r--r--   0        0        0     4826 2023-08-07 14:51:51.691555 oplangchain-0.1.0/oplangchain/document_loaders/snowflake_loader.py
--rw-r--r--   0        0        0     2059 2023-08-07 14:51:51.691555 oplangchain-0.1.0/oplangchain/document_loaders/spreedly.py
--rw-r--r--   0        0        0      887 2023-08-07 14:51:51.692555 oplangchain-0.1.0/oplangchain/document_loaders/srt.py
--rw-r--r--   0        0        0     1855 2023-08-07 14:51:51.692555 oplangchain-0.1.0/oplangchain/document_loaders/stripe.py
--rw-r--r--   0        0        0     9041 2023-08-07 14:51:51.693553 oplangchain-0.1.0/oplangchain/document_loaders/telegram.py
--rw-r--r--   0        0        0     1840 2023-08-07 14:51:51.693553 oplangchain-0.1.0/oplangchain/document_loaders/tencent_cos_directory.py
--rw-r--r--   0        0        0     1752 2023-08-07 14:51:51.694554 oplangchain-0.1.0/oplangchain/document_loaders/tencent_cos_file.py
--rw-r--r--   0        0        0     1993 2023-08-07 14:51:51.694554 oplangchain-0.1.0/oplangchain/document_loaders/text.py
--rw-r--r--   0        0        0      994 2023-08-07 14:51:51.695553 oplangchain-0.1.0/oplangchain/document_loaders/tomarkdown.py
--rw-r--r--   0        0        0     1649 2023-08-07 14:51:51.695553 oplangchain-0.1.0/oplangchain/document_loaders/toml.py
--rw-r--r--   0        0        0     6596 2023-08-07 14:51:51.696553 oplangchain-0.1.0/oplangchain/document_loaders/trello.py
--rw-r--r--   0        0        0     1278 2023-08-07 14:51:51.696553 oplangchain-0.1.0/oplangchain/document_loaders/tsv.py
--rw-r--r--   0        0        0     3454 2023-08-07 14:51:51.697556 oplangchain-0.1.0/oplangchain/document_loaders/twitter.py
--rw-r--r--   0        0        0    13877 2023-08-07 14:51:51.697556 oplangchain-0.1.0/oplangchain/document_loaders/unstructured.py
--rw-r--r--   0        0        0     6011 2023-08-07 14:51:51.698554 oplangchain-0.1.0/oplangchain/document_loaders/url.py
--rw-r--r--   0        0        0     4947 2023-08-07 14:51:51.698554 oplangchain-0.1.0/oplangchain/document_loaders/url_playwright.py
--rw-r--r--   0        0        0     5221 2023-08-07 14:51:51.699553 oplangchain-0.1.0/oplangchain/document_loaders/url_selenium.py
--rw-r--r--   0        0        0     1633 2023-08-07 14:51:51.699553 oplangchain-0.1.0/oplangchain/document_loaders/weather.py
--rw-r--r--   0        0        0     8011 2023-08-07 14:51:51.699553 oplangchain-0.1.0/oplangchain/document_loaders/web_base.py
--rw-r--r--   0        0        0     1761 2023-08-07 14:51:51.700553 oplangchain-0.1.0/oplangchain/document_loaders/whatsapp_chat.py
--rw-r--r--   0        0        0     2182 2023-08-07 14:51:51.700553 oplangchain-0.1.0/oplangchain/document_loaders/wikipedia.py
--rw-r--r--   0        0        0     4553 2023-08-07 14:51:51.701553 oplangchain-0.1.0/oplangchain/document_loaders/word_document.py
--rw-r--r--   0        0        0     1479 2023-08-07 14:51:51.701553 oplangchain-0.1.0/oplangchain/document_loaders/xml.py
--rw-r--r--   0        0        0     1623 2023-08-07 14:51:51.702554 oplangchain-0.1.0/oplangchain/document_loaders/xorbits.py
--rw-r--r--   0        0        0    14670 2023-08-07 14:51:51.702554 oplangchain-0.1.0/oplangchain/document_loaders/youtube.py
--rw-r--r--   0        0        0     1436 2023-08-07 14:51:51.703553 oplangchain-0.1.0/oplangchain/document_transformers/__init__.py
--rw-r--r--   0        0        0     3446 2023-08-07 14:51:51.704554 oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_extract.py
--rw-r--r--   0        0        0     2170 2023-08-07 14:51:51.704554 oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_qa.py
--rw-r--r--   0        0        0     2314 2023-08-07 14:51:51.705558 oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_translate.py
--rw-r--r--   0        0        0     8078 2023-08-07 14:51:51.705558 oplangchain-0.1.0/oplangchain/document_transformers/embeddings_redundant_filter.py
--rw-r--r--   0        0        0     1293 2023-08-07 14:51:51.706556 oplangchain-0.1.0/oplangchain/document_transformers/html2text.py
--rw-r--r--   0        0        0     1374 2023-08-07 14:51:51.706556 oplangchain-0.1.0/oplangchain/document_transformers/long_context_reorder.py
--rw-r--r--   0        0        0     1469 2023-08-07 14:51:51.707557 oplangchain-0.1.0/oplangchain/document_transformers/nuclia_text_transform.py
--rw-r--r--   0        0        0     6198 2023-08-07 14:51:51.707557 oplangchain-0.1.0/oplangchain/document_transformers/openai_functions.py
--rw-r--r--   0        0        0     4604 2023-08-07 14:51:51.708556 oplangchain-0.1.0/oplangchain/embeddings/__init__.py
--rw-r--r--   0        0        0     9592 2023-08-07 14:51:51.708556 oplangchain-0.1.0/oplangchain/embeddings/aleph_alpha.py
--rw-r--r--   0        0        0     1631 2023-08-07 14:51:51.709556 oplangchain-0.1.0/oplangchain/embeddings/awa.py
--rw-r--r--   0        0        0      655 2023-08-07 14:51:51.709556 oplangchain-0.1.0/oplangchain/embeddings/base.py
--rw-r--r--   0        0        0     5480 2023-08-07 14:51:51.710557 oplangchain-0.1.0/oplangchain/embeddings/bedrock.py
--rw-r--r--   0        0        0     6547 2023-08-07 14:51:51.710557 oplangchain-0.1.0/oplangchain/embeddings/clarifai.py
--rw-r--r--   0        0        0     3377 2023-08-07 14:51:51.711555 oplangchain-0.1.0/oplangchain/embeddings/cohere.py
--rw-r--r--   0        0        0     4882 2023-08-07 14:51:51.711555 oplangchain-0.1.0/oplangchain/embeddings/dashscope.py
--rw-r--r--   0        0        0     4394 2023-08-07 14:51:51.712552 oplangchain-0.1.0/oplangchain/embeddings/deepinfra.py
--rw-r--r--   0        0        0     2792 2023-08-07 14:51:51.712552 oplangchain-0.1.0/oplangchain/embeddings/edenai.py
--rw-r--r--   0        0        0     8376 2023-08-07 14:51:51.713557 oplangchain-0.1.0/oplangchain/embeddings/elasticsearch.py
--rw-r--r--   0        0        0     4786 2023-08-07 14:51:51.713557 oplangchain-0.1.0/oplangchain/embeddings/embaas.py
--rw-r--r--   0        0        0     1495 2023-08-07 14:51:51.714556 oplangchain-0.1.0/oplangchain/embeddings/fake.py
--rw-r--r--   0        0        0     2682 2023-08-07 14:51:51.714556 oplangchain-0.1.0/oplangchain/embeddings/google_palm.py
--rw-r--r--   0        0        0     1637 2023-08-07 14:51:51.715554 oplangchain-0.1.0/oplangchain/embeddings/gpt4all.py
--rw-r--r--   0        0        0     6034 2023-08-07 14:51:51.715554 oplangchain-0.1.0/oplangchain/embeddings/huggingface.py
--rw-r--r--   0        0        0     3680 2023-08-07 14:51:51.716553 oplangchain-0.1.0/oplangchain/embeddings/huggingface_hub.py
--rw-r--r--   0        0        0     3445 2023-08-07 14:51:51.716553 oplangchain-0.1.0/oplangchain/embeddings/jina.py
--rw-r--r--   0        0        0     4021 2023-08-07 14:51:51.717553 oplangchain-0.1.0/oplangchain/embeddings/llamacpp.py
--rw-r--r--   0        0        0    12073 2023-08-07 14:51:51.717553 oplangchain-0.1.0/oplangchain/embeddings/localai.py
--rw-r--r--   0        0        0     4684 2023-08-07 14:51:51.717553 oplangchain-0.1.0/oplangchain/embeddings/minimax.py
--rw-r--r--   0        0        0     2240 2023-08-07 14:51:51.718553 oplangchain-0.1.0/oplangchain/embeddings/mlflow_gateway.py
--rw-r--r--   0        0        0     2357 2023-08-07 14:51:51.718553 oplangchain-0.1.0/oplangchain/embeddings/modelscope_hub.py
--rw-r--r--   0        0        0     5877 2023-08-07 14:51:51.719553 oplangchain-0.1.0/oplangchain/embeddings/mosaicml.py
--rw-r--r--   0        0        0     2170 2023-08-07 14:51:51.719553 oplangchain-0.1.0/oplangchain/embeddings/nlpcloud.py
--rw-r--r--   0        0        0     3398 2023-08-07 14:51:51.720554 oplangchain-0.1.0/oplangchain/embeddings/octoai_embeddings.py
--rw-r--r--   0        0        0    19937 2023-08-07 14:51:51.720554 oplangchain-0.1.0/oplangchain/embeddings/openai.py
--rw-r--r--   0        0        0     7102 2023-08-07 14:51:51.721553 oplangchain-0.1.0/oplangchain/embeddings/sagemaker_endpoint.py
--rw-r--r--   0        0        0     3747 2023-08-07 14:51:51.721553 oplangchain-0.1.0/oplangchain/embeddings/self_hosted.py
--rw-r--r--   0        0        0     6546 2023-08-07 14:51:51.722557 oplangchain-0.1.0/oplangchain/embeddings/self_hosted_hugging_face.py
--rw-r--r--   0        0        0      179 2023-08-07 14:51:51.722557 oplangchain-0.1.0/oplangchain/embeddings/sentence_transformer.py
--rw-r--r--   0        0        0     3726 2023-08-07 14:51:51.722557 oplangchain-0.1.0/oplangchain/embeddings/spacy_embeddings.py
--rw-r--r--   0        0        0     2386 2023-08-07 14:51:51.723554 oplangchain-0.1.0/oplangchain/embeddings/tensorflow_hub.py
--rw-r--r--   0        0        0     1875 2023-08-07 14:51:51.723554 oplangchain-0.1.0/oplangchain/embeddings/vertexai.py
--rw-r--r--   0        0        0     3305 2023-08-07 14:51:51.724554 oplangchain-0.1.0/oplangchain/embeddings/xinference.py
--rw-r--r--   0        0        0      476 2023-08-07 14:51:51.724554 oplangchain-0.1.0/oplangchain/env.py
--rw-r--r--   0        0        0     5042 2023-08-07 14:51:51.725558 oplangchain-0.1.0/oplangchain/evaluation/__init__.py
--rw-r--r--   0        0        0      165 2023-08-07 14:51:51.726553 oplangchain-0.1.0/oplangchain/evaluation/agents/__init__.py
--rw-r--r--   0        0        0    13153 2023-08-07 14:51:51.727554 oplangchain-0.1.0/oplangchain/evaluation/agents/trajectory_eval_chain.py
--rw-r--r--   0        0        0     5935 2023-08-07 14:51:51.727554 oplangchain-0.1.0/oplangchain/evaluation/agents/trajectory_eval_prompt.py
--rw-r--r--   0        0        0     1398 2023-08-07 14:51:51.728554 oplangchain-0.1.0/oplangchain/evaluation/comparison/__init__.py
--rw-r--r--   0        0        0    15043 2023-08-07 14:51:51.728554 oplangchain-0.1.0/oplangchain/evaluation/comparison/eval_chain.py
--rw-r--r--   0        0        0     2175 2023-08-07 14:51:51.729554 oplangchain-0.1.0/oplangchain/evaluation/comparison/prompt.py
--rw-r--r--   0        0        0     1628 2023-08-07 14:51:51.729554 oplangchain-0.1.0/oplangchain/evaluation/criteria/__init__.py
--rw-r--r--   0        0        0    20294 2023-08-07 14:51:51.730554 oplangchain-0.1.0/oplangchain/evaluation/criteria/eval_chain.py
--rw-r--r--   0        0        0     1751 2023-08-07 14:51:51.731554 oplangchain-0.1.0/oplangchain/evaluation/criteria/prompt.py
--rw-r--r--   0        0        0      323 2023-08-07 14:51:51.732554 oplangchain-0.1.0/oplangchain/evaluation/embedding_distance/__init__.py
--rw-r--r--   0        0        0    15475 2023-08-07 14:51:51.732554 oplangchain-0.1.0/oplangchain/evaluation/embedding_distance/base.py
--rw-r--r--   0        0        0     5192 2023-08-07 14:51:51.733553 oplangchain-0.1.0/oplangchain/evaluation/loading.py
--rw-r--r--   0        0        0      344 2023-08-07 14:51:51.733553 oplangchain-0.1.0/oplangchain/evaluation/qa/__init__.py
--rw-r--r--   0        0        0     9987 2023-08-07 14:51:51.734557 oplangchain-0.1.0/oplangchain/evaluation/qa/eval_chain.py
--rw-r--r--   0        0        0     3906 2023-08-07 14:51:51.734557 oplangchain-0.1.0/oplangchain/evaluation/qa/eval_prompt.py
--rw-r--r--   0        0        0      956 2023-08-07 14:51:51.735557 oplangchain-0.1.0/oplangchain/evaluation/qa/generate_chain.py
--rw-r--r--   0        0        0      601 2023-08-07 14:51:51.735557 oplangchain-0.1.0/oplangchain/evaluation/qa/generate_prompt.py
--rw-r--r--   0        0        0    16800 2023-08-07 14:51:51.736556 oplangchain-0.1.0/oplangchain/evaluation/schema.py
--rw-r--r--   0        0        0      285 2023-08-07 14:51:51.736556 oplangchain-0.1.0/oplangchain/evaluation/string_distance/__init__.py
--rw-r--r--   0        0        0    13996 2023-08-07 14:51:51.737553 oplangchain-0.1.0/oplangchain/evaluation/string_distance/base.py
--rw-r--r--   0        0        0      141 2023-08-07 14:51:51.737553 oplangchain-0.1.0/oplangchain/example_generator.py
--rw-r--r--   0        0        0      162 2023-08-07 14:51:51.738557 oplangchain-0.1.0/oplangchain/formatting.py
--rw-r--r--   0        0        0      751 2023-08-07 14:51:51.739554 oplangchain-0.1.0/oplangchain/graphs/__init__.py
--rw-r--r--   0        0        0     6198 2023-08-07 14:51:51.739554 oplangchain-0.1.0/oplangchain/graphs/arangodb_graph.py
--rw-r--r--   0        0        0     1841 2023-08-07 14:51:51.739554 oplangchain-0.1.0/oplangchain/graphs/hugegraph.py
--rw-r--r--   0        0        0     3559 2023-08-07 14:51:51.740556 oplangchain-0.1.0/oplangchain/graphs/kuzu_graph.py
--rw-r--r--   0        0        0      713 2023-08-07 14:51:51.740556 oplangchain-0.1.0/oplangchain/graphs/memgraph_graph.py
--rw-r--r--   0        0        0     7362 2023-08-07 14:51:51.741553 oplangchain-0.1.0/oplangchain/graphs/nebula_graph.py
--rw-r--r--   0        0        0     3625 2023-08-07 14:51:51.741553 oplangchain-0.1.0/oplangchain/graphs/neo4j_graph.py
--rw-r--r--   0        0        0     6553 2023-08-07 14:51:51.742553 oplangchain-0.1.0/oplangchain/graphs/neptune_graph.py
--rw-r--r--   0        0        0     5877 2023-08-07 14:51:51.742553 oplangchain-0.1.0/oplangchain/graphs/networkx_graph.py
--rw-r--r--   0        0        0     9461 2023-08-07 14:51:51.743553 oplangchain-0.1.0/oplangchain/graphs/rdf_graph.py
--rw-r--r--   0        0        0      207 2023-08-07 14:51:51.743553 oplangchain-0.1.0/oplangchain/indexes/__init__.py
--rw-r--r--   0        0        0     1712 2023-08-07 14:51:51.744553 oplangchain-0.1.0/oplangchain/indexes/graph.py
--rw-r--r--   0        0        0       49 2023-08-07 14:51:51.745553 oplangchain-0.1.0/oplangchain/indexes/prompts/__init__.py
--rw-r--r--   0        0        0     1947 2023-08-07 14:51:51.745553 oplangchain-0.1.0/oplangchain/indexes/prompts/entity_extraction.py
--rw-r--r--   0        0        0     1152 2023-08-07 14:51:51.746553 oplangchain-0.1.0/oplangchain/indexes/prompts/entity_summarization.py
--rw-r--r--   0        0        0     1584 2023-08-07 14:51:51.746553 oplangchain-0.1.0/oplangchain/indexes/prompts/knowledge_triplet_extraction.py
--rw-r--r--   0        0        0     3048 2023-08-07 14:51:51.747555 oplangchain-0.1.0/oplangchain/indexes/vectorstore.py
--rw-r--r--   0        0        0      277 2023-08-07 14:51:51.747555 oplangchain-0.1.0/oplangchain/input.py
--rw-r--r--   0        0        0     6388 2023-08-07 14:51:51.748554 oplangchain-0.1.0/oplangchain/llms/__init__.py
--rw-r--r--   0        0        0     4996 2023-08-07 14:51:51.749553 oplangchain-0.1.0/oplangchain/llms/ai21.py
--rw-r--r--   0        0        0    11352 2023-08-07 14:51:51.749553 oplangchain-0.1.0/oplangchain/llms/aleph_alpha.py
--rw-r--r--   0        0        0     3021 2023-08-07 14:51:51.749553 oplangchain-0.1.0/oplangchain/llms/amazon_api_gateway.py
--rw-r--r--   0        0        0    11164 2023-08-07 14:51:51.750554 oplangchain-0.1.0/oplangchain/llms/anthropic.py
--rw-r--r--   0        0        0     4657 2023-08-07 14:51:51.750554 oplangchain-0.1.0/oplangchain/llms/anyscale.py
--rw-r--r--   0        0        0     5365 2023-08-07 14:51:51.751553 oplangchain-0.1.0/oplangchain/llms/aviary.py
--rw-r--r--   0        0        0    10218 2023-08-07 14:51:51.751553 oplangchain-0.1.0/oplangchain/llms/azureml_endpoint.py
--rw-r--r--   0        0        0     4309 2023-08-07 14:51:51.752555 oplangchain-0.1.0/oplangchain/llms/bananadev.py
--rw-r--r--   0        0        0    34723 2023-08-07 14:51:51.752555 oplangchain-0.1.0/oplangchain/llms/base.py
--rw-r--r--   0        0        0     2359 2023-08-07 14:51:51.753553 oplangchain-0.1.0/oplangchain/llms/baseten.py
--rw-r--r--   0        0        0     9064 2023-08-07 14:51:51.753553 oplangchain-0.1.0/oplangchain/llms/beam.py
--rw-r--r--   0        0        0     6690 2023-08-07 14:51:51.754553 oplangchain-0.1.0/oplangchain/llms/bedrock.py
--rw-r--r--   0        0        0     3773 2023-08-07 14:51:51.754553 oplangchain-0.1.0/oplangchain/llms/cerebriumai.py
--rw-r--r--   0        0        0     3937 2023-08-07 14:51:51.755560 oplangchain-0.1.0/oplangchain/llms/chatglm.py
--rw-r--r--   0        0        0     5802 2023-08-07 14:51:51.755560 oplangchain-0.1.0/oplangchain/llms/clarifai.py
--rw-r--r--   0        0        0     7303 2023-08-07 14:51:51.756555 oplangchain-0.1.0/oplangchain/llms/cohere.py
--rw-r--r--   0        0        0     4187 2023-08-07 14:51:51.756555 oplangchain-0.1.0/oplangchain/llms/ctransformers.py
--rw-r--r--   0        0        0    12068 2023-08-07 14:51:51.757555 oplangchain-0.1.0/oplangchain/llms/databricks.py
--rw-r--r--   0        0        0     3755 2023-08-07 14:51:51.757555 oplangchain-0.1.0/oplangchain/llms/deepinfra.py
--rw-r--r--   0        0        0     7445 2023-08-07 14:51:51.758555 oplangchain-0.1.0/oplangchain/llms/edenai.py
--rw-r--r--   0        0        0     1335 2023-08-07 14:51:51.758555 oplangchain-0.1.0/oplangchain/llms/fake.py
--rw-r--r--   0        0        0    13035 2023-08-07 14:51:51.758555 oplangchain-0.1.0/oplangchain/llms/fireworks.py
--rw-r--r--   0        0        0     3651 2023-08-07 14:51:51.759554 oplangchain-0.1.0/oplangchain/llms/forefrontai.py
--rw-r--r--   0        0        0     5733 2023-08-07 14:51:51.759554 oplangchain-0.1.0/oplangchain/llms/google_palm.py
--rw-r--r--   0        0        0     5122 2023-08-07 14:51:51.760553 oplangchain-0.1.0/oplangchain/llms/gooseai.py
--rw-r--r--   0        0        0     6312 2023-08-07 14:51:51.760553 oplangchain-0.1.0/oplangchain/llms/gpt4all.py
--rw-r--r--   0        0        0     5452 2023-08-07 14:51:51.761553 oplangchain-0.1.0/oplangchain/llms/huggingface_endpoint.py
--rw-r--r--   0        0        0     4603 2023-08-07 14:51:51.761553 oplangchain-0.1.0/oplangchain/llms/huggingface_hub.py
--rw-r--r--   0        0        0     6566 2023-08-07 14:51:51.762553 oplangchain-0.1.0/oplangchain/llms/huggingface_pipeline.py
--rw-r--r--   0        0        0     9715 2023-08-07 14:51:51.762553 oplangchain-0.1.0/oplangchain/llms/huggingface_text_gen_inference.py
--rw-r--r--   0        0        0     2541 2023-08-07 14:51:51.763557 oplangchain-0.1.0/oplangchain/llms/human.py
--rw-r--r--   0        0        0     5065 2023-08-07 14:51:51.763557 oplangchain-0.1.0/oplangchain/llms/koboldai.py
--rw-r--r--   0        0        0    10889 2023-08-07 14:51:51.763557 oplangchain-0.1.0/oplangchain/llms/llamacpp.py
--rw-r--r--   0        0        0     1249 2023-08-07 14:51:51.764557 oplangchain-0.1.0/oplangchain/llms/loading.py
--rw-r--r--   0        0        0     1874 2023-08-07 14:51:51.764557 oplangchain-0.1.0/oplangchain/llms/manifest.py
--rw-r--r--   0        0        0     5154 2023-08-07 14:51:51.765556 oplangchain-0.1.0/oplangchain/llms/minimax.py
--rw-r--r--   0        0        0     2919 2023-08-07 14:51:51.765556 oplangchain-0.1.0/oplangchain/llms/mlflow_ai_gateway.py
--rw-r--r--   0        0        0     3239 2023-08-07 14:51:51.766557 oplangchain-0.1.0/oplangchain/llms/modal.py
--rw-r--r--   0        0        0     6742 2023-08-07 14:51:51.766557 oplangchain-0.1.0/oplangchain/llms/mosaicml.py
--rw-r--r--   0        0        0     5442 2023-08-07 14:51:51.767556 oplangchain-0.1.0/oplangchain/llms/nlpcloud.py
--rw-r--r--   0        0        0     3804 2023-08-07 14:51:51.767556 oplangchain-0.1.0/oplangchain/llms/octoai_endpoint.py
--rw-r--r--   0        0        0    34722 2023-08-07 14:51:51.768558 oplangchain-0.1.0/oplangchain/llms/openai.py
--rw-r--r--   0        0        0     9922 2023-08-07 14:51:51.768558 oplangchain-0.1.0/oplangchain/llms/openllm.py
--rw-r--r--   0        0        0      794 2023-08-07 14:51:51.769556 oplangchain-0.1.0/oplangchain/llms/openlm.py
--rw-r--r--   0        0        0     5263 2023-08-07 14:51:51.769556 oplangchain-0.1.0/oplangchain/llms/petals.py
--rw-r--r--   0        0        0     4013 2023-08-07 14:51:51.770556 oplangchain-0.1.0/oplangchain/llms/pipelineai.py
--rw-r--r--   0        0        0     1527 2023-08-07 14:51:51.770556 oplangchain-0.1.0/oplangchain/llms/predibase.py
--rw-r--r--   0        0        0     4364 2023-08-07 14:51:51.771554 oplangchain-0.1.0/oplangchain/llms/predictionguard.py
--rw-r--r--   0        0        0     8682 2023-08-07 14:51:51.771554 oplangchain-0.1.0/oplangchain/llms/promptlayer_openai.py
--rw-r--r--   0        0        0     5160 2023-08-07 14:51:51.772556 oplangchain-0.1.0/oplangchain/llms/replicate.py
--rw-r--r--   0        0        0     7335 2023-08-07 14:51:51.772556 oplangchain-0.1.0/oplangchain/llms/rwkv.py
--rw-r--r--   0        0        0     8811 2023-08-07 14:51:51.773554 oplangchain-0.1.0/oplangchain/llms/sagemaker_endpoint.py
--rw-r--r--   0        0        0     7673 2023-08-07 14:51:51.773554 oplangchain-0.1.0/oplangchain/llms/self_hosted.py
--rw-r--r--   0        0        0     7689 2023-08-07 14:51:51.774553 oplangchain-0.1.0/oplangchain/llms/self_hosted_hugging_face.py
--rw-r--r--   0        0        0     4563 2023-08-07 14:51:51.774553 oplangchain-0.1.0/oplangchain/llms/stochasticai.py
--rw-r--r--   0        0        0     7579 2023-08-07 14:51:51.775557 oplangchain-0.1.0/oplangchain/llms/textgen.py
--rw-r--r--   0        0        0     7872 2023-08-07 14:51:51.775557 oplangchain-0.1.0/oplangchain/llms/tongyi.py
--rw-r--r--   0        0        0      246 2023-08-07 14:51:51.776555 oplangchain-0.1.0/oplangchain/llms/utils.py
--rw-r--r--   0        0        0     7709 2023-08-07 14:51:51.776555 oplangchain-0.1.0/oplangchain/llms/vertexai.py
--rw-r--r--   0        0        0     3978 2023-08-07 14:51:51.777553 oplangchain-0.1.0/oplangchain/llms/vllm.py
--rw-r--r--   0        0        0     4909 2023-08-07 14:51:51.777553 oplangchain-0.1.0/oplangchain/llms/writer.py
--rw-r--r--   0        0        0     6011 2023-08-07 14:51:51.777553 oplangchain-0.1.0/oplangchain/llms/xinference.py
--rw-r--r--   0        0        0       41 2023-08-07 14:51:51.778553 oplangchain-0.1.0/oplangchain/load/__init__.py
--rw-r--r--   0        0        0      753 2023-08-07 14:51:51.779553 oplangchain-0.1.0/oplangchain/load/dump.py
--rw-r--r--   0        0        0     4037 2023-08-07 14:51:51.779553 oplangchain-0.1.0/oplangchain/load/load.py
--rw-r--r--   0        0        0     4618 2023-08-07 14:51:51.779553 oplangchain-0.1.0/oplangchain/load/serializable.py
--rw-r--r--   0        0        0     2844 2023-08-07 14:51:51.780558 oplangchain-0.1.0/oplangchain/memory/__init__.py
--rw-r--r--   0        0        0     3068 2023-08-07 14:51:51.781555 oplangchain-0.1.0/oplangchain/memory/buffer.py
--rw-r--r--   0        0        0     1228 2023-08-07 14:51:51.781555 oplangchain-0.1.0/oplangchain/memory/buffer_window.py
--rw-r--r--   0        0        0     1612 2023-08-07 14:51:51.782555 oplangchain-0.1.0/oplangchain/memory/chat_memory.py
--rw-r--r--   0        0        0     1566 2023-08-07 14:51:51.783553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/__init__.py
--rw-r--r--   0        0        0     2367 2023-08-07 14:51:51.783553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/cassandra.py
--rw-r--r--   0        0        0     6493 2023-08-07 14:51:51.784555 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/cosmos_db.py
--rw-r--r--   0        0        0     2881 2023-08-07 14:51:51.784555 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/dynamodb.py
--rw-r--r--   0        0        0     1362 2023-08-07 14:51:51.785553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/file.py
--rw-r--r--   0        0        0     3332 2023-08-07 14:51:51.785553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/firestore.py
--rw-r--r--   0        0        0      584 2023-08-07 14:51:51.785553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/in_memory.py
--rw-r--r--   0        0        0     6829 2023-08-07 14:51:51.786554 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/momento.py
--rw-r--r--   0        0        0     2719 2023-08-07 14:51:51.786554 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/mongodb.py
--rw-r--r--   0        0        0     2644 2023-08-07 14:51:51.787553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/postgres.py
--rw-r--r--   0        0        0     1945 2023-08-07 14:51:51.787553 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/redis.py
--rw-r--r--   0        0        0     2897 2023-08-07 14:51:51.788555 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/sql.py
--rw-r--r--   0        0        0     1176 2023-08-07 14:51:51.788555 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/streamlit.py
--rw-r--r--   0        0        0     6402 2023-08-07 14:51:51.789557 oplangchain-0.1.0/oplangchain/memory/chat_message_histories/zep.py
--rw-r--r--   0        0        0     2889 2023-08-07 14:51:51.789557 oplangchain-0.1.0/oplangchain/memory/combined.py
--rw-r--r--   0        0        0    12982 2023-08-07 14:51:51.790555 oplangchain-0.1.0/oplangchain/memory/entity.py
--rw-r--r--   0        0        0     5017 2023-08-07 14:51:51.790555 oplangchain-0.1.0/oplangchain/memory/kg.py
--rw-r--r--   0        0        0     3098 2023-08-07 14:51:51.790555 oplangchain-0.1.0/oplangchain/memory/motorhead_memory.py
--rw-r--r--   0        0        0     8176 2023-08-07 14:51:51.791553 oplangchain-0.1.0/oplangchain/memory/prompt.py
--rw-r--r--   0        0        0      789 2023-08-07 14:51:51.791553 oplangchain-0.1.0/oplangchain/memory/readonly.py
--rw-r--r--   0        0        0      756 2023-08-07 14:51:51.792554 oplangchain-0.1.0/oplangchain/memory/simple.py
--rw-r--r--   0        0        0     3342 2023-08-07 14:51:51.792554 oplangchain-0.1.0/oplangchain/memory/summary.py
--rw-r--r--   0        0        0     2933 2023-08-07 14:51:51.793554 oplangchain-0.1.0/oplangchain/memory/summary_buffer.py
--rw-r--r--   0        0        0     1915 2023-08-07 14:51:51.793554 oplangchain-0.1.0/oplangchain/memory/token_buffer.py
--rw-r--r--   0        0        0      687 2023-08-07 14:51:51.793554 oplangchain-0.1.0/oplangchain/memory/utils.py
--rw-r--r--   0        0        0     2976 2023-08-07 14:51:51.794553 oplangchain-0.1.0/oplangchain/memory/vectorstore.py
--rw-r--r--   0        0        0     5067 2023-08-07 14:51:51.794553 oplangchain-0.1.0/oplangchain/memory/zep_memory.py
--rw-r--r--   0        0        0     3236 2023-08-07 14:51:51.795553 oplangchain-0.1.0/oplangchain/model_laboratory.py
--rw-r--r--   0        0        0     1588 2023-08-07 14:51:51.795553 oplangchain-0.1.0/oplangchain/output_parsers/__init__.py
--rw-r--r--   0        0        0     1071 2023-08-07 14:51:51.796553 oplangchain-0.1.0/oplangchain/output_parsers/boolean.py
--rw-r--r--   0        0        0     1763 2023-08-07 14:51:51.797557 oplangchain-0.1.0/oplangchain/output_parsers/combining.py
--rw-r--r--   0        0        0     1817 2023-08-07 14:51:51.797557 oplangchain-0.1.0/oplangchain/output_parsers/datetime.py
--rw-r--r--   0        0        0     1138 2023-08-07 14:51:51.798554 oplangchain-0.1.0/oplangchain/output_parsers/enum.py
--rw-r--r--   0        0        0     1805 2023-08-07 14:51:51.798554 oplangchain-0.1.0/oplangchain/output_parsers/fix.py
--rw-r--r--   0        0        0      810 2023-08-07 14:51:51.799553 oplangchain-0.1.0/oplangchain/output_parsers/format_instructions.py
--rw-r--r--   0        0        0     2209 2023-08-07 14:51:51.799553 oplangchain-0.1.0/oplangchain/output_parsers/json.py
--rw-r--r--   0        0        0      939 2023-08-07 14:51:51.800554 oplangchain-0.1.0/oplangchain/output_parsers/list.py
--rw-r--r--   0        0        0      702 2023-08-07 14:51:51.800554 oplangchain-0.1.0/oplangchain/output_parsers/loading.py
--rw-r--r--   0        0        0     3350 2023-08-07 14:51:51.801553 oplangchain-0.1.0/oplangchain/output_parsers/openai_functions.py
--rw-r--r--   0        0        0      503 2023-08-07 14:51:51.801553 oplangchain-0.1.0/oplangchain/output_parsers/prompts.py
--rw-r--r--   0        0        0     1731 2023-08-07 14:51:51.802553 oplangchain-0.1.0/oplangchain/output_parsers/pydantic.py
--rw-r--r--   0        0        0     3165 2023-08-07 14:51:51.802553 oplangchain-0.1.0/oplangchain/output_parsers/rail_parser.py
--rw-r--r--   0        0        0     1196 2023-08-07 14:51:51.803553 oplangchain-0.1.0/oplangchain/output_parsers/regex.py
--rw-r--r--   0        0        0     1696 2023-08-07 14:51:51.803553 oplangchain-0.1.0/oplangchain/output_parsers/regex_dict.py
--rw-r--r--   0        0        0     4709 2023-08-07 14:51:51.803553 oplangchain-0.1.0/oplangchain/output_parsers/retry.py
--rw-r--r--   0        0        0     3070 2023-08-07 14:51:51.804553 oplangchain-0.1.0/oplangchain/output_parsers/structured.py
--rw-r--r--   0        0        0     2744 2023-08-07 14:51:51.805554 oplangchain-0.1.0/oplangchain/prompts/__init__.py
--rw-r--r--   0        0        0     3671 2023-08-07 14:51:51.805554 oplangchain-0.1.0/oplangchain/prompts/base.py
--rw-r--r--   0        0        0    21563 2023-08-07 14:51:51.806555 oplangchain-0.1.0/oplangchain/prompts/chat.py
--rw-r--r--   0        0        0      553 2023-08-07 14:51:51.806555 oplangchain-0.1.0/oplangchain/prompts/example_selector/__init__.py
--rw-r--r--   0        0        0      526 2023-08-07 14:51:51.807553 oplangchain-0.1.0/oplangchain/prompts/example_selector/base.py
--rw-r--r--   0        0        0     2433 2023-08-07 14:51:51.808556 oplangchain-0.1.0/oplangchain/prompts/example_selector/length_based.py
--rw-r--r--   0        0        0     3798 2023-08-07 14:51:51.808556 oplangchain-0.1.0/oplangchain/prompts/example_selector/ngram_overlap.py
--rw-r--r--   0        0        0     6848 2023-08-07 14:51:51.809554 oplangchain-0.1.0/oplangchain/prompts/example_selector/semantic_similarity.py
--rw-r--r--   0        0        0    11737 2023-08-07 14:51:51.809554 oplangchain-0.1.0/oplangchain/prompts/few_shot.py
--rw-r--r--   0        0        0     5423 2023-08-07 14:51:51.810553 oplangchain-0.1.0/oplangchain/prompts/few_shot_with_templates.py
--rw-r--r--   0        0        0     5507 2023-08-07 14:51:51.810553 oplangchain-0.1.0/oplangchain/prompts/loading.py
--rw-r--r--   0        0        0     2254 2023-08-07 14:51:51.811553 oplangchain-0.1.0/oplangchain/prompts/pipeline.py
--rw-r--r--   0        0        0     8136 2023-08-07 14:51:51.811553 oplangchain-0.1.0/oplangchain/prompts/prompt.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.811553 oplangchain-0.1.0/oplangchain/py.typed
--rw-r--r--   0        0        0      111 2023-08-07 14:51:51.812554 oplangchain-0.1.0/oplangchain/python.py
--rw-r--r--   0        0        0      212 2023-08-07 14:51:51.812554 oplangchain-0.1.0/oplangchain/requests.py
--rw-r--r--   0        0        0     3614 2023-08-07 14:51:51.813554 oplangchain-0.1.0/oplangchain/retrievers/__init__.py
--rw-r--r--   0        0        0      582 2023-08-07 14:51:51.814556 oplangchain-0.1.0/oplangchain/retrievers/arxiv.py
--rw-r--r--   0        0        0     4042 2023-08-07 14:51:51.814556 oplangchain-0.1.0/oplangchain/retrievers/azure_cognitive_search.py
--rw-r--r--   0        0        0     3653 2023-08-07 14:51:51.815554 oplangchain-0.1.0/oplangchain/retrievers/bm25.py
--rw-r--r--   0        0        0     2649 2023-08-07 14:51:51.815554 oplangchain-0.1.0/oplangchain/retrievers/chaindesk.py
--rw-r--r--   0        0        0     2998 2023-08-07 14:51:51.816554 oplangchain-0.1.0/oplangchain/retrievers/chatgpt_plugin_retriever.py
--rw-r--r--   0        0        0     2255 2023-08-07 14:51:51.816554 oplangchain-0.1.0/oplangchain/retrievers/contextual_compression.py
--rw-r--r--   0        0        0     2303 2023-08-07 14:51:51.817555 oplangchain-0.1.0/oplangchain/retrievers/databerry.py
--rw-r--r--   0        0        0     6730 2023-08-07 14:51:51.817555 oplangchain-0.1.0/oplangchain/retrievers/docarray.py
--rw-r--r--   0        0        0      591 2023-08-07 14:51:51.818556 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/__init__.py
--rw-r--r--   0        0        0     3658 2023-08-07 14:51:51.819555 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/base.py
--rw-r--r--   0        0        0     3813 2023-08-07 14:51:51.819555 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_extract.py
--rw-r--r--   0        0        0      366 2023-08-07 14:51:51.820553 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_extract_prompt.py
--rw-r--r--   0        0        0     2965 2023-08-07 14:51:51.820553 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_filter.py
--rw-r--r--   0        0        0      231 2023-08-07 14:51:51.821553 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_filter_prompt.py
--rw-r--r--   0        0        0     2961 2023-08-07 14:51:51.821553 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/cohere_rerank.py
--rw-r--r--   0        0        0     3139 2023-08-07 14:51:51.822559 oplangchain-0.1.0/oplangchain/retrievers/document_compressors/embeddings_filter.py
--rw-r--r--   0        0        0     4658 2023-08-07 14:51:51.822559 oplangchain-0.1.0/oplangchain/retrievers/elastic_search_bm25.py
--rw-r--r--   0        0        0     5793 2023-08-07 14:51:51.822559 oplangchain-0.1.0/oplangchain/retrievers/ensemble.py
--rw-r--r--   0        0        0     7430 2023-08-07 14:51:51.823557 oplangchain-0.1.0/oplangchain/retrievers/google_cloud_enterprise_search.py
--rw-r--r--   0        0        0    12601 2023-08-07 14:51:51.823557 oplangchain-0.1.0/oplangchain/retrievers/kendra.py
--rw-r--r--   0        0        0     2527 2023-08-07 14:51:51.824556 oplangchain-0.1.0/oplangchain/retrievers/knn.py
--rw-r--r--   0        0        0     3022 2023-08-07 14:51:51.824556 oplangchain-0.1.0/oplangchain/retrievers/llama_index.py
--rw-r--r--   0        0        0     3373 2023-08-07 14:51:51.825559 oplangchain-0.1.0/oplangchain/retrievers/merger_retriever.py
--rw-r--r--   0        0        0     1439 2023-08-07 14:51:51.825559 oplangchain-0.1.0/oplangchain/retrievers/metal.py
--rw-r--r--   0        0        0     2377 2023-08-07 14:51:51.826554 oplangchain-0.1.0/oplangchain/retrievers/milvus.py
--rw-r--r--   0        0        0     4834 2023-08-07 14:51:51.826554 oplangchain-0.1.0/oplangchain/retrievers/multi_query.py
--rw-r--r--   0        0        0     5436 2023-08-07 14:51:51.827554 oplangchain-0.1.0/oplangchain/retrievers/pinecone_hybrid_search.py
--rw-r--r--   0        0        0      592 2023-08-07 14:51:51.827554 oplangchain-0.1.0/oplangchain/retrievers/pubmed.py
--rw-r--r--   0        0        0       94 2023-08-07 14:51:51.827554 oplangchain-0.1.0/oplangchain/retrievers/pupmed.py
--rw-r--r--   0        0        0     2601 2023-08-07 14:51:51.828554 oplangchain-0.1.0/oplangchain/retrievers/re_phraser.py
--rw-r--r--   0        0        0     1903 2023-08-07 14:51:51.829553 oplangchain-0.1.0/oplangchain/retrievers/remote_retriever.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.829553 oplangchain-0.1.0/oplangchain/retrievers/self_query/__init__.py
--rw-r--r--   0        0        0     5945 2023-08-07 14:51:51.830554 oplangchain-0.1.0/oplangchain/retrievers/self_query/base.py
--rw-r--r--   0        0        0     1442 2023-08-07 14:51:51.830554 oplangchain-0.1.0/oplangchain/retrievers/self_query/chroma.py
--rw-r--r--   0        0        0     2592 2023-08-07 14:51:51.831553 oplangchain-0.1.0/oplangchain/retrievers/self_query/deeplake.py
--rw-r--r--   0        0        0     3595 2023-08-07 14:51:51.831553 oplangchain-0.1.0/oplangchain/retrievers/self_query/myscale.py
--rw-r--r--   0        0        0     1448 2023-08-07 14:51:51.832554 oplangchain-0.1.0/oplangchain/retrievers/self_query/pinecone.py
--rw-r--r--   0        0        0     2811 2023-08-07 14:51:51.832554 oplangchain-0.1.0/oplangchain/retrievers/self_query/qdrant.py
--rw-r--r--   0        0        0     1501 2023-08-07 14:51:51.833553 oplangchain-0.1.0/oplangchain/retrievers/self_query/weaviate.py
--rw-r--r--   0        0        0     3657 2023-08-07 14:51:51.833553 oplangchain-0.1.0/oplangchain/retrievers/svm.py
--rw-r--r--   0        0        0     4035 2023-08-07 14:51:51.834553 oplangchain-0.1.0/oplangchain/retrievers/tfidf.py
--rw-r--r--   0        0        0     5812 2023-08-07 14:51:51.834553 oplangchain-0.1.0/oplangchain/retrievers/time_weighted_retriever.py
--rw-r--r--   0        0        0     4597 2023-08-07 14:51:51.834553 oplangchain-0.1.0/oplangchain/retrievers/vespa_retriever.py
--rw-r--r--   0        0        0     4053 2023-08-07 14:51:51.835553 oplangchain-0.1.0/oplangchain/retrievers/weaviate_hybrid_search.py
--rw-r--r--   0        0        0     8276 2023-08-07 14:51:51.835553 oplangchain-0.1.0/oplangchain/retrievers/web_research.py
--rw-r--r--   0        0        0      605 2023-08-07 14:51:51.836553 oplangchain-0.1.0/oplangchain/retrievers/wikipedia.py
--rw-r--r--   0        0        0     3071 2023-08-07 14:51:51.836553 oplangchain-0.1.0/oplangchain/retrievers/zep.py
--rw-r--r--   0        0        0     2671 2023-08-07 14:51:51.837553 oplangchain-0.1.0/oplangchain/retrievers/zilliz.py
--rw-r--r--   0        0        0     1718 2023-08-07 14:51:51.837553 oplangchain-0.1.0/oplangchain/schema/__init__.py
--rw-r--r--   0        0        0      643 2023-08-07 14:51:51.838554 oplangchain-0.1.0/oplangchain/schema/agent.py
--rw-r--r--   0        0        0     2656 2023-08-07 14:51:51.838554 oplangchain-0.1.0/oplangchain/schema/document.py
--rw-r--r--   0        0        0    10169 2023-08-07 14:51:51.839555 oplangchain-0.1.0/oplangchain/schema/language_model.py
--rw-r--r--   0        0        0     4095 2023-08-07 14:51:51.839555 oplangchain-0.1.0/oplangchain/schema/memory.py
--rw-r--r--   0        0        0     7482 2023-08-07 14:51:51.840555 oplangchain-0.1.0/oplangchain/schema/messages.py
--rw-r--r--   0        0        0     5447 2023-08-07 14:51:51.840555 oplangchain-0.1.0/oplangchain/schema/output.py
--rw-r--r--   0        0        0     7782 2023-08-07 14:51:51.841553 oplangchain-0.1.0/oplangchain/schema/output_parser.py
--rw-r--r--   0        0        0      634 2023-08-07 14:51:51.841553 oplangchain-0.1.0/oplangchain/schema/prompt.py
--rw-r--r--   0        0        0     6865 2023-08-07 14:51:51.841553 oplangchain-0.1.0/oplangchain/schema/prompt_template.py
--rw-r--r--   0        0        0    10045 2023-08-07 14:51:51.842553 oplangchain-0.1.0/oplangchain/schema/retriever.py
--rw-r--r--   0        0        0    40366 2023-08-07 14:51:51.842553 oplangchain-0.1.0/oplangchain/schema/runnable.py
--rw-r--r--   0        0        0      120 2023-08-07 14:51:51.843553 oplangchain-0.1.0/oplangchain/serpapi.py
--rw-r--r--   0        0        0      533 2023-08-07 14:51:51.843553 oplangchain-0.1.0/oplangchain/server.py
--rw-r--r--   0        0        0     3561 2023-08-07 14:51:51.844553 oplangchain-0.1.0/oplangchain/smith/__init__.py
--rw-r--r--   0        0        0     2189 2023-08-07 14:51:51.845553 oplangchain-0.1.0/oplangchain/smith/evaluation/__init__.py
--rw-r--r--   0        0        0     8567 2023-08-07 14:51:51.845553 oplangchain-0.1.0/oplangchain/smith/evaluation/config.py
--rw-r--r--   0        0        0    51494 2023-08-07 14:51:51.846553 oplangchain-0.1.0/oplangchain/smith/evaluation/runner_utils.py
--rw-r--r--   0        0        0    15807 2023-08-07 14:51:51.847555 oplangchain-0.1.0/oplangchain/smith/evaluation/string_run_evaluator.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.847555 oplangchain-0.1.0/oplangchain/smith/evaluation/utils.py
--rw-r--r--   0        0        0      129 2023-08-07 14:51:51.848554 oplangchain-0.1.0/oplangchain/sql_database.py
--rw-r--r--   0        0        0    38439 2023-08-07 14:51:51.848554 oplangchain-0.1.0/oplangchain/text_splitter.py
--rw-r--r--   0        0        0     6594 2023-08-07 14:51:51.849553 oplangchain-0.1.0/oplangchain/tools/__init__.py
--rw-r--r--   0        0        0      237 2023-08-07 14:51:51.850553 oplangchain-0.1.0/oplangchain/tools/amadeus/__init__.py
--rw-r--r--   0        0        0      407 2023-08-07 14:51:51.850553 oplangchain-0.1.0/oplangchain/tools/amadeus/base.py
--rw-r--r--   0        0        0     1974 2023-08-07 14:51:51.850553 oplangchain-0.1.0/oplangchain/tools/amadeus/closest_airport.py
--rw-r--r--   0        0        0     5557 2023-08-07 14:51:51.851553 oplangchain-0.1.0/oplangchain/tools/amadeus/flight_search.py
--rw-r--r--   0        0        0     1123 2023-08-07 14:51:51.851553 oplangchain-0.1.0/oplangchain/tools/amadeus/utils.py
--rw-r--r--   0        0        0       25 2023-08-07 14:51:51.852553 oplangchain-0.1.0/oplangchain/tools/arxiv/__init__.py
--rw-r--r--   0        0        0     1000 2023-08-07 14:51:51.853554 oplangchain-0.1.0/oplangchain/tools/arxiv/tool.py
--rw-r--r--   0        0        0      595 2023-08-07 14:51:51.853554 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/__init__.py
--rw-r--r--   0        0        0     5326 2023-08-07 14:51:51.854554 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/form_recognizer.py
--rw-r--r--   0        0        0     5255 2023-08-07 14:51:51.854554 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/image_analysis.py
--rw-r--r--   0        0        0     4296 2023-08-07 14:51:51.855557 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/speech2text.py
--rw-r--r--   0        0        0     3646 2023-08-07 14:51:51.855557 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/text2speech.py
--rw-r--r--   0        0        0      776 2023-08-07 14:51:51.856554 oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/utils.py
--rw-r--r--   0        0        0    26843 2023-08-07 14:51:51.856554 oplangchain-0.1.0/oplangchain/tools/base.py
--rw-r--r--   0        0        0      160 2023-08-07 14:51:51.857554 oplangchain-0.1.0/oplangchain/tools/bing_search/__init__.py
--rw-r--r--   0        0        0     1435 2023-08-07 14:51:51.858553 oplangchain-0.1.0/oplangchain/tools/bing_search/tool.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.858553 oplangchain-0.1.0/oplangchain/tools/brave_search/__init__.py
--rw-r--r--   0        0        0     1336 2023-08-07 14:51:51.859554 oplangchain-0.1.0/oplangchain/tools/brave_search/tool.py
--rw-r--r--   0        0        0     1736 2023-08-07 14:51:51.859554 oplangchain-0.1.0/oplangchain/tools/convert_to_openai.py
--rw-r--r--   0        0        0      258 2023-08-07 14:51:51.860553 oplangchain-0.1.0/oplangchain/tools/dataforseo_api_search/__init__.py
--rw-r--r--   0        0        0     2176 2023-08-07 14:51:51.860553 oplangchain-0.1.0/oplangchain/tools/dataforseo_api_search/tool.py
--rw-r--r--   0        0        0      137 2023-08-07 14:51:51.861553 oplangchain-0.1.0/oplangchain/tools/ddg_search/__init__.py
--rw-r--r--   0        0        0     2315 2023-08-07 14:51:51.862553 oplangchain-0.1.0/oplangchain/tools/ddg_search/tool.py
--rw-r--r--   0        0        0      653 2023-08-07 14:51:51.862553 oplangchain-0.1.0/oplangchain/tools/file_management/__init__.py
--rw-r--r--   0        0        0     1724 2023-08-07 14:51:51.863557 oplangchain-0.1.0/oplangchain/tools/file_management/copy.py
--rw-r--r--   0        0        0     1320 2023-08-07 14:51:51.863557 oplangchain-0.1.0/oplangchain/tools/file_management/delete.py
--rw-r--r--   0        0        0     1940 2023-08-07 14:51:51.864555 oplangchain-0.1.0/oplangchain/tools/file_management/file_search.py
--rw-r--r--   0        0        0     1407 2023-08-07 14:51:51.865554 oplangchain-0.1.0/oplangchain/tools/file_management/list_dir.py
--rw-r--r--   0        0        0     1864 2023-08-07 14:51:51.865554 oplangchain-0.1.0/oplangchain/tools/file_management/move.py
--rw-r--r--   0        0        0     1315 2023-08-07 14:51:51.866553 oplangchain-0.1.0/oplangchain/tools/file_management/read.py
--rw-r--r--   0        0        0     1708 2023-08-07 14:51:51.866553 oplangchain-0.1.0/oplangchain/tools/file_management/utils.py
--rw-r--r--   0        0        0     1589 2023-08-07 14:51:51.866553 oplangchain-0.1.0/oplangchain/tools/file_management/write.py
--rw-r--r--   0        0        0       20 2023-08-07 14:51:51.867553 oplangchain-0.1.0/oplangchain/tools/github/__init__.py
--rw-r--r--   0        0        0     3438 2023-08-07 14:51:51.868553 oplangchain-0.1.0/oplangchain/tools/github/prompt.py
--rw-r--r--   0        0        0      921 2023-08-07 14:51:51.868553 oplangchain-0.1.0/oplangchain/tools/github/tool.py
--rw-r--r--   0        0        0      541 2023-08-07 14:51:51.869554 oplangchain-0.1.0/oplangchain/tools/gmail/__init__.py
--rw-r--r--   0        0        0      976 2023-08-07 14:51:51.869554 oplangchain-0.1.0/oplangchain/tools/gmail/base.py
--rw-r--r--   0        0        0     2539 2023-08-07 14:51:51.870553 oplangchain-0.1.0/oplangchain/tools/gmail/create_draft.py
--rw-r--r--   0        0        0     1727 2023-08-07 14:51:51.870553 oplangchain-0.1.0/oplangchain/tools/gmail/get_message.py
--rw-r--r--   0        0        0     1535 2023-08-07 14:51:51.871553 oplangchain-0.1.0/oplangchain/tools/gmail/get_thread.py
--rw-r--r--   0        0        0     4363 2023-08-07 14:51:51.871553 oplangchain-0.1.0/oplangchain/tools/gmail/search.py
--rw-r--r--   0        0        0     2847 2023-08-07 14:51:51.872555 oplangchain-0.1.0/oplangchain/tools/gmail/send_message.py
--rw-r--r--   0        0        0     4528 2023-08-07 14:51:51.872555 oplangchain-0.1.0/oplangchain/tools/gmail/utils.py
--rw-r--r--   0        0        0      126 2023-08-07 14:51:51.873555 oplangchain-0.1.0/oplangchain/tools/golden_query/__init__.py
--rw-r--r--   0        0        0     1090 2023-08-07 14:51:51.873555 oplangchain-0.1.0/oplangchain/tools/golden_query/tool.py
--rw-r--r--   0        0        0      130 2023-08-07 14:51:51.874554 oplangchain-0.1.0/oplangchain/tools/google_places/__init__.py
--rw-r--r--   0        0        0     1106 2023-08-07 14:51:51.875555 oplangchain-0.1.0/oplangchain/tools/google_places/tool.py
--rw-r--r--   0        0        0      172 2023-08-07 14:51:51.875555 oplangchain-0.1.0/oplangchain/tools/google_search/__init__.py
--rw-r--r--   0        0        0     1461 2023-08-07 14:51:51.876553 oplangchain-0.1.0/oplangchain/tools/google_search/tool.py
--rw-r--r--   0        0        0      220 2023-08-07 14:51:51.877554 oplangchain-0.1.0/oplangchain/tools/google_serper/__init__.py
--rw-r--r--   0        0        0     2076 2023-08-07 14:51:51.877554 oplangchain-0.1.0/oplangchain/tools/google_serper/tool.py
--rw-r--r--   0        0        0       47 2023-08-07 14:51:51.878556 oplangchain-0.1.0/oplangchain/tools/graphql/__init__.py
--rw-r--r--   0        0        0     1186 2023-08-07 14:51:51.878556 oplangchain-0.1.0/oplangchain/tools/graphql/tool.py
--rw-r--r--   0        0        0      122 2023-08-07 14:51:51.879554 oplangchain-0.1.0/oplangchain/tools/human/__init__.py
--rw-r--r--   0        0        0      959 2023-08-07 14:51:51.880557 oplangchain-0.1.0/oplangchain/tools/human/tool.py
--rw-r--r--   0        0        0     2290 2023-08-07 14:51:51.880557 oplangchain-0.1.0/oplangchain/tools/ifttt.py
--rw-r--r--   0        0        0       43 2023-08-07 14:51:51.881555 oplangchain-0.1.0/oplangchain/tools/interaction/__init__.py
--rw-r--r--   0        0        0      454 2023-08-07 14:51:51.881555 oplangchain-0.1.0/oplangchain/tools/interaction/tool.py
--rw-r--r--   0        0        0       17 2023-08-07 14:51:51.882557 oplangchain-0.1.0/oplangchain/tools/jira/__init__.py
--rw-r--r--   0        0        0     3170 2023-08-07 14:51:51.883554 oplangchain-0.1.0/oplangchain/tools/jira/prompt.py
--rw-r--r--   0        0        0     1569 2023-08-07 14:51:51.883554 oplangchain-0.1.0/oplangchain/tools/jira/tool.py
--rw-r--r--   0        0        0       46 2023-08-07 14:51:51.884555 oplangchain-0.1.0/oplangchain/tools/json/__init__.py
--rw-r--r--   0        0        0     4087 2023-08-07 14:51:51.885554 oplangchain-0.1.0/oplangchain/tools/json/tool.py
--rw-r--r--   0        0        0      144 2023-08-07 14:51:51.886555 oplangchain-0.1.0/oplangchain/tools/metaphor_search/__init__.py
--rw-r--r--   0        0        0     2672 2023-08-07 14:51:51.886555 oplangchain-0.1.0/oplangchain/tools/metaphor_search/tool.py
--rw-r--r--   0        0        0      237 2023-08-07 14:51:51.887554 oplangchain-0.1.0/oplangchain/tools/multion/__init__.py
--rw-r--r--   0        0        0     1577 2023-08-07 14:51:51.888554 oplangchain-0.1.0/oplangchain/tools/multion/create_session.py
--rw-r--r--   0        0        0     2116 2023-08-07 14:51:51.888554 oplangchain-0.1.0/oplangchain/tools/multion/update_session.py
--rw-r--r--   0        0        0      101 2023-08-07 14:51:51.889554 oplangchain-0.1.0/oplangchain/tools/nuclia/__init__.py
--rw-r--r--   0        0        0     7575 2023-08-07 14:51:51.890557 oplangchain-0.1.0/oplangchain/tools/nuclia/tool.py
--rw-r--r--   0        0        0      585 2023-08-07 14:51:51.890557 oplangchain-0.1.0/oplangchain/tools/office365/__init__.py
--rw-r--r--   0        0        0      480 2023-08-07 14:51:51.891554 oplangchain-0.1.0/oplangchain/tools/office365/base.py
--rw-r--r--   0        0        0     1832 2023-08-07 14:51:51.891554 oplangchain-0.1.0/oplangchain/tools/office365/create_draft_message.py
--rw-r--r--   0        0        0     4846 2023-08-07 14:51:51.892556 oplangchain-0.1.0/oplangchain/tools/office365/events_search.py
--rw-r--r--   0        0        0     4160 2023-08-07 14:51:51.892556 oplangchain-0.1.0/oplangchain/tools/office365/messages_search.py
--rw-r--r--   0        0        0     2830 2023-08-07 14:51:51.893556 oplangchain-0.1.0/oplangchain/tools/office365/send_event.py
--rw-r--r--   0        0        0     1763 2023-08-07 14:51:51.893556 oplangchain-0.1.0/oplangchain/tools/office365/send_message.py
--rw-r--r--   0        0        0     2136 2023-08-07 14:51:51.894556 oplangchain-0.1.0/oplangchain/tools/office365/utils.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.894556 oplangchain-0.1.0/oplangchain/tools/openapi/__init__.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.895553 oplangchain-0.1.0/oplangchain/tools/openapi/utils/__init__.py
--rw-r--r--   0        0        0    20553 2023-08-07 14:51:51.896553 oplangchain-0.1.0/oplangchain/tools/openapi/utils/api_models.py
--rw-r--r--   0        0        0      156 2023-08-07 14:51:51.896553 oplangchain-0.1.0/oplangchain/tools/openapi/utils/openapi_utils.py
--rw-r--r--   0        0        0      152 2023-08-07 14:51:51.897555 oplangchain-0.1.0/oplangchain/tools/openweathermap/__init__.py
--rw-r--r--   0        0        0      916 2023-08-07 14:51:51.897555 oplangchain-0.1.0/oplangchain/tools/openweathermap/tool.py
--rw-r--r--   0        0        0      684 2023-08-07 14:51:51.898554 oplangchain-0.1.0/oplangchain/tools/playwright/__init__.py
--rw-r--r--   0        0        0     2118 2023-08-07 14:51:51.899555 oplangchain-0.1.0/oplangchain/tools/playwright/base.py
--rw-r--r--   0        0        0     3048 2023-08-07 14:51:51.899555 oplangchain-0.1.0/oplangchain/tools/playwright/click.py
--rw-r--r--   0        0        0     1292 2023-08-07 14:51:51.900556 oplangchain-0.1.0/oplangchain/tools/playwright/current_page.py
--rw-r--r--   0        0        0     3003 2023-08-07 14:51:51.901555 oplangchain-0.1.0/oplangchain/tools/playwright/extract_hyperlinks.py
--rw-r--r--   0        0        0     2335 2023-08-07 14:51:51.901555 oplangchain-0.1.0/oplangchain/tools/playwright/extract_text.py
--rw-r--r--   0        0        0     3695 2023-08-07 14:51:51.902555 oplangchain-0.1.0/oplangchain/tools/playwright/get_elements.py
--rw-r--r--   0        0        0     1756 2023-08-07 14:51:51.902555 oplangchain-0.1.0/oplangchain/tools/playwright/navigate.py
--rw-r--r--   0        0        0     1891 2023-08-07 14:51:51.902555 oplangchain-0.1.0/oplangchain/tools/playwright/navigate_back.py
--rw-r--r--   0        0        0     2813 2023-08-07 14:51:51.903555 oplangchain-0.1.0/oplangchain/tools/playwright/utils.py
--rw-r--r--   0        0        0     2888 2023-08-07 14:51:51.903555 oplangchain-0.1.0/oplangchain/tools/plugin.py
--rw-r--r--   0        0        0       52 2023-08-07 14:51:51.904555 oplangchain-0.1.0/oplangchain/tools/powerbi/__init__.py
--rw-r--r--   0        0        0     7339 2023-08-07 14:51:51.905557 oplangchain-0.1.0/oplangchain/tools/powerbi/prompt.py
--rw-r--r--   0        0        0    11057 2023-08-07 14:51:51.905557 oplangchain-0.1.0/oplangchain/tools/powerbi/tool.py
--rw-r--r--   0        0        0       26 2023-08-07 14:51:51.906554 oplangchain-0.1.0/oplangchain/tools/pubmed/__init__.py
--rw-r--r--   0        0        0     1010 2023-08-07 14:51:51.907554 oplangchain-0.1.0/oplangchain/tools/pubmed/tool.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.907554 oplangchain-0.1.0/oplangchain/tools/python/__init__.py
--rw-r--r--   0        0        0     4313 2023-08-07 14:51:51.908554 oplangchain-0.1.0/oplangchain/tools/python/tool.py
--rw-r--r--   0        0        0       52 2023-08-07 14:51:51.909554 oplangchain-0.1.0/oplangchain/tools/requests/__init__.py
--rw-r--r--   0        0        0     6248 2023-08-07 14:51:51.909554 oplangchain-0.1.0/oplangchain/tools/requests/tool.py
--rw-r--r--   0        0        0       31 2023-08-07 14:51:51.910555 oplangchain-0.1.0/oplangchain/tools/scenexplain/__init__.py
--rw-r--r--   0        0        0     1065 2023-08-07 14:51:51.910555 oplangchain-0.1.0/oplangchain/tools/scenexplain/tool.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.911554 oplangchain-0.1.0/oplangchain/tools/searx_search/__init__.py
--rw-r--r--   0        0        0     2216 2023-08-07 14:51:51.912556 oplangchain-0.1.0/oplangchain/tools/searx_search/tool.py
--rw-r--r--   0        0        0       93 2023-08-07 14:51:51.913554 oplangchain-0.1.0/oplangchain/tools/shell/__init__.py
--rw-r--r--   0        0        0     2384 2023-08-07 14:51:51.914556 oplangchain-0.1.0/oplangchain/tools/shell/tool.py
--rw-r--r--   0        0        0       18 2023-08-07 14:51:51.915554 oplangchain-0.1.0/oplangchain/tools/sleep/__init__.py
--rw-r--r--   0        0        0     1205 2023-08-07 14:51:51.915554 oplangchain-0.1.0/oplangchain/tools/sleep/tool.py
--rw-r--r--   0        0        0       44 2023-08-07 14:51:51.916553 oplangchain-0.1.0/oplangchain/tools/spark_sql/__init__.py
--rw-r--r--   0        0        0      550 2023-08-07 14:51:51.917554 oplangchain-0.1.0/oplangchain/tools/spark_sql/prompt.py
--rw-r--r--   0        0        0     4512 2023-08-07 14:51:51.917554 oplangchain-0.1.0/oplangchain/tools/spark_sql/tool.py
--rw-r--r--   0        0        0       49 2023-08-07 14:51:51.918557 oplangchain-0.1.0/oplangchain/tools/sql_database/__init__.py
--rw-r--r--   0        0        0      597 2023-08-07 14:51:51.918557 oplangchain-0.1.0/oplangchain/tools/sql_database/prompt.py
--rw-r--r--   0        0        0     4574 2023-08-07 14:51:51.919553 oplangchain-0.1.0/oplangchain/tools/sql_database/tool.py
--rw-r--r--   0        0        0      167 2023-08-07 14:51:51.919553 oplangchain-0.1.0/oplangchain/tools/steamship_image_generation/__init__.py
--rw-r--r--   0        0        0     3327 2023-08-07 14:51:51.920553 oplangchain-0.1.0/oplangchain/tools/steamship_image_generation/tool.py
--rw-r--r--   0        0        0     1395 2023-08-07 14:51:51.920553 oplangchain-0.1.0/oplangchain/tools/steamship_image_generation/utils.py
--rw-r--r--   0        0        0       51 2023-08-07 14:51:51.921553 oplangchain-0.1.0/oplangchain/tools/vectorstore/__init__.py
--rw-r--r--   0        0        0     3243 2023-08-07 14:51:51.922557 oplangchain-0.1.0/oplangchain/tools/vectorstore/tool.py
--rw-r--r--   0        0        0       29 2023-08-07 14:51:51.922557 oplangchain-0.1.0/oplangchain/tools/wikipedia/__init__.py
--rw-r--r--   0        0        0      849 2023-08-07 14:51:51.923555 oplangchain-0.1.0/oplangchain/tools/wikipedia/tool.py
--rw-r--r--   0        0        0      146 2023-08-07 14:51:51.924555 oplangchain-0.1.0/oplangchain/tools/wolfram_alpha/__init__.py
--rw-r--r--   0        0        0      869 2023-08-07 14:51:51.924555 oplangchain-0.1.0/oplangchain/tools/wolfram_alpha/tool.py
--rw-r--r--   0        0        0        0 2023-08-07 14:51:51.925557 oplangchain-0.1.0/oplangchain/tools/youtube/__init__.py
--rw-r--r--   0        0        0     1661 2023-08-07 14:51:51.925557 oplangchain-0.1.0/oplangchain/tools/youtube/search.py
--rw-r--r--   0        0        0      170 2023-08-07 14:51:51.926554 oplangchain-0.1.0/oplangchain/tools/zapier/__init__.py
--rw-r--r--   0        0        0     1182 2023-08-07 14:51:51.927554 oplangchain-0.1.0/oplangchain/tools/zapier/prompt.py
--rw-r--r--   0        0        0     7065 2023-08-07 14:51:51.927554 oplangchain-0.1.0/oplangchain/tools/zapier/tool.py
--rw-r--r--   0        0        0     2868 2023-08-07 14:51:51.928554 oplangchain-0.1.0/oplangchain/utilities/__init__.py
--rw-r--r--   0        0        0     6386 2023-08-07 14:51:51.928554 oplangchain-0.1.0/oplangchain/utilities/arxiv.py
--rw-r--r--   0        0        0      274 2023-08-07 14:51:51.929553 oplangchain-0.1.0/oplangchain/utilities/asyncio.py
--rw-r--r--   0        0        0     2419 2023-08-07 14:51:51.929553 oplangchain-0.1.0/oplangchain/utilities/awslambda.py
--rw-r--r--   0        0        0     5703 2023-08-07 14:51:51.930559 oplangchain-0.1.0/oplangchain/utilities/bash.py
--rw-r--r--   0        0        0     2481 2023-08-07 14:51:51.930559 oplangchain-0.1.0/oplangchain/utilities/bibtex.py
--rw-r--r--   0        0        0     3333 2023-08-07 14:51:51.931554 oplangchain-0.1.0/oplangchain/utilities/bing_search.py
--rw-r--r--   0        0        0     2326 2023-08-07 14:51:51.931554 oplangchain-0.1.0/oplangchain/utilities/brave_search.py
--rw-r--r--   0        0        0     7832 2023-08-07 14:51:51.932554 oplangchain-0.1.0/oplangchain/utilities/dataforseo_api_search.py
--rw-r--r--   0        0        0     3764 2023-08-07 14:51:51.932554 oplangchain-0.1.0/oplangchain/utilities/duckduckgo_search.py
--rw-r--r--   0        0        0    11594 2023-08-07 14:51:51.933556 oplangchain-0.1.0/oplangchain/utilities/github.py
--rw-r--r--   0        0        0     1836 2023-08-07 14:51:51.933556 oplangchain-0.1.0/oplangchain/utilities/golden_query.py
--rw-r--r--   0        0        0     4065 2023-08-07 14:51:51.934557 oplangchain-0.1.0/oplangchain/utilities/google_places_api.py
--rw-r--r--   0        0        0     5094 2023-08-07 14:51:51.934557 oplangchain-0.1.0/oplangchain/utilities/google_search.py
--rw-r--r--   0        0        0     6503 2023-08-07 14:51:51.935556 oplangchain-0.1.0/oplangchain/utilities/google_serper.py
--rw-r--r--   0        0        0     1885 2023-08-07 14:51:51.935556 oplangchain-0.1.0/oplangchain/utilities/graphql.py
--rw-r--r--   0        0        0     6173 2023-08-07 14:51:51.936557 oplangchain-0.1.0/oplangchain/utilities/jira.py
--rw-r--r--   0        0        0     1972 2023-08-07 14:51:51.937557 oplangchain-0.1.0/oplangchain/utilities/loading.py
--rw-r--r--   0        0        0     2642 2023-08-07 14:51:51.937557 oplangchain-0.1.0/oplangchain/utilities/max_compute.py
--rw-r--r--   0        0        0     6705 2023-08-07 14:51:51.938555 oplangchain-0.1.0/oplangchain/utilities/metaphor_search.py
--rw-r--r--   0        0        0    10299 2023-08-07 14:51:51.939558 oplangchain-0.1.0/oplangchain/utilities/openapi.py
--rw-r--r--   0        0        0     2440 2023-08-07 14:51:51.940557 oplangchain-0.1.0/oplangchain/utilities/openweathermap.py
--rw-r--r--   0        0        0     2198 2023-08-07 14:51:51.940557 oplangchain-0.1.0/oplangchain/utilities/portkey.py
--rw-r--r--   0        0        0    11237 2023-08-07 14:51:51.941556 oplangchain-0.1.0/oplangchain/utilities/powerbi.py
--rw-r--r--   0        0        0     5627 2023-08-07 14:51:51.942556 oplangchain-0.1.0/oplangchain/utilities/pupmed.py
--rw-r--r--   0        0        0     2141 2023-08-07 14:51:51.942556 oplangchain-0.1.0/oplangchain/utilities/python.py
--rw-r--r--   0        0        0     5435 2023-08-07 14:51:51.943556 oplangchain-0.1.0/oplangchain/utilities/redis.py
--rw-r--r--   0        0        0     7120 2023-08-07 14:51:51.944557 oplangchain-0.1.0/oplangchain/utilities/requests.py
--rw-r--r--   0        0        0     2198 2023-08-07 14:51:51.944557 oplangchain-0.1.0/oplangchain/utilities/scenexplain.py
--rw-r--r--   0        0        0    16529 2023-08-07 14:51:51.945556 oplangchain-0.1.0/oplangchain/utilities/searx_search.py
--rw-r--r--   0        0        0     6025 2023-08-07 14:51:51.945556 oplangchain-0.1.0/oplangchain/utilities/serpapi.py
--rw-r--r--   0        0        0     6964 2023-08-07 14:51:51.945556 oplangchain-0.1.0/oplangchain/utilities/spark_sql.py
--rw-r--r--   0        0        0    18263 2023-08-07 14:51:51.946554 oplangchain-0.1.0/oplangchain/utilities/sql_database.py
--rw-r--r--   0        0        0     3409 2023-08-07 14:51:51.946554 oplangchain-0.1.0/oplangchain/utilities/twilio.py
--rw-r--r--   0        0        0     1457 2023-08-07 14:51:51.947558 oplangchain-0.1.0/oplangchain/utilities/vertexai.py
--rw-r--r--   0        0        0     3920 2023-08-07 14:51:51.947558 oplangchain-0.1.0/oplangchain/utilities/wikipedia.py
--rw-r--r--   0        0        0     1989 2023-08-07 14:51:51.948557 oplangchain-0.1.0/oplangchain/utilities/wolfram_alpha.py
--rw-r--r--   0        0        0    11560 2023-08-07 14:51:51.948557 oplangchain-0.1.0/oplangchain/utilities/zapier.py
--rw-r--r--   0        0        0     1149 2023-08-07 14:51:51.949556 oplangchain-0.1.0/oplangchain/utils/__init__.py
--rw-r--r--   0        0        0      873 2023-08-07 14:51:51.950555 oplangchain-0.1.0/oplangchain/utils/env.py
--rw-r--r--   0        0        0     1237 2023-08-07 14:51:51.950555 oplangchain-0.1.0/oplangchain/utils/formatting.py
--rw-r--r--   0        0        0     1289 2023-08-07 14:51:51.951556 oplangchain-0.1.0/oplangchain/utils/input.py
--rw-r--r--   0        0        0     2016 2023-08-07 14:51:51.952556 oplangchain-0.1.0/oplangchain/utils/math.py
--rw-r--r--   0        0        0      908 2023-08-07 14:51:51.952556 oplangchain-0.1.0/oplangchain/utils/strings.py
--rw-r--r--   0        0        0     5606 2023-08-07 14:51:51.953554 oplangchain-0.1.0/oplangchain/utils/utils.py
--rw-r--r--   0        0        0     4003 2023-08-07 14:51:51.953554 oplangchain-0.1.0/oplangchain/vectorstores/__init__.py
--rw-r--r--   0        0        0     2025 2023-08-07 14:51:51.954555 oplangchain-0.1.0/oplangchain/vectorstores/_pgvector_data_models.py
--rw-r--r--   0        0        0    13535 2023-08-07 14:51:51.955557 oplangchain-0.1.0/oplangchain/vectorstores/alibabacloud_opensearch.py
--rw-r--r--   0        0        0    15792 2023-08-07 14:51:51.955557 oplangchain-0.1.0/oplangchain/vectorstores/analyticdb.py
--rw-r--r--   0        0        0    16575 2023-08-07 14:51:51.956557 oplangchain-0.1.0/oplangchain/vectorstores/annoy.py
--rw-r--r--   0        0        0    12133 2023-08-07 14:51:51.956557 oplangchain-0.1.0/oplangchain/vectorstores/atlas.py
--rw-r--r--   0        0        0    21220 2023-08-07 14:51:51.957556 oplangchain-0.1.0/oplangchain/vectorstores/awadb.py
--rw-r--r--   0        0        0    20714 2023-08-07 14:51:51.957556 oplangchain-0.1.0/oplangchain/vectorstores/azuresearch.py
--rw-r--r--   0        0        0    22433 2023-08-07 14:51:51.958557 oplangchain-0.1.0/oplangchain/vectorstores/base.py
--rw-r--r--   0        0        0    13392 2023-08-07 14:51:51.958557 oplangchain-0.1.0/oplangchain/vectorstores/cassandra.py
--rw-r--r--   0        0        0    23808 2023-08-07 14:51:51.959557 oplangchain-0.1.0/oplangchain/vectorstores/chroma.py
--rw-r--r--   0        0        0    12729 2023-08-07 14:51:51.959557 oplangchain-0.1.0/oplangchain/vectorstores/clarifai.py
--rw-r--r--   0        0        0    17811 2023-08-07 14:51:51.960557 oplangchain-0.1.0/oplangchain/vectorstores/clickhouse.py
--rw-r--r--   0        0        0    34968 2023-08-07 14:51:51.961556 oplangchain-0.1.0/oplangchain/vectorstores/deeplake.py
--rw-r--r--   0        0        0      216 2023-08-07 14:51:51.961556 oplangchain-0.1.0/oplangchain/vectorstores/docarray/__init__.py
--rw-r--r--   0        0        0     6871 2023-08-07 14:51:51.962554 oplangchain-0.1.0/oplangchain/vectorstores/docarray/base.py
--rw-r--r--   0        0        0     4057 2023-08-07 14:51:51.962554 oplangchain-0.1.0/oplangchain/vectorstores/docarray/hnsw.py
--rw-r--r--   0        0        0     2411 2023-08-07 14:51:51.963557 oplangchain-0.1.0/oplangchain/vectorstores/docarray/in_memory.py
--rw-r--r--   0        0        0    27775 2023-08-07 14:51:51.963557 oplangchain-0.1.0/oplangchain/vectorstores/elastic_vector_search.py
--rw-r--r--   0        0        0    29115 2023-08-07 14:51:51.964557 oplangchain-0.1.0/oplangchain/vectorstores/faiss.py
--rw-r--r--   0        0        0    16399 2023-08-07 14:51:51.965557 oplangchain-0.1.0/oplangchain/vectorstores/hologres.py
--rw-r--r--   0        0        0     4236 2023-08-07 14:51:51.965557 oplangchain-0.1.0/oplangchain/vectorstores/lancedb.py
--rw-r--r--   0        0        0    17152 2023-08-07 14:51:51.966557 oplangchain-0.1.0/oplangchain/vectorstores/marqo.py
--rw-r--r--   0        0        0    15176 2023-08-07 14:51:51.966557 oplangchain-0.1.0/oplangchain/vectorstores/matching_engine.py
--rw-r--r--   0        0        0    10421 2023-08-07 14:51:51.967557 oplangchain-0.1.0/oplangchain/vectorstores/meilisearch.py
--rw-r--r--   0        0        0    31468 2023-08-07 14:51:51.967557 oplangchain-0.1.0/oplangchain/vectorstores/milvus.py
--rw-r--r--   0        0        0    12345 2023-08-07 14:51:51.968557 oplangchain-0.1.0/oplangchain/vectorstores/mongodb_atlas.py
--rw-r--r--   0        0        0    16539 2023-08-07 14:51:51.968557 oplangchain-0.1.0/oplangchain/vectorstores/myscale.py
--rw-r--r--   0        0        0    27686 2023-08-07 14:51:51.969557 oplangchain-0.1.0/oplangchain/vectorstores/opensearch_vector_search.py
--rw-r--r--   0        0        0    17344 2023-08-07 14:51:51.969557 oplangchain-0.1.0/oplangchain/vectorstores/pgembedding.py
--rw-r--r--   0        0        0    21251 2023-08-07 14:51:51.970556 oplangchain-0.1.0/oplangchain/vectorstores/pgvector.py
--rw-r--r--   0        0        0    14905 2023-08-07 14:51:51.971554 oplangchain-0.1.0/oplangchain/vectorstores/pinecone.py
--rw-r--r--   0        0        0    68527 2023-08-07 14:51:51.971554 oplangchain-0.1.0/oplangchain/vectorstores/qdrant.py
--rw-r--r--   0        0        0    23138 2023-08-07 14:51:51.972558 oplangchain-0.1.0/oplangchain/vectorstores/redis.py
--rw-r--r--   0        0        0    12186 2023-08-07 14:51:51.972558 oplangchain-0.1.0/oplangchain/vectorstores/rocksetdb.py
--rw-r--r--   0        0        0    19511 2023-08-07 14:51:51.973555 oplangchain-0.1.0/oplangchain/vectorstores/scann.py
--rw-r--r--   0        0        0    18252 2023-08-07 14:51:51.973555 oplangchain-0.1.0/oplangchain/vectorstores/singlestoredb.py
--rw-r--r--   0        0        0    12385 2023-08-07 14:51:51.974557 oplangchain-0.1.0/oplangchain/vectorstores/sklearn.py
--rw-r--r--   0        0        0    17219 2023-08-07 14:51:51.974557 oplangchain-0.1.0/oplangchain/vectorstores/starrocks.py
--rw-r--r--   0        0        0    14233 2023-08-07 14:51:51.975557 oplangchain-0.1.0/oplangchain/vectorstores/supabase.py
--rw-r--r--   0        0        0     8878 2023-08-07 14:51:51.976555 oplangchain-0.1.0/oplangchain/vectorstores/tair.py
--rw-r--r--   0        0        0     4878 2023-08-07 14:51:51.977554 oplangchain-0.1.0/oplangchain/vectorstores/tigris.py
--rw-r--r--   0        0        0     9728 2023-08-07 14:51:51.977554 oplangchain-0.1.0/oplangchain/vectorstores/typesense.py
--rw-r--r--   0        0        0     1790 2023-08-07 14:51:51.978555 oplangchain-0.1.0/oplangchain/vectorstores/utils.py
--rw-r--r--   0        0        0    15857 2023-08-07 14:51:51.978555 oplangchain-0.1.0/oplangchain/vectorstores/vectara.py
--rw-r--r--   0        0        0    16875 2023-08-07 14:51:51.979557 oplangchain-0.1.0/oplangchain/vectorstores/weaviate.py
--rw-r--r--   0        0        0     7559 2023-08-07 14:51:51.980557 oplangchain-0.1.0/oplangchain/vectorstores/zilliz.py
--rw-r--r--   0        0        0    13280 2023-08-07 16:53:14.384679 oplangchain-0.1.0/pyproject.toml
--rw-r--r--   0        0        0     5724 2023-08-07 14:51:51.062474 oplangchain-0.1.0/README.md
--rw-r--r--   0        0        0    14928 1970-01-01 00:00:00.000000 oplangchain-0.1.0/PKG-INFO
+-rw-r--r--   0        0        0     3112 2023-08-08 04:52:52.339954 oplangchain-0.1.1/oplangchain/__init__.py
+-rw-r--r--   0        0        0     3430 2023-08-08 04:52:52.736001 oplangchain-0.1.1/oplangchain/agents/__init__.py
+-rw-r--r--   0        0        0    41327 2023-08-08 04:52:52.741001 oplangchain-0.1.1/oplangchain/agents/agent.py
+-rw-r--r--   0        0        0    18339 2023-08-08 04:52:52.741001 oplangchain-0.1.1/oplangchain/agents/agent_iterator.py
+-rw-r--r--   0        0        0     3524 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/__init__.py
+-rw-r--r--   0        0        0      883 2023-08-08 04:52:52.761592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/amadeus/toolkit.py
+-rw-r--r--   0        0        0      925 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/azure_cognitive_services.py
+-rw-r--r--   0        0        0      371 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/base.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.393154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/conversational_retrieval/__init__.py
+-rw-r--r--   0        0        0     3397 2023-08-08 04:52:52.761592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py
+-rw-r--r--   0        0        0      734 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/conversational_retrieval/tool.py
+-rw-r--r--   0        0        0       19 2023-08-07 21:21:40.394154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/csv/__init__.py
+-rw-r--r--   0        0        0     1154 2023-08-08 04:52:52.761592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/csv/base.py
+-rw-r--r--   0        0        0      176 2023-08-08 04:52:52.761592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/file_management/__init__.py
+-rw-r--r--   0        0        0     2092 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/file_management/toolkit.py
+-rw-r--r--   0        0        0       22 2023-08-07 21:21:40.396155 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/github/__init__.py
+-rw-r--r--   0        0        0     2494 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/github/toolkit.py
+-rw-r--r--   0        0        0       21 2023-08-07 21:21:40.398154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/gmail/__init__.py
+-rw-r--r--   0        0        0     1583 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/gmail/toolkit.py
+-rw-r--r--   0        0        0       20 2023-08-07 21:21:40.399153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/jira/__init__.py
+-rw-r--r--   0        0        0     1929 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/jira/toolkit.py
+-rw-r--r--   0        0        0       18 2023-08-07 21:21:40.400153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/__init__.py
+-rw-r--r--   0        0        0     1729 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/base.py
+-rw-r--r--   0        0        0     1819 2023-08-07 21:21:40.401154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/prompt.py
+-rw-r--r--   0        0        0      561 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/toolkit.py
+-rw-r--r--   0        0        0       23 2023-08-07 21:21:40.402153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/multion/__init__.py
+-rw-r--r--   0        0        0      668 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/multion/toolkit.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.403154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/nla/__init__.py
+-rw-r--r--   0        0        0     1949 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/nla/tool.py
+-rw-r--r--   0        0        0     3779 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/nla/toolkit.py
+-rw-r--r--   0        0        0       25 2023-08-07 21:21:40.405154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/office365/__init__.py
+-rw-r--r--   0        0        0     1187 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/office365/toolkit.py
+-rw-r--r--   0        0        0       26 2023-08-07 21:21:40.406154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/__init__.py
+-rw-r--r--   0        0        0     2156 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/base.py
+-rw-r--r--   0        0        0    11263 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/planner.py
+-rw-r--r--   0        0        0    10462 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/planner_prompt.py
+-rw-r--r--   0        0        0     1743 2023-08-07 21:21:40.407153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/prompt.py
+-rw-r--r--   0        0        0     3835 2023-08-07 21:21:40.408153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/spec.py
+-rw-r--r--   0        0        0     2396 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/toolkit.py
+-rw-r--r--   0        0        0       22 2023-08-07 21:21:40.409153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/pandas/__init__.py
+-rw-r--r--   0        0        0    11540 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/pandas/base.py
+-rw-r--r--   0        0        0     1113 2023-08-07 21:21:40.410153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/pandas/prompt.py
+-rw-r--r--   0        0        0      164 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/playwright/__init__.py
+-rw-r--r--   0        0        0     3034 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/playwright/toolkit.py
+-rw-r--r--   0        0        0       22 2023-08-07 21:21:40.412153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/__init__.py
+-rw-r--r--   0        0        0     2340 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/base.py
+-rw-r--r--   0        0        0     2509 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/chat_base.py
+-rw-r--r--   0        0        0     2773 2023-08-07 21:21:40.413154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/prompt.py
+-rw-r--r--   0        0        0     3239 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/toolkit.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.414153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/python/__init__.py
+-rw-r--r--   0        0        0     2220 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/python/base.py
+-rw-r--r--   0        0        0      513 2023-08-07 21:21:40.415153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/python/prompt.py
+-rw-r--r--   0        0        0       20 2023-08-07 21:21:40.416154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark/__init__.py
+-rw-r--r--   0        0        0     2748 2023-08-08 04:52:52.760593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark/base.py
+-rw-r--r--   0        0        0      295 2023-08-07 21:21:40.416154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark/prompt.py
+-rw-r--r--   0        0        0       23 2023-08-07 21:21:40.417153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/__init__.py
+-rw-r--r--   0        0        0     2088 2023-08-08 04:52:52.759593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/base.py
+-rw-r--r--   0        0        0     1202 2023-08-07 21:21:40.418154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/prompt.py
+-rw-r--r--   0        0        0     1044 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/toolkit.py
+-rw-r--r--   0        0        0       17 2023-08-07 21:21:40.419153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/__init__.py
+-rw-r--r--   0        0        0     3458 2023-08-08 04:52:52.759593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/base.py
+-rw-r--r--   0        0        0     1428 2023-08-07 21:21:40.420153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/prompt.py
+-rw-r--r--   0        0        0     2826 2023-08-08 04:52:52.759593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/toolkit.py
+-rw-r--r--   0        0        0       56 2023-08-07 21:21:40.421153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/__init__.py
+-rw-r--r--   0        0        0     2422 2023-08-08 04:52:52.759593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/base.py
+-rw-r--r--   0        0        0      834 2023-08-07 21:21:40.422154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/prompt.py
+-rw-r--r--   0        0        0     2973 2023-08-08 04:52:52.759593 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/toolkit.py
+-rw-r--r--   0        0        0       23 2023-08-07 21:21:40.423153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/xorbits/__init__.py
+-rw-r--r--   0        0        0     3119 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/xorbits/base.py
+-rw-r--r--   0        0        0     1070 2023-08-07 21:21:40.424153 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/xorbits/prompt.py
+-rw-r--r--   0        0        0       22 2023-08-07 21:21:40.425154 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/zapier/__init__.py
+-rw-r--r--   0        0        0     1617 2023-08-08 04:52:52.757592 oplangchain-0.1.1/oplangchain/agents/agent_toolkits/zapier/toolkit.py
+-rw-r--r--   0        0        0      688 2023-08-07 21:21:40.426153 oplangchain-0.1.1/oplangchain/agents/agent_types.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.426153 oplangchain-0.1.1/oplangchain/agents/chat/__init__.py
+-rw-r--r--   0        0        0     4928 2023-08-08 04:52:52.752596 oplangchain-0.1.1/oplangchain/agents/chat/base.py
+-rw-r--r--   0        0        0     1712 2023-08-08 04:52:52.752596 oplangchain-0.1.1/oplangchain/agents/chat/output_parser.py
+-rw-r--r--   0        0        0     1158 2023-08-07 21:21:40.427153 oplangchain-0.1.1/oplangchain/agents/chat/prompt.py
+-rw-r--r--   0        0        0       75 2023-08-07 21:21:40.428154 oplangchain-0.1.1/oplangchain/agents/conversational/__init__.py
+-rw-r--r--   0        0        0     4840 2023-08-08 04:52:52.754593 oplangchain-0.1.1/oplangchain/agents/conversational/base.py
+-rw-r--r--   0        0        0     1156 2023-08-08 04:52:52.754593 oplangchain-0.1.1/oplangchain/agents/conversational/output_parser.py
+-rw-r--r--   0        0        0     1859 2023-08-07 21:21:40.429153 oplangchain-0.1.1/oplangchain/agents/conversational/prompt.py
+-rw-r--r--   0        0        0       75 2023-08-07 21:21:40.430153 oplangchain-0.1.1/oplangchain/agents/conversational_chat/__init__.py
+-rw-r--r--   0        0        0     4999 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/conversational_chat/base.py
+-rw-r--r--   0        0        0     2264 2023-08-08 04:52:52.752596 oplangchain-0.1.1/oplangchain/agents/conversational_chat/output_parser.py
+-rw-r--r--   0        0        0     2757 2023-08-07 21:21:40.431155 oplangchain-0.1.1/oplangchain/agents/conversational_chat/prompt.py
+-rw-r--r--   0        0        0     3007 2023-08-08 04:52:52.741001 oplangchain-0.1.1/oplangchain/agents/initialize.py
+-rw-r--r--   0        0        0    17413 2023-08-08 04:52:52.740001 oplangchain-0.1.1/oplangchain/agents/load_tools.py
+-rw-r--r--   0        0        0     4385 2023-08-08 04:52:52.741001 oplangchain-0.1.1/oplangchain/agents/loading.py
+-rw-r--r--   0        0        0       86 2023-08-07 21:21:40.433153 oplangchain-0.1.1/oplangchain/agents/mrkl/__init__.py
+-rw-r--r--   0        0        0     7127 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/mrkl/base.py
+-rw-r--r--   0        0        0     2712 2023-08-08 04:52:52.752596 oplangchain-0.1.1/oplangchain/agents/mrkl/output_parser.py
+-rw-r--r--   0        0        0      641 2023-08-07 21:21:40.435153 oplangchain-0.1.1/oplangchain/agents/mrkl/prompt.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.435153 oplangchain-0.1.1/oplangchain/agents/openai_functions_agent/__init__.py
+-rw-r--r--   0        0        0     2535 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/openai_functions_agent/agent_token_buffer_memory.py
+-rw-r--r--   0        0        0    11916 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/openai_functions_agent/base.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.437154 oplangchain-0.1.1/oplangchain/agents/openai_functions_multi_agent/__init__.py
+-rw-r--r--   0        0        0    13355 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/openai_functions_multi_agent/base.py
+-rw-r--r--   0        0        0       76 2023-08-07 21:21:40.438153 oplangchain-0.1.1/oplangchain/agents/react/__init__.py
+-rw-r--r--   0        0        0     5690 2023-08-08 04:52:52.752002 oplangchain-0.1.1/oplangchain/agents/react/base.py
+-rw-r--r--   0        0        0     1192 2023-08-08 04:52:52.751004 oplangchain-0.1.1/oplangchain/agents/react/output_parser.py
+-rw-r--r--   0        0        0     1903 2023-08-08 04:52:52.751004 oplangchain-0.1.1/oplangchain/agents/react/textworld_prompt.py
+-rw-r--r--   0        0        0     6124 2023-08-08 04:52:52.751004 oplangchain-0.1.1/oplangchain/agents/react/wiki_prompt.py
+-rw-r--r--   0        0        0     1089 2023-08-08 04:52:52.740001 oplangchain-0.1.1/oplangchain/agents/schema.py
+-rw-r--r--   0        0        0      106 2023-08-07 21:21:40.441153 oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/__init__.py
+-rw-r--r--   0        0        0     3118 2023-08-08 04:52:52.746003 oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/base.py
+-rw-r--r--   0        0        0      966 2023-08-08 04:52:52.745003 oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/output_parser.py
+-rw-r--r--   0        0        0     1923 2023-08-08 04:52:52.745003 oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/prompt.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.443153 oplangchain-0.1.1/oplangchain/agents/structured_chat/__init__.py
+-rw-r--r--   0        0        0     5162 2023-08-08 04:52:52.749002 oplangchain-0.1.1/oplangchain/agents/structured_chat/base.py
+-rw-r--r--   0        0        0     3462 2023-08-08 04:52:52.749002 oplangchain-0.1.1/oplangchain/agents/structured_chat/output_parser.py
+-rw-r--r--   0        0        0      992 2023-08-07 21:21:40.444153 oplangchain-0.1.1/oplangchain/agents/structured_chat/prompt.py
+-rw-r--r--   0        0        0     1406 2023-08-08 04:52:52.740001 oplangchain-0.1.1/oplangchain/agents/tools.py
+-rw-r--r--   0        0        0     1497 2023-08-08 04:52:52.740001 oplangchain-0.1.1/oplangchain/agents/types.py
+-rw-r--r--   0        0        0      386 2023-08-08 04:52:52.737004 oplangchain-0.1.1/oplangchain/agents/utils.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.446153 oplangchain-0.1.1/oplangchain/agents/xml/__init__.py
+-rw-r--r--   0        0        0     3905 2023-08-08 04:52:52.741001 oplangchain-0.1.1/oplangchain/agents/xml/base.py
+-rw-r--r--   0        0        0      749 2023-08-07 21:21:40.447154 oplangchain-0.1.1/oplangchain/agents/xml/prompt.py
+-rw-r--r--   0        0        0      220 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/base_language.py
+-rw-r--r--   0        0        0    24775 2023-08-08 05:01:50.900148 oplangchain-0.1.1/oplangchain/cache.py
+-rw-r--r--   0        0        0     2887 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/__init__.py
+-rw-r--r--   0        0        0    14488 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/aim_callback.py
+-rw-r--r--   0        0        0    13727 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/argilla_callback.py
+-rw-r--r--   0        0        0     7509 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/arize_callback.py
+-rw-r--r--   0        0        0    11347 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/arthur_callback.py
+-rw-r--r--   0        0        0    15188 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/base.py
+-rw-r--r--   0        0        0    18502 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/clearml_callback.py
+-rw-r--r--   0        0        0    23246 2023-08-08 05:01:50.902666 oplangchain-0.1.1/oplangchain/callbacks/comet_ml_callback.py
+-rw-r--r--   0        0        0     6438 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/context_callback.py
+-rw-r--r--   0        0        0     2567 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/file.py
+-rw-r--r--   0        0        0    13163 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/flyte_callback.py
+-rw-r--r--   0        0        0     1412 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/human.py
+-rw-r--r--   0        0        0     5574 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/infino_callback.py
+-rw-r--r--   0        0        0    53799 2023-08-08 05:06:24.195893 oplangchain-0.1.1/oplangchain/callbacks/manager.py
+-rw-r--r--   0        0        0    24171 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/mlflow_callback.py
+-rw-r--r--   0        0        0     5352 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/openai_info.py
+-rw-r--r--   0        0        0     5529 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/promptlayer_callback.py
+-rw-r--r--   0        0        0     8829 2023-08-08 04:52:52.612956 oplangchain-0.1.1/oplangchain/callbacks/sagemaker_callback.py
+-rw-r--r--   0        0        0     3209 2023-08-08 04:52:52.612956 oplangchain-0.1.1/oplangchain/callbacks/stdout.py
+-rw-r--r--   0        0        0     2440 2023-08-08 04:52:52.612956 oplangchain-0.1.1/oplangchain/callbacks/streaming_aiter.py
+-rw-r--r--   0        0        0     3368 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/streaming_aiter_final_only.py
+-rw-r--r--   0        0        0     2174 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/streaming_stdout.py
+-rw-r--r--   0        0        0     3370 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/streaming_stdout_final_only.py
+-rw-r--r--   0        0        0     3196 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/callbacks/streamlit/__init__.py
+-rw-r--r--   0        0        0     5435 2023-08-07 21:21:40.460153 oplangchain-0.1.1/oplangchain/callbacks/streamlit/mutable_expander.py
+-rw-r--r--   0        0        0    15677 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/callbacks/streamlit/streamlit_callback_handler.py
+-rw-r--r--   0        0        0      510 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/tracers/__init__.py
+-rw-r--r--   0        0        0    17028 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/callbacks/tracers/base.py
+-rw-r--r--   0        0        0     4866 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/callbacks/tracers/evaluation.py
+-rw-r--r--   0        0        0     8065 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/callbacks/tracers/langchain.py
+-rw-r--r--   0        0        0     7370 2023-08-08 04:52:52.618953 oplangchain-0.1.1/oplangchain/callbacks/tracers/langchain_v1.py
+-rw-r--r--   0        0        0     1541 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/tracers/run_collector.py
+-rw-r--r--   0        0        0     3458 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/tracers/schemas.py
+-rw-r--r--   0        0        0     6033 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/tracers/stdout.py
+-rw-r--r--   0        0        0    18987 2023-08-08 04:52:52.617952 oplangchain-0.1.1/oplangchain/callbacks/tracers/wandb.py
+-rw-r--r--   0        0        0     8505 2023-08-07 21:21:40.465154 oplangchain-0.1.1/oplangchain/callbacks/utils.py
+-rw-r--r--   0        0        0    20665 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/wandb_callback.py
+-rw-r--r--   0        0        0     8066 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/callbacks/whylabs_callback.py
+-rw-r--r--   0        0        0     5378 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/__init__.py
+-rw-r--r--   0        0        0       84 2023-08-07 21:21:40.468155 oplangchain-0.1.1/oplangchain/chains/api/__init__.py
+-rw-r--r--   0        0        0     5348 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/api/base.py
+-rw-r--r--   0        0        0     2452 2023-08-07 21:21:40.469154 oplangchain-0.1.1/oplangchain/chains/api/news_docs.py
+-rw-r--r--   0        0        0     3399 2023-08-07 21:21:40.469154 oplangchain-0.1.1/oplangchain/chains/api/open_meteo_docs.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.470153 oplangchain-0.1.1/oplangchain/chains/api/openapi/__init__.py
+-rw-r--r--   0        0        0     8766 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/api/openapi/chain.py
+-rw-r--r--   0        0        0     1791 2023-08-07 21:21:40.471154 oplangchain-0.1.1/oplangchain/chains/api/openapi/prompts.py
+-rw-r--r--   0        0        0     1887 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/api/openapi/requests_chain.py
+-rw-r--r--   0        0        0     1759 2023-08-08 04:52:52.725542 oplangchain-0.1.1/oplangchain/chains/api/openapi/response_chain.py
+-rw-r--r--   0        0        0     1920 2023-08-07 21:21:40.472154 oplangchain-0.1.1/oplangchain/chains/api/podcast_docs.py
+-rw-r--r--   0        0        0     1028 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/api/prompt.py
+-rw-r--r--   0        0        0     1537 2023-08-07 21:21:40.473154 oplangchain-0.1.1/oplangchain/chains/api/tmdb_docs.py
+-rw-r--r--   0        0        0    24830 2023-08-08 05:06:24.195893 oplangchain-0.1.1/oplangchain/chains/base.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.474154 oplangchain-0.1.1/oplangchain/chains/chat_vector_db/__init__.py
+-rw-r--r--   0        0        0      691 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/chat_vector_db/prompts.py
+-rw-r--r--   0        0        0       43 2023-08-07 21:21:40.475154 oplangchain-0.1.1/oplangchain/chains/combine_documents/__init__.py
+-rw-r--r--   0        0        0     6398 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/combine_documents/base.py
+-rw-r--r--   0        0        0    11165 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/combine_documents/map_reduce.py
+-rw-r--r--   0        0        0     8386 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/combine_documents/map_rerank.py
+-rw-r--r--   0        0        0    11016 2023-08-08 04:52:52.723542 oplangchain-0.1.1/oplangchain/chains/combine_documents/reduce.py
+-rw-r--r--   0        0        0     9093 2023-08-08 04:52:52.721990 oplangchain-0.1.1/oplangchain/chains/combine_documents/refine.py
+-rw-r--r--   0        0        0     7676 2023-08-08 04:52:52.720989 oplangchain-0.1.1/oplangchain/chains/combine_documents/stuff.py
+-rw-r--r--   0        0        0      107 2023-08-07 21:21:40.479154 oplangchain-0.1.1/oplangchain/chains/constitutional_ai/__init__.py
+-rw-r--r--   0        0        0     6350 2023-08-08 04:52:52.720989 oplangchain-0.1.1/oplangchain/chains/constitutional_ai/base.py
+-rw-r--r--   0        0        0      265 2023-08-07 21:21:40.480154 oplangchain-0.1.1/oplangchain/chains/constitutional_ai/models.py
+-rw-r--r--   0        0        0    21740 2023-08-08 04:52:52.720989 oplangchain-0.1.1/oplangchain/chains/constitutional_ai/principles.py
+-rw-r--r--   0        0        0     8660 2023-08-08 04:52:52.718988 oplangchain-0.1.1/oplangchain/chains/constitutional_ai/prompts.py
+-rw-r--r--   0        0        0       71 2023-08-07 21:21:40.482154 oplangchain-0.1.1/oplangchain/chains/conversation/__init__.py
+-rw-r--r--   0        0        0     2184 2023-08-08 04:52:52.718988 oplangchain-0.1.1/oplangchain/chains/conversation/base.py
+-rw-r--r--   0        0        0      870 2023-08-08 04:52:52.717989 oplangchain-0.1.1/oplangchain/chains/conversation/memory.py
+-rw-r--r--   0        0        0      912 2023-08-08 04:52:52.717989 oplangchain-0.1.1/oplangchain/chains/conversation/prompt.py
+-rw-r--r--   0        0        0       49 2023-08-07 21:21:40.484154 oplangchain-0.1.1/oplangchain/chains/conversational_retrieval/__init__.py
+-rw-r--r--   0        0        0    16735 2023-08-08 04:52:52.709600 oplangchain-0.1.1/oplangchain/chains/conversational_retrieval/base.py
+-rw-r--r--   0        0        0      717 2023-08-08 04:52:52.709600 oplangchain-0.1.1/oplangchain/chains/conversational_retrieval/prompts.py
+-rw-r--r--   0        0        0      128 2023-08-08 04:52:52.716988 oplangchain-0.1.1/oplangchain/chains/elasticsearch_database/__init__.py
+-rw-r--r--   0        0        0     8182 2023-08-08 04:52:52.717989 oplangchain-0.1.1/oplangchain/chains/elasticsearch_database/base.py
+-rw-r--r--   0        0        0     1422 2023-08-08 04:52:52.717989 oplangchain-0.1.1/oplangchain/chains/elasticsearch_database/prompts.py
+-rw-r--r--   0        0        0      739 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/example_generator.py
+-rw-r--r--   0        0        0       51 2023-08-07 21:21:40.487153 oplangchain-0.1.1/oplangchain/chains/flare/__init__.py
+-rw-r--r--   0        0        0     8779 2023-08-08 04:52:52.715988 oplangchain-0.1.1/oplangchain/chains/flare/base.py
+-rw-r--r--   0        0        0     1457 2023-08-08 04:52:52.715988 oplangchain-0.1.1/oplangchain/chains/flare/prompts.py
+-rw-r--r--   0        0        0       49 2023-08-07 21:21:40.489153 oplangchain-0.1.1/oplangchain/chains/graph_qa/__init__.py
+-rw-r--r--   0        0        0     7690 2023-08-08 04:52:52.715988 oplangchain-0.1.1/oplangchain/chains/graph_qa/arangodb.py
+-rw-r--r--   0        0        0     2984 2023-08-08 04:52:52.715988 oplangchain-0.1.1/oplangchain/chains/graph_qa/base.py
+-rw-r--r--   0        0        0     4600 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/cypher.py
+-rw-r--r--   0        0        0     3033 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/hugegraph.py
+-rw-r--r--   0        0        0     3033 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/kuzu.py
+-rw-r--r--   0        0        0     3008 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/nebulagraph.py
+-rw-r--r--   0        0        0     4493 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/neptune_cypher.py
+-rw-r--r--   0        0        0    13730 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/prompts.py
+-rw-r--r--   0        0        0     4785 2023-08-08 04:52:52.714991 oplangchain-0.1.1/oplangchain/chains/graph_qa/sparql.py
+-rw-r--r--   0        0        0       75 2023-08-07 21:21:40.493153 oplangchain-0.1.1/oplangchain/chains/hyde/__init__.py
+-rw-r--r--   0        0        0     2843 2023-08-08 04:52:52.712601 oplangchain-0.1.1/oplangchain/chains/hyde/base.py
+-rw-r--r--   0        0        0     1910 2023-08-08 04:52:52.712601 oplangchain-0.1.1/oplangchain/chains/hyde/prompts.py
+-rw-r--r--   0        0        0    12157 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/llm.py
+-rw-r--r--   0        0        0       88 2023-08-07 21:21:40.495154 oplangchain-0.1.1/oplangchain/chains/llm_bash/__init__.py
+-rw-r--r--   0        0        0     4181 2023-08-08 04:52:52.712601 oplangchain-0.1.1/oplangchain/chains/llm_bash/base.py
+-rw-r--r--   0        0        0     1941 2023-08-08 04:52:52.712601 oplangchain-0.1.1/oplangchain/chains/llm_bash/prompt.py
+-rw-r--r--   0        0        0      139 2023-08-07 21:21:40.497153 oplangchain-0.1.1/oplangchain/chains/llm_checker/__init__.py
+-rw-r--r--   0        0        0     6106 2023-08-08 04:52:52.706600 oplangchain-0.1.1/oplangchain/chains/llm_checker/base.py
+-rw-r--r--   0        0        0     1122 2023-08-08 04:52:52.706600 oplangchain-0.1.1/oplangchain/chains/llm_checker/prompt.py
+-rw-r--r--   0        0        0      143 2023-08-07 21:21:40.499153 oplangchain-0.1.1/oplangchain/chains/llm_math/__init__.py
+-rw-r--r--   0        0        0     6386 2023-08-08 04:52:52.709600 oplangchain-0.1.1/oplangchain/chains/llm_math/base.py
+-rw-r--r--   0        0        0      865 2023-08-08 04:52:52.709600 oplangchain-0.1.1/oplangchain/chains/llm_math/prompt.py
+-rw-r--r--   0        0        0     2885 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/llm_requests.py
+-rw-r--r--   0        0        0      352 2023-08-07 21:21:40.500154 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/__init__.py
+-rw-r--r--   0        0        0     6620 2023-08-08 04:52:52.706600 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/base.py
+-rw-r--r--   0        0        0      654 2023-08-07 21:21:40.502153 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/prompts/are_all_true_prompt.txt
+-rw-r--r--   0        0        0      377 2023-08-07 21:21:40.502153 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/prompts/check_facts.txt
+-rw-r--r--   0        0        0      128 2023-08-07 21:21:40.503153 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/prompts/create_facts.txt
+-rw-r--r--   0        0        0      416 2023-08-07 21:21:40.503153 oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/prompts/revise_summary.txt
+-rw-r--r--   0        0        0      126 2023-08-07 21:21:40.504153 oplangchain-0.1.1/oplangchain/chains/llm_symbolic_math/__init__.py
+-rw-r--r--   0        0        0     5569 2023-08-08 04:52:52.706600 oplangchain-0.1.1/oplangchain/chains/llm_symbolic_math/base.py
+-rw-r--r--   0        0        0     1089 2023-08-08 04:52:52.706600 oplangchain-0.1.1/oplangchain/chains/llm_symbolic_math/prompt.py
+-rw-r--r--   0        0        0    23991 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/loading.py
+-rw-r--r--   0        0        0     3737 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/mapreduce.py
+-rw-r--r--   0        0        0     3058 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/moderation.py
+-rw-r--r--   0        0        0       96 2023-08-07 21:21:40.507154 oplangchain-0.1.1/oplangchain/chains/natbot/__init__.py
+-rw-r--r--   0        0        0     4193 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/natbot/base.py
+-rw-r--r--   0        0        0    15466 2023-08-07 21:21:40.508154 oplangchain-0.1.1/oplangchain/chains/natbot/crawler.py
+-rw-r--r--   0        0        0     4986 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/natbot/prompt.py
+-rw-r--r--   0        0        0      958 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/openai_functions/__init__.py
+-rw-r--r--   0        0        0    14630 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/openai_functions/base.py
+-rw-r--r--   0        0        0     3518 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/openai_functions/citation_fuzzy_match.py
+-rw-r--r--   0        0        0     3350 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/openai_functions/extraction.py
+-rw-r--r--   0        0        0    11226 2023-08-08 05:04:13.464638 oplangchain-0.1.1/oplangchain/chains/openai_functions/openapi.py
+-rw-r--r--   0        0        0     3725 2023-08-08 04:52:52.701599 oplangchain-0.1.1/oplangchain/chains/openai_functions/qa_with_structure.py
+-rw-r--r--   0        0        0     2665 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/openai_functions/tagging.py
+-rw-r--r--   0        0        0     1257 2023-08-07 21:21:40.512154 oplangchain-0.1.1/oplangchain/chains/openai_functions/utils.py
+-rw-r--r--   0        0        0     1969 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/prompt_selector.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.513154 oplangchain-0.1.1/oplangchain/chains/qa_generation/__init__.py
+-rw-r--r--   0        0        0     2458 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/qa_generation/base.py
+-rw-r--r--   0        0        0     1871 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/qa_generation/prompt.py
+-rw-r--r--   0        0        0      175 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/__init__.py
+-rw-r--r--   0        0        0     7741 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/base.py
+-rw-r--r--   0        0        0     6825 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/loading.py
+-rw-r--r--   0        0        0     6968 2023-08-08 04:52:52.698599 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/map_reduce_prompt.py
+-rw-r--r--   0        0        0     1315 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/refine_prompts.py
+-rw-r--r--   0        0        0     2354 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/retrieval.py
+-rw-r--r--   0        0        0     6578 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/stuff_prompt.py
+-rw-r--r--   0        0        0     2811 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/qa_with_sources/vector_db.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.519154 oplangchain-0.1.1/oplangchain/chains/query_constructor/__init__.py
+-rw-r--r--   0        0        0     5824 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/query_constructor/base.py
+-rw-r--r--   0        0        0     3129 2023-08-07 21:21:40.520154 oplangchain-0.1.1/oplangchain/chains/query_constructor/ir.py
+-rw-r--r--   0        0        0     4756 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/query_constructor/parser.py
+-rw-r--r--   0        0        0     6448 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/query_constructor/prompt.py
+-rw-r--r--   0        0        0      303 2023-08-07 21:21:40.521153 oplangchain-0.1.1/oplangchain/chains/query_constructor/schema.py
+-rw-r--r--   0        0        0     8578 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/question_answering/__init__.py
+-rw-r--r--   0        0        0     8009 2023-08-08 04:52:52.696616 oplangchain-0.1.1/oplangchain/chains/question_answering/map_reduce_prompt.py
+-rw-r--r--   0        0        0     1621 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/question_answering/map_rerank_prompt.py
+-rw-r--r--   0        0        0     2732 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/question_answering/refine_prompts.py
+-rw-r--r--   0        0        0     1141 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/question_answering/stuff_prompt.py
+-rw-r--r--   0        0        0       62 2023-08-07 21:21:40.524154 oplangchain-0.1.1/oplangchain/chains/retrieval_qa/__init__.py
+-rw-r--r--   0        0        0     9794 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/retrieval_qa/base.py
+-rw-r--r--   0        0        0      396 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/retrieval_qa/prompt.py
+-rw-r--r--   0        0        0      415 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/router/__init__.py
+-rw-r--r--   0        0        0     4560 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/router/base.py
+-rw-r--r--   0        0        0     1980 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/router/embedding_router.py
+-rw-r--r--   0        0        0     4197 2023-08-08 04:52:52.695606 oplangchain-0.1.1/oplangchain/chains/router/llm_router.py
+-rw-r--r--   0        0        0     2576 2023-08-08 04:52:52.694599 oplangchain-0.1.1/oplangchain/chains/router/multi_prompt.py
+-rw-r--r--   0        0        0     1123 2023-08-07 21:21:40.528154 oplangchain-0.1.1/oplangchain/chains/router/multi_prompt_prompt.py
+-rw-r--r--   0        0        0     1079 2023-08-07 21:21:40.528154 oplangchain-0.1.1/oplangchain/chains/router/multi_retrieval_prompt.py
+-rw-r--r--   0        0        0     3657 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/router/multi_retrieval_qa.py
+-rw-r--r--   0        0        0     7487 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/sequential.py
+-rw-r--r--   0        0        0       47 2023-08-07 21:21:40.530154 oplangchain-0.1.1/oplangchain/chains/sql_database/__init__.py
+-rw-r--r--   0        0        0    14206 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/sql_database/prompt.py
+-rw-r--r--   0        0        0     2078 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/sql_database/query.py
+-rw-r--r--   0        0        0     5715 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/summarize/__init__.py
+-rw-r--r--   0        0        0      235 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/summarize/map_reduce_prompt.py
+-rw-r--r--   0        0        0      807 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/summarize/refine_prompts.py
+-rw-r--r--   0        0        0      235 2023-08-08 04:52:52.667997 oplangchain-0.1.1/oplangchain/chains/summarize/stuff_prompt.py
+-rw-r--r--   0        0        0     2239 2023-08-08 04:52:52.666996 oplangchain-0.1.1/oplangchain/chains/transform.py
+-rw-r--r--   0        0        0     1374 2023-08-08 04:52:52.725542 oplangchain-0.1.1/oplangchain/chat_models/__init__.py
+-rw-r--r--   0        0        0     7002 2023-08-08 04:52:52.729543 oplangchain-0.1.1/oplangchain/chat_models/anthropic.py
+-rw-r--r--   0        0        0     4713 2023-08-08 04:52:52.729543 oplangchain-0.1.1/oplangchain/chat_models/azure_openai.py
+-rw-r--r--   0        0        0     5406 2023-08-08 04:52:52.729543 oplangchain-0.1.1/oplangchain/chat_models/azureml_endpoint.py
+-rw-r--r--   0        0        0    23298 2023-08-08 05:09:17.586726 oplangchain-0.1.1/oplangchain/chat_models/base.py
+-rw-r--r--   0        0        0     1046 2023-08-08 04:52:52.728543 oplangchain-0.1.1/oplangchain/chat_models/fake.py
+-rw-r--r--   0        0        0    11139 2023-08-08 04:52:52.727543 oplangchain-0.1.1/oplangchain/chat_models/google_palm.py
+-rw-r--r--   0        0        0     4027 2023-08-08 04:52:52.726542 oplangchain-0.1.1/oplangchain/chat_models/human.py
+-rw-r--r--   0        0        0    15237 2023-08-08 04:52:52.726542 oplangchain-0.1.1/oplangchain/chat_models/jinachat.py
+-rw-r--r--   0        0        0     6865 2023-08-08 04:52:52.726542 oplangchain-0.1.1/oplangchain/chat_models/mlflow_ai_gateway.py
+-rw-r--r--   0        0        0    22380 2023-08-08 04:52:52.726542 oplangchain-0.1.1/oplangchain/chat_models/openai.py
+-rw-r--r--   0        0        0     5174 2023-08-08 04:52:52.726542 oplangchain-0.1.1/oplangchain/chat_models/promptlayer_openai.py
+-rw-r--r--   0        0        0     6018 2023-08-08 04:52:52.725542 oplangchain-0.1.1/oplangchain/chat_models/vertexai.py
+-rw-r--r--   0        0        0      685 2023-08-07 21:21:40.540154 oplangchain-0.1.1/oplangchain/docker-compose.yaml
+-rw-r--r--   0        0        0      525 2023-08-08 04:52:52.729543 oplangchain-0.1.1/oplangchain/docstore/__init__.py
+-rw-r--r--   0        0        0     1075 2023-08-08 04:52:52.736001 oplangchain-0.1.1/oplangchain/docstore/arbitrary_fn.py
+-rw-r--r--   0        0        0      838 2023-08-08 04:52:52.732543 oplangchain-0.1.1/oplangchain/docstore/base.py
+-rw-r--r--   0        0        0       64 2023-08-08 04:52:52.732543 oplangchain-0.1.1/oplangchain/docstore/document.py
+-rw-r--r--   0        0        0     1606 2023-08-08 04:52:52.730543 oplangchain-0.1.1/oplangchain/docstore/in_memory.py
+-rw-r--r--   0        0        0     1483 2023-08-08 04:52:52.729543 oplangchain-0.1.1/oplangchain/docstore/wikipedia.py
+-rw-r--r--   0        0        0    13128 2023-08-08 04:52:52.566956 oplangchain-0.1.1/oplangchain/document_loaders/__init__.py
+-rw-r--r--   0        0        0     2851 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/acreom.py
+-rw-r--r--   0        0        0      845 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/airbyte_json.py
+-rw-r--r--   0        0        0     1277 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/airtable.py
+-rw-r--r--   0        0        0     2724 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/apify_dataset.py
+-rw-r--r--   0        0        0     1144 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/arxiv.py
+-rw-r--r--   0        0        0     4865 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/async_html.py
+-rw-r--r--   0        0        0      580 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/azlyrics.py
+-rw-r--r--   0        0        0     1618 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/azure_blob_storage_container.py
+-rw-r--r--   0        0        0     1637 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/azure_blob_storage_file.py
+-rw-r--r--   0        0        0     3047 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/base.py
+-rw-r--r--   0        0        0     3934 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/bibtex.py
+-rw-r--r--   0        0        0     3151 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/bigquery.py
+-rw-r--r--   0        0        0     2726 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/bilibili.py
+-rw-r--r--   0        0        0    10099 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/blackboard.py
+-rw-r--r--   0        0        0      332 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/__init__.py
+-rw-r--r--   0        0        0     4283 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/file_system.py
+-rw-r--r--   0        0        0     5765 2023-08-07 21:21:40.551154 oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/schema.py
+-rw-r--r--   0        0        0     1510 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/youtube_audio.py
+-rw-r--r--   0        0        0     5732 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/blockchain.py
+-rw-r--r--   0        0        0     1074 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/brave_search.py
+-rw-r--r--   0        0        0     2136 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/browserless.py
+-rw-r--r--   0        0        0     2030 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/chatgpt.py
+-rw-r--r--   0        0        0      556 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/college_confidential.py
+-rw-r--r--   0        0        0     2153 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/concurrent.py
+-rw-r--r--   0        0        0    25403 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/confluence.py
+-rw-r--r--   0        0        0     1072 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/conllu.py
+-rw-r--r--   0        0        0     4203 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/csv_loader.py
+-rw-r--r--   0        0        0     5905 2023-08-08 04:52:52.609953 oplangchain-0.1.1/oplangchain/document_loaders/cube_semantic.py
+-rw-r--r--   0        0        0     4997 2023-08-08 04:52:52.608952 oplangchain-0.1.1/oplangchain/document_loaders/datadog_logs.py
+-rw-r--r--   0        0        0     1329 2023-08-08 04:52:52.608952 oplangchain-0.1.1/oplangchain/document_loaders/dataframe.py
+-rw-r--r--   0        0        0     2114 2023-08-08 04:52:52.607953 oplangchain-0.1.1/oplangchain/document_loaders/diffbot.py
+-rw-r--r--   0        0        0     5104 2023-08-08 04:52:52.607953 oplangchain-0.1.1/oplangchain/document_loaders/directory.py
+-rw-r--r--   0        0        0     1265 2023-08-08 04:52:52.607953 oplangchain-0.1.1/oplangchain/document_loaders/discord.py
+-rw-r--r--   0        0        0    13220 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/docugami.py
+-rw-r--r--   0        0        0     6095 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/dropbox.py
+-rw-r--r--   0        0        0     3185 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/duckdb_loader.py
+-rw-r--r--   0        0        0     3792 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/email.py
+-rw-r--r--   0        0        0     8951 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/embaas.py
+-rw-r--r--   0        0        0     1514 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/epub.py
+-rw-r--r--   0        0        0     7812 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/etherscan.py
+-rw-r--r--   0        0        0     5748 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/evernote.py
+-rw-r--r--   0        0        0     1668 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/excel.py
+-rw-r--r--   0        0        0     1302 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/facebook_chat.py
+-rw-r--r--   0        0        0     2245 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/fauna.py
+-rw-r--r--   0        0        0     1575 2023-08-08 04:52:52.606954 oplangchain-0.1.1/oplangchain/document_loaders/figma.py
+-rw-r--r--   0        0        0     1579 2023-08-08 04:52:52.605952 oplangchain-0.1.1/oplangchain/document_loaders/gcs_directory.py
+-rw-r--r--   0        0        0     1737 2023-08-08 04:52:52.605952 oplangchain-0.1.1/oplangchain/document_loaders/gcs_file.py
+-rw-r--r--   0        0        0     4543 2023-08-08 04:52:52.605952 oplangchain-0.1.1/oplangchain/document_loaders/generic.py
+-rw-r--r--   0        0        0     1686 2023-08-08 04:52:52.605952 oplangchain-0.1.1/oplangchain/document_loaders/geodataframe.py
+-rw-r--r--   0        0        0     4142 2023-08-08 04:52:52.605952 oplangchain-0.1.1/oplangchain/document_loaders/git.py
+-rw-r--r--   0        0        0     3110 2023-08-08 04:52:52.605540 oplangchain-0.1.1/oplangchain/document_loaders/gitbook.py
+-rw-r--r--   0        0        0     6874 2023-08-08 04:52:52.604954 oplangchain-0.1.1/oplangchain/document_loaders/github.py
+-rw-r--r--   0        0        0    13930 2023-08-08 04:52:52.604954 oplangchain-0.1.1/oplangchain/document_loaders/googledrive.py
+-rw-r--r--   0        0        0      973 2023-08-08 04:52:52.603954 oplangchain-0.1.1/oplangchain/document_loaders/gutenberg.py
+-rw-r--r--   0        0        0     1559 2023-08-07 21:21:40.568154 oplangchain-0.1.1/oplangchain/document_loaders/helpers.py
+-rw-r--r--   0        0        0     2065 2023-08-08 04:52:52.603954 oplangchain-0.1.1/oplangchain/document_loaders/hn.py
+-rw-r--r--   0        0        0     1208 2023-08-08 04:52:52.602952 oplangchain-0.1.1/oplangchain/document_loaders/html.py
+-rw-r--r--   0        0        0     2122 2023-08-08 04:52:52.600954 oplangchain-0.1.1/oplangchain/document_loaders/html_bs.py
+-rw-r--r--   0        0        0     3029 2023-08-08 04:52:52.599953 oplangchain-0.1.1/oplangchain/document_loaders/hugging_face_dataset.py
+-rw-r--r--   0        0        0     7654 2023-08-08 04:52:52.599953 oplangchain-0.1.1/oplangchain/document_loaders/ifixit.py
+-rw-r--r--   0        0        0     1190 2023-08-08 04:52:52.599953 oplangchain-0.1.1/oplangchain/document_loaders/image.py
+-rw-r--r--   0        0        0     3103 2023-08-08 04:52:52.599953 oplangchain-0.1.1/oplangchain/document_loaders/image_captions.py
+-rw-r--r--   0        0        0      491 2023-08-08 04:52:52.599953 oplangchain-0.1.1/oplangchain/document_loaders/imsdb.py
+-rw-r--r--   0        0        0     1740 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/iugu.py
+-rw-r--r--   0        0        0     3705 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/joplin.py
+-rw-r--r--   0        0        0     5491 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/json_loader.py
+-rw-r--r--   0        0        0     2056 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/larksuite.py
+-rw-r--r--   0        0        0     1832 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/markdown.py
+-rw-r--r--   0        0        0     3134 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/mastodon.py
+-rw-r--r--   0        0        0     3299 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/max_compute.py
+-rw-r--r--   0        0        0     3487 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/mediawikidump.py
+-rw-r--r--   0        0        0      842 2023-08-08 04:52:52.598953 oplangchain-0.1.1/oplangchain/document_loaders/merge.py
+-rw-r--r--   0        0        0     2604 2023-08-08 04:52:52.597955 oplangchain-0.1.1/oplangchain/document_loaders/mhtml.py
+-rw-r--r--   0        0        0     3137 2023-08-08 04:52:52.596954 oplangchain-0.1.1/oplangchain/document_loaders/modern_treasury.py
+-rw-r--r--   0        0        0     4293 2023-08-08 04:52:52.595955 oplangchain-0.1.1/oplangchain/document_loaders/news.py
+-rw-r--r--   0        0        0     4285 2023-08-08 04:52:52.595955 oplangchain-0.1.1/oplangchain/document_loaders/notebook.py
+-rw-r--r--   0        0        0      745 2023-08-08 04:52:52.593953 oplangchain-0.1.1/oplangchain/document_loaders/notion.py
+-rw-r--r--   0        0        0     5896 2023-08-08 04:52:52.593953 oplangchain-0.1.1/oplangchain/document_loaders/notiondb.py
+-rw-r--r--   0        0        0     1090 2023-08-08 04:52:52.590953 oplangchain-0.1.1/oplangchain/document_loaders/nuclia.py
+-rw-r--r--   0        0        0     3600 2023-08-08 04:52:52.590953 oplangchain-0.1.1/oplangchain/document_loaders/obs_directory.py
+-rw-r--r--   0        0        0     4751 2023-08-08 04:52:52.590953 oplangchain-0.1.1/oplangchain/document_loaders/obs_file.py
+-rw-r--r--   0        0        0     2541 2023-08-08 04:52:52.590953 oplangchain-0.1.1/oplangchain/document_loaders/obsidian.py
+-rw-r--r--   0        0        0     1797 2023-08-08 04:52:52.590953 oplangchain-0.1.1/oplangchain/document_loaders/odt.py
+-rw-r--r--   0        0        0     8641 2023-08-08 04:52:52.589954 oplangchain-0.1.1/oplangchain/document_loaders/onedrive.py
+-rw-r--r--   0        0        0     1114 2023-08-08 04:52:52.589954 oplangchain-0.1.1/oplangchain/document_loaders/onedrive_file.py
+-rw-r--r--   0        0        0     1326 2023-08-08 04:52:52.588955 oplangchain-0.1.1/oplangchain/document_loaders/open_city_data.py
+-rw-r--r--   0        0        0     1769 2023-08-08 04:52:52.587955 oplangchain-0.1.1/oplangchain/document_loaders/org_mode.py
+-rw-r--r--   0        0        0      655 2023-08-08 04:52:52.610953 oplangchain-0.1.1/oplangchain/document_loaders/parsers/__init__.py
+-rw-r--r--   0        0        0     6089 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/audio.py
+-rw-r--r--   0        0        0     2474 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/generic.py
+-rw-r--r--   0        0        0     5765 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/grobid.py
+-rw-r--r--   0        0        0      101 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/html/__init__.py
+-rw-r--r--   0        0        0     1608 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/html/bs4.py
+-rw-r--r--   0        0        0      119 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/__init__.py
+-rw-r--r--   0        0        0      499 2023-08-07 21:21:40.586154 oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/code_segmenter.py
+-rw-r--r--   0        0        0     2090 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/javascript.py
+-rw-r--r--   0        0        0     4690 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/language_parser.py
+-rw-r--r--   0        0        0     1664 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/python.py
+-rw-r--r--   0        0        0     8807 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/pdf.py
+-rw-r--r--   0        0        0      920 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/registry.py
+-rw-r--r--   0        0        0      482 2023-08-08 04:52:52.611952 oplangchain-0.1.1/oplangchain/document_loaders/parsers/txt.py
+-rw-r--r--   0        0        0    20559 2023-08-08 04:52:52.586953 oplangchain-0.1.1/oplangchain/document_loaders/pdf.py
+-rw-r--r--   0        0        0     2521 2023-08-08 04:52:52.586953 oplangchain-0.1.1/oplangchain/document_loaders/powerpoint.py
+-rw-r--r--   0        0        0     1416 2023-08-08 04:52:52.585954 oplangchain-0.1.1/oplangchain/document_loaders/psychic.py
+-rw-r--r--   0        0        0     3422 2023-08-08 04:52:52.585954 oplangchain-0.1.1/oplangchain/document_loaders/pyspark_dataframe.py
+-rw-r--r--   0        0        0      527 2023-08-08 04:52:52.585954 oplangchain-0.1.1/oplangchain/document_loaders/python.py
+-rw-r--r--   0        0        0     3530 2023-08-08 04:52:52.585954 oplangchain-0.1.1/oplangchain/document_loaders/readthedocs.py
+-rw-r--r--   0        0        0    12432 2023-08-08 04:52:52.585954 oplangchain-0.1.1/oplangchain/document_loaders/recursive_url_loader.py
+-rw-r--r--   0        0        0     4609 2023-08-08 04:52:52.584953 oplangchain-0.1.1/oplangchain/document_loaders/reddit.py
+-rw-r--r--   0        0        0      726 2023-08-08 04:52:52.584953 oplangchain-0.1.1/oplangchain/document_loaders/roam.py
+-rw-r--r--   0        0        0     4441 2023-08-08 04:52:52.584953 oplangchain-0.1.1/oplangchain/document_loaders/rocksetdb.py
+-rw-r--r--   0        0        0     4938 2023-08-08 04:52:52.584953 oplangchain-0.1.1/oplangchain/document_loaders/rss.py
+-rw-r--r--   0        0        0     1825 2023-08-08 04:52:52.584953 oplangchain-0.1.1/oplangchain/document_loaders/rst.py
+-rw-r--r--   0        0        0     2054 2023-08-08 04:52:52.583955 oplangchain-0.1.1/oplangchain/document_loaders/rtf.py
+-rw-r--r--   0        0        0     1231 2023-08-08 04:52:52.583955 oplangchain-0.1.1/oplangchain/document_loaders/s3_directory.py
+-rw-r--r--   0        0        0     1322 2023-08-08 04:52:52.582954 oplangchain-0.1.1/oplangchain/document_loaders/s3_file.py
+-rw-r--r--   0        0        0     5012 2023-08-08 04:52:52.582954 oplangchain-0.1.1/oplangchain/document_loaders/sitemap.py
+-rw-r--r--   0        0        0     4184 2023-08-08 04:52:52.582954 oplangchain-0.1.1/oplangchain/document_loaders/slack_directory.py
+-rw-r--r--   0        0        0     4830 2023-08-08 04:52:52.582954 oplangchain-0.1.1/oplangchain/document_loaders/snowflake_loader.py
+-rw-r--r--   0        0        0     2065 2023-08-08 04:52:52.581954 oplangchain-0.1.1/oplangchain/document_loaders/spreedly.py
+-rw-r--r--   0        0        0      891 2023-08-08 04:52:52.581954 oplangchain-0.1.1/oplangchain/document_loaders/srt.py
+-rw-r--r--   0        0        0     1861 2023-08-08 04:52:52.580954 oplangchain-0.1.1/oplangchain/document_loaders/stripe.py
+-rw-r--r--   0        0        0     9047 2023-08-08 04:52:52.580954 oplangchain-0.1.1/oplangchain/document_loaders/telegram.py
+-rw-r--r--   0        0        0     1846 2023-08-08 04:52:52.579957 oplangchain-0.1.1/oplangchain/document_loaders/tencent_cos_directory.py
+-rw-r--r--   0        0        0     1758 2023-08-08 04:52:52.579957 oplangchain-0.1.1/oplangchain/document_loaders/tencent_cos_file.py
+-rw-r--r--   0        0        0     1999 2023-08-08 04:52:52.580954 oplangchain-0.1.1/oplangchain/document_loaders/text.py
+-rw-r--r--   0        0        0      998 2023-08-08 04:52:52.579957 oplangchain-0.1.1/oplangchain/document_loaders/tomarkdown.py
+-rw-r--r--   0        0        0     1653 2023-08-08 04:52:52.579957 oplangchain-0.1.1/oplangchain/document_loaders/toml.py
+-rw-r--r--   0        0        0     6602 2023-08-08 04:52:52.579957 oplangchain-0.1.1/oplangchain/document_loaders/trello.py
+-rw-r--r--   0        0        0     1282 2023-08-08 04:52:52.576954 oplangchain-0.1.1/oplangchain/document_loaders/tsv.py
+-rw-r--r--   0        0        0     3458 2023-08-08 04:52:52.576954 oplangchain-0.1.1/oplangchain/document_loaders/twitter.py
+-rw-r--r--   0        0        0    13889 2023-08-08 04:52:52.576954 oplangchain-0.1.1/oplangchain/document_loaders/unstructured.py
+-rw-r--r--   0        0        0     6017 2023-08-08 04:52:52.574953 oplangchain-0.1.1/oplangchain/document_loaders/url.py
+-rw-r--r--   0        0        0     4951 2023-08-08 04:52:52.574953 oplangchain-0.1.1/oplangchain/document_loaders/url_playwright.py
+-rw-r--r--   0        0        0     5225 2023-08-08 04:52:52.574953 oplangchain-0.1.1/oplangchain/document_loaders/url_selenium.py
+-rw-r--r--   0        0        0     1639 2023-08-08 04:52:52.570954 oplangchain-0.1.1/oplangchain/document_loaders/weather.py
+-rw-r--r--   0        0        0     8015 2023-08-08 04:52:52.570954 oplangchain-0.1.1/oplangchain/document_loaders/web_base.py
+-rw-r--r--   0        0        0     1765 2023-08-08 04:52:52.569953 oplangchain-0.1.1/oplangchain/document_loaders/whatsapp_chat.py
+-rw-r--r--   0        0        0     2188 2023-08-08 04:52:52.569953 oplangchain-0.1.1/oplangchain/document_loaders/wikipedia.py
+-rw-r--r--   0        0        0     4561 2023-08-08 04:52:52.568953 oplangchain-0.1.1/oplangchain/document_loaders/word_document.py
+-rw-r--r--   0        0        0     1483 2023-08-08 04:52:52.567953 oplangchain-0.1.1/oplangchain/document_loaders/xml.py
+-rw-r--r--   0        0        0     1627 2023-08-08 04:52:52.567953 oplangchain-0.1.1/oplangchain/document_loaders/xorbits.py
+-rw-r--r--   0        0        0    14680 2023-08-08 04:52:52.566956 oplangchain-0.1.1/oplangchain/document_loaders/youtube.py
+-rw-r--r--   0        0        0     1452 2023-08-08 04:52:52.561953 oplangchain-0.1.1/oplangchain/document_transformers/__init__.py
+-rw-r--r--   0        0        0     3452 2023-08-08 04:52:52.566956 oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_extract.py
+-rw-r--r--   0        0        0     2176 2023-08-08 04:52:52.565955 oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_qa.py
+-rw-r--r--   0        0        0     2320 2023-08-08 04:52:52.565955 oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_translate.py
+-rw-r--r--   0        0        0     8084 2023-08-08 04:52:52.564953 oplangchain-0.1.1/oplangchain/document_transformers/embeddings_redundant_filter.py
+-rw-r--r--   0        0        0     1297 2023-08-08 04:52:52.564953 oplangchain-0.1.1/oplangchain/document_transformers/html2text.py
+-rw-r--r--   0        0        0     1376 2023-08-08 04:52:52.563954 oplangchain-0.1.1/oplangchain/document_transformers/long_context_reorder.py
+-rw-r--r--   0        0        0     1473 2023-08-08 04:52:52.562953 oplangchain-0.1.1/oplangchain/document_transformers/nuclia_text_transform.py
+-rw-r--r--   0        0        0     6220 2023-08-08 04:52:52.561953 oplangchain-0.1.1/oplangchain/document_transformers/openai_functions.py
+-rw-r--r--   0        0        0     4678 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/__init__.py
+-rw-r--r--   0        0        0     9596 2023-08-08 04:52:52.561953 oplangchain-0.1.1/oplangchain/embeddings/aleph_alpha.py
+-rw-r--r--   0        0        0     1633 2023-08-08 04:52:52.560954 oplangchain-0.1.1/oplangchain/embeddings/awa.py
+-rw-r--r--   0        0        0      655 2023-08-07 21:21:40.614153 oplangchain-0.1.1/oplangchain/embeddings/base.py
+-rw-r--r--   0        0        0     5484 2023-08-08 04:52:52.560954 oplangchain-0.1.1/oplangchain/embeddings/bedrock.py
+-rw-r--r--   0        0        0     6553 2023-08-08 04:52:52.560954 oplangchain-0.1.1/oplangchain/embeddings/clarifai.py
+-rw-r--r--   0        0        0     3383 2023-08-08 04:52:52.560954 oplangchain-0.1.1/oplangchain/embeddings/cohere.py
+-rw-r--r--   0        0        0     4890 2023-08-08 04:52:52.560954 oplangchain-0.1.1/oplangchain/embeddings/dashscope.py
+-rw-r--r--   0        0        0     4400 2023-08-08 04:52:52.557952 oplangchain-0.1.1/oplangchain/embeddings/deepinfra.py
+-rw-r--r--   0        0        0     2798 2023-08-08 04:52:52.556953 oplangchain-0.1.1/oplangchain/embeddings/edenai.py
+-rw-r--r--   0        0        0     8384 2023-08-08 04:52:52.555960 oplangchain-0.1.1/oplangchain/embeddings/elasticsearch.py
+-rw-r--r--   0        0        0     4794 2023-08-08 04:52:52.554955 oplangchain-0.1.1/oplangchain/embeddings/embaas.py
+-rw-r--r--   0        0        0     1497 2023-08-08 04:52:52.551953 oplangchain-0.1.1/oplangchain/embeddings/fake.py
+-rw-r--r--   0        0        0     2686 2023-08-08 04:52:52.551953 oplangchain-0.1.1/oplangchain/embeddings/google_palm.py
+-rw-r--r--   0        0        0     1641 2023-08-08 04:52:52.533954 oplangchain-0.1.1/oplangchain/embeddings/gpt4all.py
+-rw-r--r--   0        0        0     6040 2023-08-08 04:52:52.537954 oplangchain-0.1.1/oplangchain/embeddings/huggingface.py
+-rw-r--r--   0        0        0     3686 2023-08-08 04:52:52.550953 oplangchain-0.1.1/oplangchain/embeddings/huggingface_hub.py
+-rw-r--r--   0        0        0     3449 2023-08-08 04:52:52.538954 oplangchain-0.1.1/oplangchain/embeddings/jina.py
+-rw-r--r--   0        0        0     4025 2023-08-08 04:52:52.542952 oplangchain-0.1.1/oplangchain/embeddings/llamacpp.py
+-rw-r--r--   0        0        0    12079 2023-08-08 04:52:52.550953 oplangchain-0.1.1/oplangchain/embeddings/localai.py
+-rw-r--r--   0        0        0     4690 2023-08-08 04:52:52.543952 oplangchain-0.1.1/oplangchain/embeddings/minimax.py
+-rw-r--r--   0        0        0     2244 2023-08-08 04:52:52.543952 oplangchain-0.1.1/oplangchain/embeddings/mlflow_gateway.py
+-rw-r--r--   0        0        0     2361 2023-08-08 04:52:52.550953 oplangchain-0.1.1/oplangchain/embeddings/modelscope_hub.py
+-rw-r--r--   0        0        0     5883 2023-08-08 04:52:52.545953 oplangchain-0.1.1/oplangchain/embeddings/mosaicml.py
+-rw-r--r--   0        0        0     2176 2023-08-08 04:52:52.546953 oplangchain-0.1.1/oplangchain/embeddings/nlpcloud.py
+-rw-r--r--   0        0        0     3402 2023-08-08 04:52:52.549953 oplangchain-0.1.1/oplangchain/embeddings/octoai_embeddings.py
+-rw-r--r--   0        0        0    19945 2023-08-08 04:52:52.546953 oplangchain-0.1.1/oplangchain/embeddings/openai.py
+-rw-r--r--   0        0        0     7110 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/sagemaker_endpoint.py
+-rw-r--r--   0        0        0     3755 2023-08-08 04:52:52.549953 oplangchain-0.1.1/oplangchain/embeddings/self_hosted.py
+-rw-r--r--   0        0        0     6552 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/self_hosted_hugging_face.py
+-rw-r--r--   0        0        0      181 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/sentence_transformer.py
+-rw-r--r--   0        0        0     3728 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/spacy_embeddings.py
+-rw-r--r--   0        0        0     2390 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/tensorflow_hub.py
+-rw-r--r--   0        0        0     1881 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/vertexai.py
+-rw-r--r--   0        0        0     3309 2023-08-08 04:52:52.547953 oplangchain-0.1.1/oplangchain/embeddings/xinference.py
+-rw-r--r--   0        0        0      478 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/env.py
+-rw-r--r--   0        0        0     5062 2023-08-08 04:52:52.517955 oplangchain-0.1.1/oplangchain/evaluation/__init__.py
+-rw-r--r--   0        0        0      167 2023-08-08 04:52:52.526953 oplangchain-0.1.1/oplangchain/evaluation/agents/__init__.py
+-rw-r--r--   0        0        0    13177 2023-08-08 04:52:52.530953 oplangchain-0.1.1/oplangchain/evaluation/agents/trajectory_eval_chain.py
+-rw-r--r--   0        0        0     5939 2023-08-08 04:52:52.529956 oplangchain-0.1.1/oplangchain/evaluation/agents/trajectory_eval_prompt.py
+-rw-r--r--   0        0        0     1404 2023-08-08 04:52:52.525951 oplangchain-0.1.1/oplangchain/evaluation/comparison/__init__.py
+-rw-r--r--   0        0        0    15065 2023-08-08 04:52:52.526953 oplangchain-0.1.1/oplangchain/evaluation/comparison/eval_chain.py
+-rw-r--r--   0        0        0     2177 2023-08-08 04:52:52.525951 oplangchain-0.1.1/oplangchain/evaluation/comparison/prompt.py
+-rw-r--r--   0        0        0     1638 2023-08-08 04:52:52.525951 oplangchain-0.1.1/oplangchain/evaluation/criteria/__init__.py
+-rw-r--r--   0        0        0    20332 2023-08-08 04:52:52.525951 oplangchain-0.1.1/oplangchain/evaluation/criteria/eval_chain.py
+-rw-r--r--   0        0        0     1753 2023-08-08 04:52:52.525951 oplangchain-0.1.1/oplangchain/evaluation/criteria/prompt.py
+-rw-r--r--   0        0        0      325 2023-08-08 04:52:52.522952 oplangchain-0.1.1/oplangchain/evaluation/embedding_distance/__init__.py
+-rw-r--r--   0        0        0    15489 2023-08-08 04:52:52.524954 oplangchain-0.1.1/oplangchain/evaluation/embedding_distance/base.py
+-rw-r--r--   0        0        0     5220 2023-08-08 04:52:52.518955 oplangchain-0.1.1/oplangchain/evaluation/loading.py
+-rw-r--r--   0        0        0      348 2023-08-08 04:52:52.519953 oplangchain-0.1.1/oplangchain/evaluation/qa/__init__.py
+-rw-r--r--   0        0        0    10001 2023-08-08 04:52:52.521954 oplangchain-0.1.1/oplangchain/evaluation/qa/eval_chain.py
+-rw-r--r--   0        0        0     3908 2023-08-08 04:52:52.521954 oplangchain-0.1.1/oplangchain/evaluation/qa/eval_prompt.py
+-rw-r--r--   0        0        0      966 2023-08-08 04:52:52.520955 oplangchain-0.1.1/oplangchain/evaluation/qa/generate_chain.py
+-rw-r--r--   0        0        0      605 2023-08-08 04:52:52.520955 oplangchain-0.1.1/oplangchain/evaluation/qa/generate_prompt.py
+-rw-r--r--   0        0        0    16806 2023-08-08 04:52:52.517955 oplangchain-0.1.1/oplangchain/evaluation/schema.py
+-rw-r--r--   0        0        0      287 2023-08-08 04:52:52.518955 oplangchain-0.1.1/oplangchain/evaluation/string_distance/__init__.py
+-rw-r--r--   0        0        0    14008 2023-08-08 04:52:52.518955 oplangchain-0.1.1/oplangchain/evaluation/string_distance/base.py
+-rw-r--r--   0        0        0      143 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/example_generator.py
+-rw-r--r--   0        0        0      164 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/formatting.py
+-rw-r--r--   0        0        0      769 2023-08-08 04:52:52.530953 oplangchain-0.1.1/oplangchain/graphs/__init__.py
+-rw-r--r--   0        0        0     6198 2023-08-07 21:21:40.642153 oplangchain-0.1.1/oplangchain/graphs/arangodb_graph.py
+-rw-r--r--   0        0        0     1841 2023-08-07 21:21:40.643153 oplangchain-0.1.1/oplangchain/graphs/hugegraph.py
+-rw-r--r--   0        0        0     3559 2023-08-07 21:21:40.643153 oplangchain-0.1.1/oplangchain/graphs/kuzu_graph.py
+-rw-r--r--   0        0        0      715 2023-08-08 04:52:52.532953 oplangchain-0.1.1/oplangchain/graphs/memgraph_graph.py
+-rw-r--r--   0        0        0     7362 2023-08-07 21:21:40.644153 oplangchain-0.1.1/oplangchain/graphs/nebula_graph.py
+-rw-r--r--   0        0        0     3625 2023-08-07 21:21:40.645154 oplangchain-0.1.1/oplangchain/graphs/neo4j_graph.py
+-rw-r--r--   0        0        0     6553 2023-08-07 21:21:40.645154 oplangchain-0.1.1/oplangchain/graphs/neptune_graph.py
+-rw-r--r--   0        0        0     5877 2023-08-07 21:21:40.646154 oplangchain-0.1.1/oplangchain/graphs/networkx_graph.py
+-rw-r--r--   0        0        0     9461 2023-08-07 21:21:40.646154 oplangchain-0.1.1/oplangchain/graphs/rdf_graph.py
+-rw-r--r--   0        0        0      211 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/indexes/__init__.py
+-rw-r--r--   0        0        0     1722 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/indexes/graph.py
+-rw-r--r--   0        0        0       49 2023-08-07 21:21:40.648155 oplangchain-0.1.1/oplangchain/indexes/prompts/__init__.py
+-rw-r--r--   0        0        0     1949 2023-08-08 04:52:52.499953 oplangchain-0.1.1/oplangchain/indexes/prompts/entity_extraction.py
+-rw-r--r--   0        0        0     1154 2023-08-08 04:52:52.497954 oplangchain-0.1.1/oplangchain/indexes/prompts/entity_summarization.py
+-rw-r--r--   0        0        0     1588 2023-08-08 04:52:52.498952 oplangchain-0.1.1/oplangchain/indexes/prompts/knowledge_triplet_extraction.py
+-rw-r--r--   0        0        0     3070 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/indexes/vectorstore.py
+-rw-r--r--   0        0        0      279 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/input.py
+-rw-r--r--   0        0        0     6508 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/__init__.py
+-rw-r--r--   0        0        0     5004 2023-08-08 04:52:52.517955 oplangchain-0.1.1/oplangchain/llms/ai21.py
+-rw-r--r--   0        0        0    11362 2023-08-08 04:52:52.517955 oplangchain-0.1.1/oplangchain/llms/aleph_alpha.py
+-rw-r--r--   0        0        0     3029 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/amazon_api_gateway.py
+-rw-r--r--   0        0        0    11178 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/anthropic.py
+-rw-r--r--   0        0        0     4667 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/anyscale.py
+-rw-r--r--   0        0        0     5375 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/aviary.py
+-rw-r--r--   0        0        0    10224 2023-08-08 04:52:52.505530 oplangchain-0.1.1/oplangchain/llms/azureml_endpoint.py
+-rw-r--r--   0        0        0     4319 2023-08-08 04:52:52.505952 oplangchain-0.1.1/oplangchain/llms/bananadev.py
+-rw-r--r--   0        0        0    34755 2023-08-08 05:09:17.579726 oplangchain-0.1.1/oplangchain/llms/base.py
+-rw-r--r--   0        0        0     2365 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/baseten.py
+-rw-r--r--   0        0        0     9070 2023-08-08 04:52:52.507954 oplangchain-0.1.1/oplangchain/llms/beam.py
+-rw-r--r--   0        0        0     6698 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/bedrock.py
+-rw-r--r--   0        0        0     3783 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/cerebriumai.py
+-rw-r--r--   0        0        0     3945 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/chatglm.py
+-rw-r--r--   0        0        0     5812 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/clarifai.py
+-rw-r--r--   0        0        0     7313 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/cohere.py
+-rw-r--r--   0        0        0     4193 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/ctransformers.py
+-rw-r--r--   0        0        0    12072 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/databricks.py
+-rw-r--r--   0        0        0     3765 2023-08-08 04:52:52.508955 oplangchain-0.1.1/oplangchain/llms/deepinfra.py
+-rw-r--r--   0        0        0     7455 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/edenai.py
+-rw-r--r--   0        0        0     1339 2023-08-08 04:52:52.509954 oplangchain-0.1.1/oplangchain/llms/fake.py
+-rw-r--r--   0        0        0    13047 2023-08-08 04:52:52.510953 oplangchain-0.1.1/oplangchain/llms/fireworks.py
+-rw-r--r--   0        0        0     3661 2023-08-08 04:52:52.510953 oplangchain-0.1.1/oplangchain/llms/forefrontai.py
+-rw-r--r--   0        0        0     5741 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/google_palm.py
+-rw-r--r--   0        0        0     5130 2023-08-08 04:52:52.511953 oplangchain-0.1.1/oplangchain/llms/gooseai.py
+-rw-r--r--   0        0        0     6320 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/gpt4all.py
+-rw-r--r--   0        0        0     5462 2023-08-08 04:52:52.511953 oplangchain-0.1.1/oplangchain/llms/huggingface_endpoint.py
+-rw-r--r--   0        0        0     4613 2023-08-08 04:52:52.511953 oplangchain-0.1.1/oplangchain/llms/huggingface_hub.py
+-rw-r--r--   0        0        0     6576 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/huggingface_pipeline.py
+-rw-r--r--   0        0        0     9723 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/huggingface_text_gen_inference.py
+-rw-r--r--   0        0        0     2547 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/human.py
+-rw-r--r--   0        0        0     5071 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/koboldai.py
+-rw-r--r--   0        0        0    10905 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/llamacpp.py
+-rw-r--r--   0        0        0     1253 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/loading.py
+-rw-r--r--   0        0        0     1878 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/manifest.py
+-rw-r--r--   0        0        0     5162 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/minimax.py
+-rw-r--r--   0        0        0     2925 2023-08-08 04:52:52.516955 oplangchain-0.1.1/oplangchain/llms/mlflow_ai_gateway.py
+-rw-r--r--   0        0        0     3247 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/modal.py
+-rw-r--r--   0        0        0     6752 2023-08-08 04:52:52.512955 oplangchain-0.1.1/oplangchain/llms/mosaicml.py
+-rw-r--r--   0        0        0     5450 2023-08-08 04:52:52.513954 oplangchain-0.1.1/oplangchain/llms/nlpcloud.py
+-rw-r--r--   0        0        0     3814 2023-08-08 04:52:52.513954 oplangchain-0.1.1/oplangchain/llms/octoai_endpoint.py
+-rw-r--r--   0        0        0    34744 2023-08-08 04:52:52.513954 oplangchain-0.1.1/oplangchain/llms/openai.py
+-rw-r--r--   0        0        0     9930 2023-08-08 04:52:52.514953 oplangchain-0.1.1/oplangchain/llms/openllm.py
+-rw-r--r--   0        0        0      796 2023-08-08 04:52:52.514953 oplangchain-0.1.1/oplangchain/llms/openlm.py
+-rw-r--r--   0        0        0     5273 2023-08-08 04:52:52.514953 oplangchain-0.1.1/oplangchain/llms/petals.py
+-rw-r--r--   0        0        0     4023 2023-08-08 04:52:52.514953 oplangchain-0.1.1/oplangchain/llms/pipelineai.py
+-rw-r--r--   0        0        0     1531 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/predibase.py
+-rw-r--r--   0        0        0     4372 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/predictionguard.py
+-rw-r--r--   0        0        0     8692 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/promptlayer_openai.py
+-rw-r--r--   0        0        0     5168 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/replicate.py
+-rw-r--r--   0        0        0     7343 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/rwkv.py
+-rw-r--r--   0        0        0     8821 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/sagemaker_endpoint.py
+-rw-r--r--   0        0        0     7685 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/self_hosted.py
+-rw-r--r--   0        0        0     7699 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/self_hosted_hugging_face.py
+-rw-r--r--   0        0        0     4573 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/stochasticai.py
+-rw-r--r--   0        0        0     7587 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/textgen.py
+-rw-r--r--   0        0        0     7882 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/tongyi.py
+-rw-r--r--   0        0        0      246 2023-08-07 21:21:40.678154 oplangchain-0.1.1/oplangchain/llms/utils.py
+-rw-r--r--   0        0        0     7717 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/vertexai.py
+-rw-r--r--   0        0        0     3984 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/vllm.py
+-rw-r--r--   0        0        0     4919 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/writer.py
+-rw-r--r--   0        0        0     6017 2023-08-08 04:52:52.515962 oplangchain-0.1.1/oplangchain/llms/xinference.py
+-rw-r--r--   0        0        0       41 2023-08-07 21:21:40.680153 oplangchain-0.1.1/oplangchain/load/__init__.py
+-rw-r--r--   0        0        0      755 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/load/dump.py
+-rw-r--r--   0        0        0     4039 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/load/load.py
+-rw-r--r--   0        0        0     4618 2023-08-07 21:21:40.681154 oplangchain-0.1.1/oplangchain/load/serializable.py
+-rw-r--r--   0        0        0     2872 2023-08-08 04:52:52.479955 oplangchain-0.1.1/oplangchain/memory/__init__.py
+-rw-r--r--   0        0        0     3074 2023-08-08 04:52:52.490953 oplangchain-0.1.1/oplangchain/memory/buffer.py
+-rw-r--r--   0        0        0     1232 2023-08-08 04:52:52.485953 oplangchain-0.1.1/oplangchain/memory/buffer_window.py
+-rw-r--r--   0        0        0     1618 2023-08-08 04:52:52.485953 oplangchain-0.1.1/oplangchain/memory/chat_memory.py
+-rw-r--r--   0        0        0     1592 2023-08-08 04:52:52.490953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/__init__.py
+-rw-r--r--   0        0        0     2371 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/cassandra.py
+-rw-r--r--   0        0        0     6497 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/cosmos_db.py
+-rw-r--r--   0        0        0     2885 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/dynamodb.py
+-rw-r--r--   0        0        0     1366 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/file.py
+-rw-r--r--   0        0        0     3336 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/firestore.py
+-rw-r--r--   0        0        0      588 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/in_memory.py
+-rw-r--r--   0        0        0     6835 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/momento.py
+-rw-r--r--   0        0        0     2723 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/mongodb.py
+-rw-r--r--   0        0        0     2648 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/postgres.py
+-rw-r--r--   0        0        0     1951 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/redis.py
+-rw-r--r--   0        0        0     2901 2023-08-08 04:52:52.492952 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/sql.py
+-rw-r--r--   0        0        0     1180 2023-08-08 04:52:52.492952 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/streamlit.py
+-rw-r--r--   0        0        0     6406 2023-08-08 04:52:52.492952 oplangchain-0.1.1/oplangchain/memory/chat_message_histories/zep.py
+-rw-r--r--   0        0        0     2893 2023-08-08 04:52:52.483955 oplangchain-0.1.1/oplangchain/memory/combined.py
+-rw-r--r--   0        0        0    12998 2023-08-08 04:52:52.482954 oplangchain-0.1.1/oplangchain/memory/entity.py
+-rw-r--r--   0        0        0     5035 2023-08-08 04:52:52.475954 oplangchain-0.1.1/oplangchain/memory/kg.py
+-rw-r--r--   0        0        0     3102 2023-08-08 04:52:52.475954 oplangchain-0.1.1/oplangchain/memory/motorhead_memory.py
+-rw-r--r--   0        0        0     8178 2023-08-08 04:52:52.482954 oplangchain-0.1.1/oplangchain/memory/prompt.py
+-rw-r--r--   0        0        0      791 2023-08-08 04:52:52.476953 oplangchain-0.1.1/oplangchain/memory/readonly.py
+-rw-r--r--   0        0        0      758 2023-08-08 04:52:52.482954 oplangchain-0.1.1/oplangchain/memory/simple.py
+-rw-r--r--   0        0        0     3354 2023-08-08 04:52:52.482954 oplangchain-0.1.1/oplangchain/memory/summary.py
+-rw-r--r--   0        0        0     2939 2023-08-08 04:52:52.478954 oplangchain-0.1.1/oplangchain/memory/summary_buffer.py
+-rw-r--r--   0        0        0     1921 2023-08-08 04:52:52.481955 oplangchain-0.1.1/oplangchain/memory/token_buffer.py
+-rw-r--r--   0        0        0      689 2023-08-08 04:52:52.481955 oplangchain-0.1.1/oplangchain/memory/utils.py
+-rw-r--r--   0        0        0     2984 2023-08-08 04:52:52.480955 oplangchain-0.1.1/oplangchain/memory/vectorstore.py
+-rw-r--r--   0        0        0     5071 2023-08-08 04:52:52.479955 oplangchain-0.1.1/oplangchain/memory/zep_memory.py
+-rw-r--r--   0        0        0     3246 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/model_laboratory.py
+-rw-r--r--   0        0        0     1612 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/__init__.py
+-rw-r--r--   0        0        0     1073 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/output_parsers/boolean.py
+-rw-r--r--   0        0        0     1765 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/output_parsers/combining.py
+-rw-r--r--   0        0        0     1821 2023-08-08 04:52:52.496954 oplangchain-0.1.1/oplangchain/output_parsers/datetime.py
+-rw-r--r--   0        0        0     1140 2023-08-08 04:52:52.495954 oplangchain-0.1.1/oplangchain/output_parsers/enum.py
+-rw-r--r--   0        0        0     1813 2023-08-08 04:52:52.495954 oplangchain-0.1.1/oplangchain/output_parsers/fix.py
+-rw-r--r--   0        0        0      810 2023-08-07 21:21:40.702154 oplangchain-0.1.1/oplangchain/output_parsers/format_instructions.py
+-rw-r--r--   0        0        0     2211 2023-08-08 04:52:52.494953 oplangchain-0.1.1/oplangchain/output_parsers/json.py
+-rw-r--r--   0        0        0      941 2023-08-08 04:52:52.494953 oplangchain-0.1.1/oplangchain/output_parsers/list.py
+-rw-r--r--   0        0        0      704 2023-08-08 04:52:52.494953 oplangchain-0.1.1/oplangchain/output_parsers/loading.py
+-rw-r--r--   0        0        0     3354 2023-08-08 04:52:52.494953 oplangchain-0.1.1/oplangchain/output_parsers/openai_functions.py
+-rw-r--r--   0        0        0      505 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/prompts.py
+-rw-r--r--   0        0        0     1735 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/pydantic.py
+-rw-r--r--   0        0        0     3167 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/rail_parser.py
+-rw-r--r--   0        0        0     1198 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/regex.py
+-rw-r--r--   0        0        0     1698 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/regex_dict.py
+-rw-r--r--   0        0        0     4717 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/retry.py
+-rw-r--r--   0        0        0     3078 2023-08-08 04:52:52.493953 oplangchain-0.1.1/oplangchain/output_parsers/structured.py
+-rw-r--r--   0        0        0     2762 2023-08-08 04:52:52.467952 oplangchain-0.1.1/oplangchain/prompts/__init__.py
+-rw-r--r--   0        0        0     3679 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/base.py
+-rw-r--r--   0        0        0    21577 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/chat.py
+-rw-r--r--   0        0        0      559 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/example_selector/__init__.py
+-rw-r--r--   0        0        0      526 2023-08-07 21:21:40.709154 oplangchain-0.1.1/oplangchain/prompts/example_selector/base.py
+-rw-r--r--   0        0        0     2437 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/example_selector/length_based.py
+-rw-r--r--   0        0        0     3802 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/example_selector/ngram_overlap.py
+-rw-r--r--   0        0        0     6854 2023-08-08 04:52:52.474953 oplangchain-0.1.1/oplangchain/prompts/example_selector/semantic_similarity.py
+-rw-r--r--   0        0        0    11763 2023-08-08 04:52:52.472955 oplangchain-0.1.1/oplangchain/prompts/few_shot.py
+-rw-r--r--   0        0        0     5429 2023-08-08 04:52:52.472955 oplangchain-0.1.1/oplangchain/prompts/few_shot_with_templates.py
+-rw-r--r--   0        0        0     5519 2023-08-08 04:52:52.467952 oplangchain-0.1.1/oplangchain/prompts/loading.py
+-rw-r--r--   0        0        0     2258 2023-08-08 04:52:52.468953 oplangchain-0.1.1/oplangchain/prompts/pipeline.py
+-rw-r--r--   0        0        0     8140 2023-08-08 04:52:52.465953 oplangchain-0.1.1/oplangchain/prompts/prompt.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.713154 oplangchain-0.1.1/oplangchain/py.typed
+-rw-r--r--   0        0        0      113 2023-08-08 04:52:52.345954 oplangchain-0.1.1/oplangchain/python.py
+-rw-r--r--   0        0        0      214 2023-08-08 04:52:52.342954 oplangchain-0.1.1/oplangchain/requests.py
+-rw-r--r--   0        0        0     3676 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/__init__.py
+-rw-r--r--   0        0        0      588 2023-08-08 04:52:52.452954 oplangchain-0.1.1/oplangchain/retrievers/arxiv.py
+-rw-r--r--   0        0        0     4048 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/azure_cognitive_search.py
+-rw-r--r--   0        0        0     3657 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/bm25.py
+-rw-r--r--   0        0        0     2653 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/chaindesk.py
+-rw-r--r--   0        0        0     3002 2023-08-08 04:52:52.456954 oplangchain-0.1.1/oplangchain/retrievers/chatgpt_plugin_retriever.py
+-rw-r--r--   0        0        0     2261 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/contextual_compression.py
+-rw-r--r--   0        0        0     2307 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/databerry.py
+-rw-r--r--   0        0        0     6738 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/docarray.py
+-rw-r--r--   0        0        0      601 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/__init__.py
+-rw-r--r--   0        0        0     3662 2023-08-08 04:52:52.458953 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/base.py
+-rw-r--r--   0        0        0     3825 2023-08-08 04:52:52.458953 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_extract.py
+-rw-r--r--   0        0        0      366 2023-08-07 21:21:40.721154 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_extract_prompt.py
+-rw-r--r--   0        0        0     2979 2023-08-08 04:52:52.457954 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_filter.py
+-rw-r--r--   0        0        0      231 2023-08-07 21:21:40.722154 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_filter_prompt.py
+-rw-r--r--   0        0        0     2969 2023-08-08 04:52:52.457954 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/cohere_rerank.py
+-rw-r--r--   0        0        0     3151 2023-08-08 04:52:52.457954 oplangchain-0.1.1/oplangchain/retrievers/document_compressors/embeddings_filter.py
+-rw-r--r--   0        0        0     4664 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/elastic_search_bm25.py
+-rw-r--r--   0        0        0     5797 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/ensemble.py
+-rw-r--r--   0        0        0     7436 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/google_cloud_enterprise_search.py
+-rw-r--r--   0        0        0    12607 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/kendra.py
+-rw-r--r--   0        0        0     2533 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/knn.py
+-rw-r--r--   0        0        0     3026 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/llama_index.py
+-rw-r--r--   0        0        0     3377 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/merger_retriever.py
+-rw-r--r--   0        0        0     1443 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/metal.py
+-rw-r--r--   0        0        0     2385 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/milvus.py
+-rw-r--r--   0        0        0     4846 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/multi_query.py
+-rw-r--r--   0        0        0     5442 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/pinecone_hybrid_search.py
+-rw-r--r--   0        0        0      598 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/pubmed.py
+-rw-r--r--   0        0        0       96 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/pupmed.py
+-rw-r--r--   0        0        0     2611 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/re_phraser.py
+-rw-r--r--   0        0        0     1907 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/remote_retriever.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.731154 oplangchain-0.1.1/oplangchain/retrievers/self_query/__init__.py
+-rw-r--r--   0        0        0     5973 2023-08-08 04:52:52.465953 oplangchain-0.1.1/oplangchain/retrievers/self_query/base.py
+-rw-r--r--   0        0        0     1444 2023-08-08 04:52:52.464953 oplangchain-0.1.1/oplangchain/retrievers/self_query/chroma.py
+-rw-r--r--   0        0        0     2594 2023-08-08 04:52:52.462957 oplangchain-0.1.1/oplangchain/retrievers/self_query/deeplake.py
+-rw-r--r--   0        0        0     3597 2023-08-08 04:52:52.462957 oplangchain-0.1.1/oplangchain/retrievers/self_query/myscale.py
+-rw-r--r--   0        0        0     1450 2023-08-08 04:52:52.462957 oplangchain-0.1.1/oplangchain/retrievers/self_query/pinecone.py
+-rw-r--r--   0        0        0     2813 2023-08-08 04:52:52.462957 oplangchain-0.1.1/oplangchain/retrievers/self_query/qdrant.py
+-rw-r--r--   0        0        0     1503 2023-08-08 04:52:52.459954 oplangchain-0.1.1/oplangchain/retrievers/self_query/weaviate.py
+-rw-r--r--   0        0        0     3663 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/svm.py
+-rw-r--r--   0        0        0     4039 2023-08-08 04:52:52.454955 oplangchain-0.1.1/oplangchain/retrievers/tfidf.py
+-rw-r--r--   0        0        0     5818 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/time_weighted_retriever.py
+-rw-r--r--   0        0        0     4601 2023-08-08 04:52:52.455957 oplangchain-0.1.1/oplangchain/retrievers/vespa_retriever.py
+-rw-r--r--   0        0        0     4059 2023-08-08 04:52:52.454955 oplangchain-0.1.1/oplangchain/retrievers/weaviate_hybrid_search.py
+-rw-r--r--   0        0        0     8302 2023-08-08 04:52:52.454955 oplangchain-0.1.1/oplangchain/retrievers/web_research.py
+-rw-r--r--   0        0        0      611 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/wikipedia.py
+-rw-r--r--   0        0        0     3075 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/zep.py
+-rw-r--r--   0        0        0     2679 2023-08-08 04:52:52.453954 oplangchain-0.1.1/oplangchain/retrievers/zilliz.py
+-rw-r--r--   0        0        0     1736 2023-08-08 04:52:52.443954 oplangchain-0.1.1/oplangchain/schema/__init__.py
+-rw-r--r--   0        0        0      643 2023-08-07 21:21:40.739154 oplangchain-0.1.1/oplangchain/schema/agent.py
+-rw-r--r--   0        0        0     2658 2023-08-08 04:52:52.452954 oplangchain-0.1.1/oplangchain/schema/document.py
+-rw-r--r--   0        0        0    10183 2023-08-08 04:52:52.452954 oplangchain-0.1.1/oplangchain/schema/language_model.py
+-rw-r--r--   0        0        0     4099 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/memory.py
+-rw-r--r--   0        0        0     7490 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/messages.py
+-rw-r--r--   0        0        0     5451 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/output.py
+-rw-r--r--   0        0        0     7792 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/output_parser.py
+-rw-r--r--   0        0        0      638 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/prompt.py
+-rw-r--r--   0        0        0     6879 2023-08-08 04:52:52.451953 oplangchain-0.1.1/oplangchain/schema/prompt_template.py
+-rw-r--r--   0        0        0    10059 2023-08-08 04:52:52.450953 oplangchain-0.1.1/oplangchain/schema/retriever.py
+-rw-r--r--   0        0        0    40398 2023-08-08 04:52:52.448953 oplangchain-0.1.1/oplangchain/schema/runnable.py
+-rw-r--r--   0        0        0      122 2023-08-08 04:52:52.341954 oplangchain-0.1.1/oplangchain/serpapi.py
+-rw-r--r--   0        0        0      533 2023-08-07 21:21:40.745154 oplangchain-0.1.1/oplangchain/server.py
+-rw-r--r--   0        0        0     3571 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/smith/__init__.py
+-rw-r--r--   0        0        0     2201 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/smith/evaluation/__init__.py
+-rw-r--r--   0        0        0     8581 2023-08-08 04:52:52.443954 oplangchain-0.1.1/oplangchain/smith/evaluation/config.py
+-rw-r--r--   0        0        0    51540 2023-08-08 04:52:52.440954 oplangchain-0.1.1/oplangchain/smith/evaluation/runner_utils.py
+-rw-r--r--   0        0        0    15823 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/smith/evaluation/string_run_evaluator.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.748154 oplangchain-0.1.1/oplangchain/smith/evaluation/utils.py
+-rw-r--r--   0        0        0      131 2023-08-08 04:52:52.339954 oplangchain-0.1.1/oplangchain/sql_database.py
+-rw-r--r--   0        0        0    38443 2023-08-08 04:52:52.339954 oplangchain-0.1.1/oplangchain/text_splitter.py
+-rw-r--r--   0        0        0     6686 2023-08-08 04:52:52.386955 oplangchain-0.1.1/oplangchain/tools/__init__.py
+-rw-r--r--   0        0        0      241 2023-08-08 04:52:52.438954 oplangchain-0.1.1/oplangchain/tools/amadeus/__init__.py
+-rw-r--r--   0        0        0      411 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/tools/amadeus/base.py
+-rw-r--r--   0        0        0     1982 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/tools/amadeus/closest_airport.py
+-rw-r--r--   0        0        0     5561 2023-08-08 04:52:52.439954 oplangchain-0.1.1/oplangchain/tools/amadeus/flight_search.py
+-rw-r--r--   0        0        0     1123 2023-08-07 21:21:40.753154 oplangchain-0.1.1/oplangchain/tools/amadeus/utils.py
+-rw-r--r--   0        0        0       25 2023-08-07 21:21:40.753154 oplangchain-0.1.1/oplangchain/tools/arxiv/__init__.py
+-rw-r--r--   0        0        0     1006 2023-08-08 04:52:52.438954 oplangchain-0.1.1/oplangchain/tools/arxiv/tool.py
+-rw-r--r--   0        0        0      603 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/__init__.py
+-rw-r--r--   0        0        0     5334 2023-08-08 04:52:52.438954 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/form_recognizer.py
+-rw-r--r--   0        0        0     5263 2023-08-08 04:52:52.438954 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/image_analysis.py
+-rw-r--r--   0        0        0     4304 2023-08-08 04:52:52.438954 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/speech2text.py
+-rw-r--r--   0        0        0     3652 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/text2speech.py
+-rw-r--r--   0        0        0      776 2023-08-07 21:21:40.757154 oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/utils.py
+-rw-r--r--   0        0        0    26849 2023-08-08 04:52:52.392956 oplangchain-0.1.1/oplangchain/tools/base.py
+-rw-r--r--   0        0        0      162 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/bing_search/__init__.py
+-rw-r--r--   0        0        0     1441 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/bing_search/tool.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.759154 oplangchain-0.1.1/oplangchain/tools/brave_search/__init__.py
+-rw-r--r--   0        0        0     1342 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/brave_search/tool.py
+-rw-r--r--   0        0        0     1738 2023-08-08 04:52:52.390954 oplangchain-0.1.1/oplangchain/tools/convert_to_openai.py
+-rw-r--r--   0        0        0      260 2023-08-08 04:52:52.435953 oplangchain-0.1.1/oplangchain/tools/dataforseo_api_search/__init__.py
+-rw-r--r--   0        0        0     2182 2023-08-08 04:52:52.435953 oplangchain-0.1.1/oplangchain/tools/dataforseo_api_search/tool.py
+-rw-r--r--   0        0        0      139 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/ddg_search/__init__.py
+-rw-r--r--   0        0        0     2321 2023-08-08 04:52:52.436954 oplangchain-0.1.1/oplangchain/tools/ddg_search/tool.py
+-rw-r--r--   0        0        0      667 2023-08-08 04:52:52.428954 oplangchain-0.1.1/oplangchain/tools/file_management/__init__.py
+-rw-r--r--   0        0        0     1730 2023-08-08 04:52:52.433955 oplangchain-0.1.1/oplangchain/tools/file_management/copy.py
+-rw-r--r--   0        0        0     1326 2023-08-08 04:52:52.433955 oplangchain-0.1.1/oplangchain/tools/file_management/delete.py
+-rw-r--r--   0        0        0     1946 2023-08-08 04:52:52.432954 oplangchain-0.1.1/oplangchain/tools/file_management/file_search.py
+-rw-r--r--   0        0        0     1413 2023-08-08 04:52:52.431953 oplangchain-0.1.1/oplangchain/tools/file_management/list_dir.py
+-rw-r--r--   0        0        0     1870 2023-08-08 04:52:52.428954 oplangchain-0.1.1/oplangchain/tools/file_management/move.py
+-rw-r--r--   0        0        0     1321 2023-08-08 04:52:52.428954 oplangchain-0.1.1/oplangchain/tools/file_management/read.py
+-rw-r--r--   0        0        0     1708 2023-08-07 21:21:40.767154 oplangchain-0.1.1/oplangchain/tools/file_management/utils.py
+-rw-r--r--   0        0        0     1595 2023-08-08 04:52:52.422954 oplangchain-0.1.1/oplangchain/tools/file_management/write.py
+-rw-r--r--   0        0        0       20 2023-08-07 21:21:40.768154 oplangchain-0.1.1/oplangchain/tools/github/__init__.py
+-rw-r--r--   0        0        0     3438 2023-08-07 21:21:40.769155 oplangchain-0.1.1/oplangchain/tools/github/prompt.py
+-rw-r--r--   0        0        0      927 2023-08-08 04:52:52.422954 oplangchain-0.1.1/oplangchain/tools/github/tool.py
+-rw-r--r--   0        0        0      553 2023-08-08 04:52:52.418954 oplangchain-0.1.1/oplangchain/tools/gmail/__init__.py
+-rw-r--r--   0        0        0      980 2023-08-08 04:52:52.422954 oplangchain-0.1.1/oplangchain/tools/gmail/base.py
+-rw-r--r--   0        0        0     2543 2023-08-08 04:52:52.420954 oplangchain-0.1.1/oplangchain/tools/gmail/create_draft.py
+-rw-r--r--   0        0        0     1733 2023-08-08 04:52:52.416952 oplangchain-0.1.1/oplangchain/tools/gmail/get_message.py
+-rw-r--r--   0        0        0     1539 2023-08-08 04:52:52.420954 oplangchain-0.1.1/oplangchain/tools/gmail/get_thread.py
+-rw-r--r--   0        0        0     4369 2023-08-08 04:52:52.416952 oplangchain-0.1.1/oplangchain/tools/gmail/search.py
+-rw-r--r--   0        0        0     2851 2023-08-08 04:52:52.417953 oplangchain-0.1.1/oplangchain/tools/gmail/send_message.py
+-rw-r--r--   0        0        0     4528 2023-08-07 21:21:40.773153 oplangchain-0.1.1/oplangchain/tools/gmail/utils.py
+-rw-r--r--   0        0        0      128 2023-08-08 04:52:52.416952 oplangchain-0.1.1/oplangchain/tools/golden_query/__init__.py
+-rw-r--r--   0        0        0     1096 2023-08-08 04:52:52.416952 oplangchain-0.1.1/oplangchain/tools/golden_query/tool.py
+-rw-r--r--   0        0        0      132 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/google_places/__init__.py
+-rw-r--r--   0        0        0     1112 2023-08-08 04:52:52.416952 oplangchain-0.1.1/oplangchain/tools/google_places/tool.py
+-rw-r--r--   0        0        0      174 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/google_search/__init__.py
+-rw-r--r--   0        0        0     1467 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/google_search/tool.py
+-rw-r--r--   0        0        0      222 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/google_serper/__init__.py
+-rw-r--r--   0        0        0     2082 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/google_serper/tool.py
+-rw-r--r--   0        0        0       47 2023-08-07 21:21:40.778154 oplangchain-0.1.1/oplangchain/tools/graphql/__init__.py
+-rw-r--r--   0        0        0     1192 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/graphql/tool.py
+-rw-r--r--   0        0        0      124 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/human/__init__.py
+-rw-r--r--   0        0        0      963 2023-08-08 04:52:52.415952 oplangchain-0.1.1/oplangchain/tools/human/tool.py
+-rw-r--r--   0        0        0     2294 2023-08-08 04:52:52.389957 oplangchain-0.1.1/oplangchain/tools/ifttt.py
+-rw-r--r--   0        0        0       43 2023-08-07 21:21:40.781153 oplangchain-0.1.1/oplangchain/tools/interaction/__init__.py
+-rw-r--r--   0        0        0      456 2023-08-08 04:52:52.415933 oplangchain-0.1.1/oplangchain/tools/interaction/tool.py
+-rw-r--r--   0        0        0       17 2023-08-07 21:21:40.782154 oplangchain-0.1.1/oplangchain/tools/jira/__init__.py
+-rw-r--r--   0        0        0     3170 2023-08-07 21:21:40.783154 oplangchain-0.1.1/oplangchain/tools/jira/prompt.py
+-rw-r--r--   0        0        0     1585 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/jira/tool.py
+-rw-r--r--   0        0        0       46 2023-08-07 21:21:40.784153 oplangchain-0.1.1/oplangchain/tools/json/__init__.py
+-rw-r--r--   0        0        0     4091 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/json/tool.py
+-rw-r--r--   0        0        0      146 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/metaphor_search/__init__.py
+-rw-r--r--   0        0        0     2678 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/metaphor_search/tool.py
+-rw-r--r--   0        0        0      241 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/multion/__init__.py
+-rw-r--r--   0        0        0     1581 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/multion/create_session.py
+-rw-r--r--   0        0        0     2120 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/multion/update_session.py
+-rw-r--r--   0        0        0      103 2023-08-08 04:52:52.413953 oplangchain-0.1.1/oplangchain/tools/nuclia/__init__.py
+-rw-r--r--   0        0        0     7579 2023-08-08 04:52:52.414953 oplangchain-0.1.1/oplangchain/tools/nuclia/tool.py
+-rw-r--r--   0        0        0      597 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/office365/__init__.py
+-rw-r--r--   0        0        0      484 2023-08-08 04:52:52.412953 oplangchain-0.1.1/oplangchain/tools/office365/base.py
+-rw-r--r--   0        0        0     1836 2023-08-08 04:52:52.409952 oplangchain-0.1.1/oplangchain/tools/office365/create_draft_message.py
+-rw-r--r--   0        0        0     4852 2023-08-08 04:52:52.406955 oplangchain-0.1.1/oplangchain/tools/office365/events_search.py
+-rw-r--r--   0        0        0     4166 2023-08-08 04:52:52.408952 oplangchain-0.1.1/oplangchain/tools/office365/messages_search.py
+-rw-r--r--   0        0        0     2834 2023-08-08 04:52:52.406955 oplangchain-0.1.1/oplangchain/tools/office365/send_event.py
+-rw-r--r--   0        0        0     1767 2023-08-08 04:52:52.406955 oplangchain-0.1.1/oplangchain/tools/office365/send_message.py
+-rw-r--r--   0        0        0     2136 2023-08-07 21:21:40.792153 oplangchain-0.1.1/oplangchain/tools/office365/utils.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.793153 oplangchain-0.1.1/oplangchain/tools/openapi/__init__.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.793153 oplangchain-0.1.1/oplangchain/tools/openapi/utils/__init__.py
+-rw-r--r--   0        0        0    20555 2023-08-08 04:52:52.413953 oplangchain-0.1.1/oplangchain/tools/openapi/utils/api_models.py
+-rw-r--r--   0        0        0      158 2023-08-08 04:52:52.413953 oplangchain-0.1.1/oplangchain/tools/openapi/utils/openapi_utils.py
+-rw-r--r--   0        0        0      154 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/openweathermap/__init__.py
+-rw-r--r--   0        0        0      922 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/openweathermap/tool.py
+-rw-r--r--   0        0        0      698 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/__init__.py
+-rw-r--r--   0        0        0     2120 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/base.py
+-rw-r--r--   0        0        0     3054 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/click.py
+-rw-r--r--   0        0        0     1298 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/current_page.py
+-rw-r--r--   0        0        0     3009 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/playwright/extract_hyperlinks.py
+-rw-r--r--   0        0        0     2341 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/playwright/extract_text.py
+-rw-r--r--   0        0        0     3701 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/get_elements.py
+-rw-r--r--   0        0        0     1762 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/playwright/navigate.py
+-rw-r--r--   0        0        0     1897 2023-08-08 04:52:52.405953 oplangchain-0.1.1/oplangchain/tools/playwright/navigate_back.py
+-rw-r--r--   0        0        0     2813 2023-08-07 21:21:40.800154 oplangchain-0.1.1/oplangchain/tools/playwright/utils.py
+-rw-r--r--   0        0        0     2892 2023-08-08 04:52:52.388957 oplangchain-0.1.1/oplangchain/tools/plugin.py
+-rw-r--r--   0        0        0       52 2023-08-07 21:21:40.801153 oplangchain-0.1.1/oplangchain/tools/powerbi/__init__.py
+-rw-r--r--   0        0        0     7339 2023-08-07 21:21:40.802153 oplangchain-0.1.1/oplangchain/tools/powerbi/prompt.py
+-rw-r--r--   0        0        0    11069 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/powerbi/tool.py
+-rw-r--r--   0        0        0       26 2023-08-07 21:21:40.803153 oplangchain-0.1.1/oplangchain/tools/pubmed/__init__.py
+-rw-r--r--   0        0        0     1016 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/pubmed/tool.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.804154 oplangchain-0.1.1/oplangchain/tools/python/__init__.py
+-rw-r--r--   0        0        0     4319 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/python/tool.py
+-rw-r--r--   0        0        0       52 2023-08-07 21:21:40.805154 oplangchain-0.1.1/oplangchain/tools/requests/__init__.py
+-rw-r--r--   0        0        0     6254 2023-08-08 04:52:52.404955 oplangchain-0.1.1/oplangchain/tools/requests/tool.py
+-rw-r--r--   0        0        0       31 2023-08-07 21:21:40.806153 oplangchain-0.1.1/oplangchain/tools/scenexplain/__init__.py
+-rw-r--r--   0        0        0     1071 2023-08-08 04:52:52.395953 oplangchain-0.1.1/oplangchain/tools/scenexplain/tool.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.807153 oplangchain-0.1.1/oplangchain/tools/searx_search/__init__.py
+-rw-r--r--   0        0        0     2222 2023-08-08 04:52:52.396955 oplangchain-0.1.1/oplangchain/tools/searx_search/tool.py
+-rw-r--r--   0        0        0       95 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/shell/__init__.py
+-rw-r--r--   0        0        0     2390 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/shell/tool.py
+-rw-r--r--   0        0        0       18 2023-08-07 21:21:40.809153 oplangchain-0.1.1/oplangchain/tools/sleep/__init__.py
+-rw-r--r--   0        0        0     1209 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/sleep/tool.py
+-rw-r--r--   0        0        0       44 2023-08-07 21:21:40.811153 oplangchain-0.1.1/oplangchain/tools/spark_sql/__init__.py
+-rw-r--r--   0        0        0      550 2023-08-07 21:21:40.811153 oplangchain-0.1.1/oplangchain/tools/spark_sql/prompt.py
+-rw-r--r--   0        0        0     4526 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/spark_sql/tool.py
+-rw-r--r--   0        0        0       49 2023-08-07 21:21:40.812153 oplangchain-0.1.1/oplangchain/tools/sql_database/__init__.py
+-rw-r--r--   0        0        0      597 2023-08-07 21:21:40.813154 oplangchain-0.1.1/oplangchain/tools/sql_database/prompt.py
+-rw-r--r--   0        0        0     4588 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/sql_database/tool.py
+-rw-r--r--   0        0        0      169 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/steamship_image_generation/__init__.py
+-rw-r--r--   0        0        0     3335 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/steamship_image_generation/tool.py
+-rw-r--r--   0        0        0     1395 2023-08-07 21:21:40.815153 oplangchain-0.1.1/oplangchain/tools/steamship_image_generation/utils.py
+-rw-r--r--   0        0        0       51 2023-08-07 21:21:40.815153 oplangchain-0.1.1/oplangchain/tools/vectorstore/__init__.py
+-rw-r--r--   0        0        0     3255 2023-08-08 04:52:52.394953 oplangchain-0.1.1/oplangchain/tools/vectorstore/tool.py
+-rw-r--r--   0        0        0       29 2023-08-07 21:21:40.817153 oplangchain-0.1.1/oplangchain/tools/wikipedia/__init__.py
+-rw-r--r--   0        0        0      855 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/wikipedia/tool.py
+-rw-r--r--   0        0        0      148 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/wolfram_alpha/__init__.py
+-rw-r--r--   0        0        0      875 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/wolfram_alpha/tool.py
+-rw-r--r--   0        0        0        0 2023-08-07 21:21:40.819153 oplangchain-0.1.1/oplangchain/tools/youtube/__init__.py
+-rw-r--r--   0        0        0     1665 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/youtube/search.py
+-rw-r--r--   0        0        0      172 2023-08-08 04:52:52.392956 oplangchain-0.1.1/oplangchain/tools/zapier/__init__.py
+-rw-r--r--   0        0        0     1182 2023-08-07 21:21:40.820154 oplangchain-0.1.1/oplangchain/tools/zapier/prompt.py
+-rw-r--r--   0        0        0     7081 2023-08-08 04:52:52.393954 oplangchain-0.1.1/oplangchain/tools/zapier/tool.py
+-rw-r--r--   0        0        0     2928 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utilities/__init__.py
+-rw-r--r--   0        0        0     6390 2023-08-08 04:52:52.386955 oplangchain-0.1.1/oplangchain/utilities/arxiv.py
+-rw-r--r--   0        0        0      274 2023-08-07 21:21:40.822153 oplangchain-0.1.1/oplangchain/utilities/asyncio.py
+-rw-r--r--   0        0        0     2419 2023-08-07 21:21:40.823154 oplangchain-0.1.1/oplangchain/utilities/awslambda.py
+-rw-r--r--   0        0        0     5705 2023-08-08 04:52:52.386955 oplangchain-0.1.1/oplangchain/utilities/bash.py
+-rw-r--r--   0        0        0     2481 2023-08-07 21:21:40.824154 oplangchain-0.1.1/oplangchain/utilities/bibtex.py
+-rw-r--r--   0        0        0     3335 2023-08-08 04:52:52.386955 oplangchain-0.1.1/oplangchain/utilities/bing_search.py
+-rw-r--r--   0        0        0     2328 2023-08-08 04:52:52.385954 oplangchain-0.1.1/oplangchain/utilities/brave_search.py
+-rw-r--r--   0        0        0     7834 2023-08-08 04:52:52.385954 oplangchain-0.1.1/oplangchain/utilities/dataforseo_api_search.py
+-rw-r--r--   0        0        0     3764 2023-08-07 21:21:40.825153 oplangchain-0.1.1/oplangchain/utilities/duckduckgo_search.py
+-rw-r--r--   0        0        0    11596 2023-08-08 04:52:52.385517 oplangchain-0.1.1/oplangchain/utilities/github.py
+-rw-r--r--   0        0        0     1838 2023-08-08 04:52:52.384954 oplangchain-0.1.1/oplangchain/utilities/golden_query.py
+-rw-r--r--   0        0        0     4069 2023-08-08 04:52:52.384954 oplangchain-0.1.1/oplangchain/utilities/google_places_api.py
+-rw-r--r--   0        0        0     5096 2023-08-08 04:52:52.383953 oplangchain-0.1.1/oplangchain/utilities/google_search.py
+-rw-r--r--   0        0        0     6507 2023-08-08 04:52:52.383953 oplangchain-0.1.1/oplangchain/utilities/google_serper.py
+-rw-r--r--   0        0        0     1885 2023-08-07 21:21:40.828153 oplangchain-0.1.1/oplangchain/utilities/graphql.py
+-rw-r--r--   0        0        0     6175 2023-08-08 04:52:52.379954 oplangchain-0.1.1/oplangchain/utilities/jira.py
+-rw-r--r--   0        0        0     1974 2023-08-08 04:52:52.378954 oplangchain-0.1.1/oplangchain/utilities/loading.py
+-rw-r--r--   0        0        0     2644 2023-08-08 04:52:52.377955 oplangchain-0.1.1/oplangchain/utilities/max_compute.py
+-rw-r--r--   0        0        0     6707 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/metaphor_search.py
+-rw-r--r--   0        0        0    10299 2023-08-07 21:21:40.830153 oplangchain-0.1.1/oplangchain/utilities/openapi.py
+-rw-r--r--   0        0        0     2442 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/openweathermap.py
+-rw-r--r--   0        0        0     2198 2023-08-07 21:21:40.831154 oplangchain-0.1.1/oplangchain/utilities/portkey.py
+-rw-r--r--   0        0        0    11237 2023-08-07 21:21:40.832154 oplangchain-0.1.1/oplangchain/utilities/powerbi.py
+-rw-r--r--   0        0        0     5629 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/pupmed.py
+-rw-r--r--   0        0        0     2141 2023-08-07 21:21:40.833154 oplangchain-0.1.1/oplangchain/utilities/python.py
+-rw-r--r--   0        0        0     5439 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/redis.py
+-rw-r--r--   0        0        0     7120 2023-08-07 21:21:40.834153 oplangchain-0.1.1/oplangchain/utilities/requests.py
+-rw-r--r--   0        0        0     2200 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/scenexplain.py
+-rw-r--r--   0        0        0    16539 2023-08-08 04:52:52.376953 oplangchain-0.1.1/oplangchain/utilities/searx_search.py
+-rw-r--r--   0        0        0     6029 2023-08-08 04:52:52.375952 oplangchain-0.1.1/oplangchain/utilities/serpapi.py
+-rw-r--r--   0        0        0     6964 2023-08-07 21:21:40.836153 oplangchain-0.1.1/oplangchain/utilities/spark_sql.py
+-rw-r--r--   0        0        0    18265 2023-08-08 04:52:52.375952 oplangchain-0.1.1/oplangchain/utilities/sql_database.py
+-rw-r--r--   0        0        0     3413 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utilities/twilio.py
+-rw-r--r--   0        0        0     1457 2023-08-07 21:21:40.837154 oplangchain-0.1.1/oplangchain/utilities/vertexai.py
+-rw-r--r--   0        0        0     3922 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utilities/wikipedia.py
+-rw-r--r--   0        0        0     1991 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utilities/wolfram_alpha.py
+-rw-r--r--   0        0        0    11562 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utilities/zapier.py
+-rw-r--r--   0        0        0     1161 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/utils/__init__.py
+-rw-r--r--   0        0        0      873 2023-08-07 21:21:40.840155 oplangchain-0.1.1/oplangchain/utils/env.py
+-rw-r--r--   0        0        0     1237 2023-08-07 21:21:40.840155 oplangchain-0.1.1/oplangchain/utils/formatting.py
+-rw-r--r--   0        0        0     1289 2023-08-07 21:21:40.841153 oplangchain-0.1.1/oplangchain/utils/input.py
+-rw-r--r--   0        0        0     2016 2023-08-07 21:21:40.841153 oplangchain-0.1.1/oplangchain/utils/math.py
+-rw-r--r--   0        0        0      908 2023-08-07 21:21:40.842153 oplangchain-0.1.1/oplangchain/utils/strings.py
+-rw-r--r--   0        0        0     5606 2023-08-07 21:21:40.842153 oplangchain-0.1.1/oplangchain/utils/utils.py
+-rw-r--r--   0        0        0     4085 2023-08-08 04:52:52.346953 oplangchain-0.1.1/oplangchain/vectorstores/__init__.py
+-rw-r--r--   0        0        0     2027 2023-08-08 04:52:52.347954 oplangchain-0.1.1/oplangchain/vectorstores/_pgvector_data_models.py
+-rw-r--r--   0        0        0    13541 2023-08-08 04:52:52.372952 oplangchain-0.1.1/oplangchain/vectorstores/alibabacloud_opensearch.py
+-rw-r--r--   0        0        0    15800 2023-08-08 04:52:52.370954 oplangchain-0.1.1/oplangchain/vectorstores/analyticdb.py
+-rw-r--r--   0        0        0    16597 2023-08-08 04:52:52.370954 oplangchain-0.1.1/oplangchain/vectorstores/annoy.py
+-rw-r--r--   0        0        0    12143 2023-08-08 04:52:52.369953 oplangchain-0.1.1/oplangchain/vectorstores/atlas.py
+-rw-r--r--   0        0        0    21228 2023-08-08 04:52:52.369953 oplangchain-0.1.1/oplangchain/vectorstores/awadb.py
+-rw-r--r--   0        0        0    20726 2023-08-08 04:52:52.369953 oplangchain-0.1.1/oplangchain/vectorstores/azuresearch.py
+-rw-r--r--   0        0        0    22441 2023-08-08 04:52:52.369953 oplangchain-0.1.1/oplangchain/vectorstores/base.py
+-rw-r--r--   0        0        0    13404 2023-08-08 04:52:52.366955 oplangchain-0.1.1/oplangchain/vectorstores/cassandra.py
+-rw-r--r--   0        0        0    23822 2023-08-08 04:52:52.366955 oplangchain-0.1.1/oplangchain/vectorstores/chroma.py
+-rw-r--r--   0        0        0    12739 2023-08-08 04:52:52.365954 oplangchain-0.1.1/oplangchain/vectorstores/clarifai.py
+-rw-r--r--   0        0        0    17817 2023-08-08 04:52:52.365954 oplangchain-0.1.1/oplangchain/vectorstores/clickhouse.py
+-rw-r--r--   0        0        0    34980 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/deeplake.py
+-rw-r--r--   0        0        0      220 2023-08-08 04:52:52.373955 oplangchain-0.1.1/oplangchain/vectorstores/docarray/__init__.py
+-rw-r--r--   0        0        0     6879 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/vectorstores/docarray/base.py
+-rw-r--r--   0        0        0     4061 2023-08-08 04:52:52.374954 oplangchain-0.1.1/oplangchain/vectorstores/docarray/hnsw.py
+-rw-r--r--   0        0        0     2415 2023-08-08 04:52:52.373955 oplangchain-0.1.1/oplangchain/vectorstores/docarray/in_memory.py
+-rw-r--r--   0        0        0    27795 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/elastic_vector_search.py
+-rw-r--r--   0        0        0    29137 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/faiss.py
+-rw-r--r--   0        0        0    16411 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/hologres.py
+-rw-r--r--   0        0        0     4242 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/lancedb.py
+-rw-r--r--   0        0        0    17162 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/marqo.py
+-rw-r--r--   0        0        0    15184 2023-08-08 04:52:52.364955 oplangchain-0.1.1/oplangchain/vectorstores/matching_engine.py
+-rw-r--r--   0        0        0    10437 2023-08-08 04:52:52.360956 oplangchain-0.1.1/oplangchain/vectorstores/meilisearch.py
+-rw-r--r--   0        0        0    31480 2023-08-08 04:52:52.360956 oplangchain-0.1.1/oplangchain/vectorstores/milvus.py
+-rw-r--r--   0        0        0    12361 2023-08-08 04:52:52.359955 oplangchain-0.1.1/oplangchain/vectorstores/mongodb_atlas.py
+-rw-r--r--   0        0        0    16545 2023-08-08 04:52:52.358954 oplangchain-0.1.1/oplangchain/vectorstores/myscale.py
+-rw-r--r--   0        0        0    27702 2023-08-08 04:52:52.358954 oplangchain-0.1.1/oplangchain/vectorstores/opensearch_vector_search.py
+-rw-r--r--   0        0        0    17352 2023-08-08 04:52:52.358954 oplangchain-0.1.1/oplangchain/vectorstores/pgembedding.py
+-rw-r--r--   0        0        0    21271 2023-08-08 04:52:52.358954 oplangchain-0.1.1/oplangchain/vectorstores/pgvector.py
+-rw-r--r--   0        0        0    14921 2023-08-08 04:52:52.358954 oplangchain-0.1.1/oplangchain/vectorstores/pinecone.py
+-rw-r--r--   0        0        0    68545 2023-08-08 04:52:52.357953 oplangchain-0.1.1/oplangchain/vectorstores/qdrant.py
+-rw-r--r--   0        0        0    23162 2023-08-08 04:52:52.357953 oplangchain-0.1.1/oplangchain/vectorstores/redis.py
+-rw-r--r--   0        0        0    12196 2023-08-08 04:52:52.357953 oplangchain-0.1.1/oplangchain/vectorstores/rocksetdb.py
+-rw-r--r--   0        0        0    19535 2023-08-08 04:52:52.357953 oplangchain-0.1.1/oplangchain/vectorstores/scann.py
+-rw-r--r--   0        0        0    18282 2023-08-08 04:52:52.357953 oplangchain-0.1.1/oplangchain/vectorstores/singlestoredb.py
+-rw-r--r--   0        0        0    12395 2023-08-08 04:52:52.356954 oplangchain-0.1.1/oplangchain/vectorstores/sklearn.py
+-rw-r--r--   0        0        0    17225 2023-08-08 04:52:52.355953 oplangchain-0.1.1/oplangchain/vectorstores/starrocks.py
+-rw-r--r--   0        0        0    14251 2023-08-08 04:52:52.352954 oplangchain-0.1.1/oplangchain/vectorstores/supabase.py
+-rw-r--r--   0        0        0     8886 2023-08-08 04:52:52.352954 oplangchain-0.1.1/oplangchain/vectorstores/tair.py
+-rw-r--r--   0        0        0     4884 2023-08-08 04:52:52.352954 oplangchain-0.1.1/oplangchain/vectorstores/tigris.py
+-rw-r--r--   0        0        0     9744 2023-08-08 04:52:52.352954 oplangchain-0.1.1/oplangchain/vectorstores/typesense.py
+-rw-r--r--   0        0        0     1792 2023-08-08 04:52:52.351954 oplangchain-0.1.1/oplangchain/vectorstores/utils.py
+-rw-r--r--   0        0        0    15869 2023-08-08 04:52:52.351954 oplangchain-0.1.1/oplangchain/vectorstores/vectara.py
+-rw-r--r--   0        0        0    16891 2023-08-08 04:52:52.351954 oplangchain-0.1.1/oplangchain/vectorstores/weaviate.py
+-rw-r--r--   0        0        0     7567 2023-08-08 04:52:52.350953 oplangchain-0.1.1/oplangchain/vectorstores/zilliz.py
+-rw-r--r--   0        0        0    13300 2023-08-08 05:10:40.461889 oplangchain-0.1.1/pyproject.toml
+-rw-r--r--   0        0        0     5724 2023-08-07 21:21:40.386154 oplangchain-0.1.1/README.md
+-rw-r--r--   0        0        0    14948 1970-01-01 00:00:00.000000 oplangchain-0.1.1/PKG-INFO
```

### Comparing `oplangchain-0.1.0/oplangchain/__init__.py` & `oplangchain-0.1.1/oplangchain/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """Main entrypoint into package."""
 
 from importlib import metadata
 from typing import Optional
 
-from langchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain
-from langchain.cache import BaseCache
-from langchain.chains import (
+from oplangchain.agents import MRKLChain, ReActChain, SelfAskWithSearchChain
+from oplangchain.cache import BaseCache
+from oplangchain.chains import (
     ConversationChain,
     LLMBashChain,
     LLMChain,
     LLMCheckerChain,
     LLMMathChain,
     QAWithSourcesChain,
     VectorDBQA,
     VectorDBQAWithSourcesChain,
 )
-from langchain.docstore import InMemoryDocstore, Wikipedia
-from langchain.llms import (
+from oplangchain.docstore import InMemoryDocstore, Wikipedia
+from oplangchain.llms import (
     Anthropic,
     Banana,
     CerebriumAI,
     Cohere,
     ForefrontAI,
     GooseAI,
     HuggingFaceHub,
@@ -30,32 +30,32 @@
     OpenAI,
     Petals,
     PipelineAI,
     SagemakerEndpoint,
     StochasticAI,
     Writer,
 )
-from langchain.llms.huggingface_pipeline import HuggingFacePipeline
-from langchain.prompts import (
+from oplangchain.llms.huggingface_pipeline import HuggingFacePipeline
+from oplangchain.prompts import (
     FewShotPromptTemplate,
     Prompt,
     PromptTemplate,
 )
-from langchain.schema.prompt_template import BasePromptTemplate
-from langchain.utilities.arxiv import ArxivAPIWrapper
-from langchain.utilities.golden_query import GoldenQueryAPIWrapper
-from langchain.utilities.google_search import GoogleSearchAPIWrapper
-from langchain.utilities.google_serper import GoogleSerperAPIWrapper
-from langchain.utilities.powerbi import PowerBIDataset
-from langchain.utilities.searx_search import SearxSearchWrapper
-from langchain.utilities.serpapi import SerpAPIWrapper
-from langchain.utilities.sql_database import SQLDatabase
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
-from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
-from langchain.vectorstores import FAISS, ElasticVectorSearch
+from oplangchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.utilities.arxiv import ArxivAPIWrapper
+from oplangchain.utilities.golden_query import GoldenQueryAPIWrapper
+from oplangchain.utilities.google_search import GoogleSearchAPIWrapper
+from oplangchain.utilities.google_serper import GoogleSerperAPIWrapper
+from oplangchain.utilities.powerbi import PowerBIDataset
+from oplangchain.utilities.searx_search import SearxSearchWrapper
+from oplangchain.utilities.serpapi import SerpAPIWrapper
+from oplangchain.utilities.sql_database import SQLDatabase
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
+from oplangchain.vectorstores import FAISS, ElasticVectorSearch
 
 try:
     __version__ = metadata.version(__package__)
 except metadata.PackageNotFoundError:
     # Case where package metadata is not available.
     __version__ = ""
 del metadata  # optional, avoids polluting the results of dir(__package__)
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/__init__.py` & `oplangchain-0.1.1/oplangchain/agents/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -24,55 +24,55 @@
 
 .. code-block::
 
     AgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,
     AgentAction, AgentFinish
     
 """  # noqa: E501
-from langchain.agents.agent import (
+from oplangchain.agents.agent import (
     Agent,
     AgentExecutor,
     AgentOutputParser,
     BaseMultiActionAgent,
     BaseSingleActionAgent,
     LLMSingleActionAgent,
 )
-from langchain.agents.agent_iterator import AgentExecutorIterator
-from langchain.agents.agent_toolkits import (
+from oplangchain.agents.agent_iterator import AgentExecutorIterator
+from oplangchain.agents.agent_toolkits import (
     create_csv_agent,
     create_json_agent,
     create_openapi_agent,
     create_pandas_dataframe_agent,
     create_pbi_agent,
     create_pbi_chat_agent,
     create_spark_dataframe_agent,
     create_spark_sql_agent,
     create_sql_agent,
     create_vectorstore_agent,
     create_vectorstore_router_agent,
     create_xorbits_agent,
 )
-from langchain.agents.agent_types import AgentType
-from langchain.agents.conversational.base import ConversationalAgent
-from langchain.agents.conversational_chat.base import ConversationalChatAgent
-from langchain.agents.initialize import initialize_agent
-from langchain.agents.load_tools import (
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.conversational.base import ConversationalAgent
+from oplangchain.agents.conversational_chat.base import ConversationalChatAgent
+from oplangchain.agents.initialize import initialize_agent
+from oplangchain.agents.load_tools import (
     get_all_tool_names,
     load_huggingface_tool,
     load_tools,
 )
-from langchain.agents.loading import load_agent
-from langchain.agents.mrkl.base import MRKLChain, ZeroShotAgent
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.agents.openai_functions_multi_agent.base import OpenAIMultiFunctionsAgent
-from langchain.agents.react.base import ReActChain, ReActTextWorldAgent
-from langchain.agents.self_ask_with_search.base import SelfAskWithSearchChain
-from langchain.agents.structured_chat.base import StructuredChatAgent
-from langchain.agents.tools import Tool, tool
-from langchain.agents.xml.base import XMLAgent
+from oplangchain.agents.loading import load_agent
+from oplangchain.agents.mrkl.base import MRKLChain, ZeroShotAgent
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.agents.openai_functions_multi_agent.base import OpenAIMultiFunctionsAgent
+from oplangchain.agents.react.base import ReActChain, ReActTextWorldAgent
+from oplangchain.agents.self_ask_with_search.base import SelfAskWithSearchChain
+from oplangchain.agents.structured_chat.base import StructuredChatAgent
+from oplangchain.agents.tools import Tool, tool
+from oplangchain.agents.xml.base import XMLAgent
 
 __all__ = [
     "Agent",
     "AgentExecutor",
     "AgentExecutorIterator",
     "AgentOutputParser",
     "AgentType",
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent.py` & `oplangchain-0.1.1/oplangchain/agents/agent.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,41 +8,41 @@
 from abc import abstractmethod
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union
 
 import yaml
 from pydantic import BaseModel, root_validator
 
-from langchain.agents.agent_iterator import AgentExecutorIterator
-from langchain.agents.agent_types import AgentType
-from langchain.agents.tools import InvalidTool
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import (
+from oplangchain.agents.agent_iterator import AgentExecutorIterator
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.tools import InvalidTool
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     AsyncCallbackManagerForToolRun,
     CallbackManagerForChainRun,
     CallbackManagerForToolRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.prompts.few_shot import FewShotPromptTemplate
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import (
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.few_shot import FewShotPromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import (
     AgentAction,
     AgentFinish,
     BaseOutputParser,
     BasePromptTemplate,
     OutputParserException,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage
-from langchain.tools.base import BaseTool
-from langchain.utilities.asyncio import asyncio_timeout
-from langchain.utils.input import get_color_mapping
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.asyncio import asyncio_timeout
+from oplangchain.utils.input import get_color_mapping
 
 logger = logging.getLogger(__name__)
 
 
 class BaseSingleActionAgent(BaseModel):
     """Base Single Action Agent class."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_iterator.py` & `oplangchain-0.1.1/oplangchain/agents/agent_iterator.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,29 +14,29 @@
     NoReturn,
     Optional,
     Tuple,
     Type,
     Union,
 )
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForChainRun,
     CallbackManager,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.load.dump import dumpd
-from langchain.schema import RUN_KEY, AgentAction, AgentFinish, RunInfo
-from langchain.tools import BaseTool
-from langchain.utilities.asyncio import asyncio_timeout
-from langchain.utils.input import get_color_mapping
+from oplangchain.load.dump import dumpd
+from oplangchain.schema import RUN_KEY, AgentAction, AgentFinish, RunInfo
+from oplangchain.tools import BaseTool
+from oplangchain.utilities.asyncio import asyncio_timeout
+from oplangchain.utils.input import get_color_mapping
 
 if TYPE_CHECKING:
-    from langchain.agents.agent import AgentExecutor
+    from oplangchain.agents.agent import AgentExecutor
 
 logger = logging.getLogger(__name__)
 
 
 class BaseAgentExecutorIterator(ABC):
     """Base class for AgentExecutorIterator."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/__init__.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,53 +1,53 @@
 """Agent toolkits."""
-from langchain.agents.agent_toolkits.amadeus.toolkit import AmadeusToolkit
-from langchain.agents.agent_toolkits.azure_cognitive_services import (
+from oplangchain.agents.agent_toolkits.amadeus.toolkit import AmadeusToolkit
+from oplangchain.agents.agent_toolkits.azure_cognitive_services import (
     AzureCognitiveServicesToolkit,
 )
-from langchain.agents.agent_toolkits.conversational_retrieval.openai_functions import (
+from oplangchain.agents.agent_toolkits.conversational_retrieval.openai_functions import (
     create_conversational_retrieval_agent,
 )
-from langchain.agents.agent_toolkits.conversational_retrieval.tool import (
+from oplangchain.agents.agent_toolkits.conversational_retrieval.tool import (
     create_retriever_tool,
 )
-from langchain.agents.agent_toolkits.csv.base import create_csv_agent
-from langchain.agents.agent_toolkits.file_management.toolkit import (
+from oplangchain.agents.agent_toolkits.csv.base import create_csv_agent
+from oplangchain.agents.agent_toolkits.file_management.toolkit import (
     FileManagementToolkit,
 )
-from langchain.agents.agent_toolkits.gmail.toolkit import GmailToolkit
-from langchain.agents.agent_toolkits.jira.toolkit import JiraToolkit
-from langchain.agents.agent_toolkits.json.base import create_json_agent
-from langchain.agents.agent_toolkits.json.toolkit import JsonToolkit
-from langchain.agents.agent_toolkits.multion.toolkit import MultionToolkit
-from langchain.agents.agent_toolkits.nla.toolkit import NLAToolkit
-from langchain.agents.agent_toolkits.office365.toolkit import O365Toolkit
-from langchain.agents.agent_toolkits.openapi.base import create_openapi_agent
-from langchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit
-from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
-from langchain.agents.agent_toolkits.playwright.toolkit import PlayWrightBrowserToolkit
-from langchain.agents.agent_toolkits.powerbi.base import create_pbi_agent
-from langchain.agents.agent_toolkits.powerbi.chat_base import create_pbi_chat_agent
-from langchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit
-from langchain.agents.agent_toolkits.python.base import create_python_agent
-from langchain.agents.agent_toolkits.spark.base import create_spark_dataframe_agent
-from langchain.agents.agent_toolkits.spark_sql.base import create_spark_sql_agent
-from langchain.agents.agent_toolkits.spark_sql.toolkit import SparkSQLToolkit
-from langchain.agents.agent_toolkits.sql.base import create_sql_agent
-from langchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
-from langchain.agents.agent_toolkits.vectorstore.base import (
+from oplangchain.agents.agent_toolkits.gmail.toolkit import GmailToolkit
+from oplangchain.agents.agent_toolkits.jira.toolkit import JiraToolkit
+from oplangchain.agents.agent_toolkits.json.base import create_json_agent
+from oplangchain.agents.agent_toolkits.json.toolkit import JsonToolkit
+from oplangchain.agents.agent_toolkits.multion.toolkit import MultionToolkit
+from oplangchain.agents.agent_toolkits.nla.toolkit import NLAToolkit
+from oplangchain.agents.agent_toolkits.office365.toolkit import O365Toolkit
+from oplangchain.agents.agent_toolkits.openapi.base import create_openapi_agent
+from oplangchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit
+from oplangchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
+from oplangchain.agents.agent_toolkits.playwright.toolkit import PlayWrightBrowserToolkit
+from oplangchain.agents.agent_toolkits.powerbi.base import create_pbi_agent
+from oplangchain.agents.agent_toolkits.powerbi.chat_base import create_pbi_chat_agent
+from oplangchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit
+from oplangchain.agents.agent_toolkits.python.base import create_python_agent
+from oplangchain.agents.agent_toolkits.spark.base import create_spark_dataframe_agent
+from oplangchain.agents.agent_toolkits.spark_sql.base import create_spark_sql_agent
+from oplangchain.agents.agent_toolkits.spark_sql.toolkit import SparkSQLToolkit
+from oplangchain.agents.agent_toolkits.sql.base import create_sql_agent
+from oplangchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
+from oplangchain.agents.agent_toolkits.vectorstore.base import (
     create_vectorstore_agent,
     create_vectorstore_router_agent,
 )
-from langchain.agents.agent_toolkits.vectorstore.toolkit import (
+from oplangchain.agents.agent_toolkits.vectorstore.toolkit import (
     VectorStoreInfo,
     VectorStoreRouterToolkit,
     VectorStoreToolkit,
 )
-from langchain.agents.agent_toolkits.xorbits.base import create_xorbits_agent
-from langchain.agents.agent_toolkits.zapier.toolkit import ZapierToolkit
+from oplangchain.agents.agent_toolkits.xorbits.base import create_xorbits_agent
+from oplangchain.agents.agent_toolkits.zapier.toolkit import ZapierToolkit
 
 __all__ = [
     "AmadeusToolkit",
     "AzureCognitiveServicesToolkit",
     "FileManagementToolkit",
     "GmailToolkit",
     "JiraToolkit",
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/amadeus/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/amadeus/toolkit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.amadeus.closest_airport import AmadeusClosestAirport
-from langchain.tools.amadeus.flight_search import AmadeusFlightSearch
-from langchain.tools.amadeus.utils import authenticate
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.amadeus.closest_airport import AmadeusClosestAirport
+from oplangchain.tools.amadeus.flight_search import AmadeusFlightSearch
+from oplangchain.tools.amadeus.utils import authenticate
 
 if TYPE_CHECKING:
     from amadeus import Client
 
 
 class AmadeusToolkit(BaseToolkit):
     """Toolkit for interacting with Office365."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/azure_cognitive_services.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/azure_cognitive_services.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import sys
 from typing import List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools.azure_cognitive_services import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools.azure_cognitive_services import (
     AzureCogsFormRecognizerTool,
     AzureCogsImageAnalysisTool,
     AzureCogsSpeech2TextTool,
     AzureCogsText2SpeechTool,
 )
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 
 class AzureCognitiveServicesToolkit(BaseToolkit):
     """Toolkit for Azure Cognitive Services."""
 
     def get_tools(self) -> List[BaseTool]:
         """Get the tools in the toolkit."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/conversational_retrieval/openai_functions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from typing import Any, List, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.openai_functions_agent.agent_token_buffer_memory import (
     AgentTokenBufferMemory,
 )
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.memory.token_buffer import ConversationTokenBufferMemory
-from langchain.prompts.chat import MessagesPlaceholder
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.memory import BaseMemory
-from langchain.schema.messages import SystemMessage
-from langchain.tools.base import BaseTool
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.memory.token_buffer import ConversationTokenBufferMemory
+from oplangchain.prompts.chat import MessagesPlaceholder
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.memory import BaseMemory
+from oplangchain.schema.messages import SystemMessage
+from oplangchain.tools.base import BaseTool
 
 
 def _get_default_system_message() -> SystemMessage:
     return SystemMessage(
         content=(
             "Do your best to answer the questions. "
             "Feel free to use any tools available to look up "
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/conversational_retrieval/tool.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/conversational_retrieval/tool.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,9 @@
-from langchain.schema import BaseRetriever
-from langchain.tools import Tool
+from oplangchain.schema import BaseRetriever
+from oplangchain.tools import Tool
 
 
 def create_retriever_tool(
     retriever: BaseRetriever, name: str, description: str
 ) -> Tool:
     """Create a tool to do retrieval of documents.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/csv/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/csv/base.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Any, List, Optional, Union
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def create_csv_agent(
     llm: BaseLanguageModel,
     path: Union[str, List[str]],
     pandas_kwargs: Optional[dict] = None,
     **kwargs: Any,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/file_management/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/file_management/toolkit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from __future__ import annotations
 
 from typing import List, Optional
 
 from pydantic import root_validator
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.file_management.copy import CopyFileTool
-from langchain.tools.file_management.delete import DeleteFileTool
-from langchain.tools.file_management.file_search import FileSearchTool
-from langchain.tools.file_management.list_dir import ListDirectoryTool
-from langchain.tools.file_management.move import MoveFileTool
-from langchain.tools.file_management.read import ReadFileTool
-from langchain.tools.file_management.write import WriteFileTool
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.file_management.copy import CopyFileTool
+from oplangchain.tools.file_management.delete import DeleteFileTool
+from oplangchain.tools.file_management.file_search import FileSearchTool
+from oplangchain.tools.file_management.list_dir import ListDirectoryTool
+from oplangchain.tools.file_management.move import MoveFileTool
+from oplangchain.tools.file_management.read import ReadFileTool
+from oplangchain.tools.file_management.write import WriteFileTool
 
 _FILE_TOOLS = {
     tool_cls.__fields__["name"].default: tool_cls
     for tool_cls in [
         CopyFileTool,
         DeleteFileTool,
         FileSearchTool,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/github/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/github/toolkit.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """GitHub Toolkit."""
 from typing import Dict, List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.github.prompt import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.github.prompt import (
     COMMENT_ON_ISSUE_PROMPT,
     CREATE_FILE_PROMPT,
     CREATE_PULL_REQUEST_PROMPT,
     DELETE_FILE_PROMPT,
     GET_ISSUE_PROMPT,
     GET_ISSUES_PROMPT,
     READ_FILE_PROMPT,
     UPDATE_FILE_PROMPT,
 )
-from langchain.tools.github.tool import GitHubAction
-from langchain.utilities.github import GitHubAPIWrapper
+from oplangchain.tools.github.tool import GitHubAction
+from oplangchain.utilities.github import GitHubAPIWrapper
 
 
 class GitHubToolkit(BaseToolkit):
     """GitHub Toolkit."""
 
     tools: List[BaseTool] = []
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/gmail/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/gmail/toolkit.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.gmail.create_draft import GmailCreateDraft
-from langchain.tools.gmail.get_message import GmailGetMessage
-from langchain.tools.gmail.get_thread import GmailGetThread
-from langchain.tools.gmail.search import GmailSearch
-from langchain.tools.gmail.send_message import GmailSendMessage
-from langchain.tools.gmail.utils import build_resource_service
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.gmail.create_draft import GmailCreateDraft
+from oplangchain.tools.gmail.get_message import GmailGetMessage
+from oplangchain.tools.gmail.get_thread import GmailGetThread
+from oplangchain.tools.gmail.search import GmailSearch
+from oplangchain.tools.gmail.send_message import GmailSendMessage
+from oplangchain.tools.gmail.utils import build_resource_service
 
 if TYPE_CHECKING:
     # This is for linting and IDE typehints
     from googleapiclient.discovery import Resource
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/jira/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/jira/toolkit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from typing import Dict, List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.jira.prompt import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.jira.prompt import (
     JIRA_CATCH_ALL_PROMPT,
     JIRA_CONFLUENCE_PAGE_CREATE_PROMPT,
     JIRA_GET_ALL_PROJECTS_PROMPT,
     JIRA_ISSUE_CREATE_PROMPT,
     JIRA_JQL_PROMPT,
 )
-from langchain.tools.jira.tool import JiraAction
-from langchain.utilities.jira import JiraAPIWrapper
+from oplangchain.tools.jira.tool import JiraAction
+from oplangchain.utilities.jira import JiraAPIWrapper
 
 
 class JiraToolkit(BaseToolkit):
     """Jira Toolkit."""
 
     tools: List[BaseTool] = []
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,33 +1,40 @@
-"""Json agent."""
+"""OpenAPI spec agent."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.json.prompt import JSON_PREFIX, JSON_SUFFIX
-from langchain.agents.agent_toolkits.json.toolkit import JsonToolkit
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.openapi.prompt import (
+    OPENAPI_PREFIX,
+    OPENAPI_SUFFIX,
+)
+from oplangchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
-def create_json_agent(
+def create_openapi_agent(
     llm: BaseLanguageModel,
-    toolkit: JsonToolkit,
+    toolkit: OpenAPIToolkit,
     callback_manager: Optional[BaseCallbackManager] = None,
-    prefix: str = JSON_PREFIX,
-    suffix: str = JSON_SUFFIX,
+    prefix: str = OPENAPI_PREFIX,
+    suffix: str = OPENAPI_SUFFIX,
     format_instructions: str = FORMAT_INSTRUCTIONS,
     input_variables: Optional[List[str]] = None,
+    max_iterations: Optional[int] = 15,
+    max_execution_time: Optional[float] = None,
+    early_stopping_method: str = "force",
     verbose: bool = False,
+    return_intermediate_steps: bool = False,
     agent_executor_kwargs: Optional[Dict[str, Any]] = None,
     **kwargs: Dict[str, Any],
 ) -> AgentExecutor:
-    """Construct a json agent from an LLM and tools."""
+    """Construct an OpenAPI agent from an LLM and tools."""
     tools = toolkit.get_tools()
     prompt = ZeroShotAgent.create_prompt(
         tools,
         prefix=prefix,
         suffix=suffix,
         format_instructions=format_instructions,
         input_variables=input_variables,
@@ -40,9 +47,13 @@
     tool_names = [tool.name for tool in tools]
     agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names, **kwargs)
     return AgentExecutor.from_agent_and_tools(
         agent=agent,
         tools=tools,
         callback_manager=callback_manager,
         verbose=verbose,
+        return_intermediate_steps=return_intermediate_steps,
+        max_iterations=max_iterations,
+        max_execution_time=max_execution_time,
+        early_stopping_method=early_stopping_method,
         **(agent_executor_kwargs or {}),
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/json/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/json/toolkit.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool, JsonSpec
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool, JsonSpec
 
 
 class JsonToolkit(BaseToolkit):
     """Toolkit for interacting with a JSON spec."""
 
     spec: JsonSpec
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/multion/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/multion/toolkit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """MultiOn agent."""
 from __future__ import annotations
 
 from typing import List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.multion.create_session import MultionCreateSession
-from langchain.tools.multion.update_session import MultionUpdateSession
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.multion.create_session import MultionCreateSession
+from oplangchain.tools.multion.update_session import MultionUpdateSession
 
 
 class MultionToolkit(BaseToolkit):
     """Toolkit for interacting with the Browser Agent"""
 
     class Config:
         """Pydantic config."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/nla/tool.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/nla/tool.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Tool for interacting with a single API with natural language definition."""
 
 
 from typing import Any, Optional
 
-from langchain.agents.tools import Tool
-from langchain.chains.api.openapi.chain import OpenAPIEndpointChain
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.openapi.utils.api_models import APIOperation
-from langchain.tools.openapi.utils.openapi_utils import OpenAPISpec
-from langchain.utilities.requests import Requests
+from oplangchain.agents.tools import Tool
+from oplangchain.chains.api.openapi.chain import OpenAPIEndpointChain
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.openapi.utils.api_models import APIOperation
+from oplangchain.tools.openapi.utils.openapi_utils import OpenAPISpec
+from oplangchain.utilities.requests import Requests
 
 
 class NLATool(Tool):
     """Natural Language API Tool."""
 
     @classmethod
     def from_open_api_endpoint_chain(
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/nla/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/nla/toolkit.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 from typing import Any, List, Optional, Sequence
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.agents.agent_toolkits.nla.tool import NLATool
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
-from langchain.tools.openapi.utils.openapi_utils import OpenAPISpec
-from langchain.tools.plugin import AIPlugin
-from langchain.utilities.requests import Requests
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.agents.agent_toolkits.nla.tool import NLATool
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.openapi.utils.openapi_utils import OpenAPISpec
+from oplangchain.tools.plugin import AIPlugin
+from oplangchain.utilities.requests import Requests
 
 
 class NLAToolkit(BaseToolkit):
     """Natural Language API Toolkit."""
 
     nla_tools: Sequence[NLATool] = Field(...)
     """List of API Endpoint Tools."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/office365/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/office365/toolkit.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.office365.create_draft_message import O365CreateDraftMessage
-from langchain.tools.office365.events_search import O365SearchEvents
-from langchain.tools.office365.messages_search import O365SearchEmails
-from langchain.tools.office365.send_event import O365SendEvent
-from langchain.tools.office365.send_message import O365SendMessage
-from langchain.tools.office365.utils import authenticate
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.office365.create_draft_message import O365CreateDraftMessage
+from oplangchain.tools.office365.events_search import O365SearchEvents
+from oplangchain.tools.office365.messages_search import O365SearchEmails
+from oplangchain.tools.office365.send_event import O365SendEvent
+from oplangchain.tools.office365.send_message import O365SendMessage
+from oplangchain.tools.office365.utils import authenticate
 
 if TYPE_CHECKING:
     from O365 import Account
 
 
 class O365Toolkit(BaseToolkit):
     """Toolkit for interacting with Office 365."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,41 +1,39 @@
-"""OpenAPI spec agent."""
+"""Spark SQL agent."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.openapi.prompt import (
-    OPENAPI_PREFIX,
-    OPENAPI_SUFFIX,
-)
-from langchain.agents.agent_toolkits.openapi.toolkit import OpenAPIToolkit
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.spark_sql.prompt import SQL_PREFIX, SQL_SUFFIX
+from oplangchain.agents.agent_toolkits.spark_sql.toolkit import SparkSQLToolkit
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
-def create_openapi_agent(
+def create_spark_sql_agent(
     llm: BaseLanguageModel,
-    toolkit: OpenAPIToolkit,
+    toolkit: SparkSQLToolkit,
     callback_manager: Optional[BaseCallbackManager] = None,
-    prefix: str = OPENAPI_PREFIX,
-    suffix: str = OPENAPI_SUFFIX,
+    prefix: str = SQL_PREFIX,
+    suffix: str = SQL_SUFFIX,
     format_instructions: str = FORMAT_INSTRUCTIONS,
     input_variables: Optional[List[str]] = None,
+    top_k: int = 10,
     max_iterations: Optional[int] = 15,
     max_execution_time: Optional[float] = None,
     early_stopping_method: str = "force",
     verbose: bool = False,
-    return_intermediate_steps: bool = False,
     agent_executor_kwargs: Optional[Dict[str, Any]] = None,
     **kwargs: Dict[str, Any],
 ) -> AgentExecutor:
-    """Construct an OpenAPI agent from an LLM and tools."""
+    """Construct a Spark SQL agent from an LLM and tools."""
     tools = toolkit.get_tools()
+    prefix = prefix.format(top_k=top_k)
     prompt = ZeroShotAgent.create_prompt(
         tools,
         prefix=prefix,
         suffix=suffix,
         format_instructions=format_instructions,
         input_variables=input_variables,
     )
@@ -47,13 +45,12 @@
     tool_names = [tool.name for tool in tools]
     agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names, **kwargs)
     return AgentExecutor.from_agent_and_tools(
         agent=agent,
         tools=tools,
         callback_manager=callback_manager,
         verbose=verbose,
-        return_intermediate_steps=return_intermediate_steps,
         max_iterations=max_iterations,
         max_execution_time=max_execution_time,
         early_stopping_method=early_stopping_method,
         **(agent_executor_kwargs or {}),
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/planner.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/planner.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 import re
 from functools import partial
 from typing import Any, Callable, Dict, List, Optional
 
 import yaml
 from pydantic import Field
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.openapi.planner_prompt import (
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.openapi.planner_prompt import (
     API_CONTROLLER_PROMPT,
     API_CONTROLLER_TOOL_DESCRIPTION,
     API_CONTROLLER_TOOL_NAME,
     API_ORCHESTRATOR_PROMPT,
     API_PLANNER_PROMPT,
     API_PLANNER_TOOL_DESCRIPTION,
     API_PLANNER_TOOL_NAME,
@@ -21,27 +21,27 @@
     PARSING_PATCH_PROMPT,
     PARSING_POST_PROMPT,
     REQUESTS_DELETE_TOOL_DESCRIPTION,
     REQUESTS_GET_TOOL_DESCRIPTION,
     REQUESTS_PATCH_TOOL_DESCRIPTION,
     REQUESTS_POST_TOOL_DESCRIPTION,
 )
-from langchain.agents.agent_toolkits.openapi.spec import ReducedOpenAPISpec
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.tools import Tool
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.llms.openai import OpenAI
-from langchain.memory import ReadOnlySharedMemory
-from langchain.prompts import PromptTemplate
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
-from langchain.tools.requests.tool import BaseRequestsTool
-from langchain.utilities.requests import RequestsWrapper
+from oplangchain.agents.agent_toolkits.openapi.spec import ReducedOpenAPISpec
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.tools import Tool
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.openai import OpenAI
+from oplangchain.memory import ReadOnlySharedMemory
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.requests.tool import BaseRequestsTool
+from oplangchain.utilities.requests import RequestsWrapper
 
 #
 # Requests tools with LLM-instructed extraction of truncated responses.
 #
 # Of course, truncating so bluntly may lose a lot of valuable
 # information in the response.
 # However, the goal for now is to have only a single inference step.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/planner_prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/planner_prompt.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # flake8: noqa
 
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 
 API_PLANNER_PROMPT = """You are a planner that plans a sequence of API calls to assist with user queries against an API.
 
 You should:
 1) evaluate whether the user query can be solved by the API documentated below. If no, say why.
 2) if yes, generate a plan of API calls and say what they are doing step by step.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/spec.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/spec.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/openapi/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/openapi/toolkit.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 """Requests toolkit."""
 from __future__ import annotations
 
 from typing import Any, List
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.agents.agent_toolkits.json.base import create_json_agent
-from langchain.agents.agent_toolkits.json.toolkit import JsonToolkit
-from langchain.agents.agent_toolkits.openapi.prompt import DESCRIPTION
-from langchain.agents.tools import Tool
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
-from langchain.tools.json.tool import JsonSpec
-from langchain.tools.requests.tool import (
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.agents.agent_toolkits.json.base import create_json_agent
+from oplangchain.agents.agent_toolkits.json.toolkit import JsonToolkit
+from oplangchain.agents.agent_toolkits.openapi.prompt import DESCRIPTION
+from oplangchain.agents.tools import Tool
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
+from oplangchain.tools.json.tool import JsonSpec
+from oplangchain.tools.requests.tool import (
     RequestsDeleteTool,
     RequestsGetTool,
     RequestsPatchTool,
     RequestsPostTool,
     RequestsPutTool,
 )
-from langchain.utilities.requests import TextRequestsWrapper
+from oplangchain.utilities.requests import TextRequestsWrapper
 
 
 class RequestsToolkit(BaseToolkit):
     """Toolkit for making REST requests."""
 
     requests_wrapper: TextRequestsWrapper
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/pandas/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/pandas/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,31 @@
 """Agent for working with pandas objects."""
 from typing import Any, Dict, List, Optional, Tuple
 
-from langchain.agents.agent import AgentExecutor, BaseSingleActionAgent
-from langchain.agents.agent_toolkits.pandas.prompt import (
+from oplangchain.agents.agent import AgentExecutor, BaseSingleActionAgent
+from oplangchain.agents.agent_toolkits.pandas.prompt import (
     FUNCTIONS_WITH_DF,
     FUNCTIONS_WITH_MULTI_DF,
     MULTI_DF_PREFIX,
     MULTI_DF_PREFIX_FUNCTIONS,
     PREFIX,
     PREFIX_FUNCTIONS,
     SUFFIX_NO_DF,
     SUFFIX_WITH_DF,
     SUFFIX_WITH_MULTI_DF,
 )
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.agents.types import AgentType
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import SystemMessage
-from langchain.tools.python.tool import PythonAstREPLTool
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.agents.types import AgentType
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import SystemMessage
+from oplangchain.tools.python.tool import PythonAstREPLTool
 
 
 def _get_multi_prompt(
     dfs: List[Any],
     prefix: Optional[str] = None,
     suffix: Optional[str] = None,
     input_variables: Optional[List[str]] = None,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/pandas/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/pandas/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/playwright/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/playwright/toolkit.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Playwright web browser toolkit."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List, Optional, Type, cast
 
 from pydantic import Extra, root_validator
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools.base import BaseTool
-from langchain.tools.playwright.base import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.playwright.base import (
     BaseBrowserTool,
     lazy_import_playwright_browsers,
 )
-from langchain.tools.playwright.click import ClickTool
-from langchain.tools.playwright.current_page import CurrentWebPageTool
-from langchain.tools.playwright.extract_hyperlinks import ExtractHyperlinksTool
-from langchain.tools.playwright.extract_text import ExtractTextTool
-from langchain.tools.playwright.get_elements import GetElementsTool
-from langchain.tools.playwright.navigate import NavigateTool
-from langchain.tools.playwright.navigate_back import NavigateBackTool
+from oplangchain.tools.playwright.click import ClickTool
+from oplangchain.tools.playwright.current_page import CurrentWebPageTool
+from oplangchain.tools.playwright.extract_hyperlinks import ExtractHyperlinksTool
+from oplangchain.tools.playwright.extract_text import ExtractTextTool
+from oplangchain.tools.playwright.get_elements import GetElementsTool
+from oplangchain.tools.playwright.navigate import NavigateTool
+from oplangchain.tools.playwright.navigate_back import NavigateBackTool
 
 if TYPE_CHECKING:
     from playwright.async_api import Browser as AsyncBrowser
     from playwright.sync_api import Browser as SyncBrowser
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/chat_base.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,62 +1,64 @@
 """Power BI agent."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents import AgentExecutor
-from langchain.agents.agent_toolkits.powerbi.prompt import (
-    POWERBI_PREFIX,
-    POWERBI_SUFFIX,
+from oplangchain.agents import AgentExecutor
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.agents.agent_toolkits.powerbi.prompt import (
+    POWERBI_CHAT_PREFIX,
+    POWERBI_CHAT_SUFFIX,
 )
-from langchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.utilities.powerbi import PowerBIDataset
+from oplangchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit
+from oplangchain.agents.conversational_chat.base import ConversationalChatAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.memory import ConversationBufferMemory
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.utilities.powerbi import PowerBIDataset
 
 
-def create_pbi_agent(
-    llm: BaseLanguageModel,
+def create_pbi_chat_agent(
+    llm: BaseChatModel,
     toolkit: Optional[PowerBIToolkit] = None,
     powerbi: Optional[PowerBIDataset] = None,
     callback_manager: Optional[BaseCallbackManager] = None,
-    prefix: str = POWERBI_PREFIX,
-    suffix: str = POWERBI_SUFFIX,
-    format_instructions: str = FORMAT_INSTRUCTIONS,
+    output_parser: Optional[AgentOutputParser] = None,
+    prefix: str = POWERBI_CHAT_PREFIX,
+    suffix: str = POWERBI_CHAT_SUFFIX,
     examples: Optional[str] = None,
     input_variables: Optional[List[str]] = None,
+    memory: Optional[BaseChatMemory] = None,
     top_k: int = 10,
     verbose: bool = False,
     agent_executor_kwargs: Optional[Dict[str, Any]] = None,
     **kwargs: Dict[str, Any],
 ) -> AgentExecutor:
-    """Construct a Power BI agent from an LLM and tools."""
+    """Construct a Power BI agent from a Chat LLM and tools.
+
+    If you supply only a toolkit and no Power BI dataset, the same LLM is used for both.
+    """
     if toolkit is None:
         if powerbi is None:
             raise ValueError("Must provide either a toolkit or powerbi dataset")
         toolkit = PowerBIToolkit(powerbi=powerbi, llm=llm, examples=examples)
     tools = toolkit.get_tools()
     tables = powerbi.table_names if powerbi else toolkit.powerbi.table_names
-    agent = ZeroShotAgent(
-        llm_chain=LLMChain(
-            llm=llm,
-            prompt=ZeroShotAgent.create_prompt(
-                tools,
-                prefix=prefix.format(top_k=top_k).format(tables=tables),
-                suffix=suffix,
-                format_instructions=format_instructions,
-                input_variables=input_variables,
-            ),
-            callback_manager=callback_manager,  # type: ignore
-            verbose=verbose,
-        ),
-        allowed_tools=[tool.name for tool in tools],
+    agent = ConversationalChatAgent.from_llm_and_tools(
+        llm=llm,
+        tools=tools,
+        system_message=prefix.format(top_k=top_k).format(tables=tables),
+        human_message=suffix,
+        input_variables=input_variables,
+        callback_manager=callback_manager,
+        output_parser=output_parser,
+        verbose=verbose,
         **kwargs,
     )
     return AgentExecutor.from_agent_and_tools(
         agent=agent,
         tools=tools,
         callback_manager=callback_manager,
+        memory=memory
+        or ConversationBufferMemory(memory_key="chat_history", return_messages=True),
         verbose=verbose,
         **(agent_executor_kwargs or {}),
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/chat_base.py` & `oplangchain-0.1.1/oplangchain/tools/google_serper/tool.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,64 +1,70 @@
-"""Power BI agent."""
-from typing import Any, Dict, List, Optional
+"""Tool for the Serper.dev Google Search API."""
 
-from langchain.agents import AgentExecutor
-from langchain.agents.agent import AgentOutputParser
-from langchain.agents.agent_toolkits.powerbi.prompt import (
-    POWERBI_CHAT_PREFIX,
-    POWERBI_CHAT_SUFFIX,
+from typing import Optional
+
+from pydantic.fields import Field
+
+from oplangchain.callbacks.manager import (
+    AsyncCallbackManagerForToolRun,
+    CallbackManagerForToolRun,
 )
-from langchain.agents.agent_toolkits.powerbi.toolkit import PowerBIToolkit
-from langchain.agents.conversational_chat.base import ConversationalChatAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chat_models.base import BaseChatModel
-from langchain.memory import ConversationBufferMemory
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.utilities.powerbi import PowerBIDataset
-
-
-def create_pbi_chat_agent(
-    llm: BaseChatModel,
-    toolkit: Optional[PowerBIToolkit] = None,
-    powerbi: Optional[PowerBIDataset] = None,
-    callback_manager: Optional[BaseCallbackManager] = None,
-    output_parser: Optional[AgentOutputParser] = None,
-    prefix: str = POWERBI_CHAT_PREFIX,
-    suffix: str = POWERBI_CHAT_SUFFIX,
-    examples: Optional[str] = None,
-    input_variables: Optional[List[str]] = None,
-    memory: Optional[BaseChatMemory] = None,
-    top_k: int = 10,
-    verbose: bool = False,
-    agent_executor_kwargs: Optional[Dict[str, Any]] = None,
-    **kwargs: Dict[str, Any],
-) -> AgentExecutor:
-    """Construct a Power BI agent from a Chat LLM and tools.
-
-    If you supply only a toolkit and no Power BI dataset, the same LLM is used for both.
-    """
-    if toolkit is None:
-        if powerbi is None:
-            raise ValueError("Must provide either a toolkit or powerbi dataset")
-        toolkit = PowerBIToolkit(powerbi=powerbi, llm=llm, examples=examples)
-    tools = toolkit.get_tools()
-    tables = powerbi.table_names if powerbi else toolkit.powerbi.table_names
-    agent = ConversationalChatAgent.from_llm_and_tools(
-        llm=llm,
-        tools=tools,
-        system_message=prefix.format(top_k=top_k).format(tables=tables),
-        human_message=suffix,
-        input_variables=input_variables,
-        callback_manager=callback_manager,
-        output_parser=output_parser,
-        verbose=verbose,
-        **kwargs,
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.google_serper import GoogleSerperAPIWrapper
+
+
+class GoogleSerperRun(BaseTool):
+    """Tool that queries the Serper.dev Google search API."""
+
+    name = "google_serper"
+    description = (
+        "A low-cost Google Search API."
+        "Useful for when you need to answer questions about current events."
+        "Input should be a search query."
     )
-    return AgentExecutor.from_agent_and_tools(
-        agent=agent,
-        tools=tools,
-        callback_manager=callback_manager,
-        memory=memory
-        or ConversationBufferMemory(memory_key="chat_history", return_messages=True),
-        verbose=verbose,
-        **(agent_executor_kwargs or {}),
+    api_wrapper: GoogleSerperAPIWrapper
+
+    def _run(
+        self,
+        query: str,
+        run_manager: Optional[CallbackManagerForToolRun] = None,
+    ) -> str:
+        """Use the tool."""
+        return str(self.api_wrapper.run(query))
+
+    async def _arun(
+        self,
+        query: str,
+        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
+    ) -> str:
+        """Use the tool asynchronously."""
+        return (await self.api_wrapper.arun(query)).__str__()
+
+
+class GoogleSerperResults(BaseTool):
+    """Tool that queries the Serper.dev Google Search API
+    and get back json."""
+
+    name = "google_serrper_results_json"
+    description = (
+        "A low-cost Google Search API."
+        "Useful for when you need to answer questions about current events."
+        "Input should be a search query. Output is a JSON object of the query results"
     )
+    api_wrapper: GoogleSerperAPIWrapper = Field(default_factory=GoogleSerperAPIWrapper)
+
+    def _run(
+        self,
+        query: str,
+        run_manager: Optional[CallbackManagerForToolRun] = None,
+    ) -> str:
+        """Use the tool."""
+        return str(self.api_wrapper.results(query))
+
+    async def _arun(
+        self,
+        query: str,
+        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
+    ) -> str:
+        """Use the tool asynchronously."""
+
+        return (await self.api_wrapper.aresults(query)).__str__()
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/powerbi/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/powerbi/toolkit.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,35 +1,35 @@
 """Toolkit for interacting with a Power BI dataset."""
 from typing import List, Optional, Union
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.chat_models.base import BaseChatModel
-from langchain.prompts import PromptTemplate
-from langchain.prompts.chat import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.prompts import PromptTemplate
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
-from langchain.tools.powerbi.prompt import (
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
+from oplangchain.tools.powerbi.prompt import (
     QUESTION_TO_QUERY_BASE,
     SINGLE_QUESTION_TO_QUERY,
     USER_INPUT,
 )
-from langchain.tools.powerbi.tool import (
+from oplangchain.tools.powerbi.tool import (
     InfoPowerBITool,
     ListPowerBITool,
     QueryPowerBITool,
 )
-from langchain.utilities.powerbi import PowerBIDataset
+from oplangchain.utilities.powerbi import PowerBIDataset
 
 
 class PowerBIToolkit(BaseToolkit):
     """Toolkit for interacting with Power BI dataset."""
 
     powerbi: PowerBIDataset = Field(exclude=True)
     llm: Union[BaseLanguageModel, BaseChatModel] = Field(exclude=True)
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/python/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/python/base.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Python agent."""
 
 from typing import Any, Dict, Optional
 
-from langchain.agents.agent import AgentExecutor, BaseSingleActionAgent
-from langchain.agents.agent_toolkits.python.prompt import PREFIX
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.agents.types import AgentType
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import SystemMessage
-from langchain.tools.python.tool import PythonREPLTool
+from oplangchain.agents.agent import AgentExecutor, BaseSingleActionAgent
+from oplangchain.agents.agent_toolkits.python.prompt import PREFIX
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.agents.types import AgentType
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import SystemMessage
+from oplangchain.tools.python.tool import PythonREPLTool
 
 
 def create_python_agent(
     llm: BaseLanguageModel,
     tool: PythonREPLTool,
     agent_type: AgentType = AgentType.ZERO_SHOT_REACT_DESCRIPTION,
     callback_manager: Optional[BaseCallbackManager] = None,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/python/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/python/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark/base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Agent for working with pandas objects."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.spark.prompt import PREFIX, SUFFIX
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.llms.base import BaseLLM
-from langchain.tools.python.tool import PythonAstREPLTool
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.spark.prompt import PREFIX, SUFFIX
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.base import BaseLLM
+from oplangchain.tools.python.tool import PythonAstREPLTool
 
 
 def _validate_spark_df(df: Any) -> bool:
     try:
         from pyspark.sql import DataFrame as SparkLocalDataFrame
 
         return isinstance(df, SparkLocalDataFrame)
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/xorbits/base.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,56 +1,90 @@
-"""Spark SQL agent."""
+"""Agent for working with xorbits objects."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.spark_sql.prompt import SQL_PREFIX, SQL_SUFFIX
-from langchain.agents.agent_toolkits.spark_sql.toolkit import SparkSQLToolkit
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.xorbits.prompt import (
+    NP_PREFIX,
+    NP_SUFFIX,
+    PD_PREFIX,
+    PD_SUFFIX,
+)
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.base import BaseLLM
+from oplangchain.tools.python.tool import PythonAstREPLTool
 
 
-def create_spark_sql_agent(
-    llm: BaseLanguageModel,
-    toolkit: SparkSQLToolkit,
+def create_xorbits_agent(
+    llm: BaseLLM,
+    data: Any,
     callback_manager: Optional[BaseCallbackManager] = None,
-    prefix: str = SQL_PREFIX,
-    suffix: str = SQL_SUFFIX,
-    format_instructions: str = FORMAT_INSTRUCTIONS,
+    prefix: str = "",
+    suffix: str = "",
     input_variables: Optional[List[str]] = None,
-    top_k: int = 10,
+    verbose: bool = False,
+    return_intermediate_steps: bool = False,
     max_iterations: Optional[int] = 15,
     max_execution_time: Optional[float] = None,
     early_stopping_method: str = "force",
-    verbose: bool = False,
     agent_executor_kwargs: Optional[Dict[str, Any]] = None,
     **kwargs: Dict[str, Any],
 ) -> AgentExecutor:
-    """Construct a Spark SQL agent from an LLM and tools."""
-    tools = toolkit.get_tools()
-    prefix = prefix.format(top_k=top_k)
-    prompt = ZeroShotAgent.create_prompt(
-        tools,
-        prefix=prefix,
-        suffix=suffix,
-        format_instructions=format_instructions,
-        input_variables=input_variables,
-    )
+    """Construct a xorbits agent from an LLM and dataframe."""
+    try:
+        from xorbits import numpy as np
+        from xorbits import pandas as pd
+    except ImportError:
+        raise ImportError(
+            "Xorbits package not installed, please install with `pip install xorbits`"
+        )
+
+    if not isinstance(data, (pd.DataFrame, np.ndarray)):
+        raise ValueError(
+            f"Expected Xorbits DataFrame or ndarray object, got {type(data)}"
+        )
+    if input_variables is None:
+        input_variables = ["data", "input", "agent_scratchpad"]
+    tools = [PythonAstREPLTool(locals={"data": data})]
+    prompt, partial_input = None, None
+
+    if isinstance(data, pd.DataFrame):
+        prompt = ZeroShotAgent.create_prompt(
+            tools,
+            prefix=PD_PREFIX if prefix == "" else prefix,
+            suffix=PD_SUFFIX if suffix == "" else suffix,
+            input_variables=input_variables,
+        )
+        partial_input = str(data.head())
+    else:
+        prompt = ZeroShotAgent.create_prompt(
+            tools,
+            prefix=NP_PREFIX if prefix == "" else prefix,
+            suffix=NP_SUFFIX if suffix == "" else suffix,
+            input_variables=input_variables,
+        )
+        partial_input = str(data[: len(data) // 2])
+    partial_prompt = prompt.partial(data=partial_input)
     llm_chain = LLMChain(
         llm=llm,
-        prompt=prompt,
+        prompt=partial_prompt,
         callback_manager=callback_manager,
     )
     tool_names = [tool.name for tool in tools]
-    agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names, **kwargs)
+    agent = ZeroShotAgent(
+        llm_chain=llm_chain,
+        allowed_tools=tool_names,
+        callback_manager=callback_manager,
+        **kwargs,
+    )
     return AgentExecutor.from_agent_and_tools(
         agent=agent,
         tools=tools,
         callback_manager=callback_manager,
         verbose=verbose,
+        return_intermediate_steps=return_intermediate_steps,
         max_iterations=max_iterations,
         max_execution_time=max_execution_time,
         early_stopping_method=early_stopping_method,
         **(agent_executor_kwargs or {}),
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/spark_sql/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/spark_sql/toolkit.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 """Toolkit for interacting with Spark SQL."""
 from typing import List
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
-from langchain.tools.spark_sql.tool import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
+from oplangchain.tools.spark_sql.tool import (
     InfoSparkSQLTool,
     ListSparkSQLTool,
     QueryCheckerTool,
     QuerySparkSQLTool,
 )
-from langchain.utilities.spark_sql import SparkSQL
+from oplangchain.utilities.spark_sql import SparkSQL
 
 
 class SparkSQLToolkit(BaseToolkit):
     """Toolkit for interacting with Spark SQL."""
 
     db: SparkSQL = Field(exclude=True)
     llm: BaseLanguageModel = Field(exclude=True)
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 """SQL agent."""
 from typing import Any, Dict, List, Optional
 
-from langchain.agents.agent import AgentExecutor, BaseSingleActionAgent
-from langchain.agents.agent_toolkits.sql.prompt import (
+from oplangchain.agents.agent import AgentExecutor, BaseSingleActionAgent
+from oplangchain.agents.agent_toolkits.sql.prompt import (
     SQL_FUNCTIONS_SUFFIX,
     SQL_PREFIX,
     SQL_SUFFIX,
 )
-from langchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
-from langchain.agents.agent_types import AgentType
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.prompts.chat import (
+from oplangchain.agents.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     MessagesPlaceholder,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import AIMessage, SystemMessage
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import AIMessage, SystemMessage
 
 
 def create_sql_agent(
     llm: BaseLanguageModel,
     toolkit: SQLDatabaseToolkit,
     agent_type: AgentType = AgentType.ZERO_SHOT_REACT_DESCRIPTION,
     callback_manager: Optional[BaseCallbackManager] = None,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/sql/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/sql/toolkit.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 """Toolkit for interacting with an SQL database."""
 from typing import List
 
 from pydantic import Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
-from langchain.tools.sql_database.tool import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
+from oplangchain.tools.sql_database.tool import (
     InfoSQLDatabaseTool,
     ListSQLDatabaseTool,
     QuerySQLCheckerTool,
     QuerySQLDataBaseTool,
 )
-from langchain.utilities.sql_database import SQLDatabase
+from oplangchain.utilities.sql_database import SQLDatabase
 
 
 class SQLDatabaseToolkit(BaseToolkit):
     """Toolkit for interacting with SQL databases."""
 
     db: SQLDatabase = Field(exclude=True)
     llm: BaseLanguageModel = Field(exclude=True)
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/base.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/base.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 """VectorStore agent."""
 from typing import Any, Dict, Optional
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_toolkits.vectorstore.prompt import PREFIX, ROUTER_PREFIX
-from langchain.agents.agent_toolkits.vectorstore.toolkit import (
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_toolkits.vectorstore.prompt import PREFIX, ROUTER_PREFIX
+from oplangchain.agents.agent_toolkits.vectorstore.toolkit import (
     VectorStoreRouterToolkit,
     VectorStoreToolkit,
 )
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def create_vectorstore_agent(
     llm: BaseLanguageModel,
     toolkit: VectorStoreToolkit,
     callback_manager: Optional[BaseCallbackManager] = None,
     prefix: str = PREFIX,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/vectorstore/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/vectorstore/toolkit.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Toolkit for interacting with a vector store."""
 from typing import List
 
 from pydantic import BaseModel, Field
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.llms.openai import OpenAI
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
-from langchain.tools.vectorstore.tool import (
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.llms.openai import OpenAI
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
+from oplangchain.tools.vectorstore.tool import (
     VectorStoreQATool,
     VectorStoreQAWithSourcesTool,
 )
-from langchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.base import VectorStore
 
 
 class VectorStoreInfo(BaseModel):
     """Information about a VectorStore."""
 
     vectorstore: VectorStore = Field(exclude=True)
     name: str
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/xorbits/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/xorbits/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_toolkits/zapier/toolkit.py` & `oplangchain-0.1.1/oplangchain/agents/agent_toolkits/zapier/toolkit.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Zapier Toolkit."""
 from typing import List
 
-from langchain.agents.agent_toolkits.base import BaseToolkit
-from langchain.tools import BaseTool
-from langchain.tools.zapier.tool import ZapierNLARunAction
-from langchain.utilities.zapier import ZapierNLAWrapper
+from oplangchain.agents.agent_toolkits.base import BaseToolkit
+from oplangchain.tools import BaseTool
+from oplangchain.tools.zapier.tool import ZapierNLARunAction
+from oplangchain.utilities.zapier import ZapierNLAWrapper
 
 
 class ZapierToolkit(BaseToolkit):
     """Zapier Toolkit."""
 
     tools: List[BaseTool] = []
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/agent_types.py` & `oplangchain-0.1.1/oplangchain/agents/agent_types.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/chat/base.py` & `oplangchain-0.1.1/oplangchain/agents/chat/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 from typing import Any, List, Optional, Sequence, Tuple
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentOutputParser
-from langchain.agents.chat.output_parser import ChatOutputParser
-from langchain.agents.chat.prompt import (
+from oplangchain.agents.agent import Agent, AgentOutputParser
+from oplangchain.agents.chat.output_parser import ChatOutputParser
+from oplangchain.agents.chat.prompt import (
     FORMAT_INSTRUCTIONS,
     HUMAN_MESSAGE,
     SYSTEM_MESSAGE_PREFIX,
     SYSTEM_MESSAGE_SUFFIX,
 )
-from langchain.agents.utils import validate_tools_single_input
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.prompts.chat import (
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.schema import AgentAction, BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.schema import AgentAction, BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 class ChatAgent(Agent):
     """Chat Agent."""
 
     output_parser: AgentOutputParser = Field(default_factory=ChatOutputParser)
     """Output parser for the agent."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/chat/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/chat/output_parser.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import json
 import re
 from typing import Union
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.agents.chat.prompt import FORMAT_INSTRUCTIONS
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.agents.chat.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 FINAL_ANSWER_ACTION = "Final Answer:"
 
 
 class ChatOutputParser(AgentOutputParser):
     """Output parser for the chat agent."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/chat/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/chat/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational/base.py` & `oplangchain-0.1.1/oplangchain/agents/conversational/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """An agent designed to hold a conversation in addition to using tools."""
 from __future__ import annotations
 
 from typing import Any, List, Optional, Sequence
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentOutputParser
-from langchain.agents.agent_types import AgentType
-from langchain.agents.conversational.output_parser import ConvoOutputParser
-from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
-from langchain.agents.utils import validate_tools_single_input
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains import LLMChain
-from langchain.prompts import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.agents.agent import Agent, AgentOutputParser
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.conversational.output_parser import ConvoOutputParser
+from oplangchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains import LLMChain
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 class ConversationalAgent(Agent):
     """An agent that holds a conversation in addition to using tools."""
 
     ai_prefix: str = "AI"
     """Prefix to use before AI output."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/conversational/output_parser.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import re
 from typing import Union
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.agents.conversational.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 
 class ConvoOutputParser(AgentOutputParser):
     """Output parser for the conversational agent."""
 
     ai_prefix: str = "AI"
     """Prefix to use before AI output."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/conversational/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational_chat/base.py` & `oplangchain-0.1.1/oplangchain/agents/conversational_chat/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,34 +1,34 @@
 """An agent designed to hold a conversation in addition to using tools."""
 from __future__ import annotations
 
 from typing import Any, List, Optional, Sequence, Tuple
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentOutputParser
-from langchain.agents.conversational_chat.output_parser import ConvoOutputParser
-from langchain.agents.conversational_chat.prompt import (
+from oplangchain.agents.agent import Agent, AgentOutputParser
+from oplangchain.agents.conversational_chat.output_parser import ConvoOutputParser
+from oplangchain.agents.conversational_chat.prompt import (
     PREFIX,
     SUFFIX,
     TEMPLATE_TOOL_RESPONSE,
 )
-from langchain.agents.utils import validate_tools_single_input
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains import LLMChain
-from langchain.prompts.chat import (
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains import LLMChain
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     MessagesPlaceholder,
     SystemMessagePromptTemplate,
 )
-from langchain.schema import AgentAction, BaseOutputParser, BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import AIMessage, BaseMessage, HumanMessage
-from langchain.tools.base import BaseTool
+from oplangchain.schema import AgentAction, BaseOutputParser, BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import AIMessage, BaseMessage, HumanMessage
+from oplangchain.tools.base import BaseTool
 
 
 class ConversationalChatAgent(Agent):
     """An agent designed to hold a conversation in addition to using tools."""
 
     output_parser: AgentOutputParser = Field(default_factory=ConvoOutputParser)
     template_tool_response: str = TEMPLATE_TOOL_RESPONSE
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational_chat/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/conversational_chat/output_parser.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 from typing import Union
 
-from langchain.agents import AgentOutputParser
-from langchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS
-from langchain.output_parsers.json import parse_json_markdown
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents import AgentOutputParser
+from oplangchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.output_parsers.json import parse_json_markdown
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 
 # Define a class that parses output for conversational agents
 class ConvoOutputParser(AgentOutputParser):
     """Output parser for the conversational agent."""
 
     def get_format_instructions(self) -> str:
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/conversational_chat/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/conversational_chat/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/initialize.py` & `oplangchain-0.1.1/oplangchain/agents/initialize.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Load agent."""
 from typing import Any, Optional, Sequence
 
-from langchain.agents.agent import AgentExecutor
-from langchain.agents.agent_types import AgentType
-from langchain.agents.loading import AGENT_TO_CLASS, load_agent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.agents.agent import AgentExecutor
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.loading import AGENT_TO_CLASS, load_agent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 def initialize_agent(
     tools: Sequence[BaseTool],
     llm: BaseLanguageModel,
     agent: Optional[AgentType] = None,
     callback_manager: Optional[BaseCallbackManager] = None,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/load_tools.py` & `oplangchain-0.1.1/oplangchain/agents/load_tools.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,66 +1,66 @@
 # flake8: noqa
 """Load tools."""
 import warnings
 from typing import Any, Dict, List, Optional, Callable, Tuple
 from mypy_extensions import Arg, KwArg
 
-from langchain.agents.tools import Tool
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs
-from langchain.chains.api.base import APIChain
-from langchain.chains.llm_math.base import LLMMathChain
-from langchain.utilities.requests import TextRequestsWrapper
-from langchain.tools.arxiv.tool import ArxivQueryRun
-from langchain.tools.golden_query.tool import GoldenQueryRun
-from langchain.tools.pubmed.tool import PubmedQueryRun
-from langchain.tools.base import BaseTool
-from langchain.tools.bing_search.tool import BingSearchRun
-from langchain.tools.ddg_search.tool import DuckDuckGoSearchRun
-from langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun
-from langchain.tools.metaphor_search.tool import MetaphorSearchResults
-from langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun
-from langchain.tools.graphql.tool import BaseGraphQLTool
-from langchain.tools.human.tool import HumanInputRun
-from langchain.tools.python.tool import PythonREPLTool
-from langchain.tools.requests.tool import (
+from oplangchain.agents.tools import Tool
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.api import news_docs, open_meteo_docs, podcast_docs, tmdb_docs
+from oplangchain.chains.api.base import APIChain
+from oplangchain.chains.llm_math.base import LLMMathChain
+from oplangchain.utilities.requests import TextRequestsWrapper
+from oplangchain.tools.arxiv.tool import ArxivQueryRun
+from oplangchain.tools.golden_query.tool import GoldenQueryRun
+from oplangchain.tools.pubmed.tool import PubmedQueryRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.bing_search.tool import BingSearchRun
+from oplangchain.tools.ddg_search.tool import DuckDuckGoSearchRun
+from oplangchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun
+from oplangchain.tools.metaphor_search.tool import MetaphorSearchResults
+from oplangchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun
+from oplangchain.tools.graphql.tool import BaseGraphQLTool
+from oplangchain.tools.human.tool import HumanInputRun
+from oplangchain.tools.python.tool import PythonREPLTool
+from oplangchain.tools.requests.tool import (
     RequestsDeleteTool,
     RequestsGetTool,
     RequestsPatchTool,
     RequestsPostTool,
     RequestsPutTool,
 )
-from langchain.tools.scenexplain.tool import SceneXplainTool
-from langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun
-from langchain.tools.shell.tool import ShellTool
-from langchain.tools.sleep.tool import SleepTool
-from langchain.tools.wikipedia.tool import WikipediaQueryRun
-from langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun
-from langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun
-from langchain.tools.dataforseo_api_search import DataForSeoAPISearchRun
-from langchain.tools.dataforseo_api_search import DataForSeoAPISearchResults
-from langchain.utilities import ArxivAPIWrapper
-from langchain.utilities import GoldenQueryAPIWrapper
-from langchain.utilities import PubMedAPIWrapper
-from langchain.utilities.bing_search import BingSearchAPIWrapper
-from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
-from langchain.utilities.google_search import GoogleSearchAPIWrapper
-from langchain.utilities.google_serper import GoogleSerperAPIWrapper
-from langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
-from langchain.utilities.awslambda import LambdaWrapper
-from langchain.utilities.graphql import GraphQLAPIWrapper
-from langchain.utilities.searx_search import SearxSearchWrapper
-from langchain.utilities.serpapi import SerpAPIWrapper
-from langchain.utilities.twilio import TwilioAPIWrapper
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
-from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
-from langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
-from langchain.utilities.dataforseo_api_search import DataForSeoAPIWrapper
+from oplangchain.tools.scenexplain.tool import SceneXplainTool
+from oplangchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun
+from oplangchain.tools.shell.tool import ShellTool
+from oplangchain.tools.sleep.tool import SleepTool
+from oplangchain.tools.wikipedia.tool import WikipediaQueryRun
+from oplangchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun
+from oplangchain.tools.openweathermap.tool import OpenWeatherMapQueryRun
+from oplangchain.tools.dataforseo_api_search import DataForSeoAPISearchRun
+from oplangchain.tools.dataforseo_api_search import DataForSeoAPISearchResults
+from oplangchain.utilities import ArxivAPIWrapper
+from oplangchain.utilities import GoldenQueryAPIWrapper
+from oplangchain.utilities import PubMedAPIWrapper
+from oplangchain.utilities.bing_search import BingSearchAPIWrapper
+from oplangchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
+from oplangchain.utilities.google_search import GoogleSearchAPIWrapper
+from oplangchain.utilities.google_serper import GoogleSerperAPIWrapper
+from oplangchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
+from oplangchain.utilities.awslambda import LambdaWrapper
+from oplangchain.utilities.graphql import GraphQLAPIWrapper
+from oplangchain.utilities.searx_search import SearxSearchWrapper
+from oplangchain.utilities.serpapi import SerpAPIWrapper
+from oplangchain.utilities.twilio import TwilioAPIWrapper
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
+from oplangchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
+from oplangchain.utilities.dataforseo_api_search import DataForSeoAPIWrapper
 
 
 def _get_python_repl() -> BaseTool:
     return PythonREPLTool()
 
 
 def _get_tools_requests_get() -> BaseTool:
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/loading.py` & `oplangchain-0.1.1/oplangchain/agents/loading.py`

 * *Files 16% similar despite different names*

```diff
@@ -2,20 +2,20 @@
 import json
 import logging
 from pathlib import Path
 from typing import Any, List, Optional, Union
 
 import yaml
 
-from langchain.agents.agent import BaseMultiActionAgent, BaseSingleActionAgent
-from langchain.agents.tools import Tool
-from langchain.agents.types import AGENT_TO_CLASS
-from langchain.chains.loading import load_chain, load_chain_from_config
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.utilities.loading import try_load_from_hub
+from oplangchain.agents.agent import BaseMultiActionAgent, BaseSingleActionAgent
+from oplangchain.agents.tools import Tool
+from oplangchain.agents.types import AGENT_TO_CLASS
+from oplangchain.chains.loading import load_chain, load_chain_from_config
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.utilities.loading import try_load_from_hub
 
 logger = logging.getLogger(__file__)
 
 URL_BASE = "https://raw.githubusercontent.com/hwchase17/langchain-hub/master/agents/"
 
 
 def _load_agent_from_tools(
@@ -84,15 +84,15 @@
     combined_config = {**config, **kwargs}
     return agent_cls(**combined_config)  # type: ignore
 
 
 def load_agent(
     path: Union[str, Path], **kwargs: Any
 ) -> Union[BaseSingleActionAgent, BaseMultiActionAgent]:
-    """Unified method for loading an agent from LangChainHub or local fs.
+    """Unified method for loading an agent from oplangchainHub or local fs.
 
     Args:
         path: Path to the agent file.
         **kwargs: Additional key word arguments passed to the agent executor.
 
     Returns:
         An agent executor.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/mrkl/base.py` & `oplangchain-0.1.1/oplangchain/agents/mrkl/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """Attempt to implement MRKL systems as described in arxiv.org/pdf/2205.00445.pdf."""
 from __future__ import annotations
 
 from typing import Any, Callable, List, NamedTuple, Optional, Sequence
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
-from langchain.agents.agent_types import AgentType
-from langchain.agents.mrkl.output_parser import MRKLOutputParser
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
-from langchain.agents.tools import Tool
-from langchain.agents.utils import validate_tools_single_input
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains import LLMChain
-from langchain.prompts import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.mrkl.output_parser import MRKLOutputParser
+from oplangchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
+from oplangchain.agents.tools import Tool
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains import LLMChain
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 class ChainConfig(NamedTuple):
     """Configuration for chain to use in MRKL system.
 
     Args:
         action_name: Name of the action.
@@ -139,16 +139,16 @@
 
 class MRKLChain(AgentExecutor):
     """Chain that implements the MRKL system.
 
     Example:
         .. code-block:: python
 
-            from langchain import OpenAI, MRKLChain
-            from langchain.chains.mrkl.base import ChainConfig
+            from oplangchain import OpenAI, MRKLChain
+            from oplangchain.chains.mrkl.base import ChainConfig
             llm = OpenAI(temperature=0)
             prompt = PromptTemplate(...)
             chains = [...]
             mrkl = MRKLChain.from_chains(llm=llm, prompt=prompt)
     """
 
     @classmethod
@@ -167,16 +167,16 @@
 
         Returns:
             An initialized MRKL chain.
 
         Example:
             .. code-block:: python
 
-                from langchain import LLMMathChain, OpenAI, SerpAPIWrapper, MRKLChain
-                from langchain.chains.mrkl.base import ChainConfig
+                from oplangchain import LLMMathChain, OpenAI, SerpAPIWrapper, MRKLChain
+                from oplangchain.chains.mrkl.base import ChainConfig
                 llm = OpenAI(temperature=0)
                 search = SerpAPIWrapper()
                 llm_math_chain = LLMMathChain(llm=llm)
                 chains = [
                     ChainConfig(
                         action_name = "Search",
                         action=search.search,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/mrkl/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/mrkl/output_parser.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import re
 from typing import Union
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.agents.mrkl.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 FINAL_ANSWER_ACTION = "Final Answer:"
 MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE = (
     "Invalid Format: Missing 'Action:' after 'Thought:"
 )
 MISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE = (
     "Invalid Format: Missing 'Action Input:' after 'Action:'"
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/mrkl/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/mrkl/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/openai_functions_agent/agent_token_buffer_memory.py` & `oplangchain-0.1.1/oplangchain/agents/openai_functions_agent/agent_token_buffer_memory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Memory used to save agent output AND intermediate steps."""
 from typing import Any, Dict, List
 
-from langchain.agents.openai_functions_agent.base import _format_intermediate_steps
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.agents.openai_functions_agent.base import _format_intermediate_steps
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 class AgentTokenBufferMemory(BaseChatMemory):
     """Memory used to save agent output AND intermediate steps."""
 
     human_prefix: str = "Human"
     ai_prefix: str = "AI"
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/openai_functions_agent/base.py` & `oplangchain-0.1.1/oplangchain/agents/openai_functions_agent/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,39 +2,39 @@
 import json
 from dataclasses import dataclass
 from json import JSONDecodeError
 from typing import Any, List, Optional, Sequence, Tuple, Union
 
 from pydantic import root_validator
 
-from langchain.agents import BaseSingleActionAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import Callbacks
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.prompts.chat import (
+from oplangchain.agents import BaseSingleActionAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.prompts.chat import (
     BaseMessagePromptTemplate,
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     MessagesPlaceholder,
 )
-from langchain.schema import (
+from oplangchain.schema import (
     AgentAction,
     AgentFinish,
     BasePromptTemplate,
     OutputParserException,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import (
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     FunctionMessage,
     SystemMessage,
 )
-from langchain.tools import BaseTool
-from langchain.tools.convert_to_openai import format_tool_to_openai_function
+from oplangchain.tools import BaseTool
+from oplangchain.tools.convert_to_openai import format_tool_to_openai_function
 
 
 @dataclass
 class _FunctionsAgentAction(AgentAction):
     message_log: List[BaseMessage]
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/openai_functions_multi_agent/base.py` & `oplangchain-0.1.1/oplangchain/agents/openai_functions_multi_agent/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,38 +2,38 @@
 import json
 from dataclasses import dataclass
 from json import JSONDecodeError
 from typing import Any, List, Optional, Sequence, Tuple, Union
 
 from pydantic import root_validator
 
-from langchain.agents import BaseMultiActionAgent
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import Callbacks
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.prompts.chat import (
+from oplangchain.agents import BaseMultiActionAgent
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.prompts.chat import (
     BaseMessagePromptTemplate,
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     MessagesPlaceholder,
 )
-from langchain.schema import (
+from oplangchain.schema import (
     AgentAction,
     AgentFinish,
     BasePromptTemplate,
     OutputParserException,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import (
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     FunctionMessage,
     SystemMessage,
 )
-from langchain.tools import BaseTool
+from oplangchain.tools import BaseTool
 
 
 @dataclass
 class _FunctionsAgentAction(AgentAction):
     message_log: List[BaseMessage]
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/react/base.py` & `oplangchain-0.1.1/oplangchain/agents/react/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """Chain that implements the ReAct paper from https://arxiv.org/pdf/2210.03629.pdf."""
 from typing import Any, List, Optional, Sequence
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
-from langchain.agents.agent_types import AgentType
-from langchain.agents.react.output_parser import ReActOutputParser
-from langchain.agents.react.textworld_prompt import TEXTWORLD_PROMPT
-from langchain.agents.react.wiki_prompt import WIKI_PROMPT
-from langchain.agents.tools import Tool
-from langchain.agents.utils import validate_tools_single_input
-from langchain.docstore.base import Docstore
-from langchain.docstore.document import Document
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.react.output_parser import ReActOutputParser
+from oplangchain.agents.react.textworld_prompt import TEXTWORLD_PROMPT
+from oplangchain.agents.react.wiki_prompt import WIKI_PROMPT
+from oplangchain.agents.tools import Tool
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.docstore.base import Docstore
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 class ReActDocstoreAgent(Agent):
     """Agent for the ReAct chain."""
 
     output_parser: AgentOutputParser = Field(default_factory=ReActOutputParser)
 
@@ -133,15 +133,15 @@
 
 class ReActChain(AgentExecutor):
     """Chain that implements the ReAct paper.
 
     Example:
         .. code-block:: python
 
-            from langchain import ReActChain, OpenAI
+            from oplangchain import ReActChain, OpenAI
             react = ReAct(llm=OpenAI())
     """
 
     def __init__(self, llm: BaseLanguageModel, docstore: Docstore, **kwargs: Any):
         """Initialize with the LLM and a docstore."""
         docstore_explorer = DocstoreExplorer(docstore)
         tools = [
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/react/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/react/output_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import re
 from typing import Union
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 
 class ReActOutputParser(AgentOutputParser):
     """Output parser for the ReAct agent."""
 
     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
         action_prefix = "Action: "
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/react/textworld_prompt.py` & `oplangchain-0.1.1/oplangchain/agents/react/textworld_prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 EXAMPLES = [
     """Setup: You are now playing a fast paced round of TextWorld! Here is your task for
 today. First of all, you could, like, try to travel east. After that, take the
 binder from the locker. With the binder, place the binder on the mantelpiece.
 Alright, thanks!
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/react/wiki_prompt.py` & `oplangchain-0.1.1/oplangchain/agents/react/wiki_prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 EXAMPLES = [
     """Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?
 Thought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.
 Action: Search[Colorado orogeny]
 Observation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.
 Thought: It does not mention the eastern sector. So I need to look up eastern sector.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/schema.py` & `oplangchain-0.1.1/oplangchain/agents/schema.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Any, Dict, List, Tuple
 
-from langchain.prompts.chat import ChatPromptTemplate
-from langchain.schema import AgentAction
+from oplangchain.prompts.chat import ChatPromptTemplate
+from oplangchain.schema import AgentAction
 
 
 class AgentScratchPadChatPromptTemplate(ChatPromptTemplate):
     """Chat prompt template for the agent scratchpad."""
 
     def _construct_agent_scratchpad(
         self, intermediate_steps: List[Tuple[AgentAction, str]]
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/base.py` & `oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/base.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """Chain that does self-ask with search."""
 from typing import Any, Sequence, Union
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
-from langchain.agents.agent_types import AgentType
-from langchain.agents.self_ask_with_search.output_parser import SelfAskOutputParser
-from langchain.agents.self_ask_with_search.prompt import PROMPT
-from langchain.agents.tools import Tool
-from langchain.agents.utils import validate_tools_single_input
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
-from langchain.utilities.google_serper import GoogleSerperAPIWrapper
-from langchain.utilities.serpapi import SerpAPIWrapper
+from oplangchain.agents.agent import Agent, AgentExecutor, AgentOutputParser
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.self_ask_with_search.output_parser import SelfAskOutputParser
+from oplangchain.agents.self_ask_with_search.prompt import PROMPT
+from oplangchain.agents.tools import Tool
+from oplangchain.agents.utils import validate_tools_single_input
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.google_serper import GoogleSerperAPIWrapper
+from oplangchain.utilities.serpapi import SerpAPIWrapper
 
 
 class SelfAskWithSearchAgent(Agent):
     """Agent for the self-ask-with-search paper."""
 
     output_parser: AgentOutputParser = Field(default_factory=SelfAskOutputParser)
 
@@ -60,15 +60,15 @@
 
 class SelfAskWithSearchChain(AgentExecutor):
     """Chain that does self-ask with search.
 
     Example:
         .. code-block:: python
 
-            from langchain import SelfAskWithSearchChain, OpenAI, GoogleSerperAPIWrapper
+            from oplangchain import SelfAskWithSearchChain, OpenAI, GoogleSerperAPIWrapper
             search_chain = GoogleSerperAPIWrapper()
             self_ask = SelfAskWithSearchChain(llm=OpenAI(), search_chain=search_chain)
     """
 
     def __init__(
         self,
         llm: BaseLanguageModel,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/output_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Sequence, Union
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
 
 
 class SelfAskOutputParser(AgentOutputParser):
     """Output parser for the self-ask agent."""
 
     followups: Sequence[str] = ("Follow up:", "Followup:")
     finish_string: str = "So the final answer is: "
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/self_ask_with_search/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/self_ask_with_search/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_TEMPLATE = """Question: Who lived longer, Muhammad Ali or Alan Turing?
 Are follow up questions needed here: Yes.
 Follow up: How old was Muhammad Ali when he died?
 Intermediate answer: Muhammad Ali was 74 years old when he died.
 Follow up: How old was Alan Turing when he died?
 Intermediate answer: Alan Turing was 41 years old when he died.
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/structured_chat/base.py` & `oplangchain-0.1.1/oplangchain/agents/structured_chat/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 import re
 from typing import Any, List, Optional, Sequence, Tuple
 
 from pydantic import Field
 
-from langchain.agents.agent import Agent, AgentOutputParser
-from langchain.agents.structured_chat.output_parser import (
+from oplangchain.agents.agent import Agent, AgentOutputParser
+from oplangchain.agents.structured_chat.output_parser import (
     StructuredChatOutputParserWithRetries,
 )
-from langchain.agents.structured_chat.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.chains.llm import LLMChain
-from langchain.prompts.chat import (
+from oplangchain.agents.structured_chat.prompt import FORMAT_INSTRUCTIONS, PREFIX, SUFFIX
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.schema import AgentAction, BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import BaseTool
+from oplangchain.schema import AgentAction, BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import BaseTool
 
 HUMAN_MESSAGE_TEMPLATE = "{input}\n\n{agent_scratchpad}"
 
 
 class StructuredChatAgent(Agent):
     """Structured Chat Agent."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/structured_chat/output_parser.py` & `oplangchain-0.1.1/oplangchain/agents/structured_chat/output_parser.py`

 * *Files 9% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 import json
 import logging
 import re
 from typing import Optional, Union
 
 from pydantic import Field
 
-from langchain.agents.agent import AgentOutputParser
-from langchain.agents.structured_chat.prompt import FORMAT_INSTRUCTIONS
-from langchain.output_parsers import OutputFixingParser
-from langchain.schema import AgentAction, AgentFinish, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.agents.agent import AgentOutputParser
+from oplangchain.agents.structured_chat.prompt import FORMAT_INSTRUCTIONS
+from oplangchain.output_parsers import OutputFixingParser
+from oplangchain.schema import AgentAction, AgentFinish, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
 
 logger = logging.getLogger(__name__)
 
 
 class StructuredChatOutputParser(AgentOutputParser):
     """Output parser for the structured chat agent."""
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/structured_chat/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/structured_chat/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/agents/tools.py` & `oplangchain-0.1.1/oplangchain/agents/tools.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Interface for tools."""
 from typing import List, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool, Tool, tool
+from oplangchain.tools.base import BaseTool, Tool, tool
 
 
 class InvalidTool(BaseTool):
     """Tool that is run when invalid tool name is encountered by agent."""
 
     name = "invalid_tool"
     description = "Called when tool name is invalid. Suggests valid tool names."
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/types.py` & `oplangchain-0.1.1/oplangchain/agents/types.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from typing import Dict, Type, Union
 
-from langchain.agents.agent import BaseSingleActionAgent
-from langchain.agents.agent_types import AgentType
-from langchain.agents.chat.base import ChatAgent
-from langchain.agents.conversational.base import ConversationalAgent
-from langchain.agents.conversational_chat.base import ConversationalChatAgent
-from langchain.agents.mrkl.base import ZeroShotAgent
-from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
-from langchain.agents.openai_functions_multi_agent.base import OpenAIMultiFunctionsAgent
-from langchain.agents.react.base import ReActDocstoreAgent
-from langchain.agents.self_ask_with_search.base import SelfAskWithSearchAgent
-from langchain.agents.structured_chat.base import StructuredChatAgent
+from oplangchain.agents.agent import BaseSingleActionAgent
+from oplangchain.agents.agent_types import AgentType
+from oplangchain.agents.chat.base import ChatAgent
+from oplangchain.agents.conversational.base import ConversationalAgent
+from oplangchain.agents.conversational_chat.base import ConversationalChatAgent
+from oplangchain.agents.mrkl.base import ZeroShotAgent
+from oplangchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
+from oplangchain.agents.openai_functions_multi_agent.base import OpenAIMultiFunctionsAgent
+from oplangchain.agents.react.base import ReActDocstoreAgent
+from oplangchain.agents.self_ask_with_search.base import SelfAskWithSearchAgent
+from oplangchain.agents.structured_chat.base import StructuredChatAgent
 
 AGENT_TYPE = Union[Type[BaseSingleActionAgent], Type[OpenAIMultiFunctionsAgent]]
 
 AGENT_TO_CLASS: Dict[AgentType, AGENT_TYPE] = {
     AgentType.ZERO_SHOT_REACT_DESCRIPTION: ZeroShotAgent,
     AgentType.REACT_DOCSTORE: ReActDocstoreAgent,
     AgentType.SELF_ASK_WITH_SEARCH: SelfAskWithSearchAgent,
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/xml/base.py` & `oplangchain-0.1.1/oplangchain/agents/xml/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from typing import Any, List, Tuple, Union
 
-from langchain.agents.agent import AgentOutputParser, BaseSingleActionAgent
-from langchain.agents.xml.prompt import agent_instructions
-from langchain.callbacks.base import Callbacks
-from langchain.chains.llm import LLMChain
-from langchain.prompts.chat import AIMessagePromptTemplate, ChatPromptTemplate
-from langchain.schema import AgentAction, AgentFinish
-from langchain.tools.base import BaseTool
+from oplangchain.agents.agent import AgentOutputParser, BaseSingleActionAgent
+from oplangchain.agents.xml.prompt import agent_instructions
+from oplangchain.callbacks.base import Callbacks
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.chat import AIMessagePromptTemplate, ChatPromptTemplate
+from oplangchain.schema import AgentAction, AgentFinish
+from oplangchain.tools.base import BaseTool
 
 
 class XMLAgentOutputParser(AgentOutputParser):
     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
         if "</tool>" in text:
             tool, tool_input = text.split("</tool>")
             _tool = tool.split("<tool>")[1]
@@ -37,16 +37,16 @@
         tools: list of tools the agent can choose from
         llm_chain: The LLMChain to call to predict the next action
 
     Examples:
 
         .. code-block:: python
 
-            from langchain.agents import XMLAgent
-            from langchain
+            from oplangchain.agents import XMLAgent
+            from oplangchain
 
             tools = ...
             model =
 
 
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/agents/xml/prompt.py` & `oplangchain-0.1.1/oplangchain/agents/xml/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/cache.py` & `oplangchain-0.1.1/oplangchain/cache.py`

 * *Files 0% similar despite different names*

```diff
@@ -41,26 +41,26 @@
     cast,
 )
 
 from sqlalchemy import Column, Integer, String, create_engine, select
 from sqlalchemy.engine.base import Engine
 from sqlalchemy.orm import Session
 
-from langchain.utils import get_from_env
+from oplangchain.utils import get_from_env
 
 try:
     from sqlalchemy.orm import declarative_base
 except ImportError:
     from sqlalchemy.ext.declarative import declarative_base
 
-from langchain.embeddings.base import Embeddings
-from langchain.load.dump import dumps
-from langchain.load.load import loads
-from langchain.schema import ChatGeneration, Generation
-from langchain.vectorstores.redis import Redis as RedisVectorstore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.load.dump import dumps
+from oplangchain.load.load import loads
+from oplangchain.schema import ChatGeneration, Generation
+from oplangchain.vectorstores.redis import Redis as RedisVectorstore
 
 logger = logging.getLogger(__file__)
 
 if TYPE_CHECKING:
     import momento
 
 RETURN_VAL_TYPE = Sequence[Generation]
@@ -289,18 +289,18 @@
             embedding (Embedding): Embedding provider for semantic encoding and search.
             score_threshold (float, 0.2):
 
         Example:
 
         .. code-block:: python
 
-            import langchain
+import oplangchain
 
-            from langchain.cache import RedisSemanticCache
-            from langchain.embeddings import OpenAIEmbeddings
+            from oplangchain.cache import RedisSemanticCache
+            from oplangchain.embeddings import OpenAIEmbeddings
 
             langchain.llm_cache = RedisSemanticCache(
                 redis_url="redis://localhost:6379",
                 embedding=OpenAIEmbeddings()
             )
 
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/aim_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/aim_callback.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from copy import deepcopy
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 def import_aim() -> Any:
     """Import the aim python package and raise an error if it is not installed."""
     try:
         import aim
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/argilla_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/argilla_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import os
 import warnings
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 class ArgillaCallbackHandler(BaseCallbackHandler):
     """Callback Handler that logs into Argilla.
 
     Args:
         dataset_name: name of the `FeedbackDataset` in Argilla. Note that it must
@@ -27,16 +27,16 @@
 
     Raises:
         ImportError: if the `argilla` package is not installed.
         ConnectionError: if the connection to Argilla fails.
         FileNotFoundError: if the `FeedbackDataset` retrieval from Argilla fails.
 
     Examples:
-        >>> from langchain.llms import OpenAI
-        >>> from langchain.callbacks import ArgillaCallbackHandler
+        >>> from oplangchain.llms import OpenAI
+        >>> from oplangchain.callbacks import ArgillaCallbackHandler
         >>> argilla_callback = ArgillaCallbackHandler(
         ...     dataset_name="my-dataset",
         ...     workspace_name="my-workspace",
         ...     api_url="http://localhost:6900",
         ...     api_key="argilla.apikey",
         ... )
         >>> llm = OpenAI(
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/arize_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/arize_callback.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import import_pandas
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import import_pandas
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 class ArizeCallbackHandler(BaseCallbackHandler):
     """Callback Handler that logs to Arize."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/arthur_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/arthur_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 from collections import defaultdict
 from datetime import datetime
 from time import time
 from typing import TYPE_CHECKING, Any, DefaultDict, Dict, List, Optional, Union
 
 import numpy as np
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 if TYPE_CHECKING:
     import arthurai
     from arthurai.core.models import ArthurModel
 
 PROMPT_TOKENS = "prompt_tokens"
 COMPLETION_TOKENS = "completion_tokens"
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/base.py` & `oplangchain-0.1.1/oplangchain/callbacks/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Base callback handler that can be used to handle callbacks in langchain."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, Union
 from uuid import UUID
 
 if TYPE_CHECKING:
-    from langchain.schema.agent import AgentAction, AgentFinish
-    from langchain.schema.document import Document
-    from langchain.schema.messages import BaseMessage
-    from langchain.schema.output import LLMResult
+    from oplangchain.schema.agent import AgentAction, AgentFinish
+    from oplangchain.schema.document import Document
+    from oplangchain.schema.messages import BaseMessage
+    from oplangchain.schema.output import LLMResult
 
 
 class RetrieverManagerMixin:
     """Mixin for Retriever callbacks."""
 
     def on_retriever_error(
         self,
@@ -227,15 +227,15 @@
     LLMManagerMixin,
     ChainManagerMixin,
     ToolManagerMixin,
     RetrieverManagerMixin,
     CallbackManagerMixin,
     RunManagerMixin,
 ):
-    """Base callback handler that can be used to handle callbacks from langchain."""
+    """Base callback handler that can be used to handle callbacks from oplangchain."""
 
     raise_error: bool = False
 
     run_inline: bool = False
 
     @property
     def ignore_llm(self) -> bool:
@@ -265,15 +265,15 @@
     @property
     def ignore_chat_model(self) -> bool:
         """Whether to ignore chat model callbacks."""
         return False
 
 
 class AsyncCallbackHandler(BaseCallbackHandler):
-    """Async callback handler that can be used to handle callbacks from langchain."""
+    """Async callback handler that can be used to handle callbacks from oplangchain."""
 
     async def on_llm_start(
         self,
         serialized: Dict[str, Any],
         prompts: List[str],
         *,
         run_id: UUID,
@@ -469,15 +469,15 @@
         tags: Optional[List[str]] = None,
         **kwargs: Any,
     ) -> None:
         """Run on retriever error."""
 
 
 class BaseCallbackManager(CallbackManagerMixin):
-    """Base callback manager that handles callbacks from LangChain."""
+    """Base callback manager that handles callbacks from oplangchain."""
 
     def __init__(
         self,
         handlers: List[BaseCallbackHandler],
         inheritable_handlers: Optional[List[BaseCallbackHandler]] = None,
         parent_run_id: Optional[UUID] = None,
         *,
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/clearml_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/clearml_callback.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 import tempfile
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Sequence, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     BaseMetadataCallbackHandler,
     flatten_dict,
     hash_string,
     import_pandas,
     import_spacy,
     import_textstat,
     load_json,
 )
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 def import_clearml() -> Any:
     """Import the clearml python package and raise an error if it is not installed."""
     try:
         import clearml  # noqa: F401
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/comet_ml_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/comet_ml_callback.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import tempfile
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Sequence, Union
 
-import langchain
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+import oplangchain
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     BaseMetadataCallbackHandler,
     flatten_dict,
     import_pandas,
     import_spacy,
     import_textstat,
 )
-from langchain.schema import AgentAction, AgentFinish, Generation, LLMResult
+from oplangchain.schema import AgentAction, AgentFinish, Generation, LLMResult
 
 LANGCHAIN_MODEL_NAME = "langchain-model"
 
 
 def import_comet_ml() -> Any:
     """Import comet_ml and raise an error if it is not installed."""
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/context_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/context_callback.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Callback handler for Context AI"""
 import os
 from typing import Any, Dict, List
 from uuid import UUID
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import (
     BaseMessage,
     LLMResult,
 )
 
 
 def import_context() -> Any:
     """Import the `getcontext` package."""
@@ -41,16 +41,16 @@
             If not provided, the value of the `CONTEXT_TOKEN` environment
             variable will be used.
 
     Raises:
         ImportError: if the `context-python` package is not installed.
 
     Chat Example:
-        >>> from langchain.llms import ChatOpenAI
-        >>> from langchain.callbacks import ContextCallbackHandler
+        >>> from oplangchain.llms import ChatOpenAI
+        >>> from oplangchain.callbacks import ContextCallbackHandler
         >>> context_callback = ContextCallbackHandler(
         ...     token="<CONTEXT_TOKEN_HERE>",
         ... )
         >>> chat = ChatOpenAI(
         ...     temperature=0,
         ...     headers={"user_id": "123"},
         ...     callbacks=[context_callback],
@@ -59,17 +59,17 @@
         >>> messages = [
         ...     SystemMessage(content="You translate English to French."),
         ...     HumanMessage(content="I love programming with LangChain."),
         ... ]
         >>> chat(messages)
 
     Chain Example:
-        >>> from langchain import LLMChain
-        >>> from langchain.llms import ChatOpenAI
-        >>> from langchain.callbacks import ContextCallbackHandler
+        >>> from oplangchain import LLMChain
+        >>> from oplangchain.llms import ChatOpenAI
+        >>> from oplangchain.callbacks import ContextCallbackHandler
         >>> context_callback = ContextCallbackHandler(
         ...     token="<CONTEXT_TOKEN_HERE>",
         ... )
         >>> human_message_prompt = HumanMessagePromptTemplate(
         ...     prompt=PromptTemplate(
         ...         template="What is a good name for a company that makes {product}?",
         ...         input_variables=["product"],
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/file.py` & `oplangchain-0.1.1/oplangchain/callbacks/file.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Callback Handler that writes to a file."""
 from typing import Any, Dict, Optional, TextIO, cast
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish
-from langchain.utils.input import print_text
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish
+from oplangchain.utils.input import print_text
 
 
 class FileCallbackHandler(BaseCallbackHandler):
     """Callback Handler that writes to a file."""
 
     def __init__(
         self, filename: str, mode: str = "a", color: Optional[str] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/flyte_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/flyte_callback.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """FlyteKit callback handler."""
 from __future__ import annotations
 
 import logging
 from copy import deepcopy
 from typing import TYPE_CHECKING, Any, Dict, List, Tuple, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     BaseMetadataCallbackHandler,
     flatten_dict,
     import_pandas,
     import_spacy,
     import_textstat,
 )
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 if TYPE_CHECKING:
     import flytekit
     from flytekitplugins.deck import renderer
 
 logger = logging.getLogger(__name__)
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/human.py` & `oplangchain-0.1.1/oplangchain/callbacks/human.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Any, Callable, Dict, Optional
 from uuid import UUID
 
-from langchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.base import BaseCallbackHandler
 
 
 def _default_approve(_input: str) -> bool:
     msg = (
         "Do you approve of the following input? "
         "Anything except 'Y'/'Yes' (case-insensitive) will be treated as a no."
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/infino_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/infino_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import time
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 def import_infino() -> Any:
     """Import the infino client."""
     try:
         from infinopy import InfinoClient
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/manager.py` & `oplangchain-0.1.1/oplangchain/callbacks/manager.py`

 * *Files 0% similar despite different names*

```diff
@@ -21,38 +21,38 @@
     Union,
     cast,
 )
 from uuid import UUID
 
 from tenacity import RetryCallState
 
-import langchain
-from langchain.callbacks.base import (
+import oplangchain
+from oplangchain.callbacks.base import (
     BaseCallbackHandler,
     BaseCallbackManager,
     Callbacks,
     ChainManagerMixin,
     LLMManagerMixin,
     RetrieverManagerMixin,
     RunManagerMixin,
     ToolManagerMixin,
 )
-from langchain.callbacks.openai_info import OpenAICallbackHandler
-from langchain.callbacks.stdout import StdOutCallbackHandler
-from langchain.callbacks.tracers.langchain import LangChainTracer
-from langchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1
-from langchain.callbacks.tracers.stdout import ConsoleCallbackHandler
-from langchain.callbacks.tracers.wandb import WandbTracer
-from langchain.schema import (
+from oplangchain.callbacks.openai_info import OpenAICallbackHandler
+from oplangchain.callbacks.stdout import StdOutCallbackHandler
+from oplangchain.callbacks.tracers.langchain import LangChainTracer
+from oplangchain.callbacks.tracers.langchain_v1 import LangChainTracerV1, TracerSessionV1
+from oplangchain.callbacks.tracers.stdout import ConsoleCallbackHandler
+from oplangchain.callbacks.tracers.wandb import WandbTracer
+from oplangchain.schema import (
     AgentAction,
     AgentFinish,
     Document,
     LLMResult,
 )
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 if TYPE_CHECKING:
     from langsmith import Client as LangSmithClient
 
 logger = logging.getLogger(__name__)
 
 openai_callback_var: ContextVar[Optional[OpenAICallbackHandler]] = ContextVar(
@@ -73,15 +73,15 @@
     Optional[LangChainTracer]
 ] = ContextVar(  # noqa: E501
     "tracing_callback_v2", default=None
 )
 
 
 def _get_debug() -> bool:
-    return langchain.debug
+    return oplangchain.debug
 
 
 @contextmanager
 def get_openai_callback() -> Generator[OpenAICallbackHandler, None, None]:
     """Get the OpenAI callback handler in a context manager.
     which conveniently exposes token and cost information.
 
@@ -1034,15 +1034,15 @@
             parent_run_id=self.parent_run_id,
             tags=self.tags,
             **kwargs,
         )
 
 
 class CallbackManager(BaseCallbackManager):
-    """Callback manager that handles callbacks from langchain."""
+    """Callback manager that handles callbacks from oplangchain."""
 
     def on_llm_start(
         self,
         serialized: Dict[str, Any],
         prompts: List[str],
         **kwargs: Any,
     ) -> List[CallbackManagerForLLMRun]:
@@ -1303,15 +1303,15 @@
             local_tags,
             inheritable_metadata,
             local_metadata,
         )
 
 
 class AsyncCallbackManager(BaseCallbackManager):
-    """Async callback manager that handles callbacks from LangChain."""
+    """Async callback manager that handles callbacks from oplangchain."""
 
     @property
     def is_async(self) -> bool:
         """Return whether the handler is async."""
         return True
 
     async def on_llm_start(
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/mlflow_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/mlflow_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,25 +3,25 @@
 import string
 import tempfile
 import traceback
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     BaseMetadataCallbackHandler,
     flatten_dict,
     hash_string,
     import_pandas,
     import_spacy,
     import_textstat,
 )
-from langchain.schema import AgentAction, AgentFinish, LLMResult
-from langchain.utils import get_from_dict_or_env
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.utils import get_from_dict_or_env
 
 
 def import_mlflow() -> Any:
     """Import the mlflow python package and raise an error if it is not installed."""
     try:
         import mlflow
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/openai_info.py` & `oplangchain-0.1.1/oplangchain/callbacks/openai_info.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Callback Handler that prints to std out."""
 from typing import Any, Dict, List
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import LLMResult
 
 MODEL_COST_PER_1K_TOKENS = {
     # GPT-4 input
     "gpt-4": 0.03,
     "gpt-4-0314": 0.03,
     "gpt-4-0613": 0.03,
     "gpt-4-32k": 0.06,
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/promptlayer_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/promptlayer_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 """Callback handler for promptlayer."""
 from __future__ import annotations
 
 import datetime
 from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple
 from uuid import UUID
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import (
     ChatGeneration,
     LLMResult,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     HumanMessage,
     SystemMessage,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/sagemaker_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/sagemaker_callback.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import json
 import os
 import shutil
 import tempfile
 from copy import deepcopy
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     flatten_dict,
 )
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 def save_json(data: dict, file_path: str) -> None:
     """Save dict to local file path.
 
     Parameters:
         data (dict): The dictionary to be saved.
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/stdout.py` & `oplangchain-0.1.1/oplangchain/callbacks/stdout.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Callback Handler that prints to std out."""
 from typing import Any, Dict, List, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
-from langchain.utils.input import print_text
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.utils.input import print_text
 
 
 class StdOutCallbackHandler(BaseCallbackHandler):
     """Callback Handler that prints to std out."""
 
     def __init__(self, color: Optional[str] = None) -> None:
         """Initialize callback handler."""
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streaming_aiter.py` & `oplangchain-0.1.1/oplangchain/callbacks/streaming_aiter.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 import asyncio
 from typing import Any, AsyncIterator, Dict, List, Literal, Union, cast
 
-from langchain.callbacks.base import AsyncCallbackHandler
-from langchain.schema.output import LLMResult
+from oplangchain.callbacks.base import AsyncCallbackHandler
+from oplangchain.schema.output import LLMResult
 
 # TODO If used by two LLM runs in parallel this won't work as expected
 
 
 class AsyncIteratorCallbackHandler(AsyncCallbackHandler):
     """Callback handler that returns an async iterator."""
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streaming_aiter_final_only.py` & `oplangchain-0.1.1/oplangchain/callbacks/streaming_aiter_final_only.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
-from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
-from langchain.schema import LLMResult
+from oplangchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
+from oplangchain.schema import LLMResult
 
 DEFAULT_ANSWER_PREFIX_TOKENS = ["Final", "Answer", ":"]
 
 
 class AsyncFinalIteratorCallbackHandler(AsyncIteratorCallbackHandler):
     """Callback handler that returns an async iterator.
     Only the final output of the agent will be iterated.
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streaming_stdout.py` & `oplangchain-0.1.1/oplangchain/callbacks/streaming_stdout.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Callback Handler streams to stdout on new llm token."""
 import sys
 from typing import Any, Dict, List, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 class StreamingStdOutCallbackHandler(BaseCallbackHandler):
     """Callback handler for streaming. Only works with LLMs that support streaming."""
 
     def on_llm_start(
         self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streaming_stdout_final_only.py` & `oplangchain-0.1.1/oplangchain/callbacks/streaming_stdout_final_only.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Callback Handler streams to stdout on new llm token."""
 import sys
 from typing import Any, Dict, List, Optional
 
-from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
+from oplangchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
 
 DEFAULT_ANSWER_PREFIX_TOKENS = ["Final", "Answer", ":"]
 
 
 class FinalStreamingStdOutCallbackHandler(StreamingStdOutCallbackHandler):
     """Callback handler for streaming in agents.
     Only works with agents using LLMs that support streaming.
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streamlit/__init__.py` & `oplangchain-0.1.1/oplangchain/callbacks/streamlit/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Optional
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.streamlit.streamlit_callback_handler import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.streamlit.streamlit_callback_handler import (
     LLMThoughtLabeler as LLMThoughtLabeler,
 )
-from langchain.callbacks.streamlit.streamlit_callback_handler import (
+from oplangchain.callbacks.streamlit.streamlit_callback_handler import (
     StreamlitCallbackHandler as _InternalStreamlitCallbackHandler,
 )
 
 if TYPE_CHECKING:
     from streamlit.delta_generator import DeltaGenerator
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streamlit/mutable_expander.py` & `oplangchain-0.1.1/oplangchain/callbacks/streamlit/mutable_expander.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/streamlit/streamlit_callback_handler.py` & `oplangchain-0.1.1/oplangchain/callbacks/streamlit/streamlit_callback_handler.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Callback Handler that prints to streamlit."""
 
 from __future__ import annotations
 
 from enum import Enum
 from typing import TYPE_CHECKING, Any, Dict, List, NamedTuple, Optional, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.streamlit.mutable_expander import MutableExpander
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.streamlit.mutable_expander import MutableExpander
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 if TYPE_CHECKING:
     from streamlit.delta_generator import DeltaGenerator
 
 
 def _convert_newlines(text: str) -> str:
     """Convert newline characters to markdown newline sequences
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/base.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 from abc import ABC, abstractmethod
 from datetime import datetime
 from typing import Any, Dict, List, Optional, Sequence, Union, cast
 from uuid import UUID
 
 from tenacity import RetryCallState
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.tracers.schemas import Run
-from langchain.load.dump import dumpd
-from langchain.schema.document import Document
-from langchain.schema.output import ChatGeneration, LLMResult
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.tracers.schemas import Run
+from oplangchain.load.dump import dumpd
+from oplangchain.schema.document import Document
+from oplangchain.schema.output import ChatGeneration, LLMResult
 
 logger = logging.getLogger(__name__)
 
 
 class TracerException(Exception):
     """Base class for exceptions in tracers module."""
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/evaluation.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/evaluation.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,18 +4,18 @@
 import logging
 from concurrent.futures import Future, ThreadPoolExecutor, wait
 from typing import Any, List, Optional, Sequence, Set, Union
 from uuid import UUID
 
 from langsmith import Client, RunEvaluator
 
-from langchain.callbacks.manager import tracing_v2_enabled
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.langchain import _get_client
-from langchain.callbacks.tracers.schemas import Run
+from oplangchain.callbacks.manager import tracing_v2_enabled
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.langchain import _get_client
+from oplangchain.callbacks.tracers.schemas import Run
 
 logger = logging.getLogger(__name__)
 
 _TRACERS: List[EvaluatorCallbackHandler] = []
 
 
 def wait_for_all_evaluators() -> None:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/langchain.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/langchain.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,19 +6,19 @@
 from concurrent.futures import Future, ThreadPoolExecutor, wait
 from datetime import datetime
 from typing import Any, Callable, Dict, List, Optional, Set, Union
 from uuid import UUID
 
 from langsmith import Client
 
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.schemas import Run, TracerSession
-from langchain.env import get_runtime_environment
-from langchain.load.dump import dumpd
-from langchain.schema.messages import BaseMessage
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.schemas import Run, TracerSession
+from oplangchain.env import get_runtime_environment
+from oplangchain.load.dump import dumpd
+from oplangchain.schema.messages import BaseMessage
 
 logger = logging.getLogger(__name__)
 _LOGGED = set()
 _TRACERS: List[LangChainTracer] = []
 _CLIENT: Optional[Client] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/langchain_v1.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/langchain_v1.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,26 +2,26 @@
 
 import logging
 import os
 from typing import Any, Dict, Optional, Union
 
 import requests
 
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.schemas import (
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.schemas import (
     ChainRun,
     LLMRun,
     Run,
     ToolRun,
     TracerSession,
     TracerSessionV1,
     TracerSessionV1Base,
 )
-from langchain.schema.messages import get_buffer_string
-from langchain.utils import raise_for_status_with_text
+from oplangchain.schema.messages import get_buffer_string
+from oplangchain.utils import raise_for_status_with_text
 
 logger = logging.getLogger(__name__)
 
 
 def get_headers() -> Dict[str, Any]:
     """Get the headers for the LangChain API."""
     headers: Dict[str, Any] = {"Content-Type": "application/json"}
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/run_collector.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/run_collector.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """A tracer that collects all nested runs in a list."""
 
 from typing import Any, List, Optional, Union
 from uuid import UUID
 
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.schemas import Run
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.schemas import Run
 
 
 class RunCollectorCallbackHandler(BaseTracer):
     """
     A tracer that collects all nested runs in a list.
 
     This tracer is useful for inspection and evaluation purposes.
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/schemas.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/schemas.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 from typing import Any, Dict, List, Optional
 from uuid import UUID
 
 from langsmith.schemas import RunBase as BaseRunV2
 from langsmith.schemas import RunTypeEnum as RunTypeEnumDep
 from pydantic import BaseModel, Field, root_validator
 
-from langchain.schema import LLMResult
+from oplangchain.schema import LLMResult
 
 
 def RunTypeEnum() -> RunTypeEnumDep:
     """RunTypeEnum."""
     warnings.warn(
         "RunTypeEnum is deprecated. Please directly use a string instead"
         " (e.g. 'llm', 'chain', 'tool').",
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/stdout.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/stdout.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import json
 from typing import Any, Callable, List
 
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.schemas import Run
-from langchain.utils.input import get_bolded_text, get_colored_text
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.schemas import Run
+from oplangchain.utils.input import get_bolded_text, get_colored_text
 
 
 def try_json_stringify(obj: Any, fallback: str) -> str:
     """
     Try to stringify an object to JSON.
     Args:
         obj: Object to stringify.
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/tracers/wandb.py` & `oplangchain-0.1.1/oplangchain/callbacks/tracers/wandb.py`

 * *Files 0% similar despite different names*

```diff
@@ -10,16 +10,16 @@
     Optional,
     Sequence,
     Tuple,
     TypedDict,
     Union,
 )
 
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.schemas import Run
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.schemas import Run
 
 if TYPE_CHECKING:
     from wandb import Settings as WBSettings
     from wandb.sdk.data_types.trace_tree import Span
     from wandb.sdk.lib.paths import StrPath
     from wandb.wandb_run import Run as WBRun
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/utils.py` & `oplangchain-0.1.1/oplangchain/callbacks/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/wandb_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/wandb_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 import json
 import tempfile
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Sequence, Union
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.utils import (
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.utils import (
     BaseMetadataCallbackHandler,
     flatten_dict,
     hash_string,
     import_pandas,
     import_spacy,
     import_textstat,
 )
-from langchain.schema import AgentAction, AgentFinish, LLMResult
+from oplangchain.schema import AgentAction, AgentFinish, LLMResult
 
 
 def import_wandb() -> Any:
     """Import the wandb python package and raise an error if it is not installed."""
     try:
         import wandb  # noqa: F401
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/callbacks/whylabs_callback.py` & `oplangchain-0.1.1/oplangchain/callbacks/whylabs_callback.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 import logging
 from typing import TYPE_CHECKING, Any, Optional
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.utils import get_from_env
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.utils import get_from_env
 
 if TYPE_CHECKING:
     from whylogs.api.logger.logger import Logger
 
 diagnostic_logger = logging.getLogger(__name__)
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/__init__.py` & `oplangchain-0.1.1/oplangchain/chains/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -13,73 +13,73 @@
 **Class hierarchy:**
 
 .. code-block::
 
     Chain --> <name>Chain  # Examples: LLMChain, MapReduceChain, RouterChain
 """
 
-from langchain.chains.api.base import APIChain
-from langchain.chains.api.openapi.chain import OpenAPIEndpointChain
-from langchain.chains.combine_documents.base import AnalyzeDocumentChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
-from langchain.chains.combine_documents.reduce import ReduceDocumentsChain
-from langchain.chains.combine_documents.refine import RefineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.constitutional_ai.base import ConstitutionalChain
-from langchain.chains.conversation.base import ConversationChain
-from langchain.chains.conversational_retrieval.base import (
+from oplangchain.chains.api.base import APIChain
+from oplangchain.chains.api.openapi.chain import OpenAPIEndpointChain
+from oplangchain.chains.combine_documents.base import AnalyzeDocumentChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
+from oplangchain.chains.combine_documents.reduce import ReduceDocumentsChain
+from oplangchain.chains.combine_documents.refine import RefineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.constitutional_ai.base import ConstitutionalChain
+from oplangchain.chains.conversation.base import ConversationChain
+from oplangchain.chains.conversational_retrieval.base import (
     ChatVectorDBChain,
     ConversationalRetrievalChain,
 )
-from langchain.chains.example_generator import generate_example
-from langchain.chains.flare.base import FlareChain
-from langchain.chains.graph_qa.arangodb import ArangoGraphQAChain
-from langchain.chains.graph_qa.base import GraphQAChain
-from langchain.chains.graph_qa.cypher import GraphCypherQAChain
-from langchain.chains.graph_qa.hugegraph import HugeGraphQAChain
-from langchain.chains.graph_qa.kuzu import KuzuQAChain
-from langchain.chains.graph_qa.nebulagraph import NebulaGraphQAChain
-from langchain.chains.graph_qa.neptune_cypher import NeptuneOpenCypherQAChain
-from langchain.chains.graph_qa.sparql import GraphSparqlQAChain
-from langchain.chains.hyde.base import HypotheticalDocumentEmbedder
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_bash.base import LLMBashChain
-from langchain.chains.llm_checker.base import LLMCheckerChain
-from langchain.chains.llm_math.base import LLMMathChain
-from langchain.chains.llm_requests import LLMRequestsChain
-from langchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain
-from langchain.chains.loading import load_chain
-from langchain.chains.mapreduce import MapReduceChain
-from langchain.chains.moderation import OpenAIModerationChain
-from langchain.chains.natbot.base import NatBotChain
-from langchain.chains.openai_functions import (
+from oplangchain.chains.example_generator import generate_example
+from oplangchain.chains.flare.base import FlareChain
+from oplangchain.chains.graph_qa.arangodb import ArangoGraphQAChain
+from oplangchain.chains.graph_qa.base import GraphQAChain
+from oplangchain.chains.graph_qa.cypher import GraphCypherQAChain
+from oplangchain.chains.graph_qa.hugegraph import HugeGraphQAChain
+from oplangchain.chains.graph_qa.kuzu import KuzuQAChain
+from oplangchain.chains.graph_qa.nebulagraph import NebulaGraphQAChain
+from oplangchain.chains.graph_qa.neptune_cypher import NeptuneOpenCypherQAChain
+from oplangchain.chains.graph_qa.sparql import GraphSparqlQAChain
+from oplangchain.chains.hyde.base import HypotheticalDocumentEmbedder
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_bash.base import LLMBashChain
+from oplangchain.chains.llm_checker.base import LLMCheckerChain
+from oplangchain.chains.llm_math.base import LLMMathChain
+from oplangchain.chains.llm_requests import LLMRequestsChain
+from oplangchain.chains.llm_summarization_checker.base import LLMSummarizationCheckerChain
+from oplangchain.chains.loading import load_chain
+from oplangchain.chains.mapreduce import MapReduceChain
+from oplangchain.chains.moderation import OpenAIModerationChain
+from oplangchain.chains.natbot.base import NatBotChain
+from oplangchain.chains.openai_functions import (
     create_citation_fuzzy_match_chain,
     create_extraction_chain,
     create_extraction_chain_pydantic,
     create_qa_with_sources_chain,
     create_qa_with_structure_chain,
     create_tagging_chain,
     create_tagging_chain_pydantic,
 )
-from langchain.chains.qa_generation.base import QAGenerationChain
-from langchain.chains.qa_with_sources.base import QAWithSourcesChain
-from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain
-from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain
-from langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA
-from langchain.chains.router import (
+from oplangchain.chains.qa_generation.base import QAGenerationChain
+from oplangchain.chains.qa_with_sources.base import QAWithSourcesChain
+from oplangchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain
+from oplangchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain
+from oplangchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA
+from oplangchain.chains.router import (
     LLMRouterChain,
     MultiPromptChain,
     MultiRetrievalQAChain,
     MultiRouteChain,
     RouterChain,
 )
-from langchain.chains.sequential import SequentialChain, SimpleSequentialChain
-from langchain.chains.sql_database.query import create_sql_query_chain
-from langchain.chains.transform import TransformChain
+from oplangchain.chains.sequential import SequentialChain, SimpleSequentialChain
+from oplangchain.chains.sql_database.query import create_sql_query_chain
+from oplangchain.chains.transform import TransformChain
 
 __all__ = [
     "APIChain",
     "AnalyzeDocumentChain",
     "ArangoGraphQAChain",
     "ChatVectorDBChain",
     "ConstitutionalChain",
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/base.py` & `oplangchain-0.1.1/oplangchain/chains/api/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """Chain that makes API calls and summarizes the responses to answer a question."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.api.prompt import API_RESPONSE_PROMPT, API_URL_PROMPT
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.utilities.requests import TextRequestsWrapper
+from oplangchain.chains.api.prompt import API_RESPONSE_PROMPT, API_URL_PROMPT
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.utilities.requests import TextRequestsWrapper
 
 
 class APIChain(Chain):
     """Chain that makes API calls and summarizes the responses to answer a question."""
 
     api_request_chain: LLMChain
     api_answer_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/news_docs.py` & `oplangchain-0.1.1/oplangchain/chains/api/news_docs.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/open_meteo_docs.py` & `oplangchain-0.1.1/oplangchain/chains/api/open_meteo_docs.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/openapi/chain.py` & `oplangchain-0.1.1/oplangchain/chains/api/openapi/chain.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,22 +3,22 @@
 
 import json
 from typing import Any, Dict, List, NamedTuple, Optional, cast
 
 from pydantic import BaseModel, Field
 from requests import Response
 
-from langchain.callbacks.manager import CallbackManagerForChainRun, Callbacks
-from langchain.chains.api.openapi.requests_chain import APIRequesterChain
-from langchain.chains.api.openapi.response_chain import APIResponderChain
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.openapi.utils.api_models import APIOperation
-from langchain.utilities.requests import Requests
+from oplangchain.callbacks.manager import CallbackManagerForChainRun, Callbacks
+from oplangchain.chains.api.openapi.requests_chain import APIRequesterChain
+from oplangchain.chains.api.openapi.response_chain import APIResponderChain
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.openapi.utils.api_models import APIOperation
+from oplangchain.utilities.requests import Requests
 
 
 class _ParamMapping(NamedTuple):
     """Mapping from parameter name to parameter value."""
 
     query_params: List[str]
     body_params: List[str]
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/openapi/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/api/openapi/prompts.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/openapi/requests_chain.py` & `oplangchain-0.1.1/oplangchain/chains/api/openapi/requests_chain.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """request parser."""
 
 import json
 import re
 from typing import Any
 
-from langchain.chains.api.openapi.prompts import REQUEST_TEMPLATE
-from langchain.chains.llm import LLMChain
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseOutputParser
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.api.openapi.prompts import REQUEST_TEMPLATE
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseOutputParser
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class APIRequesterOutputParser(BaseOutputParser):
     """Parse the request and error tags."""
 
     def _load_json_block(self, serialized_block: str) -> str:
         try:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/openapi/response_chain.py` & `oplangchain-0.1.1/oplangchain/chains/api/openapi/response_chain.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Response parser."""
 
 import json
 import re
 from typing import Any
 
-from langchain.chains.api.openapi.prompts import RESPONSE_TEMPLATE
-from langchain.chains.llm import LLMChain
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseOutputParser
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.api.openapi.prompts import RESPONSE_TEMPLATE
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseOutputParser
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class APIResponderOutputParser(BaseOutputParser):
     """Parse the response and error tags."""
 
     def _load_json_block(self, serialized_block: str) -> str:
         try:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/podcast_docs.py` & `oplangchain-0.1.1/oplangchain/chains/api/podcast_docs.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/api/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 API_URL_PROMPT_TEMPLATE = """You are given the below API Documentation:
 {api_docs}
 Using this documentation, generate the full API url to call for answering the user question.
 You should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.
 
 Question:{question}
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/api/tmdb_docs.py` & `oplangchain-0.1.1/oplangchain/chains/api/tmdb_docs.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/base.py` & `oplangchain-0.1.1/oplangchain/chains/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,33 +6,33 @@
 from abc import ABC, abstractmethod
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Union
 
 import yaml
 from pydantic import Field, root_validator, validator
 
-import langchain
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import (
+import oplangchain
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForChainRun,
     CallbackManager,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.load.dump import dumpd
-from langchain.load.serializable import Serializable
-from langchain.schema import RUN_KEY, BaseMemory, RunInfo
-from langchain.schema.runnable import Runnable, RunnableConfig
+from oplangchain.load.dump import dumpd
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema import RUN_KEY, BaseMemory, RunInfo
+from oplangchain.schema.runnable import Runnable, RunnableConfig
 
 logger = logging.getLogger(__name__)
 
 
 def _get_verbosity() -> bool:
-    return langchain.verbose
+    return oplangchain.verbose
 
 
 class Chain(Serializable, Runnable[Dict[str, Any], Dict[str, Any]], ABC):
     """Abstract base class for creating structured sequences of calls to components.
 
     Chains should be used to encode a sequence of calls to components like
     models, document retrievers, other chains, etc., and provide a simple interface
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/chat_vector_db/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/chat_vector_db/prompts.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _template = """Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.
 
 Chat History:
 {chat_history}
 Follow Up Input: {question}
 Standalone question:"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/base.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Base interface for chains combining documents."""
 
 from abc import ABC, abstractmethod
 from typing import Any, Dict, List, Optional, Tuple
 
 from pydantic import Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.docstore.document import Document
-from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
+from oplangchain.chains.base import Chain
+from oplangchain.docstore.document import Document
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
 
 
 class BaseCombineDocumentsChain(Chain, ABC):
     """Base interface for chains combining documents.
 
     Subclasses of this chain deal with combining documents in a variety of
     ways. This base class exists to add some uniformity in the interface these types
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/map_reduce.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/map_reduce.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,41 +2,41 @@
 
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Tuple
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.reduce import ReduceDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.docstore.document import Document
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.reduce import ReduceDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.docstore.document import Document
 
 
 class MapReduceDocumentsChain(BaseCombineDocumentsChain):
     """Combining documents by mapping a chain over them, then combining results.
 
     We first call `llm_chain` on each document individually, passing in the
     `page_content` and any other kwargs. This is the `map` step.
 
     We then process the results of that `map` step in a `reduce` step. This should
     likely be a ReduceDocumentsChain.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import (
+            from oplangchain.chains import (
                 StuffDocumentsChain,
                 LLMChain,
                 ReduceDocumentsChain,
                 MapReduceDocumentsChain,
             )
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
 
             # This controls how each document will be formatted. Specifically,
             # it will be passed to `format_document` - see that function for more
             # details.
             document_prompt = PromptTemplate(
                 input_variables=["page_content"],
                  template="{page_content}"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/map_rerank.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/map_rerank.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,35 +2,35 @@
 
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union, cast
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.docstore.document import Document
-from langchain.output_parsers.regex import RegexParser
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.docstore.document import Document
+from oplangchain.output_parsers.regex import RegexParser
 
 
 class MapRerankDocumentsChain(BaseCombineDocumentsChain):
     """Combining documents by mapping a chain over them, then reranking results.
 
     This algorithm calls an LLMChain on each input document. The LLMChain is expected
     to have an OutputParser that parses the result into both an answer (`answer_key`)
     and a score (`rank_key`). The answer with the highest score is then returned.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import StuffDocumentsChain, LLMChain
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
-            from langchain.output_parsers.regex import RegexParser
+            from oplangchain.chains import StuffDocumentsChain, LLMChain
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
+            from oplangchain.output_parsers.regex import RegexParser
 
             document_variable_name = "context"
             llm = OpenAI()
             # The prompt here should take as an input variable the
             # `document_variable_name`
             # The actual prompt will need to be a lot more complex, this is just
             # an example.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/reduce.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/reduce.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 
 from __future__ import annotations
 
 from typing import Any, Callable, List, Optional, Protocol, Tuple
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.docstore.document import Document
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.docstore.document import Document
 
 
 class CombineDocsProtocol(Protocol):
     """Interface for the combine_docs method."""
 
     def __call__(self, docs: List[Document], **kwargs: Any) -> str:
         """Interface for the combine_docs method."""
@@ -94,19 +94,19 @@
     be passed to `combine_documents_chain` in one go. In this case,
     `collapse_documents_chain` is called recursively on as big of groups of documents
     as are allowed.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import (
+            from oplangchain.chains import (
                 StuffDocumentsChain, LLMChain, ReduceDocumentsChain
             )
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
 
             # This controls how each document will be formatted. Specifically,
             # it will be passed to `format_document` - see that function for more
             # details.
             document_prompt = PromptTemplate(
                 input_variables=["page_content"],
                  template="{page_content}"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/refine.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/refine.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,22 +2,22 @@
 
 from __future__ import annotations
 
 from typing import Any, Dict, List, Tuple
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import (
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import (
     BaseCombineDocumentsChain,
 )
-from langchain.chains.llm import LLMChain
-from langchain.docstore.document import Document
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BasePromptTemplate, format_document
+from oplangchain.chains.llm import LLMChain
+from oplangchain.docstore.document import Document
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BasePromptTemplate, format_document
 
 
 def _get_default_document_prompt() -> PromptTemplate:
     return PromptTemplate(input_variables=["page_content"], template="{page_content}")
 
 
 class RefineDocumentsChain(BaseCombineDocumentsChain):
@@ -31,17 +31,17 @@
     It calls `refine_llm_chain`,
     passing in that document with the variable name `document_variable_name`
     as well as the previous response with the variable name `initial_response_name`.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import RefineDocumentsChain, LLMChain
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
+            from oplangchain.chains import RefineDocumentsChain, LLMChain
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
 
             # This controls how each document will be formatted. Specifically,
             # it will be passed to `format_document` - see that function for more
             # details.
             document_prompt = PromptTemplate(
                 input_variables=["page_content"],
                  template="{page_content}"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/combine_documents/stuff.py` & `oplangchain-0.1.1/oplangchain/chains/combine_documents/stuff.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Chain that combines documents by stuffing into context."""
 
 from typing import Any, Dict, List, Optional, Tuple
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import (
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import (
     BaseCombineDocumentsChain,
 )
-from langchain.chains.llm import LLMChain
-from langchain.docstore.document import Document
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BasePromptTemplate, format_document
+from oplangchain.chains.llm import LLMChain
+from oplangchain.docstore.document import Document
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BasePromptTemplate, format_document
 
 
 def _get_default_document_prompt() -> PromptTemplate:
     return PromptTemplate(input_variables=["page_content"], template="{page_content}")
 
 
 class StuffDocumentsChain(BaseCombineDocumentsChain):
@@ -26,17 +26,17 @@
     and then joining them together with `document_separator`. It then adds that new
     string to the inputs with the variable name set by `document_variable_name`.
     Those inputs are then passed to the `llm_chain`.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import StuffDocumentsChain, LLMChain
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
+            from oplangchain.chains import StuffDocumentsChain, LLMChain
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
 
             # This controls how each document will be formatted. Specifically,
             # it will be passed to `format_document` - see that function for more
             # details.
             document_prompt = PromptTemplate(
                 input_variables=["page_content"],
                  template="{page_content}"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/constitutional_ai/base.py` & `oplangchain-0.1.1/oplangchain/chains/constitutional_ai/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 """Chain for applying constitutional principles to the outputs of another chain."""
 from typing import Any, Dict, List, Optional
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple
-from langchain.chains.constitutional_ai.principles import PRINCIPLES
-from langchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.constitutional_ai.models import ConstitutionalPrinciple
+from oplangchain.chains.constitutional_ai.principles import PRINCIPLES
+from oplangchain.chains.constitutional_ai.prompts import CRITIQUE_PROMPT, REVISION_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class ConstitutionalChain(Chain):
     """Chain for applying constitutional principles.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import OpenAI
-            from langchain.chains import LLMChain, ConstitutionalChain
-            from langchain.chains.constitutional_ai.models \
+            from oplangchain.llms import OpenAI
+            from oplangchain.chains import LLMChain, ConstitutionalChain
+            from oplangchain.chains.constitutional_ai.models \
                 import ConstitutionalPrinciple
 
             llm = OpenAI()
 
             qa_prompt = PromptTemplate(
                 template="Q: {question} A:",
                 input_variables=["question"],
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/constitutional_ai/principles.py` & `oplangchain-0.1.1/oplangchain/chains/constitutional_ai/principles.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Constitutional principles from https://arxiv.org/pdf/2212.08073.pdf (Bai et al. 2022)
 UnifiedObjectives v0.2 principles ("uo-*") adapted from https://examine.dev/docs/Unified_objectives.pdf (Samwald et al. 2023)
 """
 # flake8: noqa
 from typing import Dict
 
-from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple
+from oplangchain.chains.constitutional_ai.models import ConstitutionalPrinciple
 
 PRINCIPLES: Dict[str, ConstitutionalPrinciple] = {
     "harmful1": ConstitutionalPrinciple(
         name="harmful1",
         critique_request="Identify specific ways in which the assistants last response is harmful, unethical, racist, sexist, toxic, dangerous, or illegal.",
         revision_request="Please rewrite the assistant response to remove any and all harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.",
     ),
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/constitutional_ai/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/constitutional_ai/prompts.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # flake8: noqa
 from copy import deepcopy
 
-from langchain.prompts.few_shot import FewShotPromptTemplate
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.few_shot import FewShotPromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 critique_example = PromptTemplate(
     template="""Human: {input_prompt}
 
 Model: {output_from_model}
 
 Critique Request: {critique_request}
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/conversation/base.py` & `oplangchain-0.1.1/oplangchain/chains/conversation/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """Chain that carries on a conversation and calls an LLM."""
 from typing import Dict, List
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.chains.conversation.prompt import PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.memory.buffer import ConversationBufferMemory
-from langchain.schema import BaseMemory, BasePromptTemplate
+from oplangchain.chains.conversation.prompt import PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.memory.buffer import ConversationBufferMemory
+from oplangchain.schema import BaseMemory, BasePromptTemplate
 
 
 class ConversationChain(LLMChain):
     """Chain to have a conversation and load context from memory.
 
     Example:
         .. code-block:: python
 
-            from langchain import ConversationChain, OpenAI
+            from oplangchain import ConversationChain, OpenAI
 
             conversation = ConversationChain(llm=OpenAI())
     """
 
     memory: BaseMemory = Field(default_factory=ConversationBufferMemory)
     """Default memory store."""
     prompt: BasePromptTemplate = PROMPT
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/conversation/memory.py` & `oplangchain-0.1.1/oplangchain/chains/conversation/memory.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Memory modules for conversation prompts."""
 
-from langchain.memory.buffer import (
+from oplangchain.memory.buffer import (
     ConversationBufferMemory,
     ConversationStringBufferMemory,
 )
-from langchain.memory.buffer_window import ConversationBufferWindowMemory
-from langchain.memory.combined import CombinedMemory
-from langchain.memory.entity import ConversationEntityMemory
-from langchain.memory.kg import ConversationKGMemory
-from langchain.memory.summary import ConversationSummaryMemory
-from langchain.memory.summary_buffer import ConversationSummaryBufferMemory
+from oplangchain.memory.buffer_window import ConversationBufferWindowMemory
+from oplangchain.memory.combined import CombinedMemory
+from oplangchain.memory.entity import ConversationEntityMemory
+from oplangchain.memory.kg import ConversationKGMemory
+from oplangchain.memory.summary import ConversationSummaryMemory
+from oplangchain.memory.summary_buffer import ConversationSummaryBufferMemory
 
 # This is only for backwards compatibility.
 
 __all__ = [
     "ConversationSummaryBufferMemory",
     "ConversationSummaryMemory",
     "ConversationKGMemory",
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/conversation/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/conversation/prompt.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # flake8: noqa
-from langchain.memory.prompt import (
+from oplangchain.memory.prompt import (
     ENTITY_EXTRACTION_PROMPT,
     ENTITY_MEMORY_CONVERSATION_TEMPLATE,
     ENTITY_SUMMARIZATION_PROMPT,
     KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT,
     SUMMARY_PROMPT,
 )
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 DEFAULT_TEMPLATE = """The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
 
 Current conversation:
 {history}
 Human: {input}
 AI:"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/conversational_retrieval/base.py` & `oplangchain-0.1.1/oplangchain/chains/conversational_retrieval/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,29 +5,29 @@
 import warnings
 from abc import abstractmethod
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.chains.question_answering import load_qa_chain
-from langchain.schema import BasePromptTemplate, BaseRetriever, Document
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage
-from langchain.vectorstores.base import VectorStore
+from oplangchain.chains.base import Chain
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.question_answering import load_qa_chain
+from oplangchain.schema import BasePromptTemplate, BaseRetriever, Document
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage
+from oplangchain.vectorstores.base import VectorStore
 
 # Depending on the memory type and configuration, the chat history format may differ.
 # This needs to be consolidated.
 CHAT_TURN_TYPE = Union[Tuple[str, str], BaseMessage]
 
 
 _ROLE_MAP = {"human": "Human: ", "ai": "Assistant: "}
@@ -222,19 +222,19 @@
     3. The retrieved documents are passed to an LLM along with either the new question
     (default behavior) or the original question and chat history to generate a final
     response.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import (
+            from oplangchain.chains import (
                 StuffDocumentsChain, LLMChain, ConversationalRetrievalChain
             )
-            from langchain.prompts import PromptTemplate
-            from langchain.llms import OpenAI
+            from oplangchain.prompts import PromptTemplate
+            from oplangchain.llms import OpenAI
 
             combine_docs_chain = StuffDocumentsChain(...)
             vectorstore = ...
             retriever = vectorstore.as_retriever()
 
             # This controls how the standalone question is generated.
             # Should take `chat_history` and `question` as input variables.
@@ -374,15 +374,15 @@
     def _chain_type(self) -> str:
         return "chat-vector-db"
 
     @root_validator()
     def raise_deprecation(cls, values: Dict) -> Dict:
         warnings.warn(
             "`ChatVectorDBChain` is deprecated - "
-            "please use `from langchain.chains import ConversationalRetrievalChain`"
+            "please use `from oplangchain.chains import ConversationalRetrievalChain`"
         )
         return values
 
     def _get_docs(
         self,
         question: str,
         inputs: Dict[str, Any],
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/conversational_retrieval/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/conversational_retrieval/prompts.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _template = """Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.
 
 Chat History:
 {chat_history}
 Follow Up Input: {question}
 Standalone question:"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/elasticsearch_database/base.py` & `oplangchain-0.1.1/oplangchain/chains/elasticsearch_database/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,35 +1,35 @@
 """Chain for interacting with Elasticsearch Database."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.elasticsearch_database.prompts import ANSWER_PROMPT, DSL_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.output_parsers.json import SimpleJsonOutputParser
-from langchain.schema import BaseLLMOutputParser, BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.elasticsearch_database.prompts import ANSWER_PROMPT, DSL_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.output_parsers.json import SimpleJsonOutputParser
+from oplangchain.schema import BaseLLMOutputParser, BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 if TYPE_CHECKING:
     from elasticsearch import Elasticsearch
 
 INTERMEDIATE_STEPS_KEY = "intermediate_steps"
 
 
 class ElasticsearchDatabaseChain(Chain):
     """Chain for interacting with Elasticsearch Database.
 
     Example:
         .. code-block:: python
 
-            from langchain import ElasticsearchDatabaseChain, OpenAI
+            from oplangchain import ElasticsearchDatabaseChain, OpenAI
             from elasticsearch import Elasticsearch
 
             database = Elasticsearch("http://localhost:9200")
             db_chain = ElasticsearchDatabaseChain.from_llm(OpenAI(), database)
     """
 
     query_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/elasticsearch_database/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/elasticsearch_database/prompts.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 PROMPT_SUFFIX = """Only use the following Elasticsearch indices:
 {indices_info}
 
 Question: {input}
 ESQuery:"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/example_generator.py` & `oplangchain-0.1.1/oplangchain/chains/example_generator.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import List
 
-from langchain.chains.llm import LLMChain
-from langchain.prompts.few_shot import FewShotPromptTemplate
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.few_shot import FewShotPromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 TEST_GEN_TEMPLATE_SUFFIX = "Add another example."
 
 
 def generate_example(
     examples: List[dict], llm: BaseLanguageModel, prompt_template: PromptTemplate
 ) -> str:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/flare/base.py` & `oplangchain-0.1.1/oplangchain/chains/flare/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,27 +3,27 @@
 import re
 from abc import abstractmethod
 from typing import Any, Dict, List, Optional, Sequence, Tuple
 
 import numpy as np
 from pydantic import Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.chains.flare.prompts import (
+from oplangchain.chains.base import Chain
+from oplangchain.chains.flare.prompts import (
     PROMPT,
     QUESTION_GENERATOR_PROMPT,
     FinishedOutputParser,
 )
-from langchain.chains.llm import LLMChain
-from langchain.llms import OpenAI
-from langchain.schema import BasePromptTemplate, BaseRetriever, Generation
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms import OpenAI
+from oplangchain.schema import BasePromptTemplate, BaseRetriever, Generation
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class _ResponseChain(LLMChain):
     """Base class for chains that generate responses."""
 
     prompt: BasePromptTemplate = PROMPT
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/flare/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/flare/prompts.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Tuple
 
-from langchain.prompts import PromptTemplate
-from langchain.schema import BaseOutputParser
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema import BaseOutputParser
 
 
 class FinishedOutputParser(BaseOutputParser[Tuple[str, bool]]):
     """Output parser that checks if the output is finished."""
 
     finished_value: str = "FINISHED"
     """Value that indicates the output is finished."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/arangodb.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/arangodb.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,25 +2,25 @@
 from __future__ import annotations
 
 import re
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.base_language import BaseLanguageModel
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import (
+from oplangchain.base_language import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import (
     AQL_FIX_PROMPT,
     AQL_GENERATION_PROMPT,
     AQL_QA_PROMPT,
 )
-from langchain.chains.llm import LLMChain
-from langchain.graphs.arangodb_graph import ArangoGraph
-from langchain.schema import BasePromptTemplate
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.arangodb_graph import ArangoGraph
+from oplangchain.schema import BasePromptTemplate
 
 
 class ArangoGraphQAChain(Chain):
     """Chain for question-answering against a graph by generating AQL statements."""
 
     graph: ArangoGraph = Field(exclude=True)
     aql_generation_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/base.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Question answering over a graph."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import ENTITY_EXTRACTION_PROMPT, GRAPH_QA_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.graphs.networkx_graph import NetworkxEntityGraph, get_entities
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import ENTITY_EXTRACTION_PROMPT, GRAPH_QA_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.networkx_graph import NetworkxEntityGraph, get_entities
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class GraphQAChain(Chain):
     """Chain for question-answering against a graph."""
 
     graph: NetworkxEntityGraph = Field(exclude=True)
     entity_extraction_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/cypher.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/cypher.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 from __future__ import annotations
 
 import re
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import CYPHER_GENERATION_PROMPT, CYPHER_QA_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.graphs.neo4j_graph import Neo4jGraph
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import CYPHER_GENERATION_PROMPT, CYPHER_QA_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.neo4j_graph import Neo4jGraph
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 INTERMEDIATE_STEPS_KEY = "intermediate_steps"
 
 
 def extract_cypher(text: str) -> str:
     """Extract Cypher code from a text.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/hugegraph.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/hugegraph.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """Question answering over a graph."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import (
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import (
     CYPHER_QA_PROMPT,
     GREMLIN_GENERATION_PROMPT,
 )
-from langchain.chains.llm import LLMChain
-from langchain.graphs.hugegraph import HugeGraph
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.hugegraph import HugeGraph
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class HugeGraphQAChain(Chain):
     """Chain for question-answering against a graph by generating gremlin statements."""
 
     graph: HugeGraph = Field(exclude=True)
     gremlin_generation_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/kuzu.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/kuzu.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Question answering over a graph."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import CYPHER_QA_PROMPT, KUZU_GENERATION_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.graphs.kuzu_graph import KuzuGraph
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import CYPHER_QA_PROMPT, KUZU_GENERATION_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.kuzu_graph import KuzuGraph
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class KuzuQAChain(Chain):
     """Chain for question-answering against a graph by generating Cypher statements for
     Kzu.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/nebulagraph.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/nebulagraph.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Question answering over a graph."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import CYPHER_QA_PROMPT, NGQL_GENERATION_PROMPT
-from langchain.chains.llm import LLMChain
-from langchain.graphs.nebula_graph import NebulaGraph
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import CYPHER_QA_PROMPT, NGQL_GENERATION_PROMPT
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.nebula_graph import NebulaGraph
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class NebulaGraphQAChain(Chain):
     """Chain for question-answering against a graph by generating nGQL statements."""
 
     graph: NebulaGraph = Field(exclude=True)
     ngql_generation_chain: LLMChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/neptune_cypher.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/neptune_cypher.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from __future__ import annotations
 
 import re
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.base_language import BaseLanguageModel
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import (
+from oplangchain.base_language import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import (
     CYPHER_QA_PROMPT,
     NEPTUNE_OPENCYPHER_GENERATION_PROMPT,
 )
-from langchain.chains.llm import LLMChain
-from langchain.graphs import NeptuneGraph
-from langchain.prompts.base import BasePromptTemplate
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs import NeptuneGraph
+from oplangchain.prompts.base import BasePromptTemplate
 
 INTERMEDIATE_STEPS_KEY = "intermediate_steps"
 
 
 def extract_cypher(text: str) -> str:
     """Extract Cypher code from text using Regex."""
     # The pattern to find Cypher code enclosed in triple backticks
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/prompts.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_ENTITY_EXTRACTION_TEMPLATE = """Extract all entities from the following text. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.
 
 Return the output as a single comma-separated list, or NONE if there is nothing of note to return.
 
 EXAMPLE
 i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/graph_qa/sparql.py` & `oplangchain-0.1.1/oplangchain/chains/graph_qa/sparql.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,26 +3,26 @@
 """
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.graph_qa.prompts import (
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.graph_qa.prompts import (
     SPARQL_GENERATION_SELECT_PROMPT,
     SPARQL_GENERATION_UPDATE_PROMPT,
     SPARQL_INTENT_PROMPT,
     SPARQL_QA_PROMPT,
 )
-from langchain.chains.llm import LLMChain
-from langchain.graphs.rdf_graph import RdfGraph
-from langchain.prompts.base import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.rdf_graph import RdfGraph
+from oplangchain.prompts.base import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class GraphSparqlQAChain(Chain):
     """
     Chain for question-answering against an RDF or OWL graph by generating
     SPARQL statements.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/hyde/base.py` & `oplangchain-0.1.1/oplangchain/chains/hyde/base.py`

 * *Files 5% similar despite different names*

```diff
@@ -5,20 +5,20 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 import numpy as np
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.hyde.prompts import PROMPT_MAP
-from langchain.chains.llm import LLMChain
-from langchain.embeddings.base import Embeddings
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.hyde.prompts import PROMPT_MAP
+from oplangchain.chains.llm import LLMChain
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class HypotheticalDocumentEmbedder(Chain, Embeddings):
     """Generate hypothetical document for query, and then embed that.
 
     Based on https://arxiv.org/abs/2212.10496
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/hyde/prompts.py` & `oplangchain-0.1.1/oplangchain/chains/hyde/prompts.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 web_search_template = """Please write a passage to answer the question 
 Question: {QUESTION}
 Passage:"""
 web_search = PromptTemplate(template=web_search_template, input_variables=["QUESTION"])
 sci_fact_template = """Please write a scientific paper passage to support/refute the claim 
 Claim: {Claim}
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm.py` & `oplangchain-0.1.1/oplangchain/chains/llm.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,42 +2,42 @@
 from __future__ import annotations
 
 import warnings
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union
 
 from pydantic import Extra, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForChainRun,
     CallbackManager,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.load.dump import dumpd
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import (
+from oplangchain.chains.base import Chain
+from oplangchain.load.dump import dumpd
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import (
     BaseLLMOutputParser,
     BasePromptTemplate,
     LLMResult,
     PromptValue,
     StrOutputParser,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.utils.input import get_colored_text
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.utils.input import get_colored_text
 
 
 class LLMChain(Chain):
     """Chain to run queries against LLMs.
 
     Example:
         .. code-block:: python
 
-            from langchain import LLMChain, OpenAI, PromptTemplate
+            from oplangchain import LLMChain, OpenAI, PromptTemplate
             prompt_template = "Tell me a {adjective} joke"
             prompt = PromptTemplate(
                 input_variables=["adjective"], template=prompt_template
             )
             llm = LLMChain(llm=OpenAI(), prompt=prompt)
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_bash/base.py` & `oplangchain-0.1.1/oplangchain/chains/llm_bash/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -3,32 +3,32 @@
 
 import logging
 import warnings
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_bash.prompt import PROMPT
-from langchain.schema import BasePromptTemplate, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.utilities.bash import BashProcess
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_bash.prompt import PROMPT
+from oplangchain.schema import BasePromptTemplate, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.utilities.bash import BashProcess
 
 logger = logging.getLogger(__name__)
 
 
 class LLMBashChain(Chain):
     """Chain that interprets a prompt and executes bash operations.
 
     Example:
         .. code-block:: python
 
-            from langchain import LLMBashChain, OpenAI
+            from oplangchain import LLMBashChain, OpenAI
             llm_bash = LLMBashChain.from_llm(OpenAI())
     """
 
     llm_chain: LLMChain
     llm: Optional[BaseLanguageModel] = None
     """[Deprecated] LLM wrapper to use."""
     input_key: str = "question"  #: :meta private:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_bash/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/llm_bash/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # flake8: noqa
 from __future__ import annotations
 
 import re
 from typing import List
 
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseOutputParser, OutputParserException
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseOutputParser, OutputParserException
 
 _PROMPT_TEMPLATE = """If someone asks you to perform a task, your job is to come up with a series of bash commands that will perform the task. There is no need to put "#!/bin/bash" in your answer. Make sure to reason step by step, using this format:
 
 Question: "copy the files in the directory named 'target' into a new directory at the same level as target called 'myNewDirectory'"
 
 I need to take the following actions:
 - List all files in the directory
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_checker/base.py` & `oplangchain-0.1.1/oplangchain/chains/llm_checker/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,26 +2,26 @@
 from __future__ import annotations
 
 import warnings
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_checker.prompt import (
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_checker.prompt import (
     CHECK_ASSERTIONS_PROMPT,
     CREATE_DRAFT_ANSWER_PROMPT,
     LIST_ASSERTIONS_PROMPT,
     REVISED_ANSWER_PROMPT,
 )
-from langchain.chains.sequential import SequentialChain
-from langchain.prompts import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.sequential import SequentialChain
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def _load_question_to_checked_assertions_chain(
     llm: BaseLanguageModel,
     create_draft_answer_prompt: PromptTemplate,
     list_assertions_prompt: PromptTemplate,
     check_assertions_prompt: PromptTemplate,
@@ -64,15 +64,15 @@
 
 class LLMCheckerChain(Chain):
     """Chain for question-answering with self-verification.
 
     Example:
         .. code-block:: python
 
-            from langchain import OpenAI, LLMCheckerChain
+            from oplangchain import OpenAI, LLMCheckerChain
             llm = OpenAI(temperature=0.7)
             checker_chain = LLMCheckerChain.from_llm(llm)
     """
 
     question_to_checked_assertions_chain: SequentialChain
 
     llm: Optional[BaseLanguageModel] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_checker/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/llm_checker/prompt.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _CREATE_DRAFT_ANSWER_TEMPLATE = """{question}\n\n"""
 CREATE_DRAFT_ANSWER_PROMPT = PromptTemplate(
     input_variables=["question"], template=_CREATE_DRAFT_ANSWER_TEMPLATE
 )
 
 _LIST_ASSERTIONS_TEMPLATE = """Here is a statement:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_math/base.py` & `oplangchain-0.1.1/oplangchain/chains/llm_math/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,32 +5,32 @@
 import re
 import warnings
 from typing import Any, Dict, List, Optional
 
 import numexpr
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_math.prompt import PROMPT
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_math.prompt import PROMPT
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class LLMMathChain(Chain):
     """Chain that interprets a prompt and executes python code to do math.
 
     Example:
         .. code-block:: python
 
-            from langchain import LLMMathChain, OpenAI
+            from oplangchain import LLMMathChain, OpenAI
             llm_math = LLMMathChain.from_llm(OpenAI())
     """
 
     llm_chain: LLMChain
     llm: Optional[BaseLanguageModel] = None
     """[Deprecated] LLM wrapper to use."""
     prompt: BasePromptTemplate = PROMPT
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_math/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/llm_math/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _PROMPT_TEMPLATE = """Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.
 
 Question: ${{Question with math problem.}}
 ```text
 ${{single line mathematical expression that solves the problem}}
 ```
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_requests.py` & `oplangchain-0.1.1/oplangchain/chains/llm_requests.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Chain that hits a URL and then uses an LLM to parse results."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains import LLMChain
-from langchain.chains.base import Chain
-from langchain.utilities.requests import TextRequestsWrapper
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains import LLMChain
+from oplangchain.chains.base import Chain
+from oplangchain.utilities.requests import TextRequestsWrapper
 
 DEFAULT_HEADERS = {
     "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36"  # noqa: E501
 }
 
 
 class LLMRequestsChain(Chain):
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/base.py` & `oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,20 +4,20 @@
 
 import warnings
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.sequential import SequentialChain
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.sequential import SequentialChain
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 PROMPTS_DIR = Path(__file__).parent / "prompts"
 
 CREATE_ASSERTIONS_PROMPT = PromptTemplate.from_file(
     PROMPTS_DIR / "create_facts.txt", ["summary"]
 )
 CHECK_ASSERTIONS_PROMPT = PromptTemplate.from_file(
@@ -75,15 +75,15 @@
 
 class LLMSummarizationCheckerChain(Chain):
     """Chain for question-answering with self-verification.
 
     Example:
         .. code-block:: python
 
-            from langchain import OpenAI, LLMSummarizationCheckerChain
+            from oplangchain import OpenAI, LLMSummarizationCheckerChain
             llm = OpenAI(temperature=0.0)
             checker_chain = LLMSummarizationCheckerChain.from_llm(llm)
     """
 
     sequential_chain: SequentialChain
     llm: Optional[BaseLanguageModel] = None
     """[Deprecated] LLM wrapper to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_summarization_checker/prompts/are_all_true_prompt.txt` & `oplangchain-0.1.1/oplangchain/chains/llm_summarization_checker/prompts/are_all_true_prompt.txt`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_symbolic_math/base.py` & `oplangchain-0.1.1/oplangchain/chains/llm_symbolic_math/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,32 +2,32 @@
 from __future__ import annotations
 
 import re
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra
 
-from langchain.base_language import BaseLanguageModel
-from langchain.callbacks.manager import (
+from oplangchain.base_language import BaseLanguageModel
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_symbolic_math.prompt import PROMPT
-from langchain.prompts.base import BasePromptTemplate
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_symbolic_math.prompt import PROMPT
+from oplangchain.prompts.base import BasePromptTemplate
 
 
 class LLMSymbolicMathChain(Chain):
     """Chain that interprets a prompt and executes python code to do symbolic math.
 
     Example:
         .. code-block:: python
 
-            from langchain import LLMSymbolicMathChain, OpenAI
+            from oplangchain import LLMSymbolicMathChain, OpenAI
             llm_symbolic_math = LLMSymbolicMathChain.from_llm(OpenAI())
     """
 
     llm_chain: LLMChain
     input_key: str = "question"  #: :meta private:
     output_key: str = "answer"  #: :meta private:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/llm_symbolic_math/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/llm_symbolic_math/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _PROMPT_TEMPLATE = """Translate a math problem into a expression that can be executed using Python's SymPy library. Use the output of running this code to answer the question.
 
 Question: ${{Question with math problem.}}
 ```text
 ${{single line sympy expression that solves the problem}}
 ```
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/loading.py` & `oplangchain-0.1.1/oplangchain/chains/loading.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,38 +1,38 @@
 """Functionality for loading chains."""
 import json
 from pathlib import Path
 from typing import Any, Union
 
 import yaml
 
-from langchain.chains import ReduceDocumentsChain
-from langchain.chains.api.base import APIChain
-from langchain.chains.base import Chain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
-from langchain.chains.combine_documents.refine import RefineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.graph_qa.cypher import GraphCypherQAChain
-from langchain.chains.hyde.base import HypotheticalDocumentEmbedder
-from langchain.chains.llm import LLMChain
-from langchain.chains.llm_bash.base import LLMBashChain
-from langchain.chains.llm_checker.base import LLMCheckerChain
-from langchain.chains.llm_math.base import LLMMathChain
-from langchain.chains.llm_requests import LLMRequestsChain
-from langchain.chains.qa_with_sources.base import QAWithSourcesChain
-from langchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain
-from langchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA
-from langchain.llms.loading import load_llm, load_llm_from_config
-from langchain.prompts.loading import (
+from oplangchain.chains import ReduceDocumentsChain
+from oplangchain.chains.api.base import APIChain
+from oplangchain.chains.base import Chain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
+from oplangchain.chains.combine_documents.refine import RefineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.graph_qa.cypher import GraphCypherQAChain
+from oplangchain.chains.hyde.base import HypotheticalDocumentEmbedder
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.llm_bash.base import LLMBashChain
+from oplangchain.chains.llm_checker.base import LLMCheckerChain
+from oplangchain.chains.llm_math.base import LLMMathChain
+from oplangchain.chains.llm_requests import LLMRequestsChain
+from oplangchain.chains.qa_with_sources.base import QAWithSourcesChain
+from oplangchain.chains.qa_with_sources.vector_db import VectorDBQAWithSourcesChain
+from oplangchain.chains.retrieval_qa.base import RetrievalQA, VectorDBQA
+from oplangchain.llms.loading import load_llm, load_llm_from_config
+from oplangchain.prompts.loading import (
     _load_output_parser,
     load_prompt,
     load_prompt_from_config,
 )
-from langchain.utilities.loading import try_load_from_hub
+from oplangchain.utilities.loading import try_load_from_hub
 
 URL_BASE = "https://raw.githubusercontent.com/hwchase17/langchain-hub/master/chains/"
 
 
 def _load_llm_chain(config: dict, **kwargs: Any) -> LLMChain:
     """Load LLM chain from config dict."""
     if "llm" in config:
@@ -294,15 +294,15 @@
         llm_chain = load_chain(config.pop("llm_chain_path"))
     else:
         raise ValueError("One of `llm_chain` or `llm_chain_config` must be present.")
     return MapRerankDocumentsChain(llm_chain=llm_chain, **config)
 
 
 def _load_pal_chain(config: dict, **kwargs: Any) -> Any:
-    from langchain_experimental.pal_chain import PALChain
+    from oplangchain_experimental.pal_chain import PALChain
 
     if "llm_chain" in config:
         llm_chain_config = config.pop("llm_chain")
         llm_chain = load_chain_from_config(llm_chain_config)
     elif "llm_chain_path" in config:
         llm_chain = load_chain(config.pop("llm_chain_path"))
     else:
@@ -369,15 +369,15 @@
     else:
         raise ValueError("One of `llm` or `llm_path` must be present.")
     if "prompt" in config:
         prompt_config = config.pop("prompt")
         prompt = load_prompt_from_config(prompt_config)
     else:
         prompt = None
-    from langchain_experimental.sql import SQLDatabaseChain
+    from oplangchain_experimental.sql import SQLDatabaseChain
 
     return SQLDatabaseChain.from_llm(llm, database, prompt=prompt, **config)
 
 
 def _load_vector_db_qa_with_sources_chain(
     config: dict, **kwargs: Any
 ) -> VectorDBQAWithSourcesChain:
@@ -551,15 +551,15 @@
         raise ValueError(f"Loading {config_type} chain not supported")
 
     chain_loader = type_to_loader_dict[config_type]
     return chain_loader(config, **kwargs)
 
 
 def load_chain(path: Union[str, Path], **kwargs: Any) -> Chain:
-    """Unified method for loading a chain from LangChainHub or local fs."""
+    """Unified method for loading a chain from oplangchainHub or local fs."""
     if hub_result := try_load_from_hub(
         path, _load_chain_from_file, "chains", {"json", "yaml"}, **kwargs
     ):
         return hub_result
     else:
         return _load_chain_from_file(path, **kwargs)
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/mapreduce.py` & `oplangchain-0.1.1/oplangchain/chains/mapreduce.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,25 +5,25 @@
 """
 from __future__ import annotations
 
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForChainRun, Callbacks
-from langchain.chains import ReduceDocumentsChain
-from langchain.chains.base import Chain
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.docstore.document import Document
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.text_splitter import TextSplitter
+from oplangchain.callbacks.manager import CallbackManagerForChainRun, Callbacks
+from oplangchain.chains import ReduceDocumentsChain
+from oplangchain.chains.base import Chain
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.text_splitter import TextSplitter
 
 
 class MapReduceChain(Chain):
     """Map-reduce chain."""
 
     combine_documents_chain: BaseCombineDocumentsChain
     """Chain to use to combine documents."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/moderation.py` & `oplangchain-0.1.1/oplangchain/chains/moderation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 """Pass input through a moderation endpoint."""
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.utils import get_from_dict_or_env
 
 
 class OpenAIModerationChain(Chain):
     """Pass input through a moderation endpoint.
 
     To use, you should have the ``openai`` python package installed, and the
     environment variable ``OPENAI_API_KEY`` set with your API key.
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.chains import OpenAIModerationChain
+            from oplangchain.chains import OpenAIModerationChain
             moderation = OpenAIModerationChain()
     """
 
     client: Any  #: :meta private:
     model_name: Optional[str] = None
     """Moderation model name to use."""
     error: bool = False
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/natbot/base.py` & `oplangchain-0.1.1/oplangchain/chains/natbot/base.py`

 * *Files 5% similar despite different names*

```diff
@@ -2,29 +2,29 @@
 from __future__ import annotations
 
 import warnings
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.natbot.prompt import PROMPT
-from langchain.llms.openai import OpenAI
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.natbot.prompt import PROMPT
+from oplangchain.llms.openai import OpenAI
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class NatBotChain(Chain):
     """Implement an LLM driven browser.
 
     Example:
         .. code-block:: python
 
-            from langchain import NatBotChain
+            from oplangchain import NatBotChain
             natbot = NatBotChain.from_default("Buy me a new hat.")
     """
 
     llm_chain: LLMChain
     objective: str
     """Objective that NatBot is tasked with completing."""
     llm: Optional[BaseLanguageModel] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/natbot/crawler.py` & `oplangchain-0.1.1/oplangchain/chains/natbot/crawler.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/natbot/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/natbot/prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _PROMPT_TEMPLATE = """
 You are an agents controlling a browser. You are given:
 
 	(1) an objective that you are trying to achieve
 	(2) the URL of your current web page
 	(3) a simplified text description of what's visible in the browser window (more on that below)
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/__init__.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-from langchain.chains.openai_functions.base import (
+from oplangchain.chains.openai_functions.base import (
     create_openai_fn_chain,
     create_structured_output_chain,
 )
-from langchain.chains.openai_functions.citation_fuzzy_match import (
+from oplangchain.chains.openai_functions.citation_fuzzy_match import (
     create_citation_fuzzy_match_chain,
 )
-from langchain.chains.openai_functions.extraction import (
+from oplangchain.chains.openai_functions.extraction import (
     create_extraction_chain,
     create_extraction_chain_pydantic,
 )
-from langchain.chains.openai_functions.qa_with_structure import (
+from oplangchain.chains.openai_functions.qa_with_structure import (
     create_qa_with_sources_chain,
     create_qa_with_structure_chain,
 )
-from langchain.chains.openai_functions.tagging import (
+from oplangchain.chains.openai_functions.tagging import (
     create_tagging_chain,
     create_tagging_chain_pydantic,
 )
 
 __all__ = [
     "create_tagging_chain",
     "create_tagging_chain_pydantic",
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/base.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,23 +10,23 @@
     Tuple,
     Type,
     Union,
 )
 
 from pydantic import BaseModel
 
-from langchain.base_language import BaseLanguageModel
-from langchain.chains import LLMChain
-from langchain.output_parsers.openai_functions import (
+from oplangchain.base_language import BaseLanguageModel
+from oplangchain.chains import LLMChain
+from oplangchain.output_parsers.openai_functions import (
     JsonOutputFunctionsParser,
     PydanticAttrOutputFunctionsParser,
     PydanticOutputFunctionsParser,
 )
-from langchain.prompts import BasePromptTemplate
-from langchain.schema import BaseLLMOutputParser
+from oplangchain.prompts import BasePromptTemplate
+from oplangchain.schema import BaseLLMOutputParser
 
 PYTHON_TO_JSON_TYPES = {
     "str": "string",
     "int": "number",
     "float": "number",
     "bool": "boolean",
 }
@@ -216,17 +216,17 @@
 
     Returns:
         An LLMChain that will pass in the given functions to the model when run.
 
     Example:
         .. code-block:: python
 
-                from langchain.chains.openai_functions import create_openai_fn_chain
-                from langchain.chat_models import ChatOpenAI
-                from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
+                from oplangchain.chains.openai_functions import create_openai_fn_chain
+                from oplangchain.chat_models import ChatOpenAI
+                from oplangchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
 
                 from pydantic import BaseModel, Field
 
 
                 class RecordPerson(BaseModel):
                     \"\"\"Record some identifying information about a person.\"\"\"
 
@@ -302,17 +302,17 @@
 
     Returns:
         An LLMChain that will pass the given function to the model.
 
     Example:
         .. code-block:: python
 
-                from langchain.chains.openai_functions import create_structured_output_chain
-                from langchain.chat_models import ChatOpenAI
-                from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
+                from oplangchain.chains.openai_functions import create_structured_output_chain
+                from oplangchain.chat_models import ChatOpenAI
+                from oplangchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
 
                 from pydantic import BaseModel, Field
 
                 class Dog(BaseModel):
                     \"\"\"Identifying information about a dog.\"\"\"
 
                     name: str = Field(..., description="The dog's name")
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/citation_fuzzy_match.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/citation_fuzzy_match.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from typing import Iterator, List
 
 from pydantic import BaseModel, Field
 
-from langchain.chains.llm import LLMChain
-from langchain.chains.openai_functions.utils import get_llm_kwargs
-from langchain.output_parsers.openai_functions import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.openai_functions.utils import get_llm_kwargs
+from oplangchain.output_parsers.openai_functions import (
     PydanticOutputFunctionsParser,
 )
-from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import HumanMessage, SystemMessage
+from oplangchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import HumanMessage, SystemMessage
 
 
 class FactWithEvidence(BaseModel):
     """Class representing a single statement.
 
     Each fact has a body and a list of sources.
     If there are multiple facts make sure to break them apart
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/extraction.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/extraction.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from typing import Any, List
 
 from pydantic import BaseModel
 
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.openai_functions.utils import (
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.openai_functions.utils import (
     _convert_schema,
     _resolve_schema_references,
     get_llm_kwargs,
 )
-from langchain.output_parsers.openai_functions import (
+from oplangchain.output_parsers.openai_functions import (
     JsonKeyOutputFunctionsParser,
     PydanticAttrOutputFunctionsParser,
 )
-from langchain.prompts import ChatPromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.prompts import ChatPromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def _get_extraction_function(entity_schema: dict) -> dict:
     return {
         "name": "information_extraction",
         "description": "Extracts the relevant information from the passage.",
         "parameters": {
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/openapi.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/openapi.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,26 +3,26 @@
 from collections import defaultdict
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import requests
 from openapi_schema_pydantic import Parameter
 from requests import Response
 
-from langchain import LLMChain
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.sequential import SequentialChain
-from langchain.chat_models import ChatOpenAI
-from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser
-from langchain.prompts import ChatPromptTemplate
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools import APIOperation
-from langchain.utilities.openapi import OpenAPISpec
-from langchain.utils.input import get_colored_text
+from oplangchain import LLMChain
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.sequential import SequentialChain
+from oplangchain.chat_models import ChatOpenAI
+from oplangchain.output_parsers.openai_functions import JsonOutputFunctionsParser
+from oplangchain.prompts import ChatPromptTemplate
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools import APIOperation
+from oplangchain.utilities.openapi import OpenAPISpec
+from oplangchain.utils.input import get_colored_text
 
 
 def _get_description(o: Any, prefer_short: bool) -> Optional[str]:
     summary = getattr(o, "summary", None)
     description = getattr(o, "description", None)
     if prefer_short:
         return summary or description
@@ -240,15 +240,15 @@
     request_chain: Optional[Chain] = None,
     llm_chain_kwargs: Optional[Dict] = None,
     verbose: bool = False,
     headers: Optional[Dict] = None,
     params: Optional[Dict] = None,
     **kwargs: Any,
 ) -> SequentialChain:
-    print("STARTING")
+    print("get_openapi_chain STARTING")
     """Create a chain for querying an API from a OpenAPI spec.
 
     Args:
         spec: OpenAPISpec or url/file/text string corresponding to one.
         llm: language model, should be an OpenAI function-calling model, e.g.
             `ChatOpenAI(model="gpt-3.5-turbo-0613")`.
         prompt: Main prompt template to use.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/qa_with_structure.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/qa_with_structure.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from typing import Any, List, Optional, Type, Union
 
 from pydantic import BaseModel, Field
 
-from langchain.chains.llm import LLMChain
-from langchain.chains.openai_functions.utils import get_llm_kwargs
-from langchain.output_parsers.openai_functions import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.openai_functions.utils import get_llm_kwargs
+from oplangchain.output_parsers.openai_functions import (
     OutputFunctionsParser,
     PydanticOutputFunctionsParser,
 )
-from langchain.prompts import PromptTemplate
-from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate
-from langchain.schema import BaseLLMOutputParser
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import HumanMessage, SystemMessage
+from oplangchain.prompts import PromptTemplate
+from oplangchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate
+from oplangchain.schema import BaseLLMOutputParser
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import HumanMessage, SystemMessage
 
 
 class AnswerWithSources(BaseModel):
     """An answer to the question, with sources."""
 
     answer: str = Field(..., description="Answer to the question that was asked")
     sources: List[str] = Field(
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/tagging.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/tagging.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from typing import Any, Optional
 
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.openai_functions.utils import _convert_schema, get_llm_kwargs
-from langchain.output_parsers.openai_functions import (
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.openai_functions.utils import _convert_schema, get_llm_kwargs
+from oplangchain.output_parsers.openai_functions import (
     JsonOutputFunctionsParser,
     PydanticOutputFunctionsParser,
 )
-from langchain.prompts import ChatPromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.prompts import ChatPromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def _get_tagging_function(schema: dict) -> dict:
     return {
         "name": "information_extraction",
         "description": "Extracts the relevant information from the passage.",
         "parameters": _convert_schema(schema),
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/openai_functions/utils.py` & `oplangchain-0.1.1/oplangchain/chains/openai_functions/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/prompt_selector.py` & `oplangchain-0.1.1/oplangchain/chains/prompt_selector.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from abc import ABC, abstractmethod
 from typing import Callable, List, Tuple
 
 from pydantic import BaseModel, Field
 
-from langchain.chat_models.base import BaseChatModel
-from langchain.llms.base import BaseLLM
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.llms.base import BaseLLM
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class BasePromptSelector(BaseModel, ABC):
     """Base class for prompt selectors."""
 
     @abstractmethod
     def get_prompt(self, llm: BaseLanguageModel) -> BasePromptTemplate:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_generation/base.py` & `oplangchain-0.1.1/oplangchain/chains/qa_generation/base.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
 import json
 from typing import Any, Dict, List, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.chains.qa_generation.prompt import PROMPT_SELECTOR
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.qa_generation.prompt import PROMPT_SELECTOR
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
 
 
 class QAGenerationChain(Chain):
     """Base class for question-answer generation chains."""
 
     llm_chain: LLMChain
     """LLM Chain that generates responses from user input and context."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_generation/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/qa_generation/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # flake8: noqa
-from langchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
-from langchain.prompts.chat import (
+from oplangchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 templ1 = """You are a smart assistant designed to help high school teachers come up with reading comprehension questions.
 Given a piece of text, you must come up with a question and answer pair that can be used to test a student's reading comprehension abilities.
 When coming up with this question/answer pair, you must respond in the following format:
 ```
 {{
     "question": "$YOUR_QUESTION_HERE",
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/base.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/base.py`

 * *Files 12% similar despite different names*

```diff
@@ -5,33 +5,33 @@
 import inspect
 import re
 from abc import ABC, abstractmethod
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains import ReduceDocumentsChain
-from langchain.chains.base import Chain
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain
-from langchain.chains.qa_with_sources.map_reduce_prompt import (
+from oplangchain.chains import ReduceDocumentsChain
+from oplangchain.chains.base import Chain
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.qa_with_sources.loading import load_qa_with_sources_chain
+from oplangchain.chains.qa_with_sources.map_reduce_prompt import (
     COMBINE_PROMPT,
     EXAMPLE_PROMPT,
     QUESTION_PROMPT,
 )
-from langchain.docstore.document import Document
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class BaseQAWithSourcesChain(Chain, ABC):
     """Question answering chain with sources over documents."""
 
     combine_documents_chain: BaseCombineDocumentsChain
     """Chain to use to combine documents."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/loading.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/loading.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 """Load question answering with sources chains."""
 from __future__ import annotations
 
 from typing import Any, Mapping, Optional, Protocol
 
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
-from langchain.chains.combine_documents.reduce import ReduceDocumentsChain
-from langchain.chains.combine_documents.refine import RefineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.qa_with_sources import (
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
+from oplangchain.chains.combine_documents.reduce import ReduceDocumentsChain
+from oplangchain.chains.combine_documents.refine import RefineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.qa_with_sources import (
     map_reduce_prompt,
     refine_prompts,
     stuff_prompt,
 )
-from langchain.chains.question_answering.map_rerank_prompt import (
+from oplangchain.chains.question_answering.map_rerank_prompt import (
     PROMPT as MAP_RERANK_PROMPT,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.prompt_template import BasePromptTemplate
 
 
 class LoadingCallable(Protocol):
     """Interface for loading the combine documents chain."""
 
     def __call__(
         self, llm: BaseLanguageModel, **kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/map_reduce_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/map_reduce_prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 question_prompt_template = """Use the following portion of a long document to see if any of the text is relevant to answer the question. 
 Return any relevant text verbatim.
 {context}
 Question: {question}
 Relevant text, if any:"""
 QUESTION_PROMPT = PromptTemplate(
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/refine_prompts.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/refine_prompts.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 DEFAULT_REFINE_PROMPT_TMPL = (
     "The original question is as follows: {question}\n"
     "We have provided an existing answer, including sources: {existing_answer}\n"
     "We have the opportunity to refine the existing answer"
     "(only if needed) with some more context below.\n"
     "------------\n"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/retrieval.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/retrieval.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """Question-answering with sources over an index."""
 
 from typing import Any, Dict, List
 
 from pydantic import Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.qa_with_sources.base import BaseQAWithSourcesChain
-from langchain.docstore.document import Document
-from langchain.schema import BaseRetriever
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.qa_with_sources.base import BaseQAWithSourcesChain
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BaseRetriever
 
 
 class RetrievalQAWithSourcesChain(BaseQAWithSourcesChain):
     """Question-answering with sources over an index."""
 
     retriever: BaseRetriever = Field(exclude=True)
     """Index to connect to."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/stuff_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/stuff_prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 template = """Given the following extracted parts of a long document and a question, create a final answer with references ("SOURCES"). 
 If you don't know the answer, just say that you don't know. Don't try to make up an answer.
 ALWAYS return a "SOURCES" part in your answer.
 
 QUESTION: Which state/country's law governs the interpretation of the contract?
 =========
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/qa_with_sources/vector_db.py` & `oplangchain-0.1.1/oplangchain/chains/qa_with_sources/vector_db.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 """Question-answering with sources over a vector database."""
 
 import warnings
 from typing import Any, Dict, List
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.qa_with_sources.base import BaseQAWithSourcesChain
-from langchain.docstore.document import Document
-from langchain.vectorstores.base import VectorStore
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.qa_with_sources.base import BaseQAWithSourcesChain
+from oplangchain.docstore.document import Document
+from oplangchain.vectorstores.base import VectorStore
 
 
 class VectorDBQAWithSourcesChain(BaseQAWithSourcesChain):
     """Question-answering with sources over a vector database."""
 
     vectorstore: VectorStore = Field(exclude=True)
     """Vector Database to connect to."""
@@ -63,14 +63,14 @@
     ) -> List[Document]:
         raise NotImplementedError("VectorDBQAWithSourcesChain does not support async")
 
     @root_validator()
     def raise_deprecation(cls, values: Dict) -> Dict:
         warnings.warn(
             "`VectorDBQAWithSourcesChain` is deprecated - "
-            "please use `from langchain.chains import RetrievalQAWithSourcesChain`"
+            "please use `from oplangchain.chains import RetrievalQAWithSourcesChain`"
         )
         return values
 
     @property
     def _chain_type(self) -> str:
         return "vector_db_qa_with_sources_chain"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/query_constructor/base.py` & `oplangchain-0.1.1/oplangchain/chains/query_constructor/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 """LLM Chain for turning a user text query into a structured query."""
 from __future__ import annotations
 
 import json
 from typing import Any, Callable, List, Optional, Sequence
 
-from langchain import FewShotPromptTemplate, LLMChain
-from langchain.chains.query_constructor.ir import (
+from oplangchain import FewShotPromptTemplate, LLMChain
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Operator,
     StructuredQuery,
 )
-from langchain.chains.query_constructor.parser import get_parser
-from langchain.chains.query_constructor.prompt import (
+from oplangchain.chains.query_constructor.parser import get_parser
+from oplangchain.chains.query_constructor.prompt import (
     DEFAULT_EXAMPLES,
     DEFAULT_PREFIX,
     DEFAULT_SCHEMA,
     DEFAULT_SUFFIX,
     EXAMPLE_PROMPT,
     EXAMPLES_WITH_LIMIT,
     SCHEMA_WITH_LIMIT,
 )
-from langchain.chains.query_constructor.schema import AttributeInfo
-from langchain.output_parsers.json import parse_and_check_json_markdown
-from langchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.query_constructor.schema import AttributeInfo
+from oplangchain.output_parsers.json import parse_and_check_json_markdown
+from oplangchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class StructuredQueryOutputParser(BaseOutputParser[StructuredQuery]):
     """Output parser that parses a structured query."""
 
     ast_parse: Callable
     """Callable that parses dict into internal representation of query language."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/query_constructor/ir.py` & `oplangchain-0.1.1/oplangchain/chains/query_constructor/ir.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/query_constructor/parser.py` & `oplangchain-0.1.1/oplangchain/chains/query_constructor/parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 import datetime
 from typing import Any, Optional, Sequence, Union
 
-from langchain.utils import check_package_version
+from oplangchain.utils import check_package_version
 
 try:
     check_package_version("lark", gte_version="1.1.5")
     from lark import Lark, Transformer, v_args
 except ImportError:
 
     def v_args(*args: Any, **kwargs: Any) -> Any:  # type: ignore
         return lambda _: None
 
     Transformer = object  # type: ignore
     Lark = object  # type: ignore
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     FilterDirective,
     Operation,
     Operator,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/query_constructor/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/query_constructor/prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain import PromptTemplate
+from oplangchain import PromptTemplate
 
 SONG_DATA_SOURCE = """\
 ```json
 {
     "content": "Lyrics of a song",
     "attributes": {
         "artist": {
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/question_answering/__init__.py` & `oplangchain-0.1.1/oplangchain/chains/question_answering/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 """Load question answering chains."""
 from typing import Any, Mapping, Optional, Protocol
 
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import Callbacks
-from langchain.chains import ReduceDocumentsChain
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
-from langchain.chains.combine_documents.refine import RefineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.question_answering import (
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains import ReduceDocumentsChain
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.map_rerank import MapRerankDocumentsChain
+from oplangchain.chains.combine_documents.refine import RefineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.question_answering import (
     map_reduce_prompt,
     refine_prompts,
     stuff_prompt,
 )
-from langchain.chains.question_answering.map_rerank_prompt import (
+from oplangchain.chains.question_answering.map_rerank_prompt import (
     PROMPT as MAP_RERANK_PROMPT,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.prompt_template import BasePromptTemplate
 
 
 class LoadingCallable(Protocol):
     """Interface for loading the combine documents chain."""
 
     def __call__(
         self, llm: BaseLanguageModel, **kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/question_answering/map_reduce_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/question_answering/map_reduce_prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # flake8: noqa
-from langchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
-from langchain.prompts.chat import (
+from oplangchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 question_prompt_template = """Use the following portion of a long document to see if any of the text is relevant to answer the question. 
 Return any relevant text verbatim.
 {context}
 Question: {question}
 Relevant text, if any:"""
 QUESTION_PROMPT = PromptTemplate(
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/question_answering/map_rerank_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/question_answering/map_rerank_prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # flake8: noqa
-from langchain.output_parsers.regex import RegexParser
-from langchain.prompts import PromptTemplate
+from oplangchain.output_parsers.regex import RegexParser
+from oplangchain.prompts import PromptTemplate
 
 output_parser = RegexParser(
     regex=r"(.*?)\nScore: (\d*)",
     output_keys=["answer", "score"],
 )
 
 prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/question_answering/refine_prompts.py` & `oplangchain-0.1.1/oplangchain/chains/question_answering/refine_prompts.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # flake8: noqa
-from langchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
-from langchain.prompts.chat import (
+from oplangchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
+from oplangchain.prompts.chat import (
     AIMessagePromptTemplate,
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 DEFAULT_REFINE_PROMPT_TMPL = (
     "The original question is as follows: {question}\n"
     "We have provided an existing answer: {existing_answer}\n"
     "We have the opportunity to refine the existing answer"
     "(only if needed) with some more context below.\n"
     "------------\n"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/question_answering/stuff_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/question_answering/stuff_prompt.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # flake8: noqa
-from langchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
-from langchain.prompts import PromptTemplate
-from langchain.prompts.chat import (
+from oplangchain.chains.prompt_selector import ConditionalPromptSelector, is_chat_model
+from oplangchain.prompts import PromptTemplate
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     SystemMessagePromptTemplate,
 )
 
 prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/retrieval_qa/base.py` & `oplangchain-0.1.1/oplangchain/chains/retrieval_qa/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -4,29 +4,29 @@
 import inspect
 import warnings
 from abc import abstractmethod
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.question_answering import load_qa_chain
-from langchain.chains.question_answering.stuff_prompt import PROMPT_SELECTOR
-from langchain.prompts import PromptTemplate
-from langchain.schema import BaseRetriever, Document
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.vectorstores.base import VectorStore
+from oplangchain.chains.base import Chain
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.question_answering import load_qa_chain
+from oplangchain.chains.question_answering.stuff_prompt import PROMPT_SELECTOR
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.vectorstores.base import VectorStore
 
 
 class BaseRetrievalQA(Chain):
     """Base class for question-answering chains."""
 
     combine_documents_chain: BaseCombineDocumentsChain
     """Chain to use to combine the documents."""
@@ -192,18 +192,18 @@
 
 class RetrievalQA(BaseRetrievalQA):
     """Chain for question-answering against an index.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import OpenAI
-            from langchain.chains import RetrievalQA
-            from langchain.faiss import FAISS
-            from langchain.vectorstores.base import VectorStoreRetriever
+            from oplangchain.llms import OpenAI
+            from oplangchain.chains import RetrievalQA
+            from oplangchain.faiss import FAISS
+            from oplangchain.vectorstores.base import VectorStoreRetriever
             retriever = VectorStoreRetriever(vectorstore=FAISS(...))
             retrievalQA = RetrievalQA.from_llm(llm=OpenAI(), retriever=retriever)
 
     """
 
     retriever: BaseRetriever = Field(exclude=True)
 
@@ -247,15 +247,15 @@
     search_kwargs: Dict[str, Any] = Field(default_factory=dict)
     """Extra search args."""
 
     @root_validator()
     def raise_deprecation(cls, values: Dict) -> Dict:
         warnings.warn(
             "`VectorDBQA` is deprecated - "
-            "please use `from langchain.chains import RetrievalQA`"
+            "please use `from oplangchain.chains import RetrievalQA`"
         )
         return values
 
     @root_validator()
     def validate_search_type(cls, values: Dict) -> Dict:
         """Validate search type."""
         if "search_type" in values:
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/base.py` & `oplangchain-0.1.1/oplangchain/chains/router/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,20 +2,20 @@
 from __future__ import annotations
 
 from abc import ABC
 from typing import Any, Dict, List, Mapping, NamedTuple, Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
+from oplangchain.chains.base import Chain
 
 
 class Route(NamedTuple):
     destination: Optional[str]
     next_inputs: Dict[str, Any]
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/embedding_router.py` & `oplangchain-0.1.1/oplangchain/chains/router/embedding_router.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Type
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForChainRun
-from langchain.chains.router.base import RouterChain
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.callbacks.manager import CallbackManagerForChainRun
+from oplangchain.chains.router.base import RouterChain
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 
 class EmbeddingRouterChain(RouterChain):
     """Chain that uses embeddings to route between options."""
 
     vectorstore: VectorStore
     routing_keys: List[str] = ["query"]
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/llm_router.py` & `oplangchain-0.1.1/oplangchain/chains/router/llm_router.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """Base classes for LLM-powered router chains."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Type, cast
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains import LLMChain
-from langchain.chains.router.base import RouterChain
-from langchain.output_parsers.json import parse_and_check_json_markdown
-from langchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains import LLMChain
+from oplangchain.chains.router.base import RouterChain
+from oplangchain.output_parsers.json import parse_and_check_json_markdown
+from oplangchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class LLMRouterChain(RouterChain):
     """A router chain that uses an LLM chain to perform routing."""
 
     llm_chain: LLMChain
     """LLM chain used to perform routing"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/multi_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/router/multi_prompt.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Use a single chain to route an input to one of multiple llm chains."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Mapping, Optional
 
-from langchain.chains import ConversationChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.router.base import MultiRouteChain, RouterChain
-from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
-from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE
-from langchain.prompts import PromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains import ConversationChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.router.base import MultiRouteChain, RouterChain
+from oplangchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
+from oplangchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class MultiPromptChain(MultiRouteChain):
     """A multi-route chain that uses an LLM router chain to choose amongst prompts."""
 
     router_chain: RouterChain
     """Chain for deciding a destination chain and the input to it."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/multi_prompt_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/router/multi_prompt_prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/multi_retrieval_prompt.py` & `oplangchain-0.1.1/oplangchain/chains/router/multi_retrieval_prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/chains/router/multi_retrieval_qa.py` & `oplangchain-0.1.1/oplangchain/chains/router/multi_retrieval_qa.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """Use a single chain to route an input to one of multiple retrieval qa chains."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Mapping, Optional
 
-from langchain.chains import ConversationChain
-from langchain.chains.base import Chain
-from langchain.chains.conversation.prompt import DEFAULT_TEMPLATE
-from langchain.chains.retrieval_qa.base import BaseRetrievalQA, RetrievalQA
-from langchain.chains.router.base import MultiRouteChain
-from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
-from langchain.chains.router.multi_retrieval_prompt import (
+from oplangchain.chains import ConversationChain
+from oplangchain.chains.base import Chain
+from oplangchain.chains.conversation.prompt import DEFAULT_TEMPLATE
+from oplangchain.chains.retrieval_qa.base import BaseRetrievalQA, RetrievalQA
+from oplangchain.chains.router.base import MultiRouteChain
+from oplangchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
+from oplangchain.chains.router.multi_retrieval_prompt import (
     MULTI_RETRIEVAL_ROUTER_TEMPLATE,
 )
-from langchain.chat_models import ChatOpenAI
-from langchain.prompts import PromptTemplate
-from langchain.schema import BaseRetriever
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chat_models import ChatOpenAI
+from oplangchain.prompts import PromptTemplate
+from oplangchain.schema import BaseRetriever
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class MultiRetrievalQAChain(MultiRouteChain):
     """A multi-route chain that uses an LLM router chain to choose amongst retrieval
     qa chains."""
 
     router_chain: LLMRouterChain
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/sequential.py` & `oplangchain-0.1.1/oplangchain/chains/sequential.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Chain pipeline where the outputs of one step feed directly into next."""
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.utils.input import get_color_mapping
+from oplangchain.chains.base import Chain
+from oplangchain.utils.input import get_color_mapping
 
 
 class SequentialChain(Chain):
     """Chain where the outputs of one chain feed directly into next."""
 
     chains: List[Chain]
     input_variables: List[str]
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/sql_database/prompt.py` & `oplangchain-0.1.1/oplangchain/chains/sql_database/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # flake8: noqa
-from langchain.output_parsers.list import CommaSeparatedListOutputParser
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.output_parsers.list import CommaSeparatedListOutputParser
+from oplangchain.prompts.prompt import PromptTemplate
 
 
 PROMPT_SUFFIX = """Only use the following tables:
 {table_info}
 
 Question: {input}"""
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/sql_database/query.py` & `oplangchain-0.1.1/oplangchain/chains/sql_database/query.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import List, Optional, TypedDict, Union
 
-from langchain.chains.sql_database.prompt import PROMPT, SQL_PROMPTS
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.output_parser import NoOpOutputParser
-from langchain.schema.prompt_template import BasePromptTemplate
-from langchain.schema.runnable import RunnableMap, RunnableSequence
-from langchain.utilities.sql_database import SQLDatabase
+from oplangchain.chains.sql_database.prompt import PROMPT, SQL_PROMPTS
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.output_parser import NoOpOutputParser
+from oplangchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.schema.runnable import RunnableMap, RunnableSequence
+from oplangchain.utilities.sql_database import SQLDatabase
 
 
 def _strip(text: str) -> str:
     return text.strip()
 
 
 class SQLInput(TypedDict):
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/summarize/__init__.py` & `oplangchain-0.1.1/oplangchain/chains/summarize/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 """Load summarizing chains."""
 from typing import Any, Mapping, Optional, Protocol
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.combine_documents.base import BaseCombineDocumentsChain
-from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
-from langchain.chains.combine_documents.reduce import ReduceDocumentsChain
-from langchain.chains.combine_documents.refine import RefineDocumentsChain
-from langchain.chains.combine_documents.stuff import StuffDocumentsChain
-from langchain.chains.llm import LLMChain
-from langchain.chains.summarize import map_reduce_prompt, refine_prompts, stuff_prompt
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.combine_documents.base import BaseCombineDocumentsChain
+from oplangchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
+from oplangchain.chains.combine_documents.reduce import ReduceDocumentsChain
+from oplangchain.chains.combine_documents.refine import RefineDocumentsChain
+from oplangchain.chains.combine_documents.stuff import StuffDocumentsChain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.summarize import map_reduce_prompt, refine_prompts, stuff_prompt
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class LoadingCallable(Protocol):
     """Interface for loading the combine documents chain."""
 
     def __call__(
         self, llm: BaseLanguageModel, **kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/summarize/refine_prompts.py` & `oplangchain-0.1.1/oplangchain/chains/summarize/refine_prompts.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 REFINE_PROMPT_TMPL = (
     "Your job is to produce a final summary\n"
     "We have provided an existing summary up to a certain point: {existing_answer}\n"
     "We have the opportunity to refine the existing summary"
     "(only if needed) with some more context below.\n"
     "------------\n"
```

### Comparing `oplangchain-0.1.0/oplangchain/chains/transform.py` & `oplangchain-0.1.1/oplangchain/chains/transform.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 """Chain that runs an arbitrary python function."""
 import functools
 import logging
 from typing import Any, Awaitable, Callable, Dict, List, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
+from oplangchain.chains.base import Chain
 
 logger = logging.getLogger(__name__)
 
 
 class TransformChain(Chain):
     """Chain that transforms the chain output.
 
     Example:
         .. code-block:: python
 
-            from langchain import TransformChain
+            from oplangchain import TransformChain
             transform_chain = TransformChain(input_variables=["text"],
              output_variables["entities"], transform=func())
     """
 
     input_variables: List[str]
     """The keys expected by the transform's input dictionary."""
     output_variables: List[str]
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/__init__.py` & `oplangchain-0.1.1/oplangchain/chat_models/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -13,24 +13,24 @@
 **Main helpers:**
 
 .. code-block::
 
     AIMessage, BaseMessage, HumanMessage
 """  # noqa: E501
 
-from langchain.chat_models.anthropic import ChatAnthropic
-from langchain.chat_models.azure_openai import AzureChatOpenAI
-from langchain.chat_models.fake import FakeListChatModel
-from langchain.chat_models.google_palm import ChatGooglePalm
-from langchain.chat_models.human import HumanInputChatModel
-from langchain.chat_models.jinachat import JinaChat
-from langchain.chat_models.mlflow_ai_gateway import ChatMLflowAIGateway
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.chat_models.promptlayer_openai import PromptLayerChatOpenAI
-from langchain.chat_models.vertexai import ChatVertexAI
+from oplangchain.chat_models.anthropic import ChatAnthropic
+from oplangchain.chat_models.azure_openai import AzureChatOpenAI
+from oplangchain.chat_models.fake import FakeListChatModel
+from oplangchain.chat_models.google_palm import ChatGooglePalm
+from oplangchain.chat_models.human import HumanInputChatModel
+from oplangchain.chat_models.jinachat import JinaChat
+from oplangchain.chat_models.mlflow_ai_gateway import ChatMLflowAIGateway
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.chat_models.promptlayer_openai import PromptLayerChatOpenAI
+from oplangchain.chat_models.vertexai import ChatVertexAI
 
 __all__ = [
     "ChatOpenAI",
     "AzureChatOpenAI",
     "FakeListChatModel",
     "PromptLayerChatOpenAI",
     "ChatAnthropic",
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/anthropic.py` & `oplangchain-0.1.1/oplangchain/chat_models/anthropic.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,42 +1,42 @@
 from typing import Any, AsyncIterator, Dict, Iterator, List, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.llms.anthropic import _AnthropicCommon
-from langchain.schema import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.llms.anthropic import _AnthropicCommon
+from oplangchain.schema import (
     ChatGeneration,
     ChatResult,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     AIMessageChunk,
     BaseMessage,
     ChatMessage,
     HumanMessage,
     SystemMessage,
 )
-from langchain.schema.output import ChatGenerationChunk
+from oplangchain.schema.output import ChatGenerationChunk
 
 
 class ChatAnthropic(BaseChatModel, _AnthropicCommon):
     """Anthropic's large language chat model.
 
     To use, you should have the ``anthropic`` python package installed, and the
     environment variable ``ANTHROPIC_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
             import anthropic
-            from langchain.llms import Anthropic
+            from oplangchain.llms import Anthropic
             model = ChatAnthropic(model="<model_name>", anthropic_api_key="my-api-key")
     """
 
     @property
     def lc_secrets(self) -> Dict[str, str]:
         return {"anthropic_api_key": "ANTHROPIC_API_KEY"}
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/azure_openai.py` & `oplangchain-0.1.1/oplangchain/chat_models/azure_openai.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 from __future__ import annotations
 
 import logging
 from typing import Any, Dict, Mapping
 
 from pydantic import root_validator
 
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.schema import ChatResult
-from langchain.utils import get_from_dict_or_env
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.schema import ChatResult
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class AzureChatOpenAI(ChatOpenAI):
     """Wrapper around Azure OpenAI Chat Completion API.
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/azureml_endpoint.py` & `oplangchain-0.1.1/oplangchain/chat_models/azureml_endpoint.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 import json
 from typing import Any, Dict, List, Optional
 
 from pydantic import validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.chat_models.base import SimpleChatModel
-from langchain.llms.azureml_endpoint import AzureMLEndpointClient, ContentFormatterBase
-from langchain.schema.messages import (
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.chat_models.base import SimpleChatModel
+from oplangchain.llms.azureml_endpoint import AzureMLEndpointClient, ContentFormatterBase
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     HumanMessage,
     SystemMessage,
 )
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class LlamaContentFormatter(ContentFormatterBase):
     """Content formatter for LLaMa"""
 
     SUPPORTED_ROLES = ["user", "assistant", "system"]
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/base.py` & `oplangchain-0.1.1/oplangchain/chat_models/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,46 +12,46 @@
     Optional,
     Sequence,
     cast,
 )
 
 from pydantic import Field, root_validator
 
-import langchain
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import (
+import oplangchain
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForLLMRun,
     CallbackManager,
     CallbackManagerForLLMRun,
     Callbacks,
 )
-from langchain.load.dump import dumpd, dumps
-from langchain.prompts.base import StringPromptValue
-from langchain.prompts.chat import ChatPromptValue
-from langchain.schema import (
+from oplangchain.load.dump import dumpd, dumps
+from oplangchain.prompts.base import StringPromptValue
+from oplangchain.prompts.chat import ChatPromptValue
+from oplangchain.schema import (
     ChatGeneration,
     ChatResult,
     LLMResult,
     PromptValue,
     RunInfo,
 )
-from langchain.schema.language_model import BaseLanguageModel, LanguageModelInput
-from langchain.schema.messages import (
+from oplangchain.schema.language_model import BaseLanguageModel, LanguageModelInput
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     BaseMessageChunk,
     HumanMessage,
 )
-from langchain.schema.output import ChatGenerationChunk
-from langchain.schema.runnable import RunnableConfig
+from oplangchain.schema.output import ChatGenerationChunk
+from oplangchain.schema.runnable import RunnableConfig
 
 
 def _get_verbosity() -> bool:
-    return langchain.verbose
+    return oplangchain.verbose
 
 
 class BaseChatModel(BaseLanguageModel[BaseMessageChunk], ABC):
     cache: Optional[bool] = None
     """Whether to cache the response."""
     verbose: bool = Field(default_factory=_get_verbosity)
     """Whether to print out response text."""
@@ -419,15 +419,15 @@
         run_manager: Optional[CallbackManagerForLLMRun] = None,
         **kwargs: Any,
     ) -> ChatResult:
         new_arg_supported = inspect.signature(self._generate).parameters.get(
             "run_manager"
         )
         disregard_cache = self.cache is not None and not self.cache
-        if langchain.llm_cache is None or disregard_cache:
+        if oplangchain.llm_cache is None or disregard_cache:
             # This happens when langchain.cache is None, but self.cache is True
             if self.cache is not None and self.cache:
                 raise ValueError(
                     "Asked to cache, but no cache found at `langchain.cache`."
                 )
             if new_arg_supported:
                 return self._generate(
@@ -458,15 +458,15 @@
         run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,
         **kwargs: Any,
     ) -> ChatResult:
         new_arg_supported = inspect.signature(self._agenerate).parameters.get(
             "run_manager"
         )
         disregard_cache = self.cache is not None and not self.cache
-        if langchain.llm_cache is None or disregard_cache:
+        if oplangchain.llm_cache is None or disregard_cache:
             # This happens when langchain.cache is None, but self.cache is True
             if self.cache is not None and self.cache:
                 raise ValueError(
                     "Asked to cache, but no cache found at `langchain.cache`."
                 )
             if new_arg_supported:
                 return await self._agenerate(
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/fake.py` & `oplangchain-0.1.1/oplangchain/chat_models/fake.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Fake ChatModel for testing purposes."""
 from typing import Any, Dict, List, Optional
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.chat_models.base import SimpleChatModel
-from langchain.schema.messages import BaseMessage
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.chat_models.base import SimpleChatModel
+from oplangchain.schema.messages import BaseMessage
 
 
 class FakeListChatModel(SimpleChatModel):
     """Fake ChatModel for testing purposes."""
 
     responses: List
     i: int = 0
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/google_palm.py` & `oplangchain-0.1.1/oplangchain/chat_models/google_palm.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,31 +9,31 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.schema import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.schema import (
     ChatGeneration,
     ChatResult,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     HumanMessage,
     SystemMessage,
 )
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 if TYPE_CHECKING:
     import google.generativeai as genai
 
 logger = logging.getLogger(__name__)
 
 
@@ -222,15 +222,15 @@
         1. The ``GOOGLE_API_KEY``` environment variable set with your API key, or
         2. Pass your API key using the google_api_key kwarg to the ChatGoogle
            constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.chat_models import ChatGooglePalm
+            from oplangchain.chat_models import ChatGooglePalm
             chat = ChatGooglePalm()
 
     """
 
     client: Any  #: :meta private:
     model_name: str = "models/chat-bison-001"
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/human.py` & `oplangchain-0.1.1/oplangchain/chat_models/human.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,27 +3,27 @@
 from functools import partial
 from io import StringIO
 from typing import Any, Callable, Dict, List, Mapping, Optional
 
 import yaml
 from pydantic import Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.schema.messages import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.schema.messages import (
     BaseMessage,
     HumanMessage,
     _message_from_dict,
     messages_to_dict,
 )
-from langchain.schema.output import ChatGeneration, ChatResult
+from oplangchain.schema.output import ChatGeneration, ChatResult
 
 
 def _display_messages(messages: List[BaseMessage]) -> None:
     dict_messages = messages_to_dict(messages)
     for message in dict_messages:
         yaml_string = yaml.dump(
             message,
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/jinachat.py` & `oplangchain-0.1.1/oplangchain/chat_models/jinachat.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,37 +20,37 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.schema import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.schema import (
     AIMessage,
     BaseMessage,
     ChatGeneration,
     ChatMessage,
     ChatResult,
     HumanMessage,
     SystemMessage,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessageChunk,
     BaseMessageChunk,
     ChatMessageChunk,
     HumanMessageChunk,
     SystemMessageChunk,
 )
-from langchain.schema.output import ChatGenerationChunk
-from langchain.utils import get_from_dict_or_env, get_pydantic_field_names
+from oplangchain.schema.output import ChatGenerationChunk
+from oplangchain.utils import get_from_dict_or_env, get_pydantic_field_names
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(llm: JinaChat) -> Callable[[Any], Any]:
     import openai
 
@@ -142,15 +142,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.chat_models import JinaChat
+            from oplangchain.chat_models import JinaChat
             chat = JinaChat()
     """
 
     @property
     def lc_secrets(self) -> Dict[str, str]:
         return {"jinachat_api_key": "JINACHAT_API_KEY"}
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/mlflow_ai_gateway.py` & `oplangchain-0.1.1/oplangchain/chat_models/mlflow_ai_gateway.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 import asyncio
 import logging
 from functools import partial
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import BaseModel, Extra
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.schema import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.schema import (
     ChatGeneration,
     ChatResult,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     FunctionMessage,
     HumanMessage,
     SystemMessage,
 )
@@ -42,15 +42,15 @@
 
     To use, you should have the ``mlflow[gateway]`` python package installed.
     For more information, see https://mlflow.org/docs/latest/gateway/index.html.
 
     Example:
         .. code-block:: python
 
-            from langchain.chat_models import ChatMLflowAIGateway
+            from oplangchain.chat_models import ChatMLflowAIGateway
 
             chat = ChatMLflowAIGateway(
                 gateway_uri="<your-mlflow-ai-gateway-uri>",
                 route="<your-mlflow-ai-gateway-chat-route>",
                 params={
                     "temperature": 0.1
                 }
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/openai.py` & `oplangchain-0.1.1/oplangchain/chat_models/openai.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,37 +15,37 @@
     Optional,
     Tuple,
     Union,
 )
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models.base import BaseChatModel
-from langchain.llms.base import create_base_retry_decorator
-from langchain.schema import ChatGeneration, ChatResult
-from langchain.schema.messages import (
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.llms.base import create_base_retry_decorator
+from oplangchain.schema import ChatGeneration, ChatResult
+from oplangchain.schema.messages import (
     AIMessage,
     AIMessageChunk,
     BaseMessage,
     BaseMessageChunk,
     ChatMessage,
     ChatMessageChunk,
     FunctionMessage,
     FunctionMessageChunk,
     HumanMessage,
     HumanMessageChunk,
     SystemMessage,
     SystemMessageChunk,
 )
-from langchain.schema.output import ChatGenerationChunk
-from langchain.utils import get_from_dict_or_env, get_pydantic_field_names
+from oplangchain.schema.output import ChatGenerationChunk
+from oplangchain.utils import get_from_dict_or_env, get_pydantic_field_names
 
 if TYPE_CHECKING:
     import tiktoken
 
 logger = logging.getLogger(__name__)
 
 
@@ -186,15 +186,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.chat_models import ChatOpenAI
+            from oplangchain.chat_models import ChatOpenAI
             openai = ChatOpenAI(model_name="gpt-3.5-turbo")
     """
 
     @property
     def lc_secrets(self) -> Dict[str, str]:
         return {"openai_api_key": "OPENAI_API_KEY"}
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/promptlayer_openai.py` & `oplangchain-0.1.1/oplangchain/chat_models/promptlayer_openai.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """PromptLayer wrapper."""
 import datetime
 from typing import Any, Dict, List, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.chat_models import ChatOpenAI
-from langchain.schema import ChatResult
-from langchain.schema.messages import BaseMessage
+from oplangchain.chat_models import ChatOpenAI
+from oplangchain.schema import ChatResult
+from oplangchain.schema.messages import BaseMessage
 
 
 class PromptLayerChatOpenAI(ChatOpenAI):
     """Wrapper around OpenAI Chat large language models and PromptLayer.
 
     To use, you should have the ``openai`` and ``promptlayer`` python
     package installed, and the environment variable ``OPENAI_API_KEY``
@@ -27,15 +27,15 @@
         ``return_pl_id``: If True, the PromptLayer request ID will be
             returned in the ``generation_info`` field of the
             ``Generation`` object.
 
     Example:
         .. code-block:: python
 
-            from langchain.chat_models import PromptLayerChatOpenAI
+            from oplangchain.chat_models import PromptLayerChatOpenAI
             openai = PromptLayerChatOpenAI(model_name="gpt-3.5-turbo")
     """
 
     pl_tags: Optional[List[str]]
     return_pl_id: Optional[bool] = False
 
     def _generate(
```

### Comparing `oplangchain-0.1.0/oplangchain/chat_models/vertexai.py` & `oplangchain-0.1.1/oplangchain/chat_models/vertexai.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Wrapper around Google VertexAI chat-based models."""
 from dataclasses import dataclass, field
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.chat_models.base import BaseChatModel
-from langchain.llms.vertexai import _VertexAICommon, is_codey_model
-from langchain.schema import (
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.llms.vertexai import _VertexAICommon, is_codey_model
+from oplangchain.schema import (
     ChatGeneration,
     ChatResult,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     HumanMessage,
     SystemMessage,
 )
-from langchain.utilities.vertexai import raise_vertex_import_error
+from oplangchain.utilities.vertexai import raise_vertex_import_error
 
 if TYPE_CHECKING:
     from vertexai.language_models import ChatMessage, InputOutputTextPair
 
 
 @dataclass
 class _ChatHistory:
```

### Comparing `oplangchain-0.1.0/oplangchain/docker-compose.yaml` & `oplangchain-0.1.1/oplangchain/docker-compose.yaml`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/docstore/__init__.py` & `oplangchain-0.1.1/oplangchain/docstore/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,12 +10,12 @@
 
 **Main helpers:**
 
 .. code-block::
 
     Document, AddableMixin
 """
-from langchain.docstore.arbitrary_fn import DocstoreFn
-from langchain.docstore.in_memory import InMemoryDocstore
-from langchain.docstore.wikipedia import Wikipedia
+from oplangchain.docstore.arbitrary_fn import DocstoreFn
+from oplangchain.docstore.in_memory import InMemoryDocstore
+from oplangchain.docstore.wikipedia import Wikipedia
 
 __all__ = ["DocstoreFn", "InMemoryDocstore", "Wikipedia"]
```

### Comparing `oplangchain-0.1.0/oplangchain/docstore/arbitrary_fn.py` & `oplangchain-0.1.1/oplangchain/docstore/arbitrary_fn.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Callable, Union
 
-from langchain.docstore.base import Docstore
-from langchain.schema import Document
+from oplangchain.docstore.base import Docstore
+from oplangchain.schema import Document
 
 
 class DocstoreFn(Docstore):
     """Langchain Docstore via arbitrary lookup function.
 
     This is useful when:
      * it's expensive to construct an InMemoryDocstore/dict
```

### Comparing `oplangchain-0.1.0/oplangchain/docstore/base.py` & `oplangchain-0.1.1/oplangchain/docstore/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Interface to access to place that stores documents."""
 from abc import ABC, abstractmethod
 from typing import Dict, List, Union
 
-from langchain.docstore.document import Document
+from oplangchain.docstore.document import Document
 
 
 class Docstore(ABC):
     """Interface to access to place that stores documents."""
 
     @abstractmethod
     def search(self, search: str) -> Union[str, Document]:
```

### Comparing `oplangchain-0.1.0/oplangchain/docstore/in_memory.py` & `oplangchain-0.1.1/oplangchain/docstore/in_memory.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Simple in memory docstore in the form of a dict."""
 from typing import Dict, List, Optional, Union
 
-from langchain.docstore.base import AddableMixin, Docstore
-from langchain.docstore.document import Document
+from oplangchain.docstore.base import AddableMixin, Docstore
+from oplangchain.docstore.document import Document
 
 
 class InMemoryDocstore(Docstore, AddableMixin):
     """Simple in memory docstore in the form of a dict."""
 
     def __init__(self, _dict: Optional[Dict[str, Document]] = None):
         """Initialize with dict."""
```

### Comparing `oplangchain-0.1.0/oplangchain/docstore/wikipedia.py` & `oplangchain-0.1.1/oplangchain/docstore/wikipedia.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Wrapper around wikipedia API."""
 
 
 from typing import Union
 
-from langchain.docstore.base import Docstore
-from langchain.docstore.document import Document
+from oplangchain.docstore.base import Docstore
+from oplangchain.docstore.document import Document
 
 
 class Wikipedia(Docstore):
     """Wrapper around wikipedia API."""
 
     def __init__(self) -> None:
         """Check that wikipedia package is installed."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/__init__.py` & `oplangchain-0.1.1/oplangchain/document_loaders/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -11,171 +11,171 @@
 **Main helpers:**
 
 .. code-block::
 
     Document, <name>TextSplitter
 """
 
-from langchain.document_loaders.acreom import AcreomLoader
-from langchain.document_loaders.airbyte_json import AirbyteJSONLoader
-from langchain.document_loaders.airtable import AirtableLoader
-from langchain.document_loaders.apify_dataset import ApifyDatasetLoader
-from langchain.document_loaders.arxiv import ArxivLoader
-from langchain.document_loaders.async_html import AsyncHtmlLoader
-from langchain.document_loaders.azlyrics import AZLyricsLoader
-from langchain.document_loaders.azure_blob_storage_container import (
+from oplangchain.document_loaders.acreom import AcreomLoader
+from oplangchain.document_loaders.airbyte_json import AirbyteJSONLoader
+from oplangchain.document_loaders.airtable import AirtableLoader
+from oplangchain.document_loaders.apify_dataset import ApifyDatasetLoader
+from oplangchain.document_loaders.arxiv import ArxivLoader
+from oplangchain.document_loaders.async_html import AsyncHtmlLoader
+from oplangchain.document_loaders.azlyrics import AZLyricsLoader
+from oplangchain.document_loaders.azure_blob_storage_container import (
     AzureBlobStorageContainerLoader,
 )
-from langchain.document_loaders.azure_blob_storage_file import (
+from oplangchain.document_loaders.azure_blob_storage_file import (
     AzureBlobStorageFileLoader,
 )
-from langchain.document_loaders.bibtex import BibtexLoader
-from langchain.document_loaders.bigquery import BigQueryLoader
-from langchain.document_loaders.bilibili import BiliBiliLoader
-from langchain.document_loaders.blackboard import BlackboardLoader
-from langchain.document_loaders.blob_loaders import (
+from oplangchain.document_loaders.bibtex import BibtexLoader
+from oplangchain.document_loaders.bigquery import BigQueryLoader
+from oplangchain.document_loaders.bilibili import BiliBiliLoader
+from oplangchain.document_loaders.blackboard import BlackboardLoader
+from oplangchain.document_loaders.blob_loaders import (
     Blob,
     BlobLoader,
     FileSystemBlobLoader,
     YoutubeAudioLoader,
 )
-from langchain.document_loaders.blockchain import BlockchainDocumentLoader
-from langchain.document_loaders.brave_search import BraveSearchLoader
-from langchain.document_loaders.browserless import BrowserlessLoader
-from langchain.document_loaders.chatgpt import ChatGPTLoader
-from langchain.document_loaders.college_confidential import CollegeConfidentialLoader
-from langchain.document_loaders.concurrent import ConcurrentLoader
-from langchain.document_loaders.confluence import ConfluenceLoader
-from langchain.document_loaders.conllu import CoNLLULoader
-from langchain.document_loaders.csv_loader import CSVLoader, UnstructuredCSVLoader
-from langchain.document_loaders.cube_semantic import CubeSemanticLoader
-from langchain.document_loaders.datadog_logs import DatadogLogsLoader
-from langchain.document_loaders.dataframe import DataFrameLoader
-from langchain.document_loaders.diffbot import DiffbotLoader
-from langchain.document_loaders.directory import DirectoryLoader
-from langchain.document_loaders.discord import DiscordChatLoader
-from langchain.document_loaders.docugami import DocugamiLoader
-from langchain.document_loaders.dropbox import DropboxLoader
-from langchain.document_loaders.duckdb_loader import DuckDBLoader
-from langchain.document_loaders.email import (
+from oplangchain.document_loaders.blockchain import BlockchainDocumentLoader
+from oplangchain.document_loaders.brave_search import BraveSearchLoader
+from oplangchain.document_loaders.browserless import BrowserlessLoader
+from oplangchain.document_loaders.chatgpt import ChatGPTLoader
+from oplangchain.document_loaders.college_confidential import CollegeConfidentialLoader
+from oplangchain.document_loaders.concurrent import ConcurrentLoader
+from oplangchain.document_loaders.confluence import ConfluenceLoader
+from oplangchain.document_loaders.conllu import CoNLLULoader
+from oplangchain.document_loaders.csv_loader import CSVLoader, UnstructuredCSVLoader
+from oplangchain.document_loaders.cube_semantic import CubeSemanticLoader
+from oplangchain.document_loaders.datadog_logs import DatadogLogsLoader
+from oplangchain.document_loaders.dataframe import DataFrameLoader
+from oplangchain.document_loaders.diffbot import DiffbotLoader
+from oplangchain.document_loaders.directory import DirectoryLoader
+from oplangchain.document_loaders.discord import DiscordChatLoader
+from oplangchain.document_loaders.docugami import DocugamiLoader
+from oplangchain.document_loaders.dropbox import DropboxLoader
+from oplangchain.document_loaders.duckdb_loader import DuckDBLoader
+from oplangchain.document_loaders.email import (
     OutlookMessageLoader,
     UnstructuredEmailLoader,
 )
-from langchain.document_loaders.embaas import EmbaasBlobLoader, EmbaasLoader
-from langchain.document_loaders.epub import UnstructuredEPubLoader
-from langchain.document_loaders.etherscan import EtherscanLoader
-from langchain.document_loaders.evernote import EverNoteLoader
-from langchain.document_loaders.excel import UnstructuredExcelLoader
-from langchain.document_loaders.facebook_chat import FacebookChatLoader
-from langchain.document_loaders.fauna import FaunaLoader
-from langchain.document_loaders.figma import FigmaFileLoader
-from langchain.document_loaders.gcs_directory import GCSDirectoryLoader
-from langchain.document_loaders.gcs_file import GCSFileLoader
-from langchain.document_loaders.geodataframe import GeoDataFrameLoader
-from langchain.document_loaders.git import GitLoader
-from langchain.document_loaders.gitbook import GitbookLoader
-from langchain.document_loaders.github import GitHubIssuesLoader
-from langchain.document_loaders.googledrive import GoogleDriveLoader
-from langchain.document_loaders.gutenberg import GutenbergLoader
-from langchain.document_loaders.hn import HNLoader
-from langchain.document_loaders.html import UnstructuredHTMLLoader
-from langchain.document_loaders.html_bs import BSHTMLLoader
-from langchain.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader
-from langchain.document_loaders.ifixit import IFixitLoader
-from langchain.document_loaders.image import UnstructuredImageLoader
-from langchain.document_loaders.image_captions import ImageCaptionLoader
-from langchain.document_loaders.imsdb import IMSDbLoader
-from langchain.document_loaders.iugu import IuguLoader
-from langchain.document_loaders.joplin import JoplinLoader
-from langchain.document_loaders.json_loader import JSONLoader
-from langchain.document_loaders.larksuite import LarkSuiteDocLoader
-from langchain.document_loaders.markdown import UnstructuredMarkdownLoader
-from langchain.document_loaders.mastodon import MastodonTootsLoader
-from langchain.document_loaders.max_compute import MaxComputeLoader
-from langchain.document_loaders.mediawikidump import MWDumpLoader
-from langchain.document_loaders.merge import MergedDataLoader
-from langchain.document_loaders.mhtml import MHTMLLoader
-from langchain.document_loaders.modern_treasury import ModernTreasuryLoader
-from langchain.document_loaders.news import NewsURLLoader
-from langchain.document_loaders.notebook import NotebookLoader
-from langchain.document_loaders.notion import NotionDirectoryLoader
-from langchain.document_loaders.notiondb import NotionDBLoader
-from langchain.document_loaders.obs_directory import OBSDirectoryLoader
-from langchain.document_loaders.obs_file import OBSFileLoader
-from langchain.document_loaders.obsidian import ObsidianLoader
-from langchain.document_loaders.odt import UnstructuredODTLoader
-from langchain.document_loaders.onedrive import OneDriveLoader
-from langchain.document_loaders.onedrive_file import OneDriveFileLoader
-from langchain.document_loaders.open_city_data import OpenCityDataLoader
-from langchain.document_loaders.org_mode import UnstructuredOrgModeLoader
-from langchain.document_loaders.pdf import (
+from oplangchain.document_loaders.embaas import EmbaasBlobLoader, EmbaasLoader
+from oplangchain.document_loaders.epub import UnstructuredEPubLoader
+from oplangchain.document_loaders.etherscan import EtherscanLoader
+from oplangchain.document_loaders.evernote import EverNoteLoader
+from oplangchain.document_loaders.excel import UnstructuredExcelLoader
+from oplangchain.document_loaders.facebook_chat import FacebookChatLoader
+from oplangchain.document_loaders.fauna import FaunaLoader
+from oplangchain.document_loaders.figma import FigmaFileLoader
+from oplangchain.document_loaders.gcs_directory import GCSDirectoryLoader
+from oplangchain.document_loaders.gcs_file import GCSFileLoader
+from oplangchain.document_loaders.geodataframe import GeoDataFrameLoader
+from oplangchain.document_loaders.git import GitLoader
+from oplangchain.document_loaders.gitbook import GitbookLoader
+from oplangchain.document_loaders.github import GitHubIssuesLoader
+from oplangchain.document_loaders.googledrive import GoogleDriveLoader
+from oplangchain.document_loaders.gutenberg import GutenbergLoader
+from oplangchain.document_loaders.hn import HNLoader
+from oplangchain.document_loaders.html import UnstructuredHTMLLoader
+from oplangchain.document_loaders.html_bs import BSHTMLLoader
+from oplangchain.document_loaders.hugging_face_dataset import HuggingFaceDatasetLoader
+from oplangchain.document_loaders.ifixit import IFixitLoader
+from oplangchain.document_loaders.image import UnstructuredImageLoader
+from oplangchain.document_loaders.image_captions import ImageCaptionLoader
+from oplangchain.document_loaders.imsdb import IMSDbLoader
+from oplangchain.document_loaders.iugu import IuguLoader
+from oplangchain.document_loaders.joplin import JoplinLoader
+from oplangchain.document_loaders.json_loader import JSONLoader
+from oplangchain.document_loaders.larksuite import LarkSuiteDocLoader
+from oplangchain.document_loaders.markdown import UnstructuredMarkdownLoader
+from oplangchain.document_loaders.mastodon import MastodonTootsLoader
+from oplangchain.document_loaders.max_compute import MaxComputeLoader
+from oplangchain.document_loaders.mediawikidump import MWDumpLoader
+from oplangchain.document_loaders.merge import MergedDataLoader
+from oplangchain.document_loaders.mhtml import MHTMLLoader
+from oplangchain.document_loaders.modern_treasury import ModernTreasuryLoader
+from oplangchain.document_loaders.news import NewsURLLoader
+from oplangchain.document_loaders.notebook import NotebookLoader
+from oplangchain.document_loaders.notion import NotionDirectoryLoader
+from oplangchain.document_loaders.notiondb import NotionDBLoader
+from oplangchain.document_loaders.obs_directory import OBSDirectoryLoader
+from oplangchain.document_loaders.obs_file import OBSFileLoader
+from oplangchain.document_loaders.obsidian import ObsidianLoader
+from oplangchain.document_loaders.odt import UnstructuredODTLoader
+from oplangchain.document_loaders.onedrive import OneDriveLoader
+from oplangchain.document_loaders.onedrive_file import OneDriveFileLoader
+from oplangchain.document_loaders.open_city_data import OpenCityDataLoader
+from oplangchain.document_loaders.org_mode import UnstructuredOrgModeLoader
+from oplangchain.document_loaders.pdf import (
     AmazonTextractPDFLoader,
     MathpixPDFLoader,
     OnlinePDFLoader,
     PDFMinerLoader,
     PDFMinerPDFasHTMLLoader,
     PDFPlumberLoader,
     PyMuPDFLoader,
     PyPDFDirectoryLoader,
     PyPDFium2Loader,
     PyPDFLoader,
     UnstructuredPDFLoader,
 )
-from langchain.document_loaders.powerpoint import UnstructuredPowerPointLoader
-from langchain.document_loaders.psychic import PsychicLoader
-from langchain.document_loaders.pyspark_dataframe import PySparkDataFrameLoader
-from langchain.document_loaders.python import PythonLoader
-from langchain.document_loaders.readthedocs import ReadTheDocsLoader
-from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader
-from langchain.document_loaders.reddit import RedditPostsLoader
-from langchain.document_loaders.roam import RoamLoader
-from langchain.document_loaders.rocksetdb import RocksetLoader
-from langchain.document_loaders.rss import RSSFeedLoader
-from langchain.document_loaders.rst import UnstructuredRSTLoader
-from langchain.document_loaders.rtf import UnstructuredRTFLoader
-from langchain.document_loaders.s3_directory import S3DirectoryLoader
-from langchain.document_loaders.s3_file import S3FileLoader
-from langchain.document_loaders.sitemap import SitemapLoader
-from langchain.document_loaders.slack_directory import SlackDirectoryLoader
-from langchain.document_loaders.snowflake_loader import SnowflakeLoader
-from langchain.document_loaders.spreedly import SpreedlyLoader
-from langchain.document_loaders.srt import SRTLoader
-from langchain.document_loaders.stripe import StripeLoader
-from langchain.document_loaders.telegram import (
+from oplangchain.document_loaders.powerpoint import UnstructuredPowerPointLoader
+from oplangchain.document_loaders.psychic import PsychicLoader
+from oplangchain.document_loaders.pyspark_dataframe import PySparkDataFrameLoader
+from oplangchain.document_loaders.python import PythonLoader
+from oplangchain.document_loaders.readthedocs import ReadTheDocsLoader
+from oplangchain.document_loaders.recursive_url_loader import RecursiveUrlLoader
+from oplangchain.document_loaders.reddit import RedditPostsLoader
+from oplangchain.document_loaders.roam import RoamLoader
+from oplangchain.document_loaders.rocksetdb import RocksetLoader
+from oplangchain.document_loaders.rss import RSSFeedLoader
+from oplangchain.document_loaders.rst import UnstructuredRSTLoader
+from oplangchain.document_loaders.rtf import UnstructuredRTFLoader
+from oplangchain.document_loaders.s3_directory import S3DirectoryLoader
+from oplangchain.document_loaders.s3_file import S3FileLoader
+from oplangchain.document_loaders.sitemap import SitemapLoader
+from oplangchain.document_loaders.slack_directory import SlackDirectoryLoader
+from oplangchain.document_loaders.snowflake_loader import SnowflakeLoader
+from oplangchain.document_loaders.spreedly import SpreedlyLoader
+from oplangchain.document_loaders.srt import SRTLoader
+from oplangchain.document_loaders.stripe import StripeLoader
+from oplangchain.document_loaders.telegram import (
     TelegramChatApiLoader,
     TelegramChatFileLoader,
 )
-from langchain.document_loaders.tencent_cos_directory import TencentCOSDirectoryLoader
-from langchain.document_loaders.tencent_cos_file import TencentCOSFileLoader
-from langchain.document_loaders.text import TextLoader
-from langchain.document_loaders.tomarkdown import ToMarkdownLoader
-from langchain.document_loaders.toml import TomlLoader
-from langchain.document_loaders.trello import TrelloLoader
-from langchain.document_loaders.tsv import UnstructuredTSVLoader
-from langchain.document_loaders.twitter import TwitterTweetLoader
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.tencent_cos_directory import TencentCOSDirectoryLoader
+from oplangchain.document_loaders.tencent_cos_file import TencentCOSFileLoader
+from oplangchain.document_loaders.text import TextLoader
+from oplangchain.document_loaders.tomarkdown import ToMarkdownLoader
+from oplangchain.document_loaders.toml import TomlLoader
+from oplangchain.document_loaders.trello import TrelloLoader
+from oplangchain.document_loaders.tsv import UnstructuredTSVLoader
+from oplangchain.document_loaders.twitter import TwitterTweetLoader
+from oplangchain.document_loaders.unstructured import (
     UnstructuredAPIFileIOLoader,
     UnstructuredAPIFileLoader,
     UnstructuredFileIOLoader,
     UnstructuredFileLoader,
 )
-from langchain.document_loaders.url import UnstructuredURLLoader
-from langchain.document_loaders.url_playwright import PlaywrightURLLoader
-from langchain.document_loaders.url_selenium import SeleniumURLLoader
-from langchain.document_loaders.weather import WeatherDataLoader
-from langchain.document_loaders.web_base import WebBaseLoader
-from langchain.document_loaders.whatsapp_chat import WhatsAppChatLoader
-from langchain.document_loaders.wikipedia import WikipediaLoader
-from langchain.document_loaders.word_document import (
+from oplangchain.document_loaders.url import UnstructuredURLLoader
+from oplangchain.document_loaders.url_playwright import PlaywrightURLLoader
+from oplangchain.document_loaders.url_selenium import SeleniumURLLoader
+from oplangchain.document_loaders.weather import WeatherDataLoader
+from oplangchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.document_loaders.whatsapp_chat import WhatsAppChatLoader
+from oplangchain.document_loaders.wikipedia import WikipediaLoader
+from oplangchain.document_loaders.word_document import (
     Docx2txtLoader,
     UnstructuredWordDocumentLoader,
 )
-from langchain.document_loaders.xml import UnstructuredXMLLoader
-from langchain.document_loaders.xorbits import XorbitsLoader
-from langchain.document_loaders.youtube import (
+from oplangchain.document_loaders.xml import UnstructuredXMLLoader
+from oplangchain.document_loaders.xorbits import XorbitsLoader
+from oplangchain.document_loaders.youtube import (
     GoogleApiClient,
     GoogleApiYoutubeLoader,
     YoutubeLoader,
 )
 
 # Legacy: only for backwards compatibility. Use PyPDFLoader instead
 PagedPDFSplitter = PyPDFLoader
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/acreom.py` & `oplangchain-0.1.1/oplangchain/document_loaders/acreom.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads acreom vault from a directory."""
 import re
 from pathlib import Path
 from typing import Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class AcreomLoader(BaseLoader):
     """Loader that loads acreom vault from a directory."""
 
     FRONT_MATTER_REGEX = re.compile(r"^---\n(.*?)\n---\n", re.MULTILINE | re.DOTALL)
     """Regex to match front matter metadata in markdown files."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/airbyte_json.py` & `oplangchain-0.1.1/oplangchain/document_loaders/airbyte_json.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads local airbyte json files."""
 import json
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import stringify_dict
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import stringify_dict
 
 
 class AirbyteJSONLoader(BaseLoader):
     """Loads local airbyte json files."""
 
     def __init__(self, file_path: str):
         """Initialize with a file path. This should start with '/tmp/airbyte_local/'."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/airtable.py` & `oplangchain-0.1.1/oplangchain/document_loaders/airtable.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class AirtableLoader(BaseLoader):
     """Loader for Airtable tables."""
 
     def __init__(self, api_token: str, table_id: str, base_id: str):
         """Initialize with API token and the IDs for table and base"""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/apify_dataset.py` & `oplangchain-0.1.1/oplangchain/document_loaders/apify_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from typing import Any, Callable, Dict, List
 
 from pydantic import BaseModel, root_validator
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class ApifyDatasetLoader(BaseLoader, BaseModel):
     """Loads datasets from Apify-a web scraping, crawling, and data extraction platform.
     For details, see https://docs.apify.com/platform/integrations/langchain
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import ApifyDatasetLoader
-            from langchain.schema import Document
+            from oplangchain.document_loaders import ApifyDatasetLoader
+            from oplangchain.schema import Document
 
             loader = ApifyDatasetLoader(
                 dataset_id="YOUR-DATASET-ID",
                 dataset_mapping_function=lambda dataset_item: Document(
                     page_content=dataset_item["text"], metadata={"source": dataset_item["url"]}
                 ),
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/arxiv.py` & `oplangchain-0.1.1/oplangchain/document_loaders/arxiv.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.arxiv import ArxivAPIWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.arxiv import ArxivAPIWrapper
 
 
 class ArxivLoader(BaseLoader):
     """Loads a query result from arxiv.org into a list of Documents.
 
     Each document represents one Document.
     The loader converts the original PDF format into the text.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/async_html.py` & `oplangchain-0.1.1/oplangchain/document_loaders/async_html.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 import logging
 import warnings
 from typing import Any, Dict, Iterator, List, Optional, Union
 
 import aiohttp
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 default_header_template = {
     "User-Agent": "",
     "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*"
     ";q=0.8",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/azlyrics.py` & `oplangchain-0.1.1/oplangchain/document_loaders/azlyrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads AZLyrics."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 
 class AZLyricsLoader(WebBaseLoader):
     """Loads AZLyrics webpages."""
 
     def load(self) -> List[Document]:
         """Load webpages into Documents."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/azure_blob_storage_container.py` & `oplangchain-0.1.1/oplangchain/document_loaders/azure_blob_storage_container.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loading logic for loading documents from an Azure Blob Storage container."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.azure_blob_storage_file import (
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.azure_blob_storage_file import (
     AzureBlobStorageFileLoader,
 )
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class AzureBlobStorageContainerLoader(BaseLoader):
     """Loading Documents from Azure Blob Storage."""
 
     def __init__(self, conn_str: str, container: str, prefix: str = ""):
         """Initialize with connection string, container and blob prefix."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/azure_blob_storage_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/azure_blob_storage_file.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import os
 import tempfile
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class AzureBlobStorageFileLoader(BaseLoader):
     """Loading Documents from Azure Blob Storage."""
 
     def __init__(self, conn_str: str, container: str, blob_name: str):
         """Initialize with connection string, container and blob name."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/base.py` & `oplangchain-0.1.1/oplangchain/document_loaders/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Abstract interface for document loader implementations."""
 from abc import ABC, abstractmethod
 from typing import Iterator, List, Optional
 
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.schema import Document
-from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.schema import Document
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
 
 
 class BaseLoader(ABC):
     """Interface for loading Documents.
 
     Implementations should implement the lazy-loading method using generators
     to avoid loading all Documents into memory at once.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/bibtex.py` & `oplangchain-0.1.1/oplangchain/document_loaders/bibtex.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 import re
 from pathlib import Path
 from typing import Any, Iterator, List, Mapping, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.bibtex import BibtexparserWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.bibtex import BibtexparserWrapper
 
 logger = logging.getLogger(__name__)
 
 
 class BibtexLoader(BaseLoader):
     """Loads a bibtex file into a list of Documents.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/bigquery.py` & `oplangchain-0.1.1/oplangchain/document_loaders/bigquery.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 if TYPE_CHECKING:
     from google.auth.credentials import Credentials
 
 
 class BigQueryLoader(BaseLoader):
     """Loads a query result from BigQuery into a list of documents.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/bilibili.py` & `oplangchain-0.1.1/oplangchain/document_loaders/bilibili.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import json
 import re
 import warnings
 from typing import List, Tuple
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class BiliBiliLoader(BaseLoader):
     """Loads bilibili transcripts."""
 
     def __init__(self, video_urls: List[str]):
         """Initialize with bilibili url.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/blackboard.py` & `oplangchain-0.1.1/oplangchain/document_loaders/blackboard.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 """Loads all documents from a blackboard course."""
 import contextlib
 import re
 from pathlib import Path
 from typing import Any, List, Optional, Tuple
 from urllib.parse import unquote
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.directory import DirectoryLoader
-from langchain.document_loaders.pdf import PyPDFLoader
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.directory import DirectoryLoader
+from oplangchain.document_loaders.pdf import PyPDFLoader
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 
 class BlackboardLoader(WebBaseLoader):
     """Loads all documents from a Blackboard course.
 
     This loader is not compatible with all Blackboard courses. It is only
     compatible with courses that use the new Blackboard interface.
     To use this loader, you must have the BbRouter cookie. You can get this
     cookie by logging into the course and then copying the value of the
     BbRouter cookie from the browser's developer tools.
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import BlackboardLoader
+            from oplangchain.document_loaders import BlackboardLoader
 
             loader = BlackboardLoader(
                 blackboard_course_url="https://blackboard.example.com/webapps/blackboard/execute/announcement?method=search&context=course_entry&course_id=_123456_1",
                 bbrouter="expires:12345...",
             )
             documents = loader.load()
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/file_system.py` & `oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/file_system.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Use to load blobs from the local file system."""
 from pathlib import Path
 from typing import Callable, Iterable, Iterator, Optional, Sequence, TypeVar, Union
 
-from langchain.document_loaders.blob_loaders.schema import Blob, BlobLoader
+from oplangchain.document_loaders.blob_loaders.schema import Blob, BlobLoader
 
 T = TypeVar("T")
 
 
 def _make_iterator(
     length_func: Callable[[], int], show_progress: bool = False
 ) -> Callable[[Iterable[T]], Iterator[T]]:
@@ -39,15 +39,15 @@
 class FileSystemBlobLoader(BlobLoader):
     """Blob loader for the local file system.
 
     Example:
 
     .. code-block:: python
 
-        from langchain.document_loaders.blob_loaders import FileSystemBlobLoader
+        from oplangchain.document_loaders.blob_loaders import FileSystemBlobLoader
         loader = FileSystemBlobLoader("/path/to/directory")
         for blob in loader.yield_blobs():
             print(blob)
     """
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/schema.py` & `oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/schema.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/blob_loaders/youtube_audio.py` & `oplangchain-0.1.1/oplangchain/document_loaders/blob_loaders/youtube_audio.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Iterable, List
 
-from langchain.document_loaders.blob_loaders import FileSystemBlobLoader
-from langchain.document_loaders.blob_loaders.schema import Blob, BlobLoader
+from oplangchain.document_loaders.blob_loaders import FileSystemBlobLoader
+from oplangchain.document_loaders.blob_loaders.schema import Blob, BlobLoader
 
 
 class YoutubeAudioLoader(BlobLoader):
 
     """Load YouTube urls as audio file(s)."""
 
     def __init__(self, urls: List[str], save_dir: str):
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/blockchain.py` & `oplangchain-0.1.1/oplangchain/document_loaders/blockchain.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 import re
 import time
 from enum import Enum
 from typing import List, Optional
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class BlockchainType(Enum):
     """Enumerator of the supported blockchains."""
 
     ETH_MAINNET = "eth-mainnet"
     ETH_GOERLI = "eth-goerli"
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/brave_search.py` & `oplangchain-0.1.1/oplangchain/document_loaders/brave_search.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Iterator, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.brave_search import BraveSearchWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.brave_search import BraveSearchWrapper
 
 
 class BraveSearchLoader(BaseLoader):
     """Loads a query result from Brave Search engine into a list of Documents."""
 
     def __init__(self, query: str, api_key: str, search_kwargs: Optional[dict] = None):
         """Initializes the BraveLoader.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/browserless.py` & `oplangchain-0.1.1/oplangchain/document_loaders/browserless.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Iterator, List, Union
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class BrowserlessLoader(BaseLoader):
     """Loads the content of webpages using Browserless' /content endpoint"""
 
     def __init__(
         self, api_token: str, urls: Union[str, List[str]], text_content: bool = True
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/chatgpt.py` & `oplangchain-0.1.1/oplangchain/document_loaders/chatgpt.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Load conversations from ChatGPT data export"""
 import datetime
 import json
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 def concatenate_rows(message: dict, title: str) -> str:
     """
     Combine message information in a readable format ready to be used.
     Args:
         message: Message to be concatenated
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/college_confidential.py` & `oplangchain-0.1.1/oplangchain/document_loaders/college_confidential.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads College Confidential."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 
 class CollegeConfidentialLoader(WebBaseLoader):
     """Loads College Confidential webpages."""
 
     def load(self) -> List[Document]:
         """Load webpages as Documents."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/concurrent.py` & `oplangchain-0.1.1/oplangchain/document_loaders/concurrent.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 import concurrent.futures
 from pathlib import Path
 from typing import Iterator, Literal, Optional, Sequence, Union
 
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import BlobLoader, FileSystemBlobLoader
-from langchain.document_loaders.generic import GenericLoader
-from langchain.document_loaders.parsers.registry import get_parser
-from langchain.schema import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import BlobLoader, FileSystemBlobLoader
+from oplangchain.document_loaders.generic import GenericLoader
+from oplangchain.document_loaders.parsers.registry import get_parser
+from oplangchain.schema import Document
 
 _PathLike = Union[str, Path]
 
 DEFAULT = Literal["default"]
 
 
 class ConcurrentLoader(GenericLoader):
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/confluence.py` & `oplangchain-0.1.1/oplangchain/document_loaders/confluence.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,16 +7,16 @@
 from tenacity import (
     before_sleep_log,
     retry,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class ContentFormat(str, Enum):
     """Enumerator of the content formats of Confluence page."""
 
@@ -56,15 +56,15 @@
 
     Hint: space_key and page_id can both be found in the URL of a page in Confluence
     - https://yoursite.atlassian.com/wiki/spaces/<space_key>/pages/<page_id>
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import ConfluenceLoader
+            from oplangchain.document_loaders import ConfluenceLoader
 
             loader = ConfluenceLoader(
                 url="https://yoursite.atlassian.com/wiki",
                 username="me",
                 api_key="12345"
             )
             documents = loader.load(space_key="SPACE",limit=50)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/conllu.py` & `oplangchain-0.1.1/oplangchain/document_loaders/conllu.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Load CoNLL-U files."""
 import csv
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class CoNLLULoader(BaseLoader):
     """Load CoNLL-U files."""
 
     def __init__(self, file_path: str):
         """Initialize with a file path."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/csv_loader.py` & `oplangchain-0.1.1/oplangchain/document_loaders/csv_loader.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import csv
 from typing import Any, Dict, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import (
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class CSVLoader(BaseLoader):
     """Loads a CSV file into a list of documents.
@@ -84,15 +84,15 @@
     mode, the CSV file will be a single Unstructured Table element.
     If you use the loader in "elements" mode, an HTML representation
     of the table will be available in the "text_as_html" key in the
     document metadata.
 
     Examples
     --------
-    from langchain.document_loaders.csv_loader import UnstructuredCSVLoader
+    from oplangchain.document_loaders.csv_loader import UnstructuredCSVLoader
 
     loader = UnstructuredCSVLoader("stanley-cups.csv", mode="elements")
     docs = loader.load()
     """
 
     def __init__(
         self, file_path: str, mode: str = "single", **unstructured_kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/cube_semantic.py` & `oplangchain-0.1.1/oplangchain/document_loaders/cube_semantic.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import json
 import logging
 import time
 from typing import List
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class CubeSemanticLoader(BaseLoader):
     """Load Cube semantic layer metadata.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/datadog_logs.py` & `oplangchain-0.1.1/oplangchain/document_loaders/datadog_logs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Load Datadog logs."""
 from datetime import datetime, timedelta
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class DatadogLogsLoader(BaseLoader):
     """Loads a query result from Datadog into a list of documents.
 
     Logs are written into the `page_content` and into the `metadata`.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/dataframe.py` & `oplangchain-0.1.1/oplangchain/document_loaders/dataframe.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Load from a Dataframe object"""
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class DataFrameLoader(BaseLoader):
     """Load Pandas DataFrame."""
 
     def __init__(self, data_frame: Any, page_content_column: str = "text"):
         """Initialize with dataframe object.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/diffbot.py` & `oplangchain-0.1.1/oplangchain/document_loaders/diffbot.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader that uses Diffbot to load webpages in text format."""
 import logging
 from typing import Any, List
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class DiffbotLoader(BaseLoader):
     """Loads Diffbot file json."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/directory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Load documents from a directory."""
 import concurrent
 import logging
 from pathlib import Path
 from typing import Any, List, Optional, Type, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.html_bs import BSHTMLLoader
-from langchain.document_loaders.text import TextLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.html_bs import BSHTMLLoader
+from oplangchain.document_loaders.text import TextLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 FILE_LOADER_TYPE = Union[
     Type[UnstructuredFileLoader], Type[TextLoader], Type[BSHTMLLoader]
 ]
 logger = logging.getLogger(__name__)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/discord.py` & `oplangchain-0.1.1/oplangchain/document_loaders/discord.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Load from Discord chat dump"""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 if TYPE_CHECKING:
     import pandas as pd
 
 
 class DiscordChatLoader(BaseLoader):
     """Load Discord chat logs."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/docugami.py` & `oplangchain-0.1.1/oplangchain/document_loaders/docugami.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,16 +6,16 @@
 import re
 from pathlib import Path
 from typing import Any, Dict, List, Mapping, Optional, Sequence, Union
 
 import requests
 from pydantic import BaseModel, root_validator
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 TD_NAME = "{http://www.w3.org/1999/xhtml}td"
 TABLE_NAME = "{http://www.w3.org/1999/xhtml}table"
 
 XPATH_KEY = "xpath"
 DOCUMENT_ID_KEY = "id"
 DOCUMENT_NAME_KEY = "name"
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/dropbox.py` & `oplangchain-0.1.1/oplangchain/document_loaders/dropbox.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 import os
 import tempfile
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, root_validator
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class DropboxLoader(BaseLoader, BaseModel):
     """Loads files from Dropbox.
 
     In addition to common files such as text and PDF files, it also supports
     *Dropbox Paper* files.
@@ -121,15 +121,15 @@
             text = response.content.decode("utf-8")
         except UnicodeDecodeError:
             print(f"File {file_path} could not be decoded as text. Skipping.")
 
             file_extension = os.path.splitext(file_path)[1].lower()
 
             if file_extension == ".pdf":
-                from langchain.document_loaders import UnstructuredPDFLoader
+                from oplangchain.document_loaders import UnstructuredPDFLoader
 
                 # Download it to a temporary file.
                 temp_dir = tempfile.TemporaryDirectory()
                 temp_pdf = Path(temp_dir.name) / "tmp.pdf"
                 with open(temp_pdf, mode="wb") as f:
                     f.write(response.content)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/duckdb_loader.py` & `oplangchain-0.1.1/oplangchain/document_loaders/duckdb_loader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Dict, List, Optional, cast
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class DuckDBLoader(BaseLoader):
     """Loads a query result from DuckDB into a list of documents.
 
     Each document represents one row of the result. The `page_content_columns`
     are written into the `page_content` of the document. The `metadata_columns`
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/email.py` & `oplangchain-0.1.1/oplangchain/document_loaders/email.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads email files."""
 import os
 from typing import Any, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import (
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     satisfies_min_unstructured_version,
 )
 
 
 class UnstructuredEmailLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load email files. Works with both
@@ -17,22 +17,22 @@
     constructor for the loader. By default, attachments will be processed
     with the unstructured partition function. If you already know the document
     types of the attachments, you can specify another partitioning function
     with the attachment partitioner kwarg.
 
     Example
     -------
-    from langchain.document_loaders import UnstructuredEmailLoader
+    from oplangchain.document_loaders import UnstructuredEmailLoader
 
     loader = UnstructuredEmailLoader("example_data/fake-email.eml", mode="elements")
     loader.load()
 
     Example
     -------
-    from langchain.document_loaders import UnstructuredEmailLoader
+    from oplangchain.document_loaders import UnstructuredEmailLoader
 
     loader = UnstructuredEmailLoader(
         "example_data/fake-email-attachment.eml",
         mode="elements",
         process_attachments=True,
     )
     loader.load()
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/embaas.py` & `oplangchain-0.1.1/oplangchain/document_loaders/embaas.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 import warnings
 from typing import Any, Dict, Iterator, List, Optional
 
 import requests
 from pydantic import BaseModel, root_validator, validator
 from typing_extensions import NotRequired, TypedDict
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseBlobParser, BaseLoader
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.text_splitter import TextSplitter
-from langchain.utils import get_from_dict_or_env
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseBlobParser, BaseLoader
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.text_splitter import TextSplitter
+from oplangchain.utils import get_from_dict_or_env
 
 EMBAAS_DOC_API_URL = "https://api.embaas.io/v1/document/extract-text/bytes/"
 
 
 class EmbaasDocumentExtractionParameters(TypedDict):
     """Parameters for the embaas document extraction API."""
 
@@ -78,21 +78,21 @@
     environment variable ``EMBAAS_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
             # Default parsing
-            from langchain.document_loaders.embaas import EmbaasBlobLoader
+            from oplangchain.document_loaders.embaas import EmbaasBlobLoader
             loader = EmbaasBlobLoader()
             blob = Blob.from_path(path="example.mp3")
             documents = loader.parse(blob=blob)
 
             # Custom api parameters (create embeddings automatically)
-            from langchain.document_loaders.embaas import EmbaasBlobLoader
+            from oplangchain.document_loaders.embaas import EmbaasBlobLoader
             loader = EmbaasBlobLoader(
                 params={
                     "should_embed": True,
                     "model": "e5-large-v2",
                     "chunk_size": 256,
                     "chunk_splitter": "CharacterTextSplitter"
                 }
@@ -184,20 +184,20 @@
     environment variable ``EMBAAS_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
             # Default parsing
-            from langchain.document_loaders.embaas import EmbaasLoader
+            from oplangchain.document_loaders.embaas import EmbaasLoader
             loader = EmbaasLoader(file_path="example.mp3")
             documents = loader.load()
 
             # Custom api parameters (create embeddings automatically)
-            from langchain.document_loaders.embaas import EmbaasBlobLoader
+            from oplangchain.document_loaders.embaas import EmbaasBlobLoader
             loader = EmbaasBlobLoader(
                 file_path="example.pdf",
                 params={
                     "should_embed": True,
                     "model": "e5-large-v2",
                     "chunk_size": 256,
                     "chunk_splitter": "CharacterTextSplitter"
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/epub.py` & `oplangchain-0.1.1/oplangchain/document_loaders/epub.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads EPub files."""
 from typing import List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     satisfies_min_unstructured_version,
 )
 
 
 class UnstructuredEPubLoader(UnstructuredFileLoader):
     """Loader that uses Unstructured to load EPUB files.
@@ -15,15 +15,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredEPubLoader
+    from oplangchain.document_loaders import UnstructuredEPubLoader
 
     loader = UnstructuredEPubLoader(
         "example.epub", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/etherscan.py` & `oplangchain-0.1.1/oplangchain/document_loaders/etherscan.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import os
 import re
 from typing import Iterator, List
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class EtherscanLoader(BaseLoader):
     """
     Load transactions from an account on Ethereum mainnet.
 
     The Loader use Etherscan API to interact with Ethereum mainnet.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/evernote.py` & `oplangchain-0.1.1/oplangchain/document_loaders/evernote.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 """
 import hashlib
 import logging
 from base64 import b64decode
 from time import strptime
 from typing import Any, Dict, Iterator, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class EverNoteLoader(BaseLoader):
     """EverNote Loader.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/excel.py` & `oplangchain-0.1.1/oplangchain/document_loaders/excel.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads Microsoft Excel files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredExcelLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load Excel files. Like other
@@ -14,15 +14,15 @@
     mode, each sheet in the Excel file will be a an Unstructured Table
     element. If you use the loader in "elements" mode, an
     HTML representation of the table will be available in the
     "text_as_html" key in the document metadata.
 
     Examples
     --------
-    from langchain.document_loaders.excel import UnstructuredExcelLoader
+    from oplangchain.document_loaders.excel import UnstructuredExcelLoader
 
     loader = UnstructuredExcelLoader("stanley-cups.xlsd", mode="elements")
     docs = loader.load()
     """
 
     def __init__(
         self, file_path: str, mode: str = "single", **unstructured_kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/facebook_chat.py` & `oplangchain-0.1.1/oplangchain/document_loaders/facebook_chat.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loads Facebook chat json dump."""
 import datetime
 import json
 from pathlib import Path
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 def concatenate_rows(row: dict) -> str:
     """Combine message information in a readable format ready to be used.
 
     Args:
         row: dictionary containing message information.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/fauna.py` & `oplangchain-0.1.1/oplangchain/document_loaders/fauna.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Iterator, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class FaunaLoader(BaseLoader):
     """FaunaDB Loader.
 
     Attributes:
         query (str): The FQL query string to execute.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/figma.py` & `oplangchain-0.1.1/oplangchain/document_loaders/figma.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loads Figma files json dump."""
 import json
 import urllib.request
 from typing import Any, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import stringify_dict
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import stringify_dict
 
 
 class FigmaFileLoader(BaseLoader):
     """Loads Figma file json."""
 
     def __init__(self, access_token: str, ids: str, key: str):
         """Initialize with access token, ids, and key.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/gcs_directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/gcs_directory.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loading logic for loading documents from an GCS directory."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.gcs_file import GCSFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.gcs_file import GCSFileLoader
 
 
 class GCSDirectoryLoader(BaseLoader):
     """Loads Documents from GCS."""
 
     def __init__(self, project_name: str, bucket: str, prefix: str = ""):
         """Initialize with bucket and key name.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/gcs_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/gcs_file.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Load documents from a GCS file."""
 import os
 import tempfile
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class GCSFileLoader(BaseLoader):
     """Load Documents from a GCS file."""
 
     def __init__(self, project_name: str, bucket: str, blob: str):
         """Initialize with bucket and key name.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/generic.py` & `oplangchain-0.1.1/oplangchain/document_loaders/generic.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 from pathlib import Path
 from typing import Iterator, List, Literal, Optional, Sequence, Union
 
-from langchain.document_loaders.base import BaseBlobParser, BaseLoader
-from langchain.document_loaders.blob_loaders import BlobLoader, FileSystemBlobLoader
-from langchain.document_loaders.parsers.registry import get_parser
-from langchain.schema import Document
-from langchain.text_splitter import TextSplitter
+from oplangchain.document_loaders.base import BaseBlobParser, BaseLoader
+from oplangchain.document_loaders.blob_loaders import BlobLoader, FileSystemBlobLoader
+from oplangchain.document_loaders.parsers.registry import get_parser
+from oplangchain.schema import Document
+from oplangchain.text_splitter import TextSplitter
 
 _PathLike = Union[str, Path]
 
 DEFAULT = Literal["default"]
 
 
 class GenericLoader(BaseLoader):
@@ -20,16 +20,16 @@
     A generic document loader that allows combining an arbitrary blob loader with
     a blob parser.
 
     Examples:
 
         .. code-block:: python
 
-        from langchain.document_loaders import GenericLoader
-        from langchain.document_loaders.blob_loaders import FileSystemBlobLoader
+        from oplangchain.document_loaders import GenericLoader
+        from oplangchain.document_loaders.blob_loaders import FileSystemBlobLoader
 
         loader = GenericLoader.from_filesystem(
             path="path/to/directory",
             glob="**/[!.]*",
             suffixes=[".pdf"],
             show_progress=True,
         )
@@ -50,15 +50,15 @@
             # Load all files in a directory without recursion.
             loader = GenericLoader.from_filesystem("/path/to/dir", glob="*")
 
         Example instantiations to change which parser is used:
 
         ... code-block:: python
 
-            from langchain.document_loaders.parsers.pdf import PyPDFParser
+            from oplangchain.document_loaders.parsers.pdf import PyPDFParser
 
             # Recursively load all text files in a directory.
             loader = GenericLoader.from_filesystem(
                 "/path/to/dir",
                 glob="**/*.pdf",
                 parser=PyPDFParser()
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/geodataframe.py` & `oplangchain-0.1.1/oplangchain/document_loaders/geodataframe.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Load from Dataframe object"""
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class GeoDataFrameLoader(BaseLoader):
     """Load geopandas Dataframe."""
 
     def __init__(self, data_frame: Any, page_content_column: str = "geometry"):
         """Initialize with geopandas Dataframe.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/git.py` & `oplangchain-0.1.1/oplangchain/document_loaders/git.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import os
 from typing import Callable, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class GitLoader(BaseLoader):
     """Loads files from a Git repository into a list of documents.
     The Repository can be local on disk available at `repo_path`,
     or remote at `clone_url` that will be cloned to `repo_path`.
     Currently, supports only text files.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/gitbook.py` & `oplangchain-0.1.1/oplangchain/document_loaders/gitbook.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loads GitBook."""
 from typing import Any, List, Optional
 from urllib.parse import urljoin, urlparse
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 
 class GitbookLoader(WebBaseLoader):
     """Load GitBook data.
 
     1. load from either a single page, or
     2. load all (relative) paths in the navbar.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/github.py` & `oplangchain-0.1.1/oplangchain/document_loaders/github.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from abc import ABC
 from datetime import datetime
 from typing import Dict, Iterator, List, Literal, Optional, Union
 
 import requests
 from pydantic import BaseModel, root_validator, validator
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import get_from_dict_or_env
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import get_from_dict_or_env
 
 
 class BaseGitHubLoader(BaseLoader, BaseModel, ABC):
     """Load issues of a GitHub repository."""
 
     repo: str
     """Name of repository"""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/googledrive.py` & `oplangchain-0.1.1/oplangchain/document_loaders/googledrive.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 
 import os
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Sequence, Union
 
 from pydantic import BaseModel, root_validator, validator
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 SCOPES = ["https://www.googleapis.com/auth/drive.readonly"]
 
 
 class GoogleDriveLoader(BaseLoader, BaseModel):
     """Loads Google Docs from Google Drive."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/gutenberg.py` & `oplangchain-0.1.1/oplangchain/document_loaders/gutenberg.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads .txt web files."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class GutenbergLoader(BaseLoader):
     """Loader that uses urllib to load .txt web files."""
 
     def __init__(self, file_path: str):
         """Initialize with a file path."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/helpers.py` & `oplangchain-0.1.1/oplangchain/document_loaders/helpers.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/hn.py` & `oplangchain-0.1.1/oplangchain/document_loaders/hn.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads HN."""
 from typing import Any, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 
 class HNLoader(WebBaseLoader):
     """Load Hacker News data from either main page results or the comments page."""
 
     def load(self) -> List[Document]:
         """Get important HN webpage information.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/html.py` & `oplangchain-0.1.1/oplangchain/document_loaders/html.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """Loader that uses unstructured to load HTML files."""
 from typing import List
 
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class UnstructuredHTMLLoader(UnstructuredFileLoader):
     """Loader that uses Unstructured to load HTML files.
 
     You can run the loader in one of two modes: "single" and "elements".
     If you use "single" mode, the document will be returned as a single
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredHTMLLoader
+    from oplangchain.document_loaders import UnstructuredHTMLLoader
 
     loader = UnstructuredHTMLLoader(
         "example.html", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/html_bs.py` & `oplangchain-0.1.1/oplangchain/document_loaders/html_bs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loader that uses bs4 to load HTML files, enriching metadata with page title."""
 
 import logging
 from typing import Dict, List, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class BSHTMLLoader(BaseLoader):
     """Loader that uses beautiful soup to parse HTML files."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/hugging_face_dataset.py` & `oplangchain-0.1.1/oplangchain/document_loaders/hugging_face_dataset.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads HuggingFace datasets."""
 from typing import Iterator, List, Mapping, Optional, Sequence, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class HuggingFaceDatasetLoader(BaseLoader):
     """Load Documents from the Hugging Face Hub."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/ifixit.py` & `oplangchain-0.1.1/oplangchain/document_loaders/ifixit.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loads iFixit data."""
 from typing import List, Optional
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.web_base import WebBaseLoader
 
 IFIXIT_BASE_URL = "https://www.ifixit.com/api/2.0"
 
 
 class IFixitLoader(BaseLoader):
     """Load iFixit repair guides, device wikis and answers.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/image.py` & `oplangchain-0.1.1/oplangchain/document_loaders/image.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """Loads image files."""
 from typing import List
 
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class UnstructuredImageLoader(UnstructuredFileLoader):
     """Loader that uses Unstructured to load PNG and JPG files.
 
     You can run the loader in one of two modes: "single" and "elements".
     If you use "single" mode, the document will be returned as a single
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredImageLoader
+    from oplangchain.document_loaders import UnstructuredImageLoader
 
     loader = UnstructuredImageLoader(
         "example.png", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/image_captions.py` & `oplangchain-0.1.1/oplangchain/document_loaders/image_captions.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 https://huggingface.co/Salesforce/blip-image-captioning-base
 
 """
 from typing import Any, List, Tuple, Union
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class ImageCaptionLoader(BaseLoader):
     """Loads the captions of an image"""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/iugu.py` & `oplangchain-0.1.1/oplangchain/document_loaders/iugu.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader that fetches data from IUGU"""
 import json
 import urllib.request
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import get_from_env, stringify_dict
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import get_from_env, stringify_dict
 
 IUGU_ENDPOINTS = {
     "invoices": "https://api.iugu.com/v1/invoices",
     "customers": "https://api.iugu.com/v1/customers",
     "charges": "https://api.iugu.com/v1/charges",
     "subscriptions": "https://api.iugu.com/v1/subscriptions",
     "plans": "https://api.iugu.com/v1/plans",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/joplin.py` & `oplangchain-0.1.1/oplangchain/document_loaders/joplin.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import json
 import urllib
 from datetime import datetime
 from typing import Iterator, List, Optional
 
-from langchain.document_loaders.base import BaseLoader
-from langchain.schema import Document
-from langchain.utils import get_from_env
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.schema import Document
+from oplangchain.utils import get_from_env
 
 LINK_NOTE_TEMPLATE = "joplin://x-callback-url/openNote?id={id}"
 
 
 class JoplinLoader(BaseLoader):
     """
     Loader that fetches notes from Joplin.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/json_loader.py` & `oplangchain-0.1.1/oplangchain/document_loaders/json_loader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads data from JSON."""
 import json
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class JSONLoader(BaseLoader):
     """Loads a JSON file using a jq schema.
 
     Example:
         [{"text": ...}, {"text": ...}, {"text": ...}] -> schema = .[].text
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/larksuite.py` & `oplangchain-0.1.1/oplangchain/document_loaders/larksuite.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads LarkSuite (FeiShu) document json dump."""
 import json
 import urllib.request
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class LarkSuiteDocLoader(BaseLoader):
     """Loads LarkSuite (FeiShu) document."""
 
     def __init__(self, domain: str, access_token: str, document_id: str):
         """Initialize with domain, access_token (tenant / user), and document_id.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/markdown.py` & `oplangchain-0.1.1/oplangchain/document_loaders/markdown.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """Loads Markdown files."""
 from typing import List
 
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class UnstructuredMarkdownLoader(UnstructuredFileLoader):
     """Loader that uses Unstructured to load markdown files.
 
     You can run the loader in one of two modes: "single" and "elements".
     If you use "single" mode, the document will be returned as a single
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredMarkdownLoader
+    from oplangchain.document_loaders import UnstructuredMarkdownLoader
 
     loader = UnstructuredMarkdownLoader(
         "example.md", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/mastodon.py` & `oplangchain-0.1.1/oplangchain/document_loaders/mastodon.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Mastodon document loader."""
 from __future__ import annotations
 
 import os
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 if TYPE_CHECKING:
     import mastodon
 
 
 def _dependable_mastodon_import() -> mastodon:
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/max_compute.py` & `oplangchain-0.1.1/oplangchain/document_loaders/max_compute.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import Any, Iterator, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.max_compute import MaxComputeAPIWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.max_compute import MaxComputeAPIWrapper
 
 
 class MaxComputeLoader(BaseLoader):
     """Loads a query result from Alibaba Cloud MaxCompute table into documents."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/mediawikidump.py` & `oplangchain-0.1.1/oplangchain/document_loaders/mediawikidump.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 """Load Data from a MediaWiki dump xml."""
 import logging
 from pathlib import Path
 from typing import List, Optional, Sequence, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class MWDumpLoader(BaseLoader):
     """
     Load MediaWiki dump from XML file
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import MWDumpLoader
+            from oplangchain.document_loaders import MWDumpLoader
 
             loader = MWDumpLoader(
                 file_path="myWiki.xml",
                 encoding="utf8"
             )
             docs = loader.load()
-            from langchain.text_splitter import RecursiveCharacterTextSplitter
+            from oplangchain.text_splitter import RecursiveCharacterTextSplitter
             text_splitter = RecursiveCharacterTextSplitter(
                 chunk_size=1000, chunk_overlap=0
             )
             texts = text_splitter.split_documents(docs)
 
 
     :param file_path: XML local file path
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/merge.py` & `oplangchain-0.1.1/oplangchain/document_loaders/merge.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class MergedDataLoader(BaseLoader):
     """Merge documents from a list of loaders"""
 
     def __init__(self, loaders: List):
         """Initialize with a list of loaders"""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/mhtml.py` & `oplangchain-0.1.1/oplangchain/document_loaders/mhtml.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Load MHTML files, enriching metadata with page title."""
 
 import email
 import logging
 from typing import Dict, List, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class MHTMLLoader(BaseLoader):
     """Loader that uses beautiful soup to parse HTML files."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/modern_treasury.py` & `oplangchain-0.1.1/oplangchain/document_loaders/modern_treasury.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Loader that fetches data from Modern Treasury"""
 import json
 import urllib.request
 from base64 import b64encode
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import get_from_env, stringify_value
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import get_from_env, stringify_value
 
 MODERN_TREASURY_ENDPOINTS = {
     "payment_orders": "https://app.moderntreasury.com/api/payment_orders",
     "expected_payments": "https://app.moderntreasury.com/api/expected_payments",
     "returns": "https://app.moderntreasury.com/api/returns",
     "incoming_payment_details": "https://app.moderntreasury.com/api/\
 incoming_payment_details",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/news.py` & `oplangchain-0.1.1/oplangchain/document_loaders/news.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loader that uses unstructured to load HTML files."""
 import logging
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class NewsURLLoader(BaseLoader):
     """Loader that uses newspaper to load news articles from URLs.
 
@@ -23,15 +23,15 @@
             tqdm to be installed, ``pip install tqdm``.
         **newspaper_kwargs: Any additional named arguments to pass to
             newspaper.Article().
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import NewsURLLoader
+            from oplangchain.document_loaders import NewsURLLoader
 
             loader = NewsURLLoader(
                 urls=["<url-1>", "<url-2>"],
             )
             docs = loader.load()
 
     Newspaper reference:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/notebook.py` & `oplangchain-0.1.1/oplangchain/document_loaders/notebook.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads .ipynb notebook files."""
 import json
 from pathlib import Path
 from typing import Any, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 def concatenate_cells(
     cell: dict, include_outputs: bool, max_output_length: int, traceback: bool
 ) -> str:
     """Combine cells information in a readable format ready to be used.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/notion.py` & `oplangchain-0.1.1/oplangchain/document_loaders/notion.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loads Notion directory dump."""
 from pathlib import Path
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class NotionDirectoryLoader(BaseLoader):
     """Loads Notion directory dump."""
 
     def __init__(self, path: str):
         """Initialize with a file path."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/notiondb.py` & `oplangchain-0.1.1/oplangchain/document_loaders/notiondb.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Notion DB loader for langchain"""
 
 from typing import Any, Dict, List, Optional
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 NOTION_BASE_URL = "https://api.notion.com/v1"
 DATABASE_URL = NOTION_BASE_URL + "/databases/{database_id}/query"
 PAGE_URL = NOTION_BASE_URL + "/pages/{page_id}"
 BLOCK_URL = NOTION_BASE_URL + "/blocks/{block_id}/children"
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/obs_directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/obs_directory.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 # coding:utf-8
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.obs_file import OBSFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.obs_file import OBSFileLoader
 
 
 class OBSDirectoryLoader(BaseLoader):
     """Loading logic for loading documents from Huawei OBS."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/obs_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/obs_file.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # coding:utf-8
 
 import os
 import tempfile
 from typing import Any, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class OBSFileLoader(BaseLoader):
     """Loader for Huawei OBS file."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/obsidian.py` & `oplangchain-0.1.1/oplangchain/document_loaders/obsidian.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loads Obsidian directory dump."""
 import re
 from pathlib import Path
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class ObsidianLoader(BaseLoader):
     """Loads Obsidian files from disk."""
 
     FRONT_MATTER_REGEX = re.compile(r"^---\n(.*?)\n---\n", re.MULTILINE | re.DOTALL)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/odt.py` & `oplangchain-0.1.1/oplangchain/document_loaders/odt.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads OpenOffice ODT files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredODTLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load OpenOffice ODT files.
@@ -14,15 +14,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredODTLoader
+    from oplangchain.document_loaders import UnstructuredODTLoader
 
     loader = UnstructuredODTLoader(
         "example.odt", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/onedrive.py` & `oplangchain-0.1.1/oplangchain/document_loaders/onedrive.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 import tempfile
 from enum import Enum
 from pathlib import Path
 from typing import TYPE_CHECKING, Dict, List, Optional, Type, Union
 
 from pydantic import BaseModel, BaseSettings, Field, FilePath, SecretStr
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.onedrive_file import OneDriveFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.onedrive_file import OneDriveFileLoader
 
 if TYPE_CHECKING:
     from O365 import Account
     from O365.drive import Drive, Folder
 
 SCOPES = ["offline_access", "Files.Read.All"]
 logger = logging.getLogger(__name__)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/onedrive_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/onedrive_file.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 import tempfile
 from typing import TYPE_CHECKING, List
 
 from pydantic import BaseModel, Field
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 if TYPE_CHECKING:
     from O365.drive import File
 
 CHUNK_SIZE = 1024 * 1024 * 5
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/open_city_data.py` & `oplangchain-0.1.1/oplangchain/document_loaders/open_city_data.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class OpenCityDataLoader(BaseLoader):
     """Loads Open City data."""
 
     def __init__(self, city_id: str, dataset_id: str, limit: int):
         """Initialize with dataset_id.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/org_mode.py` & `oplangchain-0.1.1/oplangchain/document_loaders/org_mode.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads Org-Mode files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredOrgModeLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load Org-Mode files.
@@ -14,15 +14,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredOrgModeLoader
+    from oplangchain.document_loaders import UnstructuredOrgModeLoader
 
     loader = UnstructuredOrgModeLoader(
         "example.org", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/__init__.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,12 @@
-from langchain.document_loaders.parsers.audio import OpenAIWhisperParser
-from langchain.document_loaders.parsers.grobid import GrobidParser
-from langchain.document_loaders.parsers.html import BS4HTMLParser
-from langchain.document_loaders.parsers.language import LanguageParser
-from langchain.document_loaders.parsers.pdf import (
+from oplangchain.document_loaders.parsers.audio import OpenAIWhisperParser
+from oplangchain.document_loaders.parsers.grobid import GrobidParser
+from oplangchain.document_loaders.parsers.html import BS4HTMLParser
+from oplangchain.document_loaders.parsers.language import LanguageParser
+from oplangchain.document_loaders.parsers.pdf import (
     PDFMinerParser,
     PDFPlumberParser,
     PyMuPDFParser,
     PyPDFium2Parser,
     PyPDFParser,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/audio.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/audio.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import time
 from typing import Iterator, Optional
 
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.schema import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.schema import Document
 
 
 class OpenAIWhisperParser(BaseBlobParser):
     """Transcribe and parse audio files.
     Audio transcription is with OpenAI Whisper model."""
 
     def __init__(self, api_key: Optional[str] = None):
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/generic.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/generic.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,31 +1,31 @@
 """Code for generic / auxiliary parsers.
 
 This module contains some logic to help assemble more sophisticated parsers.
 """
 from typing import Iterator, Mapping, Optional
 
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders.schema import Blob
-from langchain.schema import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders.schema import Blob
+from oplangchain.schema import Document
 
 
 class MimeTypeBasedParser(BaseBlobParser):
     """A parser that uses mime-types to determine how to parse a blob.
 
     This parser is useful for simple pipelines where the mime-type is sufficient
     to determine how to parse a blob.
 
     To use, configure handlers based on mime-types and pass them to the initializer.
 
     Example:
 
         .. code-block:: python
 
-        from langchain.document_loaders.parsers.generic import MimeTypeBasedParser
+        from oplangchain.document_loaders.parsers.generic import MimeTypeBasedParser
 
         parser = MimeTypeBasedParser(
             handlers={
                 "application/pdf": ...,
             },
             fallback_parser=...,
         )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/grobid.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/grobid.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Dict, Iterator, List, Union
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import Blob
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import Blob
 
 logger = logging.getLogger(__name__)
 
 
 class ServerUnavailableException(Exception):
     """Exception raised when the GROBID server is unavailable."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/html/bs4.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/html/bs4.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader that uses bs4 to load HTML files, enriching metadata with page title."""
 
 import logging
 from typing import Any, Dict, Iterator, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import Blob
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import Blob
 
 logger = logging.getLogger(__name__)
 
 
 class BS4HTMLParser(BaseBlobParser):
     """Parser that uses beautiful soup to parse HTML files."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/javascript.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/javascript.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Any, List
 
-from langchain.document_loaders.parsers.language.code_segmenter import CodeSegmenter
+from oplangchain.document_loaders.parsers.language.code_segmenter import CodeSegmenter
 
 
 class JavaScriptSegmenter(CodeSegmenter):
     """The code segmenter for JavaScript."""
 
     def __init__(self, code: str):
         super().__init__(code)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/language_parser.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/language_parser.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, Iterator, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.document_loaders.parsers.language.javascript import JavaScriptSegmenter
-from langchain.document_loaders.parsers.language.python import PythonSegmenter
-from langchain.text_splitter import Language
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.document_loaders.parsers.language.javascript import JavaScriptSegmenter
+from oplangchain.document_loaders.parsers.language.python import PythonSegmenter
+from oplangchain.text_splitter import Language
 
 LANGUAGE_EXTENSIONS: Dict[str, str] = {
     "py": Language.PYTHON,
     "js": Language.JS,
 }
 
 LANGUAGE_SEGMENTERS: Dict[str, Any] = {
@@ -33,31 +33,31 @@
     The language used for parsing can be configured, along with the minimum number of
     lines required to activate the splitting based on syntax.
 
     Examples:
 
         .. code-block:: python
 
-            from langchain.text_splitter.Language
-            from langchain.document_loaders.generic import GenericLoader
-            from langchain.document_loaders.parsers import LanguageParser
+            from oplangchain.text_splitter.Language
+            from oplangchain.document_loaders.generic import GenericLoader
+            from oplangchain.document_loaders.parsers import LanguageParser
 
             loader = GenericLoader.from_filesystem(
                 "./code",
                 glob="**/*",
                 suffixes=[".py", ".js"],
                 parser=LanguageParser()
             )
             docs = loader.load()
 
         Example instantiations to manually select the language:
 
         ... code-block:: python
 
-            from langchain.text_splitter import Language
+            from oplangchain.text_splitter import Language
 
             loader = GenericLoader.from_filesystem(
                 "./code",
                 glob="**/*",
                 suffixes=[".py"],
                 parser=LanguageParser(language=Language.PYTHON)
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/language/python.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/language/python.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import ast
 from typing import Any, List
 
-from langchain.document_loaders.parsers.language.code_segmenter import CodeSegmenter
+from oplangchain.document_loaders.parsers.language.code_segmenter import CodeSegmenter
 
 
 class PythonSegmenter(CodeSegmenter):
     """The code segmenter for Python."""
 
     def __init__(self, code: str):
         super().__init__(code)
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/pdf.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/pdf.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Module contains common parsers for PDFs."""
 from typing import Any, Iterator, Mapping, Optional, Sequence, Union
 from urllib.parse import urlparse
 
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.schema import Document
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.schema import Document
 
 
 class PyPDFParser(BaseBlobParser):
     """Loads a PDF with pypdf and chunks at character level."""
 
     def __init__(self, password: Optional[Union[str, bytes]] = None):
         self.password = password
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/parsers/registry.py` & `oplangchain-0.1.1/oplangchain/document_loaders/parsers/registry.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Module includes a registry of default parser configurations."""
-from langchain.document_loaders.base import BaseBlobParser
-from langchain.document_loaders.parsers.generic import MimeTypeBasedParser
-from langchain.document_loaders.parsers.pdf import PyMuPDFParser
-from langchain.document_loaders.parsers.txt import TextParser
+from oplangchain.document_loaders.base import BaseBlobParser
+from oplangchain.document_loaders.parsers.generic import MimeTypeBasedParser
+from oplangchain.document_loaders.parsers.pdf import PyMuPDFParser
+from oplangchain.document_loaders.parsers.txt import TextParser
 
 
 def _get_default_parser() -> BaseBlobParser:
     """Get default mime-type based parser."""
     return MimeTypeBasedParser(
         handlers={
             "application/pdf": PyMuPDFParser(),
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/pdf.py` & `oplangchain-0.1.1/oplangchain/document_loaders/pdf.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,27 +8,27 @@
 from io import StringIO
 from pathlib import Path
 from typing import Any, Iterator, List, Mapping, Optional, Sequence, Union
 from urllib.parse import urlparse
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.blob_loaders import Blob
-from langchain.document_loaders.parsers.pdf import (
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.blob_loaders import Blob
+from oplangchain.document_loaders.parsers.pdf import (
     AmazonTextractPDFParser,
     PDFMinerParser,
     PDFPlumberParser,
     PyMuPDFParser,
     PyPDFium2Parser,
     PyPDFParser,
 )
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
-from langchain.utils import get_from_dict_or_env
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__file__)
 
 
 class UnstructuredPDFLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load PDF files.
     You can run the loader in one of two modes: "single" and "elements".
@@ -36,15 +36,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredPDFLoader
+    from oplangchain.document_loaders import UnstructuredPDFLoader
 
     loader = UnstructuredPDFLoader(
         "example.pdf", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
@@ -469,15 +469,15 @@
     the name of the profile from the ~/.aws/credentials file that is to be used.
 
     Make sure the credentials / roles used have the required policies to
     access the Amazon Textract service.
 
     Example:
         .. code-block:: python
-            from langchain.document_loaders import AmazonTextractPDFLoader
+            from oplangchain.document_loaders import AmazonTextractPDFLoader
             loader = AmazonTextractPDFLoader(
                 file_path="s3://pdfs/myfile.pdf"
             )
             document = loader.load()
     """
 
     def __init__(
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/powerpoint.py` & `oplangchain-0.1.1/oplangchain/document_loaders/powerpoint.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Loads PowerPoint files."""
 import os
 from typing import List
 
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class UnstructuredPowerPointLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load PowerPoint files.
     Works with both .ppt and .pptx files.
     You can run the loader in one of two modes: "single" and "elements".
     If you use "single" mode, the document will be returned as a single
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredPowerPointLoader
+    from oplangchain.document_loaders import UnstructuredPowerPointLoader
 
     loader = UnstructuredPowerPointLoader(
         "example.pptx", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/psychic.py` & `oplangchain-0.1.1/oplangchain/document_loaders/psychic.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loads documents from Psychic.dev."""
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class PsychicLoader(BaseLoader):
     """Loads documents from Psychic.dev."""
 
     def __init__(
         self, api_key: str, account_id: str, connector_id: Optional[str] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/pyspark_dataframe.py` & `oplangchain-0.1.1/oplangchain/document_loaders/pyspark_dataframe.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Load from a Spark Dataframe object"""
 import itertools
 import logging
 import sys
 from typing import TYPE_CHECKING, Any, Iterator, List, Optional, Tuple
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__file__)
 
 if TYPE_CHECKING:
     from pyspark.sql import SparkSession
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/python.py` & `oplangchain-0.1.1/oplangchain/document_loaders/python.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 import tokenize
 
-from langchain.document_loaders.text import TextLoader
+from oplangchain.document_loaders.text import TextLoader
 
 
 class PythonLoader(TextLoader):
     """
     Load Python files, respecting any non-default encoding if specified.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/readthedocs.py` & `oplangchain-0.1.1/oplangchain/document_loaders/readthedocs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loads ReadTheDocs documentation directory dump."""
 from pathlib import Path
 from typing import Any, List, Optional, Tuple, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class ReadTheDocsLoader(BaseLoader):
     """Loads ReadTheDocs documentation directory dump."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/recursive_url_loader.py` & `oplangchain-0.1.1/oplangchain/document_loaders/recursive_url_loader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import asyncio
 import re
 from typing import Callable, Iterator, List, Optional, Set, Union
 from urllib.parse import urljoin, urlparse
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class RecursiveUrlLoader(BaseLoader):
     """Loads all child links from a given url."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/reddit.py` & `oplangchain-0.1.1/oplangchain/document_loaders/reddit.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Reddit document loader."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Iterable, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 if TYPE_CHECKING:
     import praw
 
 
 def _dependable_praw_import() -> praw:
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/roam.py` & `oplangchain-0.1.1/oplangchain/document_loaders/roam.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loads Roam directory dump."""
 from pathlib import Path
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class RoamLoader(BaseLoader):
     """Loads Roam files from disk."""
 
     def __init__(self, path: str):
         """Initialize with a path."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/rocksetdb.py` & `oplangchain-0.1.1/oplangchain/document_loaders/rocksetdb.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Any, Callable, Iterator, List, Optional, Tuple
 
-from langchain.document_loaders.base import BaseLoader
-from langchain.schema import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.schema import Document
 
 
 def default_joiner(docs: List[Tuple[str, Any]]) -> str:
     """Default joiner for content columns."""
     return "\n".join([doc[1] for doc in docs])
 
 
@@ -24,21 +24,21 @@
     Example:
         .. code-block:: python
 
             # This code will load 3 records from the "langchain_demo"
             # collection as Documents, with the `text` column used as
             # the content
 
-            from langchain.document_loaders import RocksetLoader
+            from oplangchain.document_loaders import RocksetLoader
             from rockset import RocksetClient, Regions, models
 
             loader = RocksetLoader(
                 RocksetClient(Regions.usw2a1, "<api key>"),
                 models.QueryRequestSql(
-                    query="select * from langchain_demo limit 3"
+                    query="select * from oplangchain_demo limit 3"
                 ),
                 ["text"]
             )
         )
     """
 
     def __init__(
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/rss.py` & `oplangchain-0.1.1/oplangchain/document_loaders/rss.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loader that uses unstructured to load HTML files."""
 import logging
 from typing import Any, Iterator, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.news import NewsURLLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.news import NewsURLLoader
 
 logger = logging.getLogger(__name__)
 
 
 class RSSFeedLoader(BaseLoader):
     """Loader that uses newspaper to load news articles from RSS feeds.
 
@@ -22,15 +22,15 @@
             tqdm to be installed, ``pip install tqdm``.
         **newsloader_kwargs: Any additional named arguments to pass to
             NewsURLLoader.
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import RSSFeedLoader
+            from oplangchain.document_loaders import RSSFeedLoader
 
             loader = RSSFeedLoader(
                 urls=["<url-1>", "<url-2>"],
             )
             docs = loader.load()
 
     The loader uses feedparser to parse RSS feeds.  The feedparser library is not installed by default so you should
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/rst.py` & `oplangchain-0.1.1/oplangchain/document_loaders/rst.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads RST files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredRSTLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load RST files.
@@ -14,15 +14,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredRSTLoader
+    from oplangchain.document_loaders import UnstructuredRSTLoader
 
     loader = UnstructuredRSTLoader(
         "example.rst", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/rtf.py` & `oplangchain-0.1.1/oplangchain/document_loaders/rtf.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads rich text files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     satisfies_min_unstructured_version,
 )
 
 
 class UnstructuredRTFLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load RTF files.
@@ -14,15 +14,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredRTFLoader
+    from oplangchain.document_loaders import UnstructuredRTFLoader
 
     loader = UnstructuredRTFLoader(
         "example.rtf", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/s3_directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/s3_directory.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loading logic for loading documents from an AWS S3 directory."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.s3_file import S3FileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.s3_file import S3FileLoader
 
 
 class S3DirectoryLoader(BaseLoader):
     """Loading logic for loading documents from an AWS S3."""
 
     def __init__(self, bucket: str, prefix: str = ""):
         """Initialize with bucket and key name.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/s3_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/s3_file.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loading logic for loading documents from an AWS S3 file."""
 import os
 import tempfile
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class S3FileLoader(BaseLoader):
     """Loading logic for loading documents from an AWS S3 file."""
 
     def __init__(self, bucket: str, key: str):
         """Initialize with bucket and key name.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/sitemap.py` & `oplangchain-0.1.1/oplangchain/document_loaders/sitemap.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loader that fetches a sitemap and loads those URLs."""
 import itertools
 import re
 from typing import Any, Callable, Generator, Iterable, List, Optional
 
-from langchain.document_loaders.web_base import WebBaseLoader
-from langchain.schema import Document
+from oplangchain.document_loaders.web_base import WebBaseLoader
+from oplangchain.schema import Document
 
 
 def _default_parsing_function(content: Any) -> str:
     return str(content.get_text())
 
 
 def _default_meta_function(meta: dict, _content: Any) -> dict:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/slack_directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/slack_directory.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader for documents from a Slack export."""
 import json
 import zipfile
 from pathlib import Path
 from typing import Dict, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class SlackDirectoryLoader(BaseLoader):
     """Loads documents from a Slack directory dump."""
 
     def __init__(self, zip_path: str, workspace_url: Optional[str] = None):
         """Initialize the SlackDirectoryLoader.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/snowflake_loader.py` & `oplangchain-0.1.1/oplangchain/document_loaders/snowflake_loader.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 from typing import Any, Dict, Iterator, List, Optional, Tuple
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class SnowflakeLoader(BaseLoader):
     """Loads a query result from Snowflake into a list of documents.
 
     Each document represents one row of the result. The `page_content_columns`
     are written into the `page_content` of the document. The `metadata_columns`
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/spreedly.py` & `oplangchain-0.1.1/oplangchain/document_loaders/spreedly.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader that fetches data from Spreedly API."""
 import json
 import urllib.request
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import stringify_dict
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import stringify_dict
 
 SPREEDLY_ENDPOINTS = {
     "gateways_options": "https://core.spreedly.com/v1/gateways_options.json",
     "gateways": "https://core.spreedly.com/v1/gateways.json",
     "receivers_options": "https://core.spreedly.com/v1/receivers_options.json",
     "receivers": "https://core.spreedly.com/v1/receivers.json",
     "payment_methods": "https://core.spreedly.com/v1/payment_methods.json",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/srt.py` & `oplangchain-0.1.1/oplangchain/document_loaders/srt.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Loader for .srt (subtitle) files."""
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class SRTLoader(BaseLoader):
     """Loader for .srt (subtitle) files."""
 
     def __init__(self, file_path: str):
         """Initialize with a file path."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/stripe.py` & `oplangchain-0.1.1/oplangchain/document_loaders/stripe.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loader that fetches data from Stripe"""
 import json
 import urllib.request
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import get_from_env, stringify_dict
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import get_from_env, stringify_dict
 
 STRIPE_ENDPOINTS = {
     "balance_transactions": "https://api.stripe.com/v1/balance_transactions",
     "charges": "https://api.stripe.com/v1/charges",
     "customers": "https://api.stripe.com/v1/customers",
     "events": "https://api.stripe.com/v1/events",
     "refunds": "https://api.stripe.com/v1/refunds",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/telegram.py` & `oplangchain-0.1.1/oplangchain/document_loaders/telegram.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 from __future__ import annotations
 
 import asyncio
 import json
 from pathlib import Path
 from typing import TYPE_CHECKING, Dict, List, Optional, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.text_splitter import RecursiveCharacterTextSplitter
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter
 
 if TYPE_CHECKING:
     import pandas as pd
     from telethon.hints import EntityLike
 
 
 def concatenate_rows(row: dict) -> str:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/tencent_cos_directory.py` & `oplangchain-0.1.1/oplangchain/document_loaders/tencent_cos_directory.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loading logic for loading documents from Tencent Cloud COS directory."""
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.tencent_cos_file import TencentCOSFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.tencent_cos_file import TencentCOSFileLoader
 
 
 class TencentCOSDirectoryLoader(BaseLoader):
     """Loader for Tencent Cloud COS directory."""
 
     def __init__(self, conf: Any, bucket: str, prefix: str = ""):
         """Initialize with COS config, bucket and prefix.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/tencent_cos_file.py` & `oplangchain-0.1.1/oplangchain/document_loaders/tencent_cos_file.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loading logic for loading documents from Tencent Cloud COS file."""
 import os
 import tempfile
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class TencentCOSFileLoader(BaseLoader):
     """Loader for Tencent Cloud COS file."""
 
     def __init__(self, conf: Any, bucket: str, key: str):
         """Initialize with COS config, bucket and key name.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/text.py` & `oplangchain-0.1.1/oplangchain/document_loaders/text.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import logging
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.helpers import detect_file_encodings
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.helpers import detect_file_encodings
 
 logger = logging.getLogger(__name__)
 
 
 class TextLoader(BaseLoader):
     """Load text files.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/tomarkdown.py` & `oplangchain-0.1.1/oplangchain/document_loaders/tomarkdown.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Loads HTML to markdown using 2markdown."""
 from __future__ import annotations
 
 from typing import Iterator, List
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class ToMarkdownLoader(BaseLoader):
     """Loads HTML to markdown using 2markdown."""
 
     def __init__(self, url: str, api_key: str):
         """Initialize with url and api key."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/toml.py` & `oplangchain-0.1.1/oplangchain/document_loaders/toml.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import json
 from pathlib import Path
 from typing import Iterator, List, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class TomlLoader(BaseLoader):
     """
     A TOML document loader that inherits from the BaseLoader class.
 
     This class can be initialized with either a single source file or a source
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/trello.py` & `oplangchain-0.1.1/oplangchain/document_loaders/trello.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Loads cards from Trello"""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, List, Literal, Optional, Tuple
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utils import get_from_env
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utils import get_from_env
 
 if TYPE_CHECKING:
     from trello import Board, Card, TrelloClient
 
 
 class TrelloLoader(BaseLoader):
     """Trello loader. Reads all cards from a Trello board."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/tsv.py` & `oplangchain-0.1.1/oplangchain/document_loaders/tsv.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredTSVLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load TSV files. Like other
@@ -13,15 +13,15 @@
     mode, the TSV file will be a single Unstructured Table element.
     If you use the loader in "elements" mode, an HTML representation
     of the table will be available in the "text_as_html" key in the
     document metadata.
 
     Examples
     --------
-    from langchain.document_loaders.tsv import UnstructuredTSVLoader
+    from oplangchain.document_loaders.tsv import UnstructuredTSVLoader
 
     loader = UnstructuredTSVLoader("stanley-cups.tsv", mode="elements")
     docs = loader.load()
     """
 
     def __init__(
         self, file_path: str, mode: str = "single", **unstructured_kwargs: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/twitter.py` & `oplangchain-0.1.1/oplangchain/document_loaders/twitter.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Twitter document loader."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Sequence, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 if TYPE_CHECKING:
     import tweepy
     from tweepy import OAuth2BearerHandler, OAuthHandler
 
 
 def _dependable_tweepy_import() -> tweepy:
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/unstructured.py` & `oplangchain-0.1.1/oplangchain/document_loaders/unstructured.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loader that uses unstructured to load files."""
 import collections
 from abc import ABC, abstractmethod
 from typing import IO, Any, Callable, Dict, List, Sequence, Union
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 def satisfies_min_unstructured_version(min_version: str) -> bool:
     """Checks to see if the installed unstructured version exceeds the minimum version
     for the feature in question."""
     from unstructured.__version__ import __version__ as __unstructured_version__
 
@@ -139,15 +139,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredFileLoader
+    from oplangchain.document_loaders import UnstructuredFileLoader
 
     loader = UnstructuredFileLoader(
         "example.pdf", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
@@ -224,15 +224,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     ```python
-    from langchain.document_loaders import UnstructuredAPIFileLoader
+    from oplangchain.document_loaders import UnstructuredAPIFileLoader
 
     loader = UnstructuredFileAPILoader(
         "example.pdf", mode="elements", strategy="fast", api_key="MY_API_KEY",
     )
     docs = loader.load()
 
     References
@@ -284,15 +284,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredFileIOLoader
+    from oplangchain.document_loaders import UnstructuredFileIOLoader
 
     with open("example.pdf", "rb") as f:
         loader = UnstructuredFileIOLoader(
             f, mode="elements", strategy="fast",
         )
         docs = loader.load()
 
@@ -335,15 +335,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredAPIFileLoader
+    from oplangchain.document_loaders import UnstructuredAPIFileLoader
 
     with open("example.pdf", "rb") as f:
         loader = UnstructuredFileAPILoader(
             f, mode="elements", strategy="fast", api_key="MY_API_KEY",
         )
         docs = loader.load()
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/url.py` & `oplangchain-0.1.1/oplangchain/document_loaders/url.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Loader that uses unstructured to load HTML files."""
 import logging
 from typing import Any, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class UnstructuredURLLoader(BaseLoader):
     """Loader that use Unstructured to load files from remote URLs.
     Use the unstructured partition function to detect the MIME type
@@ -18,15 +18,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredURLLoader
+    from oplangchain.document_loaders import UnstructuredURLLoader
 
     loader = UnstructuredURLLoader(
         ursl=["<url-1>", "<url-2>"], mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/url_playwright.py` & `oplangchain-0.1.1/oplangchain/document_loaders/url_playwright.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Loader that uses Playwright to load a page, then uses unstructured to load the html.
 """
 import logging
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class PlaywrightURLLoader(BaseLoader):
     """Loader that uses Playwright and to load a page and unstructured to load the html.
     This is useful for loading pages that require javascript to render.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/url_selenium.py` & `oplangchain-0.1.1/oplangchain/document_loaders/url_selenium.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 """
 import logging
 from typing import TYPE_CHECKING, List, Literal, Optional, Union
 
 if TYPE_CHECKING:
     from selenium.webdriver import Chrome, Firefox
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 
 class SeleniumURLLoader(BaseLoader):
     """Loader that uses Selenium and to load a page and unstructured to load the html.
     This is useful for loading pages that require javascript to render.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/weather.py` & `oplangchain-0.1.1/oplangchain/document_loaders/weather.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Simple reader that reads weather data from OpenWeatherMap API"""
 from __future__ import annotations
 
 from datetime import datetime
 from typing import Iterator, List, Optional, Sequence
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
 
 
 class WeatherDataLoader(BaseLoader):
     """Weather Reader.
 
     Reads the forecast & current weather of any location using OpenWeatherMap's free
     API. Checkout 'https://openweathermap.org/appid' for more on how to generate a free
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/web_base.py` & `oplangchain-0.1.1/oplangchain/document_loaders/web_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 import logging
 import warnings
 from typing import Any, Dict, Iterator, List, Optional, Union
 
 import aiohttp
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 default_header_template = {
     "User-Agent": "",
     "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*"
     ";q=0.8",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/whatsapp_chat.py` & `oplangchain-0.1.1/oplangchain/document_loaders/whatsapp_chat.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import re
 from pathlib import Path
 from typing import List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 def concatenate_rows(date: str, sender: str, text: str) -> str:
     """Combine message information in a readable format ready to be used."""
     return f"{sender} on {date}: {text}\n\n"
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/wikipedia.py` & `oplangchain-0.1.1/oplangchain/document_loaders/wikipedia.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import List, Optional
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
 
 
 class WikipediaLoader(BaseLoader):
     """Loads a query result from www.wikipedia.org into a list of Documents.
     The hard limit on the number of downloaded Documents is 300 for now.
 
     Each wiki page represents one Document.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/word_document.py` & `oplangchain-0.1.1/oplangchain/document_loaders/word_document.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 import tempfile
 from abc import ABC
 from typing import List
 from urllib.parse import urlparse
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
-from langchain.document_loaders.unstructured import UnstructuredFileLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.document_loaders.unstructured import UnstructuredFileLoader
 
 
 class Docx2txtLoader(BaseLoader, ABC):
     """Loads a DOCX with docx2txt and chunks at character level.
 
     Defaults to check for local file, but if the file is a web path, it will download it
     to a temporary file, and use that, then clean up the temporary file after completion
@@ -72,15 +72,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredWordDocumentLoader
+    from oplangchain.document_loaders import UnstructuredWordDocumentLoader
 
     loader = UnstructuredWordDocumentLoader(
         "example.docx", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/xml.py` & `oplangchain-0.1.1/oplangchain/document_loaders/xml.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Loads Microsoft Excel files."""
 from typing import Any, List
 
-from langchain.document_loaders.unstructured import (
+from oplangchain.document_loaders.unstructured import (
     UnstructuredFileLoader,
     validate_unstructured_version,
 )
 
 
 class UnstructuredXMLLoader(UnstructuredFileLoader):
     """Loader that uses unstructured to load XML files.
@@ -14,15 +14,15 @@
     langchain Document object. If you use "elements" mode, the unstructured
     library will split the document into elements such as Title and NarrativeText.
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
     Examples
     --------
-    from langchain.document_loaders import UnstructuredXMLLoader
+    from oplangchain.document_loaders import UnstructuredXMLLoader
 
     loader = UnstructuredXMLLoader(
         "example.xml", mode="elements", strategy="fast",
     )
     docs = loader.load()
 
     References
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/xorbits.py` & `oplangchain-0.1.1/oplangchain/document_loaders/xorbits.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Any, Iterator, List
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 
 class XorbitsLoader(BaseLoader):
     """Load Xorbits DataFrame."""
 
     def __init__(self, data_frame: Any, page_content_column: str = "text"):
         """Initialize with dataframe object.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_loaders/youtube.py` & `oplangchain-0.1.1/oplangchain/document_loaders/youtube.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Sequence, Union
 from urllib.parse import parse_qs, urlparse
 
 from pydantic import root_validator
 from pydantic.dataclasses import dataclass
 
-from langchain.docstore.document import Document
-from langchain.document_loaders.base import BaseLoader
+from oplangchain.docstore.document import Document
+from oplangchain.document_loaders.base import BaseLoader
 
 logger = logging.getLogger(__name__)
 
 SCOPES = ["https://www.googleapis.com/auth/youtube.readonly"]
 
 
 @dataclass
@@ -27,15 +27,15 @@
     register your Service. "https://developers.google.com/docs/api/quickstart/python"
 
 
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import GoogleApiClient
+            from oplangchain.document_loaders import GoogleApiClient
             google_api_client = GoogleApiClient(
                 service_account_path=Path("path_to_your_sec_file.json")
             )
 
     """
 
     credentials_path: Path = Path.home() / ".credentials" / "credentials.json"
@@ -263,16 +263,16 @@
     "https://developers.google.com/docs/api/quickstart/python"
 
 
 
     Example:
         .. code-block:: python
 
-            from langchain.document_loaders import GoogleApiClient
-            from langchain.document_loaders import GoogleApiYoutubeLoader
+            from oplangchain.document_loaders import GoogleApiClient
+            from oplangchain.document_loaders import GoogleApiYoutubeLoader
             google_api_client = GoogleApiClient(
                 service_account_path=Path("path_to_your_sec_file.json")
             )
             loader = GoogleApiYoutubeLoader(
                 google_api_client=google_api_client,
                 channel_name = "CodeAesthetic"
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/__init__.py` & `oplangchain-0.1.1/oplangchain/document_transformers/__init__.py`

 * *Files 24% similar despite different names*

```diff
@@ -11,28 +11,28 @@
 **Main helpers:**
 
 .. code-block::
 
     Document
 """  # noqa: E501
 
-from langchain.document_transformers.doctran_text_extract import (
+from oplangchain.document_transformers.doctran_text_extract import (
     DoctranPropertyExtractor,
 )
-from langchain.document_transformers.doctran_text_qa import DoctranQATransformer
-from langchain.document_transformers.doctran_text_translate import DoctranTextTranslator
-from langchain.document_transformers.embeddings_redundant_filter import (
+from oplangchain.document_transformers.doctran_text_qa import DoctranQATransformer
+from oplangchain.document_transformers.doctran_text_translate import DoctranTextTranslator
+from oplangchain.document_transformers.embeddings_redundant_filter import (
     EmbeddingsClusteringFilter,
     EmbeddingsRedundantFilter,
     get_stateful_documents,
 )
-from langchain.document_transformers.html2text import Html2TextTransformer
-from langchain.document_transformers.long_context_reorder import LongContextReorder
-from langchain.document_transformers.nuclia_text_transform import NucliaTextTransformer
-from langchain.document_transformers.openai_functions import OpenAIMetadataTagger
+from oplangchain.document_transformers.html2text import Html2TextTransformer
+from oplangchain.document_transformers.long_context_reorder import LongContextReorder
+from oplangchain.document_transformers.nuclia_text_transform import NucliaTextTransformer
+from oplangchain.document_transformers.openai_functions import OpenAIMetadataTagger
 
 __all__ = [
     "DoctranQATransformer",
     "DoctranTextTranslator",
     "DoctranPropertyExtractor",
     "EmbeddingsClusteringFilter",
     "EmbeddingsRedundantFilter",
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_extract.py` & `oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_extract.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from typing import Any, List, Optional, Sequence
 
-from langchain.schema import BaseDocumentTransformer, Document
-from langchain.utils import get_from_env
+from oplangchain.schema import BaseDocumentTransformer, Document
+from oplangchain.utils import get_from_env
 
 
 class DoctranPropertyExtractor(BaseDocumentTransformer):
     """Extract properties from text documents using doctran.
 
     Arguments:
         properties: A list of the properties to extract.
         openai_api_key: OpenAI API key. Can also be specified via environment variable
             ``OPENAI_API_KEY``.
 
     Example:
         .. code-block:: python
 
-            from langchain.document_transformers import DoctranPropertyExtractor
+            from oplangchain.document_transformers import DoctranPropertyExtractor
 
             properties = [
                 {
                     "name": "category",
                     "description": "What type of email this is.",
                     "type": "string",
                     "enum": ["update", "action_item", "customer_feedback", "announcement", "other"],
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_qa.py` & `oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_qa.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from typing import Any, Optional, Sequence
 
-from langchain.schema import BaseDocumentTransformer, Document
-from langchain.utils import get_from_env
+from oplangchain.schema import BaseDocumentTransformer, Document
+from oplangchain.utils import get_from_env
 
 
 class DoctranQATransformer(BaseDocumentTransformer):
     """Extract QA from text documents using doctran.
 
     Arguments:
         openai_api_key: OpenAI API key. Can also be specified via environment variable
             ``OPENAI_API_KEY``.
 
     Example:
         .. code-block:: python
 
-            from langchain.document_transformers import DoctranQATransformer
+            from oplangchain.document_transformers import DoctranQATransformer
 
             # Pass in openai_api_key or set env var OPENAI_API_KEY
             qa_transformer = DoctranQATransformer()
             transformed_document = await qa_transformer.atransform_documents(documents)
     """
 
     def __init__(
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/doctran_text_translate.py` & `oplangchain-0.1.1/oplangchain/document_transformers/doctran_text_translate.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from typing import Any, Optional, Sequence
 
-from langchain.schema import BaseDocumentTransformer, Document
-from langchain.utils import get_from_env
+from oplangchain.schema import BaseDocumentTransformer, Document
+from oplangchain.utils import get_from_env
 
 
 class DoctranTextTranslator(BaseDocumentTransformer):
     """Translate text documents using doctran.
 
     Arguments:
         openai_api_key: OpenAI API key. Can also be specified via environment variable
         ``OPENAI_API_KEY``.
         language: The language to translate *to*.
 
     Example:
         .. code-block:: python
 
-        from langchain.document_transformers import DoctranTextTranslator
+        from oplangchain.document_transformers import DoctranTextTranslator
 
         # Pass in openai_api_key or set env var OPENAI_API_KEY
         qa_translator = DoctranTextTranslator(language="spanish")
         translated_document = await qa_translator.atransform_documents(documents)
     """
 
     def __init__(
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/embeddings_redundant_filter.py` & `oplangchain-0.1.1/oplangchain/document_transformers/embeddings_redundant_filter.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Transform documents"""
 from typing import Any, Callable, List, Sequence
 
 import numpy as np
 from pydantic import BaseModel, Field
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseDocumentTransformer, Document
-from langchain.utils.math import cosine_similarity
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseDocumentTransformer, Document
+from oplangchain.utils.math import cosine_similarity
 
 
 class _DocumentWithState(Document):
     """Wrapper for a document that includes arbitrary state."""
 
     state: dict = Field(default_factory=dict)
     """State associated with the document."""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/html2text.py` & `oplangchain-0.1.1/oplangchain/document_transformers/html2text.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import Any, Sequence
 
-from langchain.schema import BaseDocumentTransformer, Document
+from oplangchain.schema import BaseDocumentTransformer, Document
 
 
 class Html2TextTransformer(BaseDocumentTransformer):
     """Replace occurrences of a particular search pattern with a replacement string
     Example:
         .. code-block:: python
-            from langchain.document_transformers import Html2TextTransformer
+            from oplangchain.document_transformers import Html2TextTransformer
             html2text=Html2TextTransformer()
             docs_transform=html2text.transform_documents(docs)
     """
 
     def transform_documents(
         self,
         documents: Sequence[Document],
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/long_context_reorder.py` & `oplangchain-0.1.1/oplangchain/document_transformers/long_context_reorder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Reorder documents"""
 from typing import Any, List, Sequence
 
 from pydantic import BaseModel
 
-from langchain.schema import BaseDocumentTransformer, Document
+from oplangchain.schema import BaseDocumentTransformer, Document
 
 
 def _litm_reordering(documents: List[Document]) -> List[Document]:
     """Los in the middle reorder: the most relevant will be at the
     middle of the list and more relevant elements at beginning / end.
     See: https://arxiv.org/abs//2307.03172"""
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/nuclia_text_transform.py` & `oplangchain-0.1.1/oplangchain/document_transformers/nuclia_text_transform.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import asyncio
 import json
 import uuid
 from typing import Any, Sequence
 
-from langchain.schema.document import BaseDocumentTransformer, Document
-from langchain.tools.nuclia.tool import NucliaUnderstandingAPI
+from oplangchain.schema.document import BaseDocumentTransformer, Document
+from oplangchain.tools.nuclia.tool import NucliaUnderstandingAPI
 
 
 class NucliaTextTransformer(BaseDocumentTransformer):
     """
     The Nuclia Understanding API splits into paragraphs and sentences,
     identifies entities, provides a summary of the text and generates
     embeddings for all the sentences.
```

### Comparing `oplangchain-0.1.0/oplangchain/document_transformers/openai_functions.py` & `oplangchain-0.1.1/oplangchain/document_transformers/openai_functions.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 """Document transformers that use OpenAI Functions models"""
 from typing import Any, Dict, Optional, Sequence, Type, Union
 
 from pydantic import BaseModel
 
-from langchain.chains.llm import LLMChain
-from langchain.chains.openai_functions import create_tagging_chain
-from langchain.prompts import ChatPromptTemplate
-from langchain.schema import BaseDocumentTransformer, Document
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chains.openai_functions import create_tagging_chain
+from oplangchain.prompts import ChatPromptTemplate
+from oplangchain.schema import BaseDocumentTransformer, Document
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class OpenAIMetadataTagger(BaseDocumentTransformer, BaseModel):
     """Extract metadata tags from document contents using OpenAI functions.
 
     Example:
         .. code-block:: python
 
-                from langchain.chat_models import ChatOpenAI
-                from langchain.document_transformers import OpenAIMetadataTagger
-                from langchain.schema import Document
+                from oplangchain.chat_models import ChatOpenAI
+                from oplangchain.document_transformers import OpenAIMetadataTagger
+                from oplangchain.schema import Document
 
                 schema = {
                     "properties": {
                         "movie_title": { "type": "string" },
                         "critic": { "type": "string" },
                         "tone": {
                             "type": "string",
@@ -95,17 +95,17 @@
 
     Returns:
         An LLMChain that will pass the given function to the model.
 
     Example:
         .. code-block:: python
 
-                from langchain.chat_models import ChatOpenAI
-                from langchain.document_transformers import create_metadata_tagger
-                from langchain.schema import Document
+                from oplangchain.chat_models import ChatOpenAI
+                from oplangchain.document_transformers import create_metadata_tagger
+                from oplangchain.schema import Document
 
                 schema = {
                     "properties": {
                         "movie_title": { "type": "string" },
                         "critic": { "type": "string" },
                         "tone": {
                             "type": "string",
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/__init__.py` & `oplangchain-0.1.1/oplangchain/embeddings/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -10,56 +10,56 @@
     Embeddings --> <name>Embeddings  # Examples: OpenAIEmbeddings, HuggingFaceEmbeddings
 """
 
 
 import logging
 from typing import Any
 
-from langchain.embeddings.aleph_alpha import (
+from oplangchain.embeddings.aleph_alpha import (
     AlephAlphaAsymmetricSemanticEmbedding,
     AlephAlphaSymmetricSemanticEmbedding,
 )
-from langchain.embeddings.awa import AwaEmbeddings
-from langchain.embeddings.bedrock import BedrockEmbeddings
-from langchain.embeddings.clarifai import ClarifaiEmbeddings
-from langchain.embeddings.cohere import CohereEmbeddings
-from langchain.embeddings.dashscope import DashScopeEmbeddings
-from langchain.embeddings.deepinfra import DeepInfraEmbeddings
-from langchain.embeddings.edenai import EdenAiEmbeddings
-from langchain.embeddings.elasticsearch import ElasticsearchEmbeddings
-from langchain.embeddings.embaas import EmbaasEmbeddings
-from langchain.embeddings.fake import DeterministicFakeEmbedding, FakeEmbeddings
-from langchain.embeddings.google_palm import GooglePalmEmbeddings
-from langchain.embeddings.gpt4all import GPT4AllEmbeddings
-from langchain.embeddings.huggingface import (
+from oplangchain.embeddings.awa import AwaEmbeddings
+from oplangchain.embeddings.bedrock import BedrockEmbeddings
+from oplangchain.embeddings.clarifai import ClarifaiEmbeddings
+from oplangchain.embeddings.cohere import CohereEmbeddings
+from oplangchain.embeddings.dashscope import DashScopeEmbeddings
+from oplangchain.embeddings.deepinfra import DeepInfraEmbeddings
+from oplangchain.embeddings.edenai import EdenAiEmbeddings
+from oplangchain.embeddings.elasticsearch import ElasticsearchEmbeddings
+from oplangchain.embeddings.embaas import EmbaasEmbeddings
+from oplangchain.embeddings.fake import DeterministicFakeEmbedding, FakeEmbeddings
+from oplangchain.embeddings.google_palm import GooglePalmEmbeddings
+from oplangchain.embeddings.gpt4all import GPT4AllEmbeddings
+from oplangchain.embeddings.huggingface import (
     HuggingFaceEmbeddings,
     HuggingFaceInstructEmbeddings,
 )
-from langchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings
-from langchain.embeddings.jina import JinaEmbeddings
-from langchain.embeddings.llamacpp import LlamaCppEmbeddings
-from langchain.embeddings.localai import LocalAIEmbeddings
-from langchain.embeddings.minimax import MiniMaxEmbeddings
-from langchain.embeddings.mlflow_gateway import MlflowAIGatewayEmbeddings
-from langchain.embeddings.modelscope_hub import ModelScopeEmbeddings
-from langchain.embeddings.mosaicml import MosaicMLInstructorEmbeddings
-from langchain.embeddings.nlpcloud import NLPCloudEmbeddings
-from langchain.embeddings.octoai_embeddings import OctoAIEmbeddings
-from langchain.embeddings.openai import OpenAIEmbeddings
-from langchain.embeddings.sagemaker_endpoint import SagemakerEndpointEmbeddings
-from langchain.embeddings.self_hosted import SelfHostedEmbeddings
-from langchain.embeddings.self_hosted_hugging_face import (
+from oplangchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings
+from oplangchain.embeddings.jina import JinaEmbeddings
+from oplangchain.embeddings.llamacpp import LlamaCppEmbeddings
+from oplangchain.embeddings.localai import LocalAIEmbeddings
+from oplangchain.embeddings.minimax import MiniMaxEmbeddings
+from oplangchain.embeddings.mlflow_gateway import MlflowAIGatewayEmbeddings
+from oplangchain.embeddings.modelscope_hub import ModelScopeEmbeddings
+from oplangchain.embeddings.mosaicml import MosaicMLInstructorEmbeddings
+from oplangchain.embeddings.nlpcloud import NLPCloudEmbeddings
+from oplangchain.embeddings.octoai_embeddings import OctoAIEmbeddings
+from oplangchain.embeddings.openai import OpenAIEmbeddings
+from oplangchain.embeddings.sagemaker_endpoint import SagemakerEndpointEmbeddings
+from oplangchain.embeddings.self_hosted import SelfHostedEmbeddings
+from oplangchain.embeddings.self_hosted_hugging_face import (
     SelfHostedHuggingFaceEmbeddings,
     SelfHostedHuggingFaceInstructEmbeddings,
 )
-from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
-from langchain.embeddings.spacy_embeddings import SpacyEmbeddings
-from langchain.embeddings.tensorflow_hub import TensorflowHubEmbeddings
-from langchain.embeddings.vertexai import VertexAIEmbeddings
-from langchain.embeddings.xinference import XinferenceEmbeddings
+from oplangchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
+from oplangchain.embeddings.spacy_embeddings import SpacyEmbeddings
+from oplangchain.embeddings.tensorflow_hub import TensorflowHubEmbeddings
+from oplangchain.embeddings.vertexai import VertexAIEmbeddings
+from oplangchain.embeddings.xinference import XinferenceEmbeddings
 
 logger = logging.getLogger(__name__)
 
 __all__ = [
     "OpenAIEmbeddings",
     "HuggingFaceEmbeddings",
     "CohereEmbeddings",
@@ -101,22 +101,22 @@
 
 
 # TODO: this is in here to maintain backwards compatibility
 class HypotheticalDocumentEmbedder:
     def __init__(self, *args: Any, **kwargs: Any):
         logger.warning(
             "Using a deprecated class. Please use "
-            "`from langchain.chains import HypotheticalDocumentEmbedder` instead"
+            "`from oplangchain.chains import HypotheticalDocumentEmbedder` instead"
         )
-        from langchain.chains.hyde.base import HypotheticalDocumentEmbedder as H
+        from oplangchain.chains.hyde.base import HypotheticalDocumentEmbedder as H
 
         return H(*args, **kwargs)  # type: ignore
 
     @classmethod
     def from_llm(cls, *args: Any, **kwargs: Any) -> Any:
         logger.warning(
             "Using a deprecated class. Please use "
-            "`from langchain.chains import HypotheticalDocumentEmbedder` instead"
+            "`from oplangchain.chains import HypotheticalDocumentEmbedder` instead"
         )
-        from langchain.chains.hyde.base import HypotheticalDocumentEmbedder as H
+        from oplangchain.chains.hyde.base import HypotheticalDocumentEmbedder as H
 
         return H.from_llm(*args, **kwargs)
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/aleph_alpha.py` & `oplangchain-0.1.1/oplangchain/embeddings/aleph_alpha.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 
 class AlephAlphaAsymmetricSemanticEmbedding(BaseModel, Embeddings):
     """Aleph Alpha's asymmetric semantic embedding.
 
     AA provides you with an endpoint to embed a document and a query.
     The models were optimized to make the embeddings of documents and
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/awa.py` & `oplangchain-0.1.1/oplangchain/embeddings/awa.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Any, Dict, List
 
 from pydantic import BaseModel, root_validator
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class AwaEmbeddings(BaseModel, Embeddings):
     client: Any  #: :meta private:
     model: str = "all-mpnet-base-v2"
 
     @root_validator()
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/base.py` & `oplangchain-0.1.1/oplangchain/embeddings/base.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/bedrock.py` & `oplangchain-0.1.1/oplangchain/embeddings/bedrock.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import json
 import os
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class BedrockEmbeddings(BaseModel, Embeddings):
     """Bedrock embedding models.
 
     To authenticate, the AWS client uses the following methods to
     automatically load credentials:
@@ -21,15 +21,15 @@
     access the Bedrock service.
     """
 
     """
     Example:
         .. code-block:: python
 
-            from langchain.bedrock_embeddings import BedrockEmbeddings
+            from oplangchain.bedrock_embeddings import BedrockEmbeddings
             
             region_name ="us-east-1"
             credentials_profile_name = "default"
             model_id = "amazon.titan-e1t-medium"
 
             be = BedrockEmbeddings(
                 credentials_profile_name=credentials_profile_name,
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/clarifai.py` & `oplangchain-0.1.1/oplangchain/embeddings/clarifai.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 import logging
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class ClarifaiEmbeddings(BaseModel, Embeddings):
     """Clarifai embedding models.
 
     To use, you should have the ``clarifai`` python package installed, and the
     environment variable ``CLARIFAI_PAT`` set with your personal access token or pass it
     as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import ClarifaiEmbeddings
+            from oplangchain.embeddings import ClarifaiEmbeddings
             clarifai = ClarifaiEmbeddings(
                 model="embed-english-light-v2.0", clarifai_api_key="my-api-key"
             )
     """
 
     stub: Any  #: :meta private:
     """Clarifai stub."""
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/cohere.py` & `oplangchain-0.1.1/oplangchain/embeddings/cohere.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 
 class CohereEmbeddings(BaseModel, Embeddings):
     """Cohere embedding models.
 
     To use, you should have the ``cohere`` python package installed, and the
     environment variable ``COHERE_API_KEY`` set with your API key or pass it
     as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import CohereEmbeddings
+            from oplangchain.embeddings import CohereEmbeddings
             cohere = CohereEmbeddings(
                 model="embed-english-light-v2.0", cohere_api_key="my-api-key"
             )
     """
 
     client: Any  #: :meta private:
     """Cohere client."""
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/dashscope.py` & `oplangchain-0.1.1/oplangchain/embeddings/dashscope.py`

 * *Files 5% similar despite different names*

```diff
@@ -15,16 +15,16 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(embeddings: DashScopeEmbeddings) -> Callable[[Any], Any]:
     multiplier = 1
     min_seconds = 1
@@ -69,24 +69,24 @@
     To use, you should have the ``dashscope`` python package installed, and the
     environment variable ``DASHSCOPE_API_KEY`` set with your API key or pass it
     as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import DashScopeEmbeddings
+            from oplangchain.embeddings import DashScopeEmbeddings
             embeddings = DashScopeEmbeddings(dashscope_api_key="my-api-key")
 
     Example:
         .. code-block:: python
 
             import os
             os.environ["DASHSCOPE_API_KEY"] = "your DashScope API KEY"
 
-            from langchain.embeddings.dashscope import DashScopeEmbeddings
+            from oplangchain.embeddings.dashscope import DashScopeEmbeddings
             embeddings = DashScopeEmbeddings(
                 model="text-embedding-v1",
             )
             text = "This is a test query."
             query_result = embeddings.embed_query(text)
 
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/deepinfra.py` & `oplangchain-0.1.1/oplangchain/embeddings/deepinfra.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 DEFAULT_MODEL_ID = "sentence-transformers/clip-ViT-B-32"
 
 
 class DeepInfraEmbeddings(BaseModel, Embeddings):
     """Deep Infra's embedding inference service.
 
@@ -17,15 +17,15 @@
     it as a named parameter to the constructor.
     There are multiple embeddings models available,
     see https://deepinfra.com/models?type=embeddings.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import DeepInfraEmbeddings
+            from oplangchain.embeddings import DeepInfraEmbeddings
             deepinfra_emb = DeepInfraEmbeddings(
                 model_id="sentence-transformers/clip-ViT-B-32",
                 deepinfra_api_token="my-api-key"
             )
             r1 = deepinfra_emb.embed_documents(
                 [
                     "Alpha is the first letter of Greek alphabet",
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/edenai.py` & `oplangchain-0.1.1/oplangchain/embeddings/edenai.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Dict, List, Optional
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.requests import Requests
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.requests import Requests
+from oplangchain.utils import get_from_dict_or_env
 
 
 class EdenAiEmbeddings(BaseModel, Embeddings):
     """EdenAI embedding.
     environment variable ``EDENAI_API_KEY`` set with your API key, or pass
     it as a named parameter.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/elasticsearch.py` & `oplangchain-0.1.1/oplangchain/embeddings/elasticsearch.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, List, Optional
 
-from langchain.utils import get_from_env
+from oplangchain.utils import get_from_env
 
 if TYPE_CHECKING:
     from elasticsearch import Elasticsearch
     from elasticsearch.client import MlClient
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class ElasticsearchEmbeddings(Embeddings):
     """Elasticsearch embedding models.
 
     This class provides an interface to generate embeddings using a model deployed
     in an Elasticsearch cluster. It requires an Elasticsearch connection object
@@ -64,15 +64,15 @@
             es_cloud_id: (str, optional): The Elasticsearch cloud ID to connect to.
             es_user: (str, optional): Elasticsearch username.
             es_password: (str, optional): Elasticsearch password.
 
         Example:
             .. code-block:: python
 
-                from langchain.embeddings import ElasticsearchEmbeddings
+                from oplangchain.embeddings import ElasticsearchEmbeddings
 
                 # Define the model ID and input field name (if different from default)
                 model_id = "your_model_id"
                 # Optional, only if different from 'text_field'
                 input_field = "your_input_field"
 
                 # Credentials can be passed in two ways. Either set the env vars
@@ -137,15 +137,15 @@
         ElasticsearchEmbeddings: An instance of the ElasticsearchEmbeddings class.
 
         Example:
             .. code-block:: python
 
                 from elasticsearch import Elasticsearch
 
-                from langchain.embeddings import ElasticsearchEmbeddings
+                from oplangchain.embeddings import ElasticsearchEmbeddings
 
                 # Define the model ID and input field name (if different from default)
                 model_id = "your_model_id"
                 # Optional, only if different from 'text_field'
                 input_field = "your_input_field"
 
                 # Create Elasticsearch connection
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/embaas.py` & `oplangchain-0.1.1/oplangchain/embeddings/embaas.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 from typing_extensions import NotRequired, TypedDict
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 # Currently supported maximum batch size for embedding requests
 MAX_BATCH_SIZE = 256
 EMBAAS_API_URL = "https://api.embaas.io/v1/embeddings/"
 
 
 class EmbaasEmbeddingsPayload(TypedDict):
@@ -27,19 +27,19 @@
     environment variable ``EMBAAS_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
             # Initialise with default model and instruction
-            from langchain.embeddings import EmbaasEmbeddings
+            from oplangchain.embeddings import EmbaasEmbeddings
             emb = EmbaasEmbeddings()
 
             # Initialise with custom model and instruction
-            from langchain.embeddings import EmbaasEmbeddings
+            from oplangchain.embeddings import EmbaasEmbeddings
             emb_model = "instructor-large"
             emb_inst = "Represent the Wikipedia document for retrieval"
             emb = EmbaasEmbeddings(
                 model=emb_model,
                 instruction=emb_inst
             )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/fake.py` & `oplangchain-0.1.1/oplangchain/embeddings/fake.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import hashlib
 from typing import List
 
 import numpy as np
 from pydantic import BaseModel
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class FakeEmbeddings(Embeddings, BaseModel):
     """Fake embedding model."""
 
     size: int
     """The size of the embedding vector."""
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/google_palm.py` & `oplangchain-0.1.1/oplangchain/embeddings/google_palm.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,16 +8,16 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator() -> Callable[[Any], Any]:
     """Returns a tenacity retry decorator, preconfigured to handle PaLM exceptions"""
     import google.api_core.exceptions
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/gpt4all.py` & `oplangchain-0.1.1/oplangchain/embeddings/gpt4all.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 from typing import Any, Dict, List
 
 from pydantic import BaseModel, root_validator
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class GPT4AllEmbeddings(BaseModel, Embeddings):
     """GPT4All embedding models.
 
     To use, you should have the gpt4all python package installed
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import GPT4AllEmbeddings
+            from oplangchain.embeddings import GPT4AllEmbeddings
 
             embeddings = GPT4AllEmbeddings()
     """
 
     client: Any  #: :meta private:
 
     @root_validator()
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/huggingface.py` & `oplangchain-0.1.1/oplangchain/embeddings/huggingface.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, Field
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 DEFAULT_MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
 DEFAULT_INSTRUCT_MODEL = "hkunlp/instructor-large"
 DEFAULT_EMBED_INSTRUCTION = "Represent the document for retrieval: "
 DEFAULT_QUERY_INSTRUCTION = (
     "Represent the question for retrieving supporting documents: "
 )
@@ -16,15 +16,15 @@
     """HuggingFace sentence_transformers embedding models.
 
     To use, you should have the ``sentence_transformers`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import HuggingFaceEmbeddings
+            from oplangchain.embeddings import HuggingFaceEmbeddings
 
             model_name = "sentence-transformers/all-mpnet-base-v2"
             model_kwargs = {'device': 'cpu'}
             encode_kwargs = {'normalize_embeddings': False}
             hf = HuggingFaceEmbeddings(
                 model_name=model_name,
                 model_kwargs=model_kwargs,
@@ -96,15 +96,15 @@
 
     To use, you should have the ``sentence_transformers``
     and ``InstructorEmbedding`` python packages installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import HuggingFaceInstructEmbeddings
+            from oplangchain.embeddings import HuggingFaceInstructEmbeddings
 
             model_name = "hkunlp/instructor-large"
             model_kwargs = {'device': 'cpu'}
             encode_kwargs = {'normalize_embeddings': True}
             hf = HuggingFaceInstructEmbeddings(
                 model_name=model_name,
                 model_kwargs=model_kwargs,
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/huggingface_hub.py` & `oplangchain-0.1.1/oplangchain/embeddings/huggingface_hub.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 DEFAULT_REPO_ID = "sentence-transformers/all-mpnet-base-v2"
 VALID_TASKS = ("feature-extraction",)
 
 
 class HuggingFaceHubEmbeddings(BaseModel, Embeddings):
     """HuggingFaceHub embedding models.
@@ -15,15 +15,15 @@
     To use, you should have the ``huggingface_hub`` python package installed, and the
     environment variable ``HUGGINGFACEHUB_API_TOKEN`` set with your API token, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import HuggingFaceHubEmbeddings
+            from oplangchain.embeddings import HuggingFaceHubEmbeddings
             repo_id = "sentence-transformers/all-mpnet-base-v2"
             hf = HuggingFaceHubEmbeddings(
                 repo_id=repo_id,
                 task="feature-extraction",
                 huggingfacehub_api_token="my-api-key",
             )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/jina.py` & `oplangchain-0.1.1/oplangchain/embeddings/jina.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import os
 from typing import Any, Dict, List, Optional
 
 import requests
 from pydantic import BaseModel, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 
 class JinaEmbeddings(BaseModel, Embeddings):
     """Jina embedding models."""
 
     client: Any  #: :meta private:
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/llamacpp.py` & `oplangchain-0.1.1/oplangchain/embeddings/llamacpp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class LlamaCppEmbeddings(BaseModel, Embeddings):
     """llama.cpp embedding models.
 
     To use, you should have the llama-cpp-python library installed, and provide the
     path to the Llama model as a named parameter to the constructor.
     Check out: https://github.com/abetlen/llama-cpp-python
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import LlamaCppEmbeddings
+            from oplangchain.embeddings import LlamaCppEmbeddings
             llama = LlamaCppEmbeddings(model_path="/path/to/model.bin")
     """
 
     client: Any  #: :meta private:
     model_path: str
 
     n_ctx: int = Field(512, alias="n_ctx")
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/localai.py` & `oplangchain-0.1.1/oplangchain/embeddings/localai.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,16 +21,16 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env, get_pydantic_field_names
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env, get_pydantic_field_names
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(embeddings: LocalAIEmbeddings) -> Callable[[Any], Any]:
     import openai
 
@@ -123,15 +123,15 @@
     To use, you should have the ``openai`` python package installed, and the
     environment variable ``OPENAI_API_KEY`` set to a random string. You need to
     specify ``OPENAI_API_BASE`` to point to your LocalAI service endpoint.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import LocalAIEmbeddings
+            from oplangchain.embeddings import LocalAIEmbeddings
             openai = LocalAIEmbeddings(
                 openai_api_key="random-key",
                 openai_api_base="http://localhost:8080"
             )
 
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/minimax.py` & `oplangchain-0.1.1/oplangchain/embeddings/minimax.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,16 +8,16 @@
 from tenacity import (
     before_sleep_log,
     retry,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator() -> Callable[[Any], Any]:
     """Returns a tenacity retry decorator."""
 
@@ -51,15 +51,15 @@
     To use, you should have the environment variable ``MINIMAX_GROUP_ID`` and
     ``MINIMAX_API_KEY`` set with your API token, or pass it as a named parameter to
     the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import MiniMaxEmbeddings
+            from oplangchain.embeddings import MiniMaxEmbeddings
             embeddings = MiniMaxEmbeddings()
 
             query_text = "This is a test query."
             query_result = embeddings.embed_query(query_text)
 
             document_text = "This is a test document."
             document_result = embeddings.embed_documents([document_text])
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/mlflow_gateway.py` & `oplangchain-0.1.1/oplangchain/embeddings/mlflow_gateway.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import Any, Iterator, List, Optional
 
 from pydantic import BaseModel
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 def _chunk(texts: List[str], size: int) -> Iterator[List[str]]:
     for i in range(0, len(texts), size):
         yield texts[i : i + size]
 
 
@@ -18,15 +18,15 @@
 
     To use, you should have the ``mlflow[gateway]`` python package installed.
     For more information, see https://mlflow.org/docs/latest/gateway/index.html.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import MlflowAIGatewayEmbeddings
+            from oplangchain.embeddings import MlflowAIGatewayEmbeddings
 
             embeddings = MlflowAIGatewayEmbeddings(
                 gateway_uri="<your-mlflow-ai-gateway-uri>",
                 route="<your-mlflow-ai-gateway-embeddings-route>"
             )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/modelscope_hub.py` & `oplangchain-0.1.1/oplangchain/embeddings/modelscope_hub.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 from typing import Any, List, Optional
 
 from pydantic import BaseModel, Extra
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class ModelScopeEmbeddings(BaseModel, Embeddings):
     """ModelScopeHub embedding models.
 
     To use, you should have the ``modelscope`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import ModelScopeEmbeddings
+            from oplangchain.embeddings import ModelScopeEmbeddings
             model_id = "damo/nlp_corom_sentence-embedding_english-base"
             embed = ModelScopeEmbeddings(model_id=model_id, model_revision="v1.0.0")
     """
 
     embed: Any
     model_id: str = "damo/nlp_corom_sentence-embedding_english-base"
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/mosaicml.py` & `oplangchain-0.1.1/oplangchain/embeddings/mosaicml.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 from typing import Any, Dict, List, Mapping, Optional, Tuple
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 
 class MosaicMLInstructorEmbeddings(BaseModel, Embeddings):
     """MosaicML embedding service.
 
     To use, you should have the
     environment variable ``MOSAICML_API_TOKEN`` set with your API token, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import MosaicMLInstructorEmbeddings
+            from oplangchain.llms import MosaicMLInstructorEmbeddings
             endpoint_url = (
                 "https://models.hosted-on.mosaicml.hosting/instructor-large/v1/predict"
             )
             mosaic_llm = MosaicMLInstructorEmbeddings(
                 endpoint_url=endpoint_url,
                 mosaicml_api_token="my-api-key"
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/nlpcloud.py` & `oplangchain-0.1.1/oplangchain/embeddings/nlpcloud.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 from typing import Any, Dict, List
 
 from pydantic import BaseModel, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 
 class NLPCloudEmbeddings(BaseModel, Embeddings):
     """NLP Cloud embedding models.
 
     To use, you should have the nlpcloud python package installed
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import NLPCloudEmbeddings
+            from oplangchain.embeddings import NLPCloudEmbeddings
 
             embeddings = NLPCloudEmbeddings()
     """
 
     model_name: str  # Define model_name as a class attribute
     gpu: bool  # Define gpu as a class attribute
     client: Any  #: :meta private:
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/octoai_embeddings.py` & `oplangchain-0.1.1/oplangchain/embeddings/octoai_embeddings.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
 
 DEFAULT_EMBED_INSTRUCTION = "Represent this input: "
 DEFAULT_QUERY_INSTRUCTION = "Represent the question for retrieving similar documents: "
 
 
 class OctoAIEmbeddings(BaseModel, Embeddings):
     """OctoAI Compute Service embedding models.
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/openai.py` & `oplangchain-0.1.1/oplangchain/embeddings/openai.py`

 * *Files 1% similar despite different names*

```diff
@@ -22,16 +22,16 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env, get_pydantic_field_names
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env, get_pydantic_field_names
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(embeddings: OpenAIEmbeddings) -> Callable[[Any], Any]:
     import openai
 
@@ -124,15 +124,15 @@
     To use, you should have the ``openai`` python package installed, and the
     environment variable ``OPENAI_API_KEY`` set with your API key or pass it
     as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import OpenAIEmbeddings
+            from oplangchain.embeddings import OpenAIEmbeddings
             openai = OpenAIEmbeddings(openai_api_key="my-api-key")
 
     In order to use the library with Microsoft Azure endpoints, you need to set
     the OPENAI_API_TYPE, OPENAI_API_BASE, OPENAI_API_KEY and OPENAI_API_VERSION.
     The OPENAI_API_TYPE must be set to 'azure' and the others correspond to
     the properties of your endpoint.
     In addition, the deployment name must be passed as the model parameter.
@@ -143,15 +143,15 @@
             import os
             os.environ["OPENAI_API_TYPE"] = "azure"
             os.environ["OPENAI_API_BASE"] = "https://<your-endpoint.openai.azure.com/"
             os.environ["OPENAI_API_KEY"] = "your AzureOpenAI key"
             os.environ["OPENAI_API_VERSION"] = "2023-05-15"
             os.environ["OPENAI_PROXY"] = "http://your-corporate-proxy:8080"
 
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
             embeddings = OpenAIEmbeddings(
                 deployment="your-embeddings-deployment-name",
                 model="your-embeddings-model-name",
                 openai_api_base="https://your-endpoint.openai.azure.com/",
                 openai_api_type="azure",
             )
             text = "This is a test query."
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/sagemaker_endpoint.py` & `oplangchain-0.1.1/oplangchain/embeddings/sagemaker_endpoint.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.llms.sagemaker_endpoint import ContentHandlerBase
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.llms.sagemaker_endpoint import ContentHandlerBase
 
 
 class EmbeddingsContentHandler(ContentHandlerBase[List[str], List[List[float]]]):
     """Content handler for LLM class."""
 
 
 class SagemakerEndpointEmbeddings(BaseModel, Embeddings):
@@ -28,15 +28,15 @@
     See: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
     """
 
     """
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import SagemakerEndpointEmbeddings
+            from oplangchain.embeddings import SagemakerEndpointEmbeddings
             endpoint_name = (
                 "my-endpoint-name"
             )
             region_name = (
                 "us-west-2"
             )
             credentials_profile_name = (
@@ -71,15 +71,15 @@
     and the endpoint.
     """
 
     """
      Example:
         .. code-block:: python
 
-        from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler
+        from oplangchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler
 
         class ContentHandler(EmbeddingsContentHandler):
                 content_type = "application/json"
                 accepts = "application/json"
 
                 def transform_input(self, prompts: List[str], model_kwargs: Dict) -> bytes:
                     input_str = json.dumps({prompts: prompts, **model_kwargs})
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/self_hosted.py` & `oplangchain-0.1.1/oplangchain/embeddings/self_hosted.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Callable, List
 
 from pydantic import Extra
 
-from langchain.embeddings.base import Embeddings
-from langchain.llms import SelfHostedPipeline
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.llms import SelfHostedPipeline
 
 
 def _embed_documents(pipeline: Any, *args: Any, **kwargs: Any) -> List[List[float]]:
     """Inference function to send to the remote hardware.
 
     Accepts a sentence_transformer model_id and
     returns a list of embeddings for each document in the batch.
@@ -24,15 +24,15 @@
     cloud like Paperspace, Coreweave, etc.).
 
     To use, you should have the ``runhouse`` python package installed.
 
     Example using a model load function:
         .. code-block:: python
 
-            from langchain.embeddings import SelfHostedEmbeddings
+            from oplangchain.embeddings import SelfHostedEmbeddings
             from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
             import runhouse as rh
 
             gpu = rh.cluster(name="rh-a10x", instance_type="A100:1")
             def get_pipeline():
                 model_id = "facebook/bart-large"
                 tokenizer = AutoTokenizer.from_pretrained(model_id)
@@ -42,15 +42,15 @@
                 model_load_fn=get_pipeline,
                 hardware=gpu
                 model_reqs=["./", "torch", "transformers"],
             )
     Example passing in a pipeline path:
         .. code-block:: python
 
-            from langchain.embeddings import SelfHostedHFEmbeddings
+            from oplangchain.embeddings import SelfHostedHFEmbeddings
             import runhouse as rh
             from transformers import pipeline
 
             gpu = rh.cluster(name="rh-a10x", instance_type="A100:1")
             pipeline = pipeline(model="bert-base-uncased", task="feature-extraction")
             rh.blob(pickle.dumps(pipeline),
                 path="models/pipeline.pkl").save().to(gpu, path="models")
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/self_hosted_hugging_face.py` & `oplangchain-0.1.1/oplangchain/embeddings/self_hosted_hugging_face.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import importlib
 import logging
 from typing import Any, Callable, List, Optional
 
-from langchain.embeddings.self_hosted import SelfHostedEmbeddings
+from oplangchain.embeddings.self_hosted import SelfHostedEmbeddings
 
 DEFAULT_MODEL_NAME = "sentence-transformers/all-mpnet-base-v2"
 DEFAULT_INSTRUCT_MODEL = "hkunlp/instructor-large"
 DEFAULT_EMBED_INSTRUCTION = "Represent the document for retrieval: "
 DEFAULT_QUERY_INSTRUCTION = (
     "Represent the question for retrieving supporting documents: "
 )
@@ -65,15 +65,15 @@
     like Paperspace, Coreweave, etc.).
 
     To use, you should have the ``runhouse`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import SelfHostedHuggingFaceEmbeddings
+            from oplangchain.embeddings import SelfHostedHuggingFaceEmbeddings
             import runhouse as rh
             model_name = "sentence-transformers/all-mpnet-base-v2"
             gpu = rh.cluster(name="rh-a10x", instance_type="A100:1")
             hf = SelfHostedHuggingFaceEmbeddings(model_name=model_name, hardware=gpu)
     """
 
     client: Any  #: :meta private:
@@ -108,15 +108,15 @@
     cloud like Paperspace, Coreweave, etc.).
 
     To use, you should have the ``runhouse`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import SelfHostedHuggingFaceInstructEmbeddings
+            from oplangchain.embeddings import SelfHostedHuggingFaceInstructEmbeddings
             import runhouse as rh
             model_name = "hkunlp/instructor-large"
             gpu = rh.cluster(name='rh-a10x', instance_type='A100:1')
             hf = SelfHostedHuggingFaceInstructEmbeddings(
                 model_name=model_name, hardware=gpu)
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/spacy_embeddings.py` & `oplangchain-0.1.1/oplangchain/embeddings/spacy_embeddings.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import importlib.util
 from typing import Any, Dict, List
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class SpacyEmbeddings(BaseModel, Embeddings):
     """Embeddings by SpaCy models.
 
     It only supports the 'en_core_web_sm' model.
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/tensorflow_hub.py` & `oplangchain-0.1.1/oplangchain/embeddings/tensorflow_hub.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from typing import Any, List
 
 from pydantic import BaseModel, Extra
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 DEFAULT_MODEL_URL = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"
 
 
 class TensorflowHubEmbeddings(BaseModel, Embeddings):
     """TensorflowHub embedding models.
 
     To use, you should have the ``tensorflow_text`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import TensorflowHubEmbeddings
+            from oplangchain.embeddings import TensorflowHubEmbeddings
             url = "https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"
             tf = TensorflowHubEmbeddings(model_url=url)
     """
 
     embed: Any  #: :meta private:
     model_url: str = DEFAULT_MODEL_URL
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/vertexai.py` & `oplangchain-0.1.1/oplangchain/embeddings/vertexai.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Dict, List
 
 from pydantic import root_validator
 
-from langchain.embeddings.base import Embeddings
-from langchain.llms.vertexai import _VertexAICommon
-from langchain.utilities.vertexai import raise_vertex_import_error
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.llms.vertexai import _VertexAICommon
+from oplangchain.utilities.vertexai import raise_vertex_import_error
 
 
 class VertexAIEmbeddings(_VertexAICommon, Embeddings):
     """Google Cloud VertexAI embedding models."""
 
     model_name: str = "textembedding-gecko"
```

### Comparing `oplangchain-0.1.0/oplangchain/embeddings/xinference.py` & `oplangchain-0.1.1/oplangchain/embeddings/xinference.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Wrapper around Xinference embedding models."""
 from typing import Any, List, Optional
 
-from langchain.embeddings.base import Embeddings
+from oplangchain.embeddings.base import Embeddings
 
 
 class XinferenceEmbeddings(Embeddings):
 
     """Wrapper around xinference embedding models.
     To use, you should have the xinference library installed:
     .. code-block:: bash
@@ -37,15 +37,15 @@
             $ xinference launch -n orca -s 3 -q q4_0
 
     It will return a model UID. Then you can use Xinference Embedding with LangChain.
 
     Example:
     .. code-block:: python
 
-        from langchain.embeddings import XinferenceEmbeddings
+        from oplangchain.embeddings import XinferenceEmbeddings
 
         xinference = XinferenceEmbeddings(
             server_url="http://0.0.0.0:9997",
             model_uid = {model_uid} # replace model_uid with the model UID return from launching the model
         )
 
     """  # noqa: E501
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/__init__.py` & `oplangchain-0.1.1/oplangchain/evaluation/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 To load an evaluator, you can use the :func:`load_evaluators <langchain.evaluation.loading.load_evaluators>` or
 :func:`load_evaluator <langchain.evaluation.loading.load_evaluator>` functions with the
 names of the evaluators to load.
 
 .. code-block:: python
 
-    from langchain.evaluation import load_evaluator
+    from oplangchain.evaluation import load_evaluator
 
     evaluator = load_evaluator("qa")
     evaluator.evaluate_strings(
         prediction="We sold more than 40,000 units last week",
         input="How many units did we sell last week?",
         reference="We sold 32,378 units",
     )
@@ -25,15 +25,15 @@
 **Datasets**
 
 To load one of the LangChain HuggingFace datasets, you can use the :func:`load_dataset <langchain.evaluation.loading.load_dataset>` function with the
 name of the dataset to load.
 
 .. code-block:: python
 
-        from langchain.evaluation import load_dataset
+        from oplangchain.evaluation import load_dataset
         ds = load_dataset("llm-math")
 
 **Some common use cases for evaluation include:**
 
 - Grading the accuracy of a response against ground truth answers: :class:`QAEvalChain <langchain.evaluation.qa.eval_chain.QAEvalChain>`
 - Comparing the output of two models: :class:`PairwiseStringEvalChain <langchain.evaluation.comparison.eval_chain.PairwiseStringEvalChain>` or :class:`LabeledPairwiseStringEvalChain <langchain.evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain>` when there is additionally a reference label.
 - Judging the efficacy of an agent's tool usage: :class:`TrajectoryEvalChain <langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain>`
@@ -48,38 +48,38 @@
 - :class:`StringEvaluator <langchain.evaluation.schema.StringEvaluator>`: Evaluate a prediction string against a reference label and/or input context.
 - :class:`PairwiseStringEvaluator <langchain.evaluation.schema.PairwiseStringEvaluator>`: Evaluate two prediction strings against each other. Useful for scoring preferences, measuring similarity between two chain or llm agents, or comparing outputs on similar inputs.
 - :class:`AgentTrajectoryEvaluator <langchain.evaluation.schema.AgentTrajectoryEvaluator>` Evaluate the full sequence of actions taken by an agent.
 
 These interfaces enable easier composability and usage within a higher level evaluation framework.
 
 """  # noqa: E501
-from langchain.evaluation.agents import TrajectoryEvalChain
-from langchain.evaluation.comparison import (
+from oplangchain.evaluation.agents import TrajectoryEvalChain
+from oplangchain.evaluation.comparison import (
     LabeledPairwiseStringEvalChain,
     PairwiseStringEvalChain,
 )
-from langchain.evaluation.criteria import (
+from oplangchain.evaluation.criteria import (
     Criteria,
     CriteriaEvalChain,
     LabeledCriteriaEvalChain,
 )
-from langchain.evaluation.embedding_distance import (
+from oplangchain.evaluation.embedding_distance import (
     EmbeddingDistance,
     EmbeddingDistanceEvalChain,
     PairwiseEmbeddingDistanceEvalChain,
 )
-from langchain.evaluation.loading import load_dataset, load_evaluator, load_evaluators
-from langchain.evaluation.qa import ContextQAEvalChain, CotQAEvalChain, QAEvalChain
-from langchain.evaluation.schema import (
+from oplangchain.evaluation.loading import load_dataset, load_evaluator, load_evaluators
+from oplangchain.evaluation.qa import ContextQAEvalChain, CotQAEvalChain, QAEvalChain
+from oplangchain.evaluation.schema import (
     AgentTrajectoryEvaluator,
     EvaluatorType,
     PairwiseStringEvaluator,
     StringEvaluator,
 )
-from langchain.evaluation.string_distance import (
+from oplangchain.evaluation.string_distance import (
     PairwiseStringDistanceEvalChain,
     StringDistance,
     StringDistanceEvalChain,
 )
 
 __all__ = [
     "EvaluatorType",
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/agents/trajectory_eval_chain.py` & `oplangchain-0.1.1/oplangchain/evaluation/agents/trajectory_eval_chain.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,29 +15,29 @@
     TypedDict,
     Union,
     cast,
 )
 
 from pydantic import Extra, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.llm import LLMChain
-from langchain.chat_models.base import BaseChatModel
-from langchain.evaluation.agents.trajectory_eval_prompt import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chat_models.base import BaseChatModel
+from oplangchain.evaluation.agents.trajectory_eval_prompt import (
     EVAL_CHAT_PROMPT,
     TOOL_FREE_EVAL_CHAT_PROMPT,
 )
-from langchain.evaluation.schema import AgentTrajectoryEvaluator, LLMEvalChain
-from langchain.schema import AgentAction, BaseOutputParser, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
+from oplangchain.evaluation.schema import AgentTrajectoryEvaluator, LLMEvalChain
+from oplangchain.schema import AgentAction, BaseOutputParser, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
 
 
 class TrajectoryEval(TypedDict):
     """A named tuple containing the score and reasoning for a trajectory."""
 
     score: float
     """The score for the trajectory, normalized from 0 to 1."""
@@ -92,18 +92,18 @@
     This chain is used to evaluate ReAct style agents by reasoning about
     the sequence of actions taken and their outcomes.
 
     Example:
 
     .. code-block:: python
 
-        from langchain.agents import AgentType, initialize_agent
-        from langchain.chat_models import ChatOpenAI
-        from langchain.evaluation import TrajectoryEvalChain
-        from langchain.tools import tool
+        from oplangchain.agents import AgentType, initialize_agent
+        from oplangchain.chat_models import ChatOpenAI
+        from oplangchain.evaluation import TrajectoryEvalChain
+        from oplangchain.tools import tool
 
         @tool
         def geography_answers(country: str, question: str) -> str:
             \"\"\"Very helpful answers to geography questions.\"\"\"
             return f"{country}? IDK - We may never know {question}."
 
         llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/agents/trajectory_eval_prompt.py` & `oplangchain-0.1.1/oplangchain/evaluation/agents/trajectory_eval_prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Prompt for trajectory evaluation chain."""
 # flake8: noqa
-from langchain.schema.messages import HumanMessage, AIMessage, SystemMessage
+from oplangchain.schema.messages import HumanMessage, AIMessage, SystemMessage
 
-from langchain.prompts.chat import (
+from oplangchain.prompts.chat import (
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
 )
 
 
 EVAL_TEMPLATE = """An AI language model has been given access to the following set of tools to help answer a user's question.
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/comparison/__init__.py` & `oplangchain-0.1.1/oplangchain/evaluation/comparison/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 
 This module contains evaluators for comparing the output of two models,
 be they LLMs, Chains, or otherwise. This can be used for scoring
 preferences, measuring similarity / semantic equivalence between outputs,
 or any other comparison task.
 
 Example:
-    >>> from langchain.chat_models import ChatOpenAI
-    >>> from langchain.evaluation.comparison import PairwiseStringEvalChain
+    >>> from oplangchain.chat_models import ChatOpenAI
+    >>> from oplangchain.evaluation.comparison import PairwiseStringEvalChain
     >>> llm = ChatOpenAI(temperature=0)
     >>> chain = PairwiseStringEvalChain.from_llm(llm=llm)
     >>> result = chain.evaluate_string_pairs(
     ...     input = "What is the chemical formula for water?",
     ...     prediction = "H2O",
     ...     prediction_b = (
     ...        "The chemical formula for water is H2O, which means"
@@ -23,13 +23,13 @@
     #    "value": "B",
     #    "comment": "Both responses accurately state"
     #       " that the chemical formula for water is H2O."
     #       " However, Response B provides additional information"
     # .     " by explaining what the formula means.\\n[[B]]"
     # }
 """
-from langchain.evaluation.comparison.eval_chain import (
+from oplangchain.evaluation.comparison.eval_chain import (
     LabeledPairwiseStringEvalChain,
     PairwiseStringEvalChain,
 )
 
 __all__ = ["PairwiseStringEvalChain", "LabeledPairwiseStringEvalChain"]
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/comparison/eval_chain.py` & `oplangchain-0.1.1/oplangchain/evaluation/comparison/eval_chain.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 """Base classes for comparing the output of two models."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Union
 
 from pydantic import Extra, Field
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple
-from langchain.chains.llm import LLMChain
-from langchain.evaluation.comparison.prompt import PROMPT, PROMPT_WITH_REFERENCE
-from langchain.evaluation.criteria.eval_chain import (
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.constitutional_ai.models import ConstitutionalPrinciple
+from oplangchain.chains.llm import LLMChain
+from oplangchain.evaluation.comparison.prompt import PROMPT, PROMPT_WITH_REFERENCE
+from oplangchain.evaluation.criteria.eval_chain import (
     CRITERIA_TYPE,
     Criteria,
 )
-from langchain.evaluation.schema import LLMEvalChain, PairwiseStringEvaluator
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import RUN_KEY, BaseOutputParser
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.evaluation.schema import LLMEvalChain, PairwiseStringEvaluator
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import RUN_KEY, BaseOutputParser
+from oplangchain.schema.language_model import BaseLanguageModel
 
 _SUPPORTED_CRITERIA = {
     Criteria.CONCISENESS: "Is the submission concise and to the point?",
     Criteria.RELEVANCE: "Is the submission referring to a real quote from the text?",
     Criteria.CORRECTNESS: "Is the submission correct, accurate, and factual?",
     Criteria.COHERENCE: "Is the submission coherent, well-structured, and organized?",
     Criteria.HARMFULNESS: "Is the submission harmful, offensive, or inappropriate?",
@@ -143,16 +143,16 @@
     """A chain for comparing two outputs, such as the outputs
      of two models, prompts, or outputs of a single model on similar inputs.
 
     Attributes:
         output_parser (BaseOutputParser): The output parser for the chain.
 
     Example:
-        >>> from langchain.chat_models import ChatOpenAI
-        >>> from langchain.evaluation.comparison import PairwiseStringEvalChain
+        >>> from oplangchain.chat_models import ChatOpenAI
+        >>> from oplangchain.evaluation.comparison import PairwiseStringEvalChain
         >>> llm = ChatOpenAI(temperature=0)
         >>> chain = PairwiseStringEvalChain.from_llm(llm=llm)
         >>> result = chain.evaluate_string_pairs(
         ...     input = "What is the chemical formula for water?",
         ...     prediction = "H2O",
         ...     prediction_b = (
         ...        "The chemical formula for water is H2O, which means"
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/comparison/prompt.py` & `oplangchain-0.1.1/oplangchain/evaluation/comparison/prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Prompts for comparing the outputs of two models for a given question.
 
 This prompt is used to compare two responses and evaluate which one best follows the instructions
 and answers the question. The prompt is based on the paper from
 Zheng, et. al. https://arxiv.org/abs/2306.05685
 """
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 template = """Act as a fair judge and rate the two responses to the question below.\
  Choose the response that best followed the instructions and answered the question.\
  Your assessment should weigh the following criteria:
 {criteria}\
  Start by comparing both responses and give a brief rationale.\
  Avoid bias from the order of presentation or response length.
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/criteria/__init__.py` & `oplangchain-0.1.1/oplangchain/evaluation/criteria/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -8,30 +8,30 @@
 -------
 CriteriaEvalChain : Evaluates the output of a language model or
 chain against specified criteria.
 
 Examples
 --------
 Using a pre-defined criterion:
->>> from langchain.llms import OpenAI
->>> from langchain.evaluation.criteria import CriteriaEvalChain
+>>> from oplangchain.llms import OpenAI
+>>> from oplangchain.evaluation.criteria import CriteriaEvalChain
 
 >>> llm = OpenAI()
 >>> criteria = "conciseness"
 >>> chain = CriteriaEvalChain.from_llm(llm=llm, criteria=criteria)
 >>> chain.evaluate_strings(
         prediction="The answer is 42.",
         reference="42",
         input="What is the answer to life, the universe, and everything?",
     )
 
 Using a custom criterion:
 
->>> from langchain.llms import OpenAI
->>> from langchain.evaluation.criteria import LabeledCriteriaEvalChain
+>>> from oplangchain.llms import OpenAI
+>>> from oplangchain.evaluation.criteria import LabeledCriteriaEvalChain
 
 >>> llm = OpenAI()
 >>> criteria = {
        "hallucination": (
             "Does this submission contain information"
             " not present in the input or reference?"
         ),
@@ -43,14 +43,14 @@
 >>> chain.evaluate_strings(
         prediction="The answer to life is 42.",
         reference="It's commonly known that the answer to life is 42.",
         input="Please summarize the following: The answer to life, the universe, and everything is unknowable.",
     )
 """  # noqa: E501
 
-from langchain.evaluation.criteria.eval_chain import (
+from oplangchain.evaluation.criteria.eval_chain import (
     Criteria,
     CriteriaEvalChain,
     LabeledCriteriaEvalChain,
 )
 
 __all__ = ["CriteriaEvalChain", "LabeledCriteriaEvalChain", "Criteria"]
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/criteria/eval_chain.py` & `oplangchain-0.1.1/oplangchain/evaluation/criteria/eval_chain.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
 from enum import Enum
 from typing import Any, Dict, List, Mapping, Optional, Union
 
 from pydantic import Extra, Field
 
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple
-from langchain.chains.llm import LLMChain
-from langchain.evaluation.criteria.prompt import PROMPT, PROMPT_WITH_REFERENCES
-from langchain.evaluation.schema import LLMEvalChain, StringEvaluator
-from langchain.schema import RUN_KEY, BaseOutputParser, BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.constitutional_ai.models import ConstitutionalPrinciple
+from oplangchain.chains.llm import LLMChain
+from oplangchain.evaluation.criteria.prompt import PROMPT, PROMPT_WITH_REFERENCES
+from oplangchain.evaluation.schema import LLMEvalChain, StringEvaluator
+from oplangchain.schema import RUN_KEY, BaseOutputParser, BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class Criteria(str, Enum):
     """A Criteria to evaluate."""
 
     CONCISENESS = "conciseness"
     RELEVANCE = "relevance"
@@ -165,28 +165,28 @@
     Returns
     -------
     CriteriaEvalChain
         An instance of the `CriteriaEvalChain` class.
 
     Examples
     --------
-    >>> from langchain.chat_models import ChatAnthropic
-    >>> from langchain.evaluation.criteria import CriteriaEvalChain
+    >>> from oplangchain.chat_models import ChatAnthropic
+    >>> from oplangchain.evaluation.criteria import CriteriaEvalChain
     >>> llm = ChatAnthropic(temperature=0)
     >>> criteria = {"my-custom-criterion": "Is the submission the most amazing ever?"}
     >>> evaluator = CriteriaEvalChain.from_llm(llm=llm, criteria=criteria)
     >>> evaluator.evaluate_strings(prediction="Imagine an ice cream flavor for the color aquamarine", input="Tell me an idea")
     {
         'reasoning': 'Here is my step-by-step reasoning for the given criteria:\\n\\nThe criterion is: "Is the submission the most amazing ever?" This is a subjective criterion and open to interpretation. The submission suggests an aquamarine-colored ice cream flavor which is creative but may or may not be considered the most amazing idea ever conceived. There are many possible amazing ideas and this one ice cream flavor suggestion may or may not rise to that level for every person. \\n\\nN',
         'value': 'N',
         'score': 0,
     }
 
-    >>> from langchain.chat_models import ChatOpenAI
-    >>> from langchain.evaluation.criteria import LabeledCriteriaEvalChain
+    >>> from oplangchain.chat_models import ChatOpenAI
+    >>> from oplangchain.evaluation.criteria import LabeledCriteriaEvalChain
     >>> llm = ChatOpenAI(model="gpt-4", temperature=0)
     >>> criteria = "correctness"
     >>> evaluator = LabeledCriteriaEvalChain.from_llm(
     ...     llm=llm,
     ...     criteria=criteria,
     ... )
     >>> evaluator.evaluate_strings(
@@ -312,16 +312,16 @@
         Returns
         -------
         CriteriaEvalChain
             An instance of the `CriteriaEvalChain` class.
 
         Examples
         --------
-        >>> from langchain.llms import OpenAI
-        >>> from langchain.evaluation.criteria import LabeledCriteriaEvalChain
+        >>> from oplangchain.llms import OpenAI
+        >>> from oplangchain.evaluation.criteria import LabeledCriteriaEvalChain
         >>> llm = OpenAI()
         >>> criteria = {
                 "hallucination": (
                     "Does this submission contain information"
                     " not present in the input or reference?"
                 ),
             }
@@ -400,16 +400,16 @@
         Returns
         -------
         dict
             The evaluation results.
 
         Examples
         --------
-        >>> from langchain.llms import OpenAI
-        >>> from langchain.evaluation.criteria import CriteriaEvalChain
+        >>> from oplangchain.llms import OpenAI
+        >>> from oplangchain.evaluation.criteria import CriteriaEvalChain
         >>> llm = OpenAI()
         >>> criteria = "conciseness"
         >>> chain = CriteriaEvalChain.from_llm(llm=llm, criteria=criteria)
         >>> chain.evaluate_strings(
                 prediction="The answer is 42.",
                 reference="42",
                 input="What is the answer to life, the universe, and everything?",
@@ -455,16 +455,16 @@
         Returns
         -------
         dict
             The evaluation results.
 
         Examples
         --------
-        >>> from langchain.llms import OpenAI
-        >>> from langchain.evaluation.criteria import CriteriaEvalChain
+        >>> from oplangchain.llms import OpenAI
+        >>> from oplangchain.evaluation.criteria import CriteriaEvalChain
         >>> llm = OpenAI()
         >>> criteria = "conciseness"
         >>> chain = CriteriaEvalChain.from_llm(llm=llm, criteria=criteria)
         >>> await chain.aevaluate_strings(
                 prediction="The answer is 42.",
                 reference="42",
                 input="What is the answer to life, the universe, and everything?",
@@ -532,16 +532,16 @@
         Returns
         -------
         LabeledCriteriaEvalChain
             An instance of the `LabeledCriteriaEvalChain` class.
 
         Examples
         --------
-        >>> from langchain.llms import OpenAI
-        >>> from langchain.evaluation.criteria import LabeledCriteriaEvalChain
+        >>> from oplangchain.llms import OpenAI
+        >>> from oplangchain.evaluation.criteria import LabeledCriteriaEvalChain
         >>> llm = OpenAI()
         >>> criteria = {
                 "hallucination": (
                     "Does this submission contain information"
                     " not present in the input or reference?"
                 ),
             }
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/criteria/prompt.py` & `oplangchain-0.1.1/oplangchain/evaluation/criteria/prompt.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # flake8: noqa
 # Credit to https://github.com/openai/evals/tree/main
 
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 template = """You are assessing a submitted answer on a given task or input based on a set of criteria. Here is the data:
 [BEGIN DATA]
 ***
 [Input]: {input}
 ***
 [Submission]: {output}
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/embedding_distance/base.py` & `oplangchain-0.1.1/oplangchain/evaluation/embedding_distance/base.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """A chain for comparing the output of two models using embeddings."""
 from enum import Enum
 from typing import Any, Dict, List, Optional
 
 import numpy as np
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.embeddings.base import Embeddings
-from langchain.embeddings.openai import OpenAIEmbeddings
-from langchain.evaluation.schema import PairwiseStringEvaluator, StringEvaluator
-from langchain.schema import RUN_KEY
-from langchain.utils.math import cosine_similarity
+from oplangchain.chains.base import Chain
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.embeddings.openai import OpenAIEmbeddings
+from oplangchain.evaluation.schema import PairwiseStringEvaluator, StringEvaluator
+from oplangchain.schema import RUN_KEY
+from oplangchain.utils.math import cosine_similarity
 
 
 class EmbeddingDistance(str, Enum):
     """Embedding Distance Metric.
 
     Attributes:
         COSINE: Cosine distance metric.
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/loading.py` & `oplangchain-0.1.1/oplangchain/evaluation/loading.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,30 @@
 """Loading datasets and evaluators."""
 from typing import Any, Dict, List, Optional, Sequence, Type, Union
 
-from langchain.chains.base import Chain
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.evaluation.agents.trajectory_eval_chain import TrajectoryEvalChain
-from langchain.evaluation.comparison import PairwiseStringEvalChain
-from langchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain
-from langchain.evaluation.criteria.eval_chain import (
+from oplangchain.chains.base import Chain
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.evaluation.agents.trajectory_eval_chain import TrajectoryEvalChain
+from oplangchain.evaluation.comparison import PairwiseStringEvalChain
+from oplangchain.evaluation.comparison.eval_chain import LabeledPairwiseStringEvalChain
+from oplangchain.evaluation.criteria.eval_chain import (
     CriteriaEvalChain,
     LabeledCriteriaEvalChain,
 )
-from langchain.evaluation.embedding_distance.base import (
+from oplangchain.evaluation.embedding_distance.base import (
     EmbeddingDistanceEvalChain,
     PairwiseEmbeddingDistanceEvalChain,
 )
-from langchain.evaluation.qa import ContextQAEvalChain, CotQAEvalChain, QAEvalChain
-from langchain.evaluation.schema import EvaluatorType, LLMEvalChain
-from langchain.evaluation.string_distance.base import (
+from oplangchain.evaluation.qa import ContextQAEvalChain, CotQAEvalChain, QAEvalChain
+from oplangchain.evaluation.schema import EvaluatorType, LLMEvalChain
+from oplangchain.evaluation.string_distance.base import (
     PairwiseStringDistanceEvalChain,
     StringDistanceEvalChain,
 )
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def load_dataset(uri: str) -> List[Dict]:
     """Load a dataset from the `LangChainDatasets HuggingFace org <https://huggingface.co/LangChainDatasets>`_.
 
     Args:
         uri: The uri of the dataset to load.
@@ -38,15 +38,15 @@
 
         pip install datasets
 
     Examples
     --------
     .. code-block:: python
 
-        from langchain.evaluation import load_dataset
+        from oplangchain.evaluation import load_dataset
         ds = load_dataset("llm-math")
     """  # noqa: E501
     try:
         from datasets import load_dataset
     except ImportError:
         raise ImportError(
             "load_dataset requires the `datasets` package."
@@ -93,15 +93,15 @@
     Returns
     -------
     Chain
         The loaded evaluation chain.
 
     Examples
     --------
-    >>> from langchain.evaluation import load_evaluator, EvaluatorType
+    >>> from oplangchain.evaluation import load_evaluator, EvaluatorType
     >>> evaluator = load_evaluator(EvaluatorType.QA)
     """
     llm = llm or ChatOpenAI(model="gpt-4", temperature=0)
     if evaluator not in _EVALUATOR_MAP:
         raise ValueError(
             f"Unknown evaluator type: {evaluator}"
             f"Valid types are: {list(_EVALUATOR_MAP.keys())}"
@@ -138,15 +138,15 @@
     Returns
     -------
     List[Chain]
         The loaded evaluators.
 
     Examples
     --------
-    >>> from langchain.evaluation import load_evaluators, EvaluatorType
+    >>> from oplangchain.evaluation import load_evaluators, EvaluatorType
     >>> evaluators = [EvaluatorType.QA, EvaluatorType.CRITERIA]
     >>> loaded_evaluators = load_evaluators(evaluators, criteria="helpfulness")
     """
     llm = llm or ChatOpenAI(model="gpt-4", temperature=0)
     loaded = []
     for evaluator in evaluators:
         _kwargs = config.get(evaluator, {}) if config else {}
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/qa/eval_chain.py` & `oplangchain-0.1.1/oplangchain/evaluation/qa/eval_chain.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 from __future__ import annotations
 
 import re
 from typing import Any, List, Optional, Sequence
 
 from pydantic import Extra
 
-from langchain import PromptTemplate
-from langchain.callbacks.manager import Callbacks
-from langchain.chains.llm import LLMChain
-from langchain.evaluation.qa.eval_prompt import CONTEXT_PROMPT, COT_PROMPT, PROMPT
-from langchain.evaluation.schema import LLMEvalChain, StringEvaluator
-from langchain.schema import RUN_KEY
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain import PromptTemplate
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.chains.llm import LLMChain
+from oplangchain.evaluation.qa.eval_prompt import CONTEXT_PROMPT, COT_PROMPT, PROMPT
+from oplangchain.evaluation.schema import LLMEvalChain, StringEvaluator
+from oplangchain.schema import RUN_KEY
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def _get_score(verdict: str) -> Optional[int]:
     match = re.search(r"(?i)(?:grade:\s*)?(correct|incorrect)", verdict)
     if match:
         if match.group(1).upper() == "CORRECT":
             return 1
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/qa/eval_prompt.py` & `oplangchain-0.1.1/oplangchain/evaluation/qa/eval_prompt.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts import PromptTemplate
+from oplangchain.prompts import PromptTemplate
 
 template = """You are a teacher grading a quiz.
 You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.
 
 Example Format:
 QUESTION: question here
 STUDENT ANSWER: student's answer here
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/qa/generate_chain.py` & `oplangchain-0.1.1/oplangchain/evaluation/qa/generate_chain.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """LLM Chain for generating examples for question answering."""
 from __future__ import annotations
 
 from typing import Any
 
 from pydantic import Field
 
-from langchain.chains.llm import LLMChain
-from langchain.evaluation.qa.generate_prompt import PROMPT
-from langchain.output_parsers.regex import RegexParser
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.output_parser import BaseLLMOutputParser
+from oplangchain.chains.llm import LLMChain
+from oplangchain.evaluation.qa.generate_prompt import PROMPT
+from oplangchain.output_parsers.regex import RegexParser
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.output_parser import BaseLLMOutputParser
 
 _QA_OUTPUT_PARSER = RegexParser(
     regex=r"QUESTION: (.*?)\n+ANSWER: (.*)", output_keys=["query", "answer"]
 )
 
 
 class QAGenerateChain(LLMChain):
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/qa/generate_prompt.py` & `oplangchain-0.1.1/oplangchain/evaluation/qa/generate_prompt.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 # flake8: noqa
-from langchain.output_parsers.regex import RegexParser
-from langchain.prompts import PromptTemplate
+from oplangchain.output_parsers.regex import RegexParser
+from oplangchain.prompts import PromptTemplate
 
 template = """You are a teacher coming up with questions to ask on a quiz. 
 Given the following document, please generate a question and answer based on that document.
 
 Example Format:
 <Begin Document>
 ...
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/schema.py` & `oplangchain-0.1.1/oplangchain/evaluation/schema.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,17 +3,17 @@
 
 import logging
 from abc import ABC, abstractmethod
 from enum import Enum
 from typing import Any, Optional, Sequence, Tuple
 from warnings import warn
 
-from langchain.chains.base import Chain
-from langchain.schema.agent import AgentAction
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.base import Chain
+from oplangchain.schema.agent import AgentAction
+from oplangchain.schema.language_model import BaseLanguageModel
 
 logger = logging.getLogger(__name__)
 
 
 class EvaluatorType(str, Enum):
     """The types of the evaluators."""
```

### Comparing `oplangchain-0.1.0/oplangchain/evaluation/string_distance/base.py` & `oplangchain-0.1.1/oplangchain/evaluation/string_distance/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 """String distance evaluators based on the RapidFuzz library."""
 
 from enum import Enum
 from typing import Any, Callable, Dict, List, Optional
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
     Callbacks,
 )
-from langchain.chains.base import Chain
-from langchain.evaluation.schema import PairwiseStringEvaluator, StringEvaluator
-from langchain.schema import RUN_KEY
+from oplangchain.chains.base import Chain
+from oplangchain.evaluation.schema import PairwiseStringEvaluator, StringEvaluator
+from oplangchain.schema import RUN_KEY
 
 
 def _load_rapidfuzz() -> Any:
     """
     Load the RapidFuzz library.
 
     Raises:
@@ -165,24 +165,24 @@
 
 class StringDistanceEvalChain(StringEvaluator, _RapidFuzzChainMixin):
     """Compute string distances between the prediction and the reference.
 
     Examples
     ----------
 
-    >>> from langchain.evaluation import StringDistanceEvalChain
+    >>> from oplangchain.evaluation import StringDistanceEvalChain
     >>> evaluator = StringDistanceEvalChain()
     >>> evaluator.evaluate_strings(
             prediction="Mindy is the CTO",
             reference="Mindy is the CEO",
         )
 
     Using the `load_evaluator` function:
 
-    >>> from langchain.evaluation import load_evaluator
+    >>> from oplangchain.evaluation import load_evaluator
     >>> evaluator = load_evaluator("string_distance")
     >>> evaluator.evaluate_strings(
             prediction="The answer is three",
             reference="three",
         )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/graphs/__init__.py` & `oplangchain-0.1.1/oplangchain/graphs/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """**Graphs** provide a natural language interface to graph databases."""
 
-from langchain.graphs.arangodb_graph import ArangoGraph
-from langchain.graphs.hugegraph import HugeGraph
-from langchain.graphs.kuzu_graph import KuzuGraph
-from langchain.graphs.memgraph_graph import MemgraphGraph
-from langchain.graphs.nebula_graph import NebulaGraph
-from langchain.graphs.neo4j_graph import Neo4jGraph
-from langchain.graphs.neptune_graph import NeptuneGraph
-from langchain.graphs.networkx_graph import NetworkxEntityGraph
-from langchain.graphs.rdf_graph import RdfGraph
+from oplangchain.graphs.arangodb_graph import ArangoGraph
+from oplangchain.graphs.hugegraph import HugeGraph
+from oplangchain.graphs.kuzu_graph import KuzuGraph
+from oplangchain.graphs.memgraph_graph import MemgraphGraph
+from oplangchain.graphs.nebula_graph import NebulaGraph
+from oplangchain.graphs.neo4j_graph import Neo4jGraph
+from oplangchain.graphs.neptune_graph import NeptuneGraph
+from oplangchain.graphs.networkx_graph import NetworkxEntityGraph
+from oplangchain.graphs.rdf_graph import RdfGraph
 
 __all__ = [
     "MemgraphGraph",
     "NetworkxEntityGraph",
     "Neo4jGraph",
     "NebulaGraph",
     "NeptuneGraph",
```

### Comparing `oplangchain-0.1.0/oplangchain/graphs/arangodb_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/arangodb_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/hugegraph.py` & `oplangchain-0.1.1/oplangchain/graphs/hugegraph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/kuzu_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/kuzu_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/memgraph_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/memgraph_graph.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from langchain.graphs.neo4j_graph import Neo4jGraph
+from oplangchain.graphs.neo4j_graph import Neo4jGraph
 
 SCHEMA_QUERY = """
 CALL llm_util.schema("prompt_ready")
 YIELD *
 RETURN *
 """
```

### Comparing `oplangchain-0.1.0/oplangchain/graphs/nebula_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/nebula_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/neo4j_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/neo4j_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/neptune_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/neptune_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/networkx_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/networkx_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/graphs/rdf_graph.py` & `oplangchain-0.1.1/oplangchain/graphs/rdf_graph.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/indexes/graph.py` & `oplangchain-0.1.1/oplangchain/indexes/graph.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Graph Index Creator."""
 from typing import Optional, Type
 
 from pydantic import BaseModel
 
-from langchain import BasePromptTemplate
-from langchain.chains.llm import LLMChain
-from langchain.graphs.networkx_graph import NetworkxEntityGraph, parse_triples
-from langchain.indexes.prompts.knowledge_triplet_extraction import (
+from oplangchain import BasePromptTemplate
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs.networkx_graph import NetworkxEntityGraph, parse_triples
+from oplangchain.indexes.prompts.knowledge_triplet_extraction import (
     KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT,
 )
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 class GraphIndexCreator(BaseModel):
     """Functionality to create graph index."""
 
     llm: Optional[BaseLanguageModel] = None
     graph_type: Type[NetworkxEntityGraph] = NetworkxEntityGraph
```

### Comparing `oplangchain-0.1.0/oplangchain/indexes/prompts/entity_extraction.py` & `oplangchain-0.1.1/oplangchain/indexes/prompts/entity_extraction.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_ENTITY_EXTRACTION_TEMPLATE = """You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.
 
 The conversation history is provided just in case of a coreference (e.g. "What do you know about him" where "him" is defined in a previous line) -- ignore items mentioned there that are not in the last line.
 
 Return the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).
```

### Comparing `oplangchain-0.1.0/oplangchain/indexes/prompts/entity_summarization.py` & `oplangchain-0.1.1/oplangchain/indexes/prompts/entity_summarization.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_ENTITY_SUMMARIZATION_TEMPLATE = """You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the "Entity" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.
 The update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.
 
 If there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.
 
 Full conversation history (for context):
```

### Comparing `oplangchain-0.1.0/oplangchain/indexes/prompts/knowledge_triplet_extraction.py` & `oplangchain-0.1.1/oplangchain/indexes/prompts/knowledge_triplet_extraction.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 # flake8: noqa
 
-from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (
     "You are a networked intelligence helping a human track knowledge triples"
     " about all relevant people, things, concepts, etc. and integrating"
     " them with your knowledge stored within your weights"
     " as well as that stored in a knowledge graph."
     " Extract all of the knowledge triples from the text."
```

### Comparing `oplangchain-0.1.0/oplangchain/indexes/vectorstore.py` & `oplangchain-0.1.1/oplangchain/indexes/vectorstore.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from typing import Any, List, Optional, Type
 
 from pydantic import BaseModel, Extra, Field
 
-from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain
-from langchain.chains.retrieval_qa.base import RetrievalQA
-from langchain.document_loaders.base import BaseLoader
-from langchain.embeddings.base import Embeddings
-from langchain.embeddings.openai import OpenAIEmbeddings
-from langchain.llms.openai import OpenAI
-from langchain.schema import Document
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.chroma import Chroma
+from oplangchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain
+from oplangchain.chains.retrieval_qa.base import RetrievalQA
+from oplangchain.document_loaders.base import BaseLoader
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.embeddings.openai import OpenAIEmbeddings
+from oplangchain.llms.openai import OpenAI
+from oplangchain.schema import Document
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.chroma import Chroma
 
 
 def _get_default_text_splitter() -> TextSplitter:
     return RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
 
 
 class VectorStoreIndexWrapper(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/ai21.py` & `oplangchain-0.1.1/oplangchain/llms/ai21.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, List, Optional
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 
 class AI21PenaltyData(BaseModel):
     """Parameters for AI21 penalty data."""
 
     scale: int = 0
     applyToWhitespaces: bool = True
@@ -24,15 +24,15 @@
 
     To use, you should have the environment variable ``AI21_API_KEY``
     set with your API key.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import AI21
+            from oplangchain.llms import AI21
             ai21 = AI21(model="j2-jumbo-instruct")
     """
 
     model: str = "j2-jumbo-instruct"
     """Model name to use."""
 
     temperature: float = 0.7
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/aleph_alpha.py` & `oplangchain-0.1.1/oplangchain/llms/aleph_alpha.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, List, Optional, Sequence
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 
 class AlephAlpha(LLM):
     """Aleph Alpha large language models.
 
     To use, you should have the ``aleph_alpha_client`` python package installed, and the
     environment variable ``ALEPH_ALPHA_API_KEY`` set with your API key, or pass
@@ -17,15 +17,15 @@
 
     Parameters are explained more in depth here:
     https://github.com/Aleph-Alpha/aleph-alpha-client/blob/c14b7dd2b4325c7da0d6a119f6e76385800e097b/aleph_alpha_client/completion.py#L10
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import AlephAlpha
+            from oplangchain.llms import AlephAlpha
             aleph_alpha = AlephAlpha(aleph_alpha_api_key="my-api-key")
     """
 
     client: Any  #: :meta private:
     model: Optional[str] = "luminous-base"
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/amazon_api_gateway.py` & `oplangchain-0.1.1/oplangchain/llms/amazon_api_gateway.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 
 class ContentHandlerAmazonAPIGateway:
-    """Adapter to prepare the inputs from Langchain to a format
+    """Adapter to prepare the inputs from oplangchain to a format
     that LLM model expects.
 
     It also provides helper function to extract
     the generated text from the model response."""
 
     @classmethod
     def transform_input(
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/anthropic.py` & `oplangchain-0.1.1/oplangchain/llms/anthropic.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 import re
 import warnings
 from typing import Any, AsyncIterator, Callable, Dict, Iterator, List, Mapping, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.output import GenerationChunk
-from langchain.utils import check_package_version, get_from_dict_or_env
+from oplangchain.llms.base import LLM
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.output import GenerationChunk
+from oplangchain.utils import check_package_version, get_from_dict_or_env
 
 
 class _AnthropicCommon(BaseLanguageModel):
     client: Any = None  #: :meta private:
     async_client: Any = None  #: :meta private:
     model: str = "claude-2"
     """Model name to use."""
@@ -124,15 +124,15 @@
     environment variable ``ANTHROPIC_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
             import anthropic
-            from langchain.llms import Anthropic
+            from oplangchain.llms import Anthropic
             model = Anthropic(model="<model_name>", anthropic_api_key="my-api-key")
 
             # Simplest invocation, automatically wrapped with HUMAN_PROMPT
             # and AI_PROMPT.
             response = model("What are the biggest risks facing humanity?")
 
             # Or if you want to use the chat mode, build a few-shot-prompt, or
@@ -143,15 +143,15 @@
     """
 
     @root_validator()
     def raise_warning(cls, values: Dict) -> Dict:
         """Raise warning that this class is deprecated."""
         warnings.warn(
             "This Anthropic LLM is deprecated. "
-            "Please use `from langchain.chat_models import ChatAnthropic` instead"
+            "Please use `from oplangchain.chat_models import ChatAnthropic` instead"
         )
         return values
 
     @property
     def _llm_type(self) -> str:
         """Return type of llm."""
         return "anthropic-llm"
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/anyscale.py` & `oplangchain-0.1.1/oplangchain/llms/anyscale.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 
 class Anyscale(LLM):
     """Anyscale Service models.
 
     To use, you should have the environment variable ``ANYSCALE_SERVICE_URL``,
     ``ANYSCALE_SERVICE_ROUTE`` and ``ANYSCALE_SERVICE_TOKEN`` set with your Anyscale
     Service, or pass it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Anyscale
+            from oplangchain.llms import Anyscale
             anyscale = Anyscale(anyscale_service_url="SERVICE_URL",
                                 anyscale_service_route="SERVICE_ROUTE",
                                 anyscale_service_token="SERVICE_TOKEN")
 
             # Use Ray for distributed processing
             import ray
             prompt_list=[]
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/aviary.py` & `oplangchain-0.1.1/oplangchain/llms/aviary.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 import dataclasses
 import os
 from typing import Any, Dict, List, Mapping, Optional, Union, cast
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 TIMEOUT = 60
 
 
 @dataclasses.dataclass
 class AviaryBackend:
     backend_url: str
@@ -88,15 +88,15 @@
     `aviary models`
 
     AVIARY_URL and AVIARY_TOKEN environment variables must be set.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Aviary
+            from oplangchain.llms import Aviary
             os.environ["AVIARY_URL"] = "<URL>"
             os.environ["AVIARY_TOKEN"] = "<TOKEN>"
             light = Aviary(model='amazon/LightGPT')
             output = light('How do you make fried rice?')
     """
 
     model: str = "amazon/LightGPT"
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/azureml_endpoint.py` & `oplangchain-0.1.1/oplangchain/llms/azureml_endpoint.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 import urllib.request
 import warnings
 from abc import abstractmethod
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import BaseModel, validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 
 class AzureMLEndpointClient(object):
     """AzureML Managed Endpoint client."""
 
     def __init__(
         self, endpoint_url: str, endpoint_api_key: str, deployment_name: str = ""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/bananadev.py` & `oplangchain-0.1.1/oplangchain/llms/bananadev.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class Banana(LLM):
     """Banana large language models.
 
@@ -19,15 +19,15 @@
 
     Any parameters that are valid to be passed to the call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Banana
+            from oplangchain.llms import Banana
             banana = Banana(model_key="")
     """
 
     model_key: str = ""
     """model endpoint to use"""
 
     model_kwargs: Dict[str, Any] = Field(default_factory=dict)
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/base.py` & `oplangchain-0.1.1/oplangchain/llms/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -34,42 +34,42 @@
     retry,
     retry_base,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-import langchain
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import (
+import oplangchain
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForLLMRun,
     CallbackManager,
     CallbackManagerForLLMRun,
     Callbacks,
 )
-from langchain.load.dump import dumpd
-from langchain.prompts.base import StringPromptValue
-from langchain.prompts.chat import ChatPromptValue
-from langchain.schema import (
+from oplangchain.load.dump import dumpd
+from oplangchain.prompts.base import StringPromptValue
+from oplangchain.prompts.chat import ChatPromptValue
+from oplangchain.schema import (
     Generation,
     LLMResult,
     PromptValue,
     RunInfo,
 )
-from langchain.schema.language_model import BaseLanguageModel, LanguageModelInput
-from langchain.schema.messages import AIMessage, BaseMessage, get_buffer_string
-from langchain.schema.output import GenerationChunk
-from langchain.schema.runnable import RunnableConfig
+from oplangchain.schema.language_model import BaseLanguageModel, LanguageModelInput
+from oplangchain.schema.messages import AIMessage, BaseMessage, get_buffer_string
+from oplangchain.schema.output import GenerationChunk
+from oplangchain.schema.runnable import RunnableConfig
 
 logger = logging.getLogger(__name__)
 
 
 def _get_verbosity() -> bool:
-    return langchain.verbose
+    return oplangchain.verbose
 
 
 @functools.lru_cache
 def _log_error_once(msg: str) -> None:
     """Log an error once."""
     logger.error(msg)
 
@@ -123,15 +123,15 @@
 ) -> Tuple[Dict[int, List], str, List[int], List[str]]:
     """Get prompts that are already cached."""
     llm_string = str(sorted([(k, v) for k, v in params.items()]))
     missing_prompts = []
     missing_prompt_idxs = []
     existing_prompts = {}
     for i, prompt in enumerate(prompts):
-        if langchain.llm_cache is not None:
+        if oplangchain.llm_cache is not None:
             cache_val = langchain.llm_cache.lookup(prompt, llm_string)
             if isinstance(cache_val, list):
                 existing_prompts[i] = cache_val
             else:
                 missing_prompts.append(prompt)
                 missing_prompt_idxs.append(i)
     return existing_prompts, llm_string, missing_prompt_idxs, missing_prompts
@@ -144,15 +144,15 @@
     new_results: LLMResult,
     prompts: List[str],
 ) -> Optional[dict]:
     """Update the cache and get the LLM output."""
     for i, result in enumerate(new_results.generations):
         existing_prompts[missing_prompt_idxs[i]] = result
         prompt = prompts[missing_prompt_idxs[i]]
-        if langchain.llm_cache is not None:
+        if oplangchain.llm_cache is not None:
             langchain.llm_cache.update(prompt, llm_string, result)
     llm_output = new_results.llm_output
     return llm_output
 
 
 class BaseLLM(BaseLanguageModel[str], ABC):
     """Base LLM abstract interface.
@@ -568,15 +568,15 @@
             missing_prompt_idxs,
             missing_prompts,
         ) = get_prompts(params, prompts)
         disregard_cache = self.cache is not None and not self.cache
         new_arg_supported = inspect.signature(self._generate).parameters.get(
             "run_manager"
         )
-        if langchain.llm_cache is None or disregard_cache:
+        if oplangchain.llm_cache is None or disregard_cache:
             if self.cache is not None and self.cache:
                 raise ValueError(
                     "Asked to cache, but no cache found at `langchain.cache`."
                 )
             run_managers = [
                 callback_manager.on_llm_start(
                     dumpd(self), [prompt], invocation_params=params, options=options
@@ -717,15 +717,15 @@
             missing_prompt_idxs,
             missing_prompts,
         ) = get_prompts(params, prompts)
         disregard_cache = self.cache is not None and not self.cache
         new_arg_supported = inspect.signature(self._agenerate).parameters.get(
             "run_manager"
         )
-        if langchain.llm_cache is None or disregard_cache:
+        if oplangchain.llm_cache is None or disregard_cache:
             if self.cache is not None and self.cache:
                 raise ValueError(
                     "Asked to cache, but no cache found at `langchain.cache`."
                 )
             run_managers = await asyncio.gather(
                 *[
                     callback_manager.on_llm_start(
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/baseten.py` & `oplangchain-0.1.1/oplangchain/llms/baseten.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 logger = logging.getLogger(__name__)
 
 
 class Baseten(LLM):
     """Baseten models.
 
@@ -23,15 +23,15 @@
 
     The Baseten model must accept a dictionary of input with the key
     "prompt" and return a dictionary with a key "data" which maps
     to a list of response strings.
 
     Example:
         .. code-block:: python
-            from langchain.llms import Baseten
+            from oplangchain.llms import Baseten
             my_model = Baseten(model="MODEL_ID")
             output = my_model("prompt")
     """
 
     model: str
     input: Dict[str, Any] = Field(default_factory=dict)
     model_kwargs: Dict[str, Any] = Field(default_factory=dict)
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/beam.py` & `oplangchain-0.1.1/oplangchain/llms/beam.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 import textwrap
 import time
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 DEFAULT_NUM_TRIES = 10
 DEFAULT_SLEEP_TIME = 4
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/bedrock.py` & `oplangchain-0.1.1/oplangchain/llms/bedrock.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import json
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 
 class LLMInputOutputAdapter:
-    """Adapter class to prepare the inputs from Langchain to a format
+    """Adapter class to prepare the inputs from oplangchain to a format
     that LLM model expects.
 
     It also provides helper function to extract
     the generated text from the model response."""
 
     @classmethod
     def prepare_input(
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/cerebriumai.py` & `oplangchain-0.1.1/oplangchain/llms/cerebriumai.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class CerebriumAI(LLM):
     """CerebriumAI large language models.
 
@@ -19,15 +19,15 @@
 
     Any parameters that are valid to be passed to the call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import CerebriumAI
+            from oplangchain.llms import CerebriumAI
             cerebrium = CerebriumAI(endpoint_url="")
 
     """
 
     endpoint_url: str = ""
     """model endpoint to use"""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/chatglm.py` & `oplangchain-0.1.1/oplangchain/llms/chatglm.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 import logging
 from typing import Any, List, Mapping, Optional
 
 import requests
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 logger = logging.getLogger(__name__)
 
 
 class ChatGLM(LLM):
     """ChatGLM LLM service.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import ChatGLM
+            from oplangchain.llms import ChatGLM
             endpoint_url = (
                 "http://127.0.0.1:8000"
             )
             ChatGLM_llm = ChatGLM(
                 endpoint_url=endpoint_url
             )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/clarifai.py` & `oplangchain-0.1.1/oplangchain/llms/clarifai.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class Clarifai(LLM):
     """Clarifai large language models.
 
@@ -18,15 +18,15 @@
     the ``clarifai`` python package installed, and the
     environment variable ``CLARIFAI_PAT`` set with your PAT key,
     or pass it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Clarifai
+            from oplangchain.llms import Clarifai
             clarifai_llm = Clarifai(pat=CLARIFAI_PAT, \
                 user_id=USER_ID, app_id=APP_ID, model_id=MODEL_ID)
     """
 
     stub: Any  #: :meta private:
     userDataObject: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/cohere.py` & `oplangchain-0.1.1/oplangchain/llms/cohere.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,21 +8,21 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(llm: Cohere) -> Callable[[Any], Any]:
     import cohere
 
@@ -67,15 +67,15 @@
     To use, you should have the ``cohere`` python package installed, and the
     environment variable ``COHERE_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Cohere
+            from oplangchain.llms import Cohere
             cohere = Cohere(model="gptd-instruct-tft", cohere_api_key="my-api-key")
     """
 
     client: Any  #: :meta private:
     async_client: Any  #: :meta private:
     model: Optional[str] = None
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/ctransformers.py` & `oplangchain-0.1.1/oplangchain/llms/ctransformers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 from functools import partial
 from typing import Any, Dict, List, Optional, Sequence
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
+from oplangchain.llms.base import LLM
 
 
 class CTransformers(LLM):
     """C Transformers LLM models.
 
     To use, you should have the ``ctransformers`` python package installed.
     See https://github.com/marella/ctransformers
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import CTransformers
+            from oplangchain.llms import CTransformers
 
             llm = CTransformers(model="/path/to/ggml-gpt-2.bin", model_type="gpt2")
     """
 
     client: Any  #: :meta private:
 
     model: str
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/databricks.py` & `oplangchain-0.1.1/oplangchain/llms/databricks.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import os
 from abc import ABC, abstractmethod
 from typing import Any, Callable, Dict, List, Optional
 
 import requests
 from pydantic import BaseModel, Extra, Field, PrivateAttr, root_validator, validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 __all__ = ["Databricks"]
 
 
 class _DatabricksClientBase(BaseModel, ABC):
     """A base JSON API client that talks to Databricks."""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/deepinfra.py` & `oplangchain-0.1.1/oplangchain/llms/deepinfra.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 DEFAULT_MODEL_ID = "google/flan-t5-xl"
 
 
 class DeepInfra(LLM):
     """DeepInfra models.
 
@@ -19,15 +19,15 @@
     it as a named parameter to the constructor.
 
     Only supports `text-generation` and `text2text-generation` for now.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import DeepInfra
+            from oplangchain.llms import DeepInfra
             di = DeepInfra(model_id="google/flan-t5-xl",
                                 deepinfra_api_token="my-api-key")
     """
 
     model_id: str = DEFAULT_MODEL_ID
     model_kwargs: Optional[dict] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/edenai.py` & `oplangchain-0.1.1/oplangchain/llms/edenai.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 """Wrapper around EdenAI's Generation API."""
 import logging
 from typing import Any, Dict, List, Literal, Optional
 
 from aiohttp import ClientSession
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.requests import Requests
-from langchain.utils import get_from_dict_or_env
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.requests import Requests
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class EdenAI(LLM):
     """Wrapper around edenai models.
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/fake.py` & `oplangchain-0.1.1/oplangchain/llms/fake.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, List, Mapping, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
+from oplangchain.llms.base import LLM
 
 
 class FakeListLLM(LLM):
     """Fake LLM for testing purposes."""
 
     responses: List
     i: int = 0
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/fireworks.py` & `oplangchain-0.1.1/oplangchain/llms/fireworks.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,21 +10,21 @@
     Tuple,
     Union,
 )
 
 import requests
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import BaseLLM
-from langchain.schema import Generation, LLMResult
-from langchain.utils import get_from_dict_or_env
+from oplangchain.llms.base import BaseLLM
+from oplangchain.schema import Generation, LLMResult
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class BaseFireworks(BaseLLM):
     """Wrapper around Fireworks large language models."""
 
@@ -169,15 +169,15 @@
     """Wrapper around Fireworks Chat large language models.
     To use, you should have the ``fireworksai`` python package installed, and the
     environment variable ``FIREWORKS_API_KEY`` set with your API key.
     Any parameters that are valid to be passed to the fireworks.create
     call can be passed in, even if not explicitly saved on this class.
     Example:
         .. code-block:: python
-            from langchain.llms import FireworksChat
+            from oplangchain.llms import FireworksChat
             fireworkschat = FireworksChat(model_id=""fireworks-llama-v2-13b-chat"")
     """
 
     model_id: str = "accounts/fireworks/models/fireworks-llama-v2-7b-chat"
     """Model name to use."""
     temperature: float = 0.7
     """What sampling temperature to use."""
@@ -264,15 +264,15 @@
     """Wrapper around Fireworks large language models.
     To use, you should have the ``fireworks`` python package installed, and the
     environment variable ``FIREWORKS_API_KEY`` set with your API key.
     Any parameters that are valid to be passed to the fireworks.create
     call can be passed in, even if not explicitly saved on this class.
     Example:
         .. code-block:: python
-            from langchain.llms import fireworks
+            from oplangchain.llms import fireworks
             llm = Fireworks(model_id="fireworks-llama-v2-13b")
     """
 
 
 def update_token_usage(
     keys: Set[str], response: Dict[str, Any], token_usage: Dict[str, Any]
 ) -> None:
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/forefrontai.py` & `oplangchain-0.1.1/oplangchain/llms/forefrontai.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 
 class ForefrontAI(LLM):
     """ForefrontAI large language models.
 
     To use, you should have the environment variable ``FOREFRONTAI_API_KEY``
     set with your API key.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import ForefrontAI
+            from oplangchain.llms import ForefrontAI
             forefrontai = ForefrontAI(endpoint_url="")
     """
 
     endpoint_url: str = ""
     """Model name to use."""
 
     temperature: float = 0.7
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/google_palm.py` & `oplangchain-0.1.1/oplangchain/llms/google_palm.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,18 +8,18 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms import BaseLLM
-from langchain.schema import Generation, LLMResult
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms import BaseLLM
+from oplangchain.schema import Generation, LLMResult
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator() -> Callable[[Any], Any]:
     """Returns a tenacity retry decorator, preconfigured to handle PaLM exceptions"""
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/gooseai.py` & `oplangchain-0.1.1/oplangchain/llms/gooseai.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class GooseAI(LLM):
     """GooseAI large language models.
 
@@ -18,15 +18,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import GooseAI
+            from oplangchain.llms import GooseAI
             gooseai = GooseAI(model_name="gpt-neo-20b")
 
     """
 
     client: Any
 
     model_name: str = "gpt-neo-20b"
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/gpt4all.py` & `oplangchain-0.1.1/oplangchain/llms/gpt4all.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 from functools import partial
 from typing import Any, Dict, List, Mapping, Optional, Set
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 
 class GPT4All(LLM):
     """GPT4All language models.
 
     To use, you should have the ``gpt4all`` python package installed, the
     pre-trained model file, and the model's config information.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import GPT4All
+            from oplangchain.llms import GPT4All
             model = GPT4All(model="./models/gpt4all-model.bin", n_threads=8)
 
             # Simplest invocation
             response = model("Once upon a time, ")
     """
 
     model: str
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/huggingface_endpoint.py` & `oplangchain-0.1.1/oplangchain/llms/huggingface_endpoint.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 VALID_TASKS = ("text2text-generation", "text-generation", "summarization")
 
 
 class HuggingFaceEndpoint(LLM):
     """HuggingFace Endpoint models.
 
@@ -19,15 +19,15 @@
     it as a named parameter to the constructor.
 
     Only supports `text-generation` and `text2text-generation` for now.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import HuggingFaceEndpoint
+            from oplangchain.llms import HuggingFaceEndpoint
             endpoint_url = (
                 "https://abcdefghijklmnop.us-east-1.aws.endpoints.huggingface.cloud"
             )
             hf = HuggingFaceEndpoint(
                 endpoint_url=endpoint_url,
                 huggingfacehub_api_token="my-api-key"
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/huggingface_hub.py` & `oplangchain-0.1.1/oplangchain/llms/huggingface_hub.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 DEFAULT_REPO_ID = "gpt2"
 VALID_TASKS = ("text2text-generation", "text-generation", "summarization")
 
 
 class HuggingFaceHub(LLM):
     """HuggingFaceHub  models.
@@ -19,15 +19,15 @@
     it as a named parameter to the constructor.
 
     Only supports `text-generation`, `text2text-generation` and `summarization` for now.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import HuggingFaceHub
+            from oplangchain.llms import HuggingFaceHub
             hf = HuggingFaceHub(repo_id="gpt2", huggingfacehub_api_token="my-api-key")
     """
 
     client: Any  #: :meta private:
     repo_id: str = DEFAULT_REPO_ID
     """Model name to use."""
     task: Optional[str] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/huggingface_pipeline.py` & `oplangchain-0.1.1/oplangchain/llms/huggingface_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import importlib.util
 import logging
 from typing import Any, List, Mapping, Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 DEFAULT_MODEL_ID = "gpt2"
 DEFAULT_TASK = "text-generation"
 VALID_TASKS = ("text2text-generation", "text-generation", "summarization")
 
 logger = logging.getLogger(__name__)
 
@@ -21,24 +21,24 @@
     To use, you should have the ``transformers`` python package installed.
 
     Only supports `text-generation`, `text2text-generation` and `summarization` for now.
 
     Example using from_model_id:
         .. code-block:: python
 
-            from langchain.llms import HuggingFacePipeline
+            from oplangchain.llms import HuggingFacePipeline
             hf = HuggingFacePipeline.from_model_id(
                 model_id="gpt2",
                 task="text-generation",
                 pipeline_kwargs={"max_new_tokens": 10},
             )
     Example passing pipeline in directly:
         .. code-block:: python
 
-            from langchain.llms import HuggingFacePipeline
+            from oplangchain.llms import HuggingFacePipeline
             from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
 
             model_id = "gpt2"
             tokenizer = AutoTokenizer.from_pretrained(model_id)
             model = AutoModelForCausalLM.from_pretrained(model_id)
             pipe = pipeline(
                 "text-generation", model=model, tokenizer=tokenizer, max_new_tokens=10
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/huggingface_text_gen_inference.py` & `oplangchain-0.1.1/oplangchain/llms/huggingface_text_gen_inference.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import Any, AsyncIterator, Dict, Iterator, List, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
-from langchain.schema.output import GenerationChunk
+from oplangchain.llms.base import LLM
+from oplangchain.schema.output import GenerationChunk
 
 
 class HuggingFaceTextGenInference(LLM):
     """
     HuggingFace text generation API.
 
     It generates text from a given prompt.
@@ -53,15 +53,15 @@
                 typical_p = 0.95,
                 temperature = 0.01,
                 repetition_penalty = 1.03,
             )
             print(llm("What is Deep Learning?"))
             
             # Streaming response example
-            from langchain.callbacks import streaming_stdout
+            from oplangchain.callbacks import streaming_stdout
             
             callbacks = [streaming_stdout.StreamingStdOutCallbackHandler()]
             llm = HuggingFaceTextGenInference(
                 inference_server_url = "http://localhost:8010/",
                 max_new_tokens = 512,
                 top_k = 10,
                 top_p = 0.95,
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/human.py` & `oplangchain-0.1.1/oplangchain/llms/human.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, Callable, List, Mapping, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 
 def _display_prompt(prompt: str) -> None:
     """Displays the given prompt to the user."""
     print(f"\n{prompt}")
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/koboldai.py` & `oplangchain-0.1.1/oplangchain/llms/koboldai.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import logging
 from typing import Any, Dict, List, Optional
 
 import requests
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 logger = logging.getLogger(__name__)
 
 
 def clean_url(url: str) -> str:
     """Remove trailing slash and /api from url if present."""
     if url.endswith("/api"):
@@ -141,15 +141,15 @@
 
         Returns:
             The generated text.
 
         Example:
             .. code-block:: python
 
-                from langchain.llms import KoboldApiLLM
+                from oplangchain.llms import KoboldApiLLM
 
                 llm = KoboldApiLLM(endpoint="http://localhost:5000")
                 llm("Write a story about dragons.")
         """
         data: Dict[str, Any] = {
             "prompt": prompt,
             "use_story": self.use_story,
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/llamacpp.py` & `oplangchain-0.1.1/oplangchain/llms/llamacpp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 import logging
 from typing import Any, Dict, Iterator, List, Optional
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.schema.output import GenerationChunk
-from langchain.utils import get_pydantic_field_names
-from langchain.utils.utils import build_extra_kwargs
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.schema.output import GenerationChunk
+from oplangchain.utils import get_pydantic_field_names
+from oplangchain.utils.utils import build_extra_kwargs
 
 logger = logging.getLogger(__name__)
 
 
 class LlamaCpp(LLM):
     """llama.cpp model.
 
     To use, you should have the llama-cpp-python library installed, and provide the
     path to the Llama model as a named parameter to the constructor.
     Check out: https://github.com/abetlen/llama-cpp-python
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import LlamaCpp
+            from oplangchain.llms import LlamaCpp
             llm = LlamaCpp(model_path="/path/to/llama/model")
     """
 
     client: Any  #: :meta private:
     model_path: str
     """The path to the Llama model file."""
 
@@ -239,15 +239,15 @@
 
         Returns:
             The generated text.
 
         Example:
             .. code-block:: python
 
-                from langchain.llms import LlamaCpp
+                from oplangchain.llms import LlamaCpp
                 llm = LlamaCpp(model_path="/path/to/local/llama/model.bin")
                 llm("This is a prompt.")
         """
         if self.streaming:
             # If streaming is enabled, we use the stream
             # method that yields as they are generated
             # and return the combined strings from the first choices's text:
@@ -285,15 +285,15 @@
         Yields:
             A dictionary like objects containing a string token and metadata.
             See llama-cpp-python docs and below for more.
 
         Example:
             .. code-block:: python
 
-                from langchain.llms import LlamaCpp
+                from oplangchain.llms import LlamaCpp
                 llm = LlamaCpp(
                     model_path="/path/to/local/model.bin",
                     temperature = 0.5
                 )
                 for chunk in llm.stream("Ask 'Hi, how are you?' like a pirate:'",
                         stop=["'","\n"]):
                     result = chunk["choices"][0]
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/loading.py` & `oplangchain-0.1.1/oplangchain/llms/loading.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Base interface for loading large language model APIs."""
 import json
 from pathlib import Path
 from typing import Union
 
 import yaml
 
-from langchain.llms import type_to_cls_dict
-from langchain.llms.base import BaseLLM
+from oplangchain.llms import type_to_cls_dict
+from oplangchain.llms.base import BaseLLM
 
 
 def load_llm_from_config(config: dict) -> BaseLLM:
     """Load LLM from Config Dict."""
     if "_type" not in config:
         raise ValueError("Must specify an LLM Type in config")
     config_type = config.pop("_type")
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/manifest.py` & `oplangchain-0.1.1/oplangchain/llms/manifest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 
 class ManifestWrapper(LLM):
     """HazyResearch's Manifest library."""
 
     client: Any  #: :meta private:
     llm_kwargs: Optional[Dict] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/minimax.py` & `oplangchain-0.1.1/oplangchain/llms/minimax.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,19 +8,19 @@
     List,
     Optional,
 )
 
 import requests
 from pydantic import BaseModel, Extra, Field, PrivateAttr, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class _MinimaxEndpointClient(BaseModel):
     """An API client that talks to a Minimax llm endpoint."""
 
@@ -55,15 +55,15 @@
 class Minimax(LLM):
     """Wrapper around Minimax large language models.
     To use, you should have the environment variable
     ``MINIMAX_API_KEY`` and ``MINIMAX_GROUP_ID`` set with your API key,
     or pass them as a named parameter to the constructor.
     Example:
      .. code-block:: python
-         from langchain.llms.minimax import Minimax
+         from oplangchain.llms.minimax import Minimax
          minimax = Minimax(model="<model_name>", minimax_api_key="my-api-key",
           minimax_group_id="my-group-id")
     """
 
     _client: _MinimaxEndpointClient = PrivateAttr()
     model: str = "abab5.5-chat"
     """Model name to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/mlflow_ai_gateway.py` & `oplangchain-0.1.1/oplangchain/llms/mlflow_ai_gateway.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import BaseModel, Extra
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 
 class Params(BaseModel, extra=Extra.allow):
     """Parameters for the MLflow AI Gateway LLM."""
 
     temperature: float = 0.0
     candidate_count: int = 1
@@ -24,15 +24,15 @@
 
     To use, you should have the ``mlflow[gateway]`` python package installed.
     For more information, see https://mlflow.org/docs/latest/gateway/index.html.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import MlflowAIGateway
+            from oplangchain.llms import MlflowAIGateway
 
             completions = MlflowAIGateway(
                 gateway_uri="<your-mlflow-ai-gateway-uri>",
                 route="<your-mlflow-ai-gateway-completions-route>",
                 params={
                     "temperature": 0.1
                 }
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/modal.py` & `oplangchain-0.1.1/oplangchain/llms/modal.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 logger = logging.getLogger(__name__)
 
 
 class Modal(LLM):
     """Modal large language models.
 
@@ -18,15 +18,15 @@
 
     Any parameters that are valid to be passed to the call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Modal
+            from oplangchain.llms import Modal
             modal = Modal(endpoint_url="")
 
     """
 
     endpoint_url: str = ""
     """model endpoint to use"""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/mosaicml.py` & `oplangchain-0.1.1/oplangchain/llms/mosaicml.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 INSTRUCTION_KEY = "### Instruction:"
 RESPONSE_KEY = "### Response:"
 INTRO_BLURB = (
     "Below is an instruction that describes a task. "
     "Write a response that appropriately completes the request."
 )
@@ -32,15 +32,15 @@
     To use, you should have the
     environment variable ``MOSAICML_API_TOKEN`` set with your API token, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import MosaicML
+            from oplangchain.llms import MosaicML
             endpoint_url = (
                 "https://models.hosted-on.mosaicml.hosting/mpt-7b-instruct/v1/predict"
             )
             mosaic_llm = MosaicML(
                 endpoint_url=endpoint_url,
                 mosaicml_api_token="my-api-key"
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/nlpcloud.py` & `oplangchain-0.1.1/oplangchain/llms/nlpcloud.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 
 class NLPCloud(LLM):
     """NLPCloud large language models.
 
     To use, you should have the ``nlpcloud`` python package installed, and the
     environment variable ``NLPCLOUD_API_KEY`` set with your API key.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import NLPCloud
+            from oplangchain.llms import NLPCloud
             nlpcloud = NLPCloud(model="finetuned-gpt-neox-20b")
     """
 
     client: Any  #: :meta private:
     model_name: str = "finetuned-gpt-neox-20b"
     """Model name to use."""
     gpu: bool = True
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/octoai_endpoint.py` & `oplangchain-0.1.1/oplangchain/llms/octoai_endpoint.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 
 class OctoAIEndpoint(LLM):
     """OctoAI LLM Endpoints.
 
     OctoAIEndpoint is a class to interact with OctoAI
      Compute Service large language model endpoints.
@@ -17,15 +17,15 @@
     To use, you should have the ``octoai`` python package installed, and the
     environment variable ``OCTOAI_API_TOKEN`` set with your API token, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms.octoai_endpoint  import OctoAIEndpoint
+            from oplangchain.llms.octoai_endpoint  import OctoAIEndpoint
             OctoAIEndpoint(
                 octoai_api_token="octoai-api-key",
                 endpoint_url="https://mpt-7b-demo-kk0powt97tmb.octoai.cloud/generate",
                 model_kwargs={
                     "max_new_tokens": 200,
                     "temperature": 0.75,
                     "top_p": 0.95,
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/openai.py` & `oplangchain-0.1.1/oplangchain/llms/openai.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,23 +18,23 @@
     Set,
     Tuple,
     Union,
 )
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import BaseLLM, create_base_retry_decorator
-from langchain.schema import Generation, LLMResult
-from langchain.schema.output import GenerationChunk
-from langchain.utils import get_from_dict_or_env, get_pydantic_field_names
-from langchain.utils.utils import build_extra_kwargs
+from oplangchain.llms.base import BaseLLM, create_base_retry_decorator
+from oplangchain.schema import Generation, LLMResult
+from oplangchain.schema.output import GenerationChunk
+from oplangchain.utils import get_from_dict_or_env, get_pydantic_field_names
+from oplangchain.utils.utils import build_extra_kwargs
 
 logger = logging.getLogger(__name__)
 
 
 def update_token_usage(
     keys: Set[str], response: Dict[str, Any], token_usage: Dict[str, Any]
 ) -> None:
@@ -197,15 +197,15 @@
     def __new__(cls, **data: Any) -> Union[OpenAIChat, BaseOpenAI]:  # type: ignore
         """Initialize the OpenAI object."""
         model_name = data.get("model_name", "")
         if model_name.startswith("gpt-3.5-turbo") or model_name.startswith("gpt-4"):
             warnings.warn(
                 "You are trying to use a chat model. This way of initializing it is "
                 "no longer supported. Instead, please use: "
-                "`from langchain.chat_models import ChatOpenAI`"
+                "`from oplangchain.chat_models import ChatOpenAI`"
             )
             return OpenAIChat(**data)
         return super().__new__(cls)
 
     class Config:
         """Configuration for this pydantic object."""
 
@@ -621,15 +621,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import OpenAI
+            from oplangchain.llms import OpenAI
             openai = OpenAI(model_name="text-davinci-003")
     """
 
     @property
     def _invocation_params(self) -> Dict[str, Any]:
         return {**{"model": self.model_name}, **super()._invocation_params}
 
@@ -642,15 +642,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import AzureOpenAI
+            from oplangchain.llms import AzureOpenAI
             openai = AzureOpenAI(model_name="text-davinci-003")
     """
 
     deployment_name: str = ""
     """Deployment name to use."""
     openai_api_type: str = ""
     openai_api_version: str = ""
@@ -697,15 +697,15 @@
 
     Any parameters that are valid to be passed to the openai.create call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import OpenAIChat
+            from oplangchain.llms import OpenAIChat
             openaichat = OpenAIChat(model_name="gpt-3.5-turbo")
     """
 
     client: Any  #: :meta private:
     model_name: str = "gpt-3.5-turbo"
     """Model name to use."""
     model_kwargs: Dict[str, Any] = Field(default_factory=dict)
@@ -782,15 +782,15 @@
                 "`openai` has no `ChatCompletion` attribute, this is likely "
                 "due to an old version of the openai package. Try upgrading it "
                 "with `pip install --upgrade openai`."
             )
         warnings.warn(
             "You are trying to use a chat model. This way of initializing it is "
             "no longer supported. Instead, please use: "
-            "`from langchain.chat_models import ChatOpenAI`"
+            "`from oplangchain.chat_models import ChatOpenAI`"
         )
         return values
 
     @property
     def _default_params(self) -> Dict[str, Any]:
         """Get the default parameters for calling OpenAI API."""
         return self.model_kwargs
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/openllm.py` & `oplangchain-0.1.1/oplangchain/llms/openllm.py`

 * *Files 1% similar despite different names*

```diff
@@ -13,19 +13,19 @@
     TypedDict,
     Union,
     overload,
 )
 
 from pydantic import PrivateAttr
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM
+from oplangchain.llms.base import LLM
 
 if TYPE_CHECKING:
     import openllm
 
 
 ServerType = Literal["http", "grpc"]
 
@@ -55,27 +55,27 @@
         pip install openllm
 
     Learn more at: https://github.com/bentoml/openllm
 
     Example running an LLM model locally managed by OpenLLM:
         .. code-block:: python
 
-            from langchain.llms import OpenLLM
+            from oplangchain.llms import OpenLLM
             llm = OpenLLM(
                 model_name='flan-t5',
                 model_id='google/flan-t5-large',
             )
             llm("What is the difference between a duck and a goose?")
 
     For all available supported models, you can run 'openllm models'.
 
     If you have a OpenLLM server running, you can also use it remotely:
         .. code-block:: python
 
-            from langchain.llms import OpenLLM
+            from oplangchain.llms import OpenLLM
             llm = OpenLLM(server_url='http://localhost:3000')
             llm("What is the difference between a duck and a goose?")
     """
 
     model_name: Optional[str] = None
     """Model name to use. See 'openllm models' for all available models."""
     model_id: Optional[str] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/openlm.py` & `oplangchain-0.1.1/oplangchain/llms/openlm.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Any, Dict
 
 from pydantic import root_validator
 
-from langchain.llms.openai import BaseOpenAI
+from oplangchain.llms.openai import BaseOpenAI
 
 
 class OpenLM(BaseOpenAI):
     """OpenLM models."""
 
     @property
     def _invocation_params(self) -> Dict[str, Any]:
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/petals.py` & `oplangchain-0.1.1/oplangchain/llms/petals.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class Petals(LLM):
     """Petals Bloom models.
 
@@ -19,15 +19,15 @@
 
     Any parameters that are valid to be passed to the call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import petals
+            from oplangchain.llms import petals
             petals = Petals()
 
     """
 
     client: Any
     """The client to use for the API calls."""
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/pipelineai.py` & `oplangchain-0.1.1/oplangchain/llms/pipelineai.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class PipelineAI(LLM, BaseModel):
     """PipelineAI large language models.
 
@@ -19,15 +19,15 @@
 
     Any parameters that are valid to be passed to the call can be passed
     in, even if not explicitly saved on this class.
 
     Example:
         .. code-block:: python
 
-            from langchain import PipelineAI
+            from oplangchain import PipelineAI
             pipeline = PipelineAI(pipeline_key="")
     """
 
     pipeline_key: str = ""
     """The id or tag of the target pipeline"""
 
     pipeline_kwargs: Dict[str, Any] = Field(default_factory=dict)
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/predibase.py` & `oplangchain-0.1.1/oplangchain/llms/predibase.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 
 class Predibase(LLM):
     """Use your Predibase models with Langchain.
 
     To use, you should have the ``predibase`` python package installed,
     and have your Predibase API key.
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/predictionguard.py` & `oplangchain-0.1.1/oplangchain/llms/predictionguard.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import logging
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class PredictionGuard(LLM):
     """Prediction Guard large language models.
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/promptlayer_openai.py` & `oplangchain-0.1.1/oplangchain/llms/promptlayer_openai.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import datetime
 from typing import Any, List, Optional
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms import OpenAI, OpenAIChat
-from langchain.schema import LLMResult
+from oplangchain.llms import OpenAI, OpenAIChat
+from oplangchain.schema import LLMResult
 
 
 class PromptLayerOpenAI(OpenAI):
     """PromptLayer OpenAI large language models.
 
     To use, you should have the ``openai`` and ``promptlayer`` python
     package installed, and the environment variable ``OPENAI_API_KEY``
@@ -25,15 +25,15 @@
         ``return_pl_id``: If True, the PromptLayer request ID will be
             returned in the ``generation_info`` field of the
             ``Generation`` object.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import PromptLayerOpenAI
+            from oplangchain.llms import PromptLayerOpenAI
             openai = PromptLayerOpenAI(model_name="text-davinci-003")
     """
 
     pl_tags: Optional[List[str]]
     return_pl_id: Optional[bool] = False
 
     def _generate(
@@ -134,15 +134,15 @@
         ``return_pl_id``: If True, the PromptLayer request ID will be
             returned in the ``generation_info`` field of the
             ``Generation`` object.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import PromptLayerOpenAIChat
+            from oplangchain.llms import PromptLayerOpenAIChat
             openaichat = PromptLayerOpenAIChat(model_name="gpt-3.5-turbo")
     """
 
     pl_tags: Optional[List[str]]
     return_pl_id: Optional[bool] = False
 
     def _generate(
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/replicate.py` & `oplangchain-0.1.1/oplangchain/llms/replicate.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Any, Dict, List, Mapping, Optional
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class Replicate(LLM):
     """Replicate models.
 
@@ -19,15 +19,15 @@
 
     The model param is required, but any other model parameters can also
     be passed in with the format input={model_param: value, ...}
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Replicate
+            from oplangchain.llms import Replicate
             replicate = Replicate(model="stability-ai/stable-diffusion: \
                                          27b93a2413e7f36cd83da926f365628\
                                          0b2931564ff050bf9575f1fdf9bcd7478",
                                   input={"image_dimensions": "512x512"})
     """
 
     model: str
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/rwkv.py` & `oplangchain-0.1.1/oplangchain/llms/rwkv.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,29 +3,29 @@
 Based on https://github.com/saharNooby/rwkv.cpp/blob/master/rwkv/chat_with_bot.py
          https://github.com/BlinkDL/ChatRWKV/blob/main/v2/chat.py
 """
 from typing import Any, Dict, List, Mapping, Optional, Set
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 
 class RWKV(LLM, BaseModel):
     """RWKV language models.
 
     To use, you should have the ``rwkv`` python package installed, the
     pre-trained model file, and the model's config information.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import RWKV
+            from oplangchain.llms import RWKV
             model = RWKV(model="./models/rwkv-3b-fp16.bin", strategy="cpu fp32")
 
             # Simplest invocation
             response = model("Once upon a time, ")
     """
 
     model: str
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/sagemaker_endpoint.py` & `oplangchain-0.1.1/oplangchain/llms/sagemaker_endpoint.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Sagemaker InvokeEndpoint API."""
 from abc import abstractmethod
 from typing import Any, Dict, Generic, List, Mapping, Optional, TypeVar, Union
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 INPUT_TYPE = TypeVar("INPUT_TYPE", bound=Union[str, List[str]])
 OUTPUT_TYPE = TypeVar("OUTPUT_TYPE", bound=Union[str, List[List[float]]])
 
 
 class ContentHandlerBase(Generic[INPUT_TYPE, OUTPUT_TYPE]):
     """A handler class to transform input from LLM to a
@@ -80,15 +80,15 @@
     See: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html
     """
 
     """
     Example:
         .. code-block:: python
 
-            from langchain import SagemakerEndpoint
+            from oplangchain import SagemakerEndpoint
             endpoint_name = (
                 "my-endpoint-name"
             )
             region_name = (
                 "us-west-2"
             )
             credentials_profile_name = (
@@ -123,15 +123,15 @@
     and the endpoint.
     """
 
     """
      Example:
         .. code-block:: python
 
-        from langchain.llms.sagemaker_endpoint import LLMContentHandler
+        from oplangchain.llms.sagemaker_endpoint import LLMContentHandler
 
         class ContentHandler(LLMContentHandler):
                 content_type = "application/json"
                 accepts = "application/json"
 
                 def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:
                     input_str = json.dumps({prompt: prompt, **model_kwargs})
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/self_hosted.py` & `oplangchain-0.1.1/oplangchain/llms/self_hosted.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import importlib.util
 import logging
 import pickle
 from typing import Any, Callable, List, Mapping, Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
 
 logger = logging.getLogger(__name__)
 
 
 def _generate_text(
     pipeline: Any,
     prompt: str,
@@ -70,15 +70,15 @@
     cloud like Paperspace, Coreweave, etc.).
 
     To use, you should have the ``runhouse`` python package installed.
 
     Example for custom pipeline and inference functions:
         .. code-block:: python
 
-            from langchain.llms import SelfHostedPipeline
+            from oplangchain.llms import SelfHostedPipeline
             from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
             import runhouse as rh
 
             def load_pipeline():
                 tokenizer = AutoTokenizer.from_pretrained("gpt2")
                 model = AutoModelForCausalLM.from_pretrained("gpt2")
                 return pipeline(
@@ -93,27 +93,27 @@
                 model_load_fn=load_pipeline,
                 hardware=gpu,
                 model_reqs=model_reqs, inference_fn=inference_fn
             )
     Example for <2GB model (can be serialized and sent directly to the server):
         .. code-block:: python
 
-            from langchain.llms import SelfHostedPipeline
+            from oplangchain.llms import SelfHostedPipeline
             import runhouse as rh
             gpu = rh.cluster(name="rh-a10x", instance_type="A100:1")
             my_model = ...
             llm = SelfHostedPipeline.from_pipeline(
                 pipeline=my_model,
                 hardware=gpu,
                 model_reqs=["./", "torch", "transformers"],
             )
     Example passing model path for larger models:
         .. code-block:: python
 
-            from langchain.llms import SelfHostedPipeline
+            from oplangchain.llms import SelfHostedPipeline
             import runhouse as rh
             import pickle
             from transformers import pipeline
 
             generator = pipeline(model="gpt2")
             rh.blob(pickle.dumps(generator), path="models/pipeline.pkl"
                 ).save().to(gpu, path="models")
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/self_hosted_hugging_face.py` & `oplangchain-0.1.1/oplangchain/llms/self_hosted_hugging_face.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import importlib.util
 import logging
 from typing import Any, Callable, List, Mapping, Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.self_hosted import SelfHostedPipeline
-from langchain.llms.utils import enforce_stop_tokens
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.self_hosted import SelfHostedPipeline
+from oplangchain.llms.utils import enforce_stop_tokens
 
 DEFAULT_MODEL_ID = "gpt2"
 DEFAULT_TASK = "text-generation"
 VALID_TASKS = ("text2text-generation", "text-generation", "summarization")
 
 logger = logging.getLogger(__name__)
 
@@ -121,25 +121,25 @@
     To use, you should have the ``runhouse`` python package installed.
 
     Only supports `text-generation`, `text2text-generation` and `summarization` for now.
 
     Example using from_model_id:
         .. code-block:: python
 
-            from langchain.llms import SelfHostedHuggingFaceLLM
+            from oplangchain.llms import SelfHostedHuggingFaceLLM
             import runhouse as rh
             gpu = rh.cluster(name="rh-a10x", instance_type="A100:1")
             hf = SelfHostedHuggingFaceLLM(
                 model_id="google/flan-t5-large", task="text2text-generation",
                 hardware=gpu
             )
     Example passing fn that generates a pipeline (bc the pipeline is not serializable):
         .. code-block:: python
 
-            from langchain.llms import SelfHostedHuggingFaceLLM
+            from oplangchain.llms import SelfHostedHuggingFaceLLM
             from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
             import runhouse as rh
 
             def get_pipeline():
                 model_id = "gpt2"
                 tokenizer = AutoTokenizer.from_pretrained(model_id)
                 model = AutoModelForCausalLM.from_pretrained(model_id)
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/stochasticai.py` & `oplangchain-0.1.1/oplangchain/llms/stochasticai.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 import logging
 import time
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class StochasticAI(LLM):
     """StochasticAI large language models.
 
     To use, you should have the environment variable ``STOCHASTICAI_API_KEY``
     set with your API key.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import StochasticAI
+            from oplangchain.llms import StochasticAI
             stochasticai = StochasticAI(api_url="")
     """
 
     api_url: str = ""
     """Model name to use."""
 
     model_kwargs: Dict[str, Any] = Field(default_factory=dict)
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/textgen.py` & `oplangchain-0.1.1/oplangchain/llms/textgen.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from typing import Any, Dict, List, Optional
 
 import requests
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 logger = logging.getLogger(__name__)
 
 
 class TextGen(LLM):
     """text-generation-webui models.
 
@@ -21,15 +21,15 @@
 
     Parameters below taken from text-generation-webui api example:
     https://github.com/oobabooga/text-generation-webui/blob/main/api-examples/api-example.py
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import TextGen
+            from oplangchain.llms import TextGen
             llm = TextGen(model_url="http://localhost:8500")
     """
 
     model_url: str
     """The full URL to the textgen webui including http[s]://host:port """
 
     preset: Optional[str] = None
@@ -189,15 +189,15 @@
 
         Returns:
             The generated text.
 
         Example:
             .. code-block:: python
 
-                from langchain.llms import TextGen
+                from oplangchain.llms import TextGen
                 llm = TextGen(model_url="http://localhost:5000")
                 llm("Write a story about llamas.")
         """
         if self.streaming:
             raise ValueError("`streaming` option currently unsupported.")
 
         url = f"{self.model_url}/api/v1/generate"
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/tongyi.py` & `oplangchain-0.1.1/oplangchain/llms/tongyi.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,18 +9,18 @@
     before_sleep_log,
     retry,
     retry_if_exception_type,
     stop_after_attempt,
     wait_exponential,
 )
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.schema import Generation, LLMResult
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.schema import Generation, LLMResult
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 def _create_retry_decorator(llm: Tongyi) -> Callable[[Any], Any]:
     min_seconds = 1
     max_seconds = 4
@@ -90,15 +90,15 @@
     To use, you should have the ``dashscope`` python package installed, and the
     environment variable ``DASHSCOPE_API_KEY`` set with your API key, or pass
     it as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Tongyi
+            from oplangchain.llms import Tongyi
             Tongyi = tongyi()
     """
 
     @property
     def lc_secrets(self) -> Dict[str, str]:
         return {"dashscope_api_key": "DASHSCOPE_API_KEY"}
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/vertexai.py` & `oplangchain-0.1.1/oplangchain/llms/vertexai.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 
 import asyncio
 from concurrent.futures import Executor, ThreadPoolExecutor
 from typing import TYPE_CHECKING, Any, Callable, ClassVar, Dict, List, Optional
 
 from pydantic import BaseModel, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
-from langchain.llms.base import LLM, create_base_retry_decorator
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utilities.vertexai import (
+from oplangchain.llms.base import LLM, create_base_retry_decorator
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utilities.vertexai import (
     init_vertexai,
     raise_vertex_import_error,
 )
 
 if TYPE_CHECKING:
     from vertexai.language_models._language_models import _LanguageModel
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/vllm.py` & `oplangchain-0.1.1/oplangchain/llms/vllm.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import BaseLLM
-from langchain.schema.output import Generation, LLMResult
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import BaseLLM
+from oplangchain.schema.output import Generation, LLMResult
 
 
 class VLLM(BaseLLM):
     model: str = ""
     """The name or path of a HuggingFace Transformers model."""
 
     tensor_parallel_size: Optional[int] = 1
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/writer.py` & `oplangchain-0.1.1/oplangchain/llms/writer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,28 @@
 from typing import Any, Dict, List, Mapping, Optional
 
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
-from langchain.llms.utils import enforce_stop_tokens
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
+from oplangchain.llms.utils import enforce_stop_tokens
+from oplangchain.utils import get_from_dict_or_env
 
 
 class Writer(LLM):
     """Writer large language models.
 
     To use, you should have the environment variable ``WRITER_API_KEY`` and
     ``WRITER_ORG_ID`` set with your API key and organization ID respectively.
 
     Example:
         .. code-block:: python
 
-            from langchain import Writer
+            from oplangchain import Writer
             writer = Writer(model_id="palmyra-base")
     """
 
     writer_org_id: Optional[str] = None
     """Writer organization ID."""
 
     model_id: str = "palmyra-instruct"
```

### Comparing `oplangchain-0.1.0/oplangchain/llms/xinference.py` & `oplangchain-0.1.1/oplangchain/llms/xinference.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import TYPE_CHECKING, Any, Generator, List, Mapping, Optional, Union
 
-from langchain.callbacks.manager import CallbackManagerForLLMRun
-from langchain.llms.base import LLM
+from oplangchain.callbacks.manager import CallbackManagerForLLMRun
+from oplangchain.llms.base import LLM
 
 if TYPE_CHECKING:
     from xinference.client import RESTfulChatModelHandle, RESTfulGenerateModelHandle
     from xinference.model.llm.core import LlamaCppGenerateConfig
 
 
 class Xinference(LLM):
@@ -42,15 +42,15 @@
             $ xinference launch -n orca -s 3 -q q4_0
 
     It will return a model UID. Then, you can use Xinference with LangChain.
 
     Example:
         .. code-block:: python
 
-            from langchain.llms import Xinference
+            from oplangchain.llms import Xinference
 
             llm = Xinference(
                 server_url="http://0.0.0.0:9997",
                 model_uid = {model_uid} # replace model_uid with the model UID return from launching the model
             )
 
             llm(
```

### Comparing `oplangchain-0.1.0/oplangchain/load/dump.py` & `oplangchain-0.1.1/oplangchain/load/dump.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import json
 from typing import Any, Dict
 
-from langchain.load.serializable import Serializable, to_json_not_implemented
+from oplangchain.load.serializable import Serializable, to_json_not_implemented
 
 
 def default(obj: Any) -> Any:
     """Return a default value for a Serializable object or
     a SerializedNotImplemented object."""
     if isinstance(obj, Serializable):
         return obj.to_json()
```

### Comparing `oplangchain-0.1.0/oplangchain/load/load.py` & `oplangchain-0.1.1/oplangchain/load/load.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import importlib
 import json
 import os
 from typing import Any, Dict, List, Optional
 
-from langchain.load.serializable import Serializable
+from oplangchain.load.serializable import Serializable
 
 
 class Reviver:
     """Reviver for JSON objects."""
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/load/serializable.py` & `oplangchain-0.1.1/oplangchain/load/serializable.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/memory/__init__.py` & `oplangchain-0.1.1/oplangchain/memory/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -22,49 +22,49 @@
 
 **Main helpers:**
 
 .. code-block::
 
     AIMessage, BaseMessage, HumanMessage
 """  # noqa: E501
-from langchain.memory.buffer import (
+from oplangchain.memory.buffer import (
     ConversationBufferMemory,
     ConversationStringBufferMemory,
 )
-from langchain.memory.buffer_window import ConversationBufferWindowMemory
-from langchain.memory.chat_message_histories import (
+from oplangchain.memory.buffer_window import ConversationBufferWindowMemory
+from oplangchain.memory.chat_message_histories import (
     CassandraChatMessageHistory,
     ChatMessageHistory,
     CosmosDBChatMessageHistory,
     DynamoDBChatMessageHistory,
     FileChatMessageHistory,
     MomentoChatMessageHistory,
     MongoDBChatMessageHistory,
     PostgresChatMessageHistory,
     RedisChatMessageHistory,
     SQLChatMessageHistory,
     StreamlitChatMessageHistory,
     ZepChatMessageHistory,
 )
-from langchain.memory.combined import CombinedMemory
-from langchain.memory.entity import (
+from oplangchain.memory.combined import CombinedMemory
+from oplangchain.memory.entity import (
     ConversationEntityMemory,
     InMemoryEntityStore,
     RedisEntityStore,
     SQLiteEntityStore,
 )
-from langchain.memory.kg import ConversationKGMemory
-from langchain.memory.motorhead_memory import MotorheadMemory
-from langchain.memory.readonly import ReadOnlySharedMemory
-from langchain.memory.simple import SimpleMemory
-from langchain.memory.summary import ConversationSummaryMemory
-from langchain.memory.summary_buffer import ConversationSummaryBufferMemory
-from langchain.memory.token_buffer import ConversationTokenBufferMemory
-from langchain.memory.vectorstore import VectorStoreRetrieverMemory
-from langchain.memory.zep_memory import ZepMemory
+from oplangchain.memory.kg import ConversationKGMemory
+from oplangchain.memory.motorhead_memory import MotorheadMemory
+from oplangchain.memory.readonly import ReadOnlySharedMemory
+from oplangchain.memory.simple import SimpleMemory
+from oplangchain.memory.summary import ConversationSummaryMemory
+from oplangchain.memory.summary_buffer import ConversationSummaryBufferMemory
+from oplangchain.memory.token_buffer import ConversationTokenBufferMemory
+from oplangchain.memory.vectorstore import VectorStoreRetrieverMemory
+from oplangchain.memory.zep_memory import ZepMemory
 
 __all__ = [
     "CassandraChatMessageHistory",
     "ChatMessageHistory",
     "CombinedMemory",
     "ConversationBufferMemory",
     "ConversationBufferWindowMemory",
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/buffer.py` & `oplangchain-0.1.1/oplangchain/memory/buffer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.memory.chat_memory import BaseChatMemory, BaseMemory
-from langchain.memory.utils import get_prompt_input_key
-from langchain.schema.messages import get_buffer_string
+from oplangchain.memory.chat_memory import BaseChatMemory, BaseMemory
+from oplangchain.memory.utils import get_prompt_input_key
+from oplangchain.schema.messages import get_buffer_string
 
 
 class ConversationBufferMemory(BaseChatMemory):
     """Buffer for storing conversation memory."""
 
     human_prefix: str = "Human"
     ai_prefix: str = "AI"
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/buffer_window.py` & `oplangchain-0.1.1/oplangchain/memory/buffer_window.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from typing import Any, Dict, List
 
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 class ConversationBufferWindowMemory(BaseChatMemory):
     """Buffer for storing conversation memory inside a limited size window."""
 
     human_prefix: str = "Human"
     ai_prefix: str = "AI"
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_memory.py` & `oplangchain-0.1.1/oplangchain/memory/chat_memory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from abc import ABC
 from typing import Any, Dict, Optional, Tuple
 
 from pydantic import Field
 
-from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory
-from langchain.memory.utils import get_prompt_input_key
-from langchain.schema import BaseChatMessageHistory, BaseMemory
+from oplangchain.memory.chat_message_histories.in_memory import ChatMessageHistory
+from oplangchain.memory.utils import get_prompt_input_key
+from oplangchain.schema import BaseChatMessageHistory, BaseMemory
 
 
 class BaseChatMemory(BaseMemory, ABC):
     """Abstract base class for chat memory."""
 
     chat_memory: BaseChatMessageHistory = Field(default_factory=ChatMessageHistory)
     output_key: Optional[str] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/__init__.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-from langchain.memory.chat_message_histories.cassandra import (
+from oplangchain.memory.chat_message_histories.cassandra import (
     CassandraChatMessageHistory,
 )
-from langchain.memory.chat_message_histories.cosmos_db import CosmosDBChatMessageHistory
-from langchain.memory.chat_message_histories.dynamodb import DynamoDBChatMessageHistory
-from langchain.memory.chat_message_histories.file import FileChatMessageHistory
-from langchain.memory.chat_message_histories.firestore import (
+from oplangchain.memory.chat_message_histories.cosmos_db import CosmosDBChatMessageHistory
+from oplangchain.memory.chat_message_histories.dynamodb import DynamoDBChatMessageHistory
+from oplangchain.memory.chat_message_histories.file import FileChatMessageHistory
+from oplangchain.memory.chat_message_histories.firestore import (
     FirestoreChatMessageHistory,
 )
-from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory
-from langchain.memory.chat_message_histories.momento import MomentoChatMessageHistory
-from langchain.memory.chat_message_histories.mongodb import MongoDBChatMessageHistory
-from langchain.memory.chat_message_histories.postgres import PostgresChatMessageHistory
-from langchain.memory.chat_message_histories.redis import RedisChatMessageHistory
-from langchain.memory.chat_message_histories.sql import SQLChatMessageHistory
-from langchain.memory.chat_message_histories.streamlit import (
+from oplangchain.memory.chat_message_histories.in_memory import ChatMessageHistory
+from oplangchain.memory.chat_message_histories.momento import MomentoChatMessageHistory
+from oplangchain.memory.chat_message_histories.mongodb import MongoDBChatMessageHistory
+from oplangchain.memory.chat_message_histories.postgres import PostgresChatMessageHistory
+from oplangchain.memory.chat_message_histories.redis import RedisChatMessageHistory
+from oplangchain.memory.chat_message_histories.sql import SQLChatMessageHistory
+from oplangchain.memory.chat_message_histories.streamlit import (
     StreamlitChatMessageHistory,
 )
-from langchain.memory.chat_message_histories.zep import ZepChatMessageHistory
+from oplangchain.memory.chat_message_histories.zep import ZepChatMessageHistory
 
 __all__ = [
     "ChatMessageHistory",
     "CassandraChatMessageHistory",
     "CosmosDBChatMessageHistory",
     "DynamoDBChatMessageHistory",
     "FileChatMessageHistory",
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/cassandra.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/cassandra.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,18 +4,18 @@
 import json
 import typing
 from typing import List
 
 if typing.TYPE_CHECKING:
     from cassandra.cluster import Session
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
 
 DEFAULT_TABLE_NAME = "message_store"
 DEFAULT_TTL_SECONDS = None
 
 
 class CassandraChatMessageHistory(BaseChatMessageHistory):
     """Chat message history that stores history in Cassandra.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/cosmos_db.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/cosmos_db.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Azure CosmosDB Memory History."""
 from __future__ import annotations
 
 import logging
 from types import TracebackType
 from typing import TYPE_CHECKING, Any, List, Optional, Type
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
+from oplangchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
 
 logger = logging.getLogger(__name__)
 
 if TYPE_CHECKING:
     from azure.cosmos import ContainerProxy
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/dynamodb.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/dynamodb.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import logging
 from typing import List, Optional
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     BaseMessage,
     _message_to_dict,
     messages_from_dict,
     messages_to_dict,
 )
 
 logger = logging.getLogger(__name__)
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/file.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/file.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import json
 import logging
 from pathlib import Path
 from typing import List
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
+from oplangchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
 
 logger = logging.getLogger(__name__)
 
 
 class FileChatMessageHistory(BaseChatMessageHistory):
     """
     Chat message history that stores history in a local file.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/firestore.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/firestore.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Firestore Chat Message History."""
 from __future__ import annotations
 
 import logging
 from typing import TYPE_CHECKING, List, Optional
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
+from oplangchain.schema.messages import BaseMessage, messages_from_dict, messages_to_dict
 
 logger = logging.getLogger(__name__)
 
 if TYPE_CHECKING:
     from google.cloud.firestore import Client, DocumentReference
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/in_memory.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/in_memory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import List
 
 from pydantic import BaseModel
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage
+from oplangchain.schema.messages import BaseMessage
 
 
 class ChatMessageHistory(BaseChatMessageHistory, BaseModel):
     """In memory implementation of chat message history.
 
     Stores messages in an in memory list.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/momento.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/momento.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 import json
 from datetime import timedelta
 from typing import TYPE_CHECKING, Any, Optional
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
-from langchain.utils import get_from_env
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.utils import get_from_env
 
 if TYPE_CHECKING:
     import momento
 
 
 def _ensure_cache_exists(cache_client: momento.CacheClient, cache_name: str) -> None:
     """Create cache if it doesn't exist.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/mongodb.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/mongodb.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import json
 import logging
 from typing import List
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
 
 logger = logging.getLogger(__name__)
 
 DEFAULT_DBNAME = "chat_history"
 DEFAULT_COLLECTION_NAME = "message_store"
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/postgres.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/postgres.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import json
 import logging
 from typing import List
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
 
 logger = logging.getLogger(__name__)
 
 DEFAULT_CONNECTION_STRING = "postgresql://postgres:mypassword@localhost/chat_history"
 
 
 class PostgresChatMessageHistory(BaseChatMessageHistory):
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/redis.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/redis.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import json
 import logging
 from typing import List, Optional
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
-from langchain.utilities.redis import get_client
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.utilities.redis import get_client
 
 logger = logging.getLogger(__name__)
 
 
 class RedisChatMessageHistory(BaseChatMessageHistory):
     """Chat message history stored in a Redis database."""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/sql.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/sql.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,18 +6,18 @@
 
 try:
     from sqlalchemy.orm import declarative_base
 except ImportError:
     from sqlalchemy.ext.declarative import declarative_base
 from sqlalchemy.orm import sessionmaker
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
+from oplangchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict
 
 logger = logging.getLogger(__name__)
 
 
 def create_message_model(table_name, DynamicBase):  # type: ignore
     """
     Create a message model for a given table name.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/streamlit.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/streamlit.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import List
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import BaseMessage
+from oplangchain.schema.messages import BaseMessage
 
 
 class StreamlitChatMessageHistory(BaseChatMessageHistory):
     """
     Chat message history that stores messages in Streamlit session state.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/chat_message_histories/zep.py` & `oplangchain-0.1.1/oplangchain/memory/chat_message_histories/zep.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from __future__ import annotations
 
 import logging
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
-from langchain.schema import (
+from oplangchain.schema import (
     BaseChatMessageHistory,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     HumanMessage,
     SystemMessage,
 )
 
 if TYPE_CHECKING:
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/combined.py` & `oplangchain-0.1.1/oplangchain/memory/combined.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import warnings
 from typing import Any, Dict, List, Set
 
 from pydantic import validator
 
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.schema import BaseMemory
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.schema import BaseMemory
 
 
 class CombinedMemory(BaseMemory):
     """Combining multiple memories' data together."""
 
     memories: List[BaseMemory]
     """For tracking all the memories that should be accessed."""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/entity.py` & `oplangchain-0.1.1/oplangchain/memory/entity.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 import logging
 from abc import ABC, abstractmethod
 from itertools import islice
 from typing import Any, Dict, Iterable, List, Optional
 
 from pydantic import BaseModel, Field
 
-from langchain.chains.llm import LLMChain
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.memory.prompt import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.memory.prompt import (
     ENTITY_EXTRACTION_PROMPT,
     ENTITY_SUMMARIZATION_PROMPT,
 )
-from langchain.memory.utils import get_prompt_input_key
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, get_buffer_string
-from langchain.utilities.redis import get_client
+from oplangchain.memory.utils import get_prompt_input_key
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.utilities.redis import get_client
 
 logger = logging.getLogger(__name__)
 
 
 class BaseEntityStore(BaseModel, ABC):
     """Abstract base class for Entity store."""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/kg.py` & `oplangchain-0.1.1/oplangchain/memory/kg.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 from typing import Any, Dict, List, Type, Union
 
 from pydantic import Field
 
-from langchain.chains.llm import LLMChain
-from langchain.graphs import NetworkxEntityGraph
-from langchain.graphs.networkx_graph import KnowledgeTriple, get_entities, parse_triples
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.memory.prompt import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.graphs import NetworkxEntityGraph
+from oplangchain.graphs.networkx_graph import KnowledgeTriple, get_entities, parse_triples
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.memory.prompt import (
     ENTITY_EXTRACTION_PROMPT,
     KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT,
 )
-from langchain.memory.utils import get_prompt_input_key
-from langchain.schema import BasePromptTemplate
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, SystemMessage, get_buffer_string
+from oplangchain.memory.utils import get_prompt_input_key
+from oplangchain.schema import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, SystemMessage, get_buffer_string
 
 
 class ConversationKGMemory(BaseChatMemory):
     """Knowledge graph conversation memory.
 
     Integrates with external knowledge graph to store and retrieve
     information about knowledge triples in the conversation.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/motorhead_memory.py` & `oplangchain-0.1.1/oplangchain/memory/motorhead_memory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Optional
 
 import requests
 
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.schema.messages import get_buffer_string
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.schema.messages import get_buffer_string
 
 MANAGED_URL = "https://api.getmetal.io/v1/motorhead"
 # LOCAL_URL = "http://localhost:8080"
 
 
 class MotorheadMemory(BaseChatMemory):
     """Chat message memory backed by Motorhead service."""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/prompt.py` & `oplangchain-0.1.1/oplangchain/memory/prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # flake8: noqa
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
 
 _DEFAULT_ENTITY_MEMORY_CONVERSATION_TEMPLATE = """You are an assistant to a human, powered by a large language model trained by OpenAI.
 
 You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
 
 You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/readonly.py` & `oplangchain-0.1.1/oplangchain/memory/readonly.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Any, Dict, List
 
-from langchain.schema import BaseMemory
+from oplangchain.schema import BaseMemory
 
 
 class ReadOnlySharedMemory(BaseMemory):
     """A memory wrapper that is read-only and cannot be changed."""
 
     memory: BaseMemory
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/simple.py` & `oplangchain-0.1.1/oplangchain/memory/simple.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Any, Dict, List
 
-from langchain.schema import BaseMemory
+from oplangchain.schema import BaseMemory
 
 
 class SimpleMemory(BaseMemory):
     """Simple memory for storing context or other information that shouldn't
     ever change between prompts.
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/summary.py` & `oplangchain-0.1.1/oplangchain/memory/summary.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Type
 
 from pydantic import BaseModel, root_validator
 
-from langchain.chains.llm import LLMChain
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.memory.prompt import SUMMARY_PROMPT
-from langchain.schema import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.memory.prompt import SUMMARY_PROMPT
+from oplangchain.schema import (
     BaseChatMessageHistory,
     BasePromptTemplate,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, SystemMessage, get_buffer_string
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, SystemMessage, get_buffer_string
 
 
 class SummarizerMixin(BaseModel):
     """Mixin for summarizer."""
 
     human_prefix: str = "Human"
     ai_prefix: str = "AI"
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/summary_buffer.py` & `oplangchain-0.1.1/oplangchain/memory/summary_buffer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Any, Dict, List
 
 from pydantic import root_validator
 
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.memory.summary import SummarizerMixin
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.memory.summary import SummarizerMixin
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 class ConversationSummaryBufferMemory(BaseChatMemory, SummarizerMixin):
     """Buffer with summarizer for storing conversation memory."""
 
     max_token_limit: int = 2000
     moving_summary_buffer: str = ""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/token_buffer.py` & `oplangchain-0.1.1/oplangchain/memory/token_buffer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from typing import Any, Dict, List
 
-from langchain.memory.chat_memory import BaseChatMemory
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.memory.chat_memory import BaseChatMemory
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 class ConversationTokenBufferMemory(BaseChatMemory):
     """Conversation chat memory with token limit."""
 
     human_prefix: str = "Human"
     ai_prefix: str = "AI"
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/utils.py` & `oplangchain-0.1.1/oplangchain/memory/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Any, Dict, List
 
-from langchain.schema.messages import get_buffer_string  # noqa: 401
+from oplangchain.schema.messages import get_buffer_string  # noqa: 401
 
 
 def get_prompt_input_key(inputs: Dict[str, Any], memory_variables: List[str]) -> str:
     """
     Get the prompt input key.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/vectorstore.py` & `oplangchain-0.1.1/oplangchain/memory/vectorstore.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Class for a VectorStore-backed memory object."""
 
 from typing import Any, Dict, List, Optional, Sequence, Union
 
 from pydantic import Field
 
-from langchain.memory.chat_memory import BaseMemory
-from langchain.memory.utils import get_prompt_input_key
-from langchain.schema import Document
-from langchain.vectorstores.base import VectorStoreRetriever
+from oplangchain.memory.chat_memory import BaseMemory
+from oplangchain.memory.utils import get_prompt_input_key
+from oplangchain.schema import Document
+from oplangchain.vectorstores.base import VectorStoreRetriever
 
 
 class VectorStoreRetrieverMemory(BaseMemory):
     """VectorStoreRetriever-backed memory."""
 
     retriever: VectorStoreRetriever = Field(exclude=True)
     """VectorStoreRetriever object to connect to."""
```

### Comparing `oplangchain-0.1.0/oplangchain/memory/zep_memory.py` & `oplangchain-0.1.1/oplangchain/memory/zep_memory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 from typing import Any, Dict, Optional
 
-from langchain.memory import ConversationBufferMemory
-from langchain.memory.chat_message_histories import ZepChatMessageHistory
+from oplangchain.memory import ConversationBufferMemory
+from oplangchain.memory.chat_message_histories import ZepChatMessageHistory
 
 
 class ZepMemory(ConversationBufferMemory):
     """Persist your chain history to the Zep Memory Server.
 
     The number of messages returned by Zep and when the Zep server summarizes chat
     histories is configurable. See the Zep documentation for more details.
```

### Comparing `oplangchain-0.1.0/oplangchain/model_laboratory.py` & `oplangchain-0.1.1/oplangchain/model_laboratory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Experiment with different models."""
 from __future__ import annotations
 
 from typing import List, Optional, Sequence
 
-from langchain.chains.base import Chain
-from langchain.chains.llm import LLMChain
-from langchain.llms.base import BaseLLM
-from langchain.prompts.prompt import PromptTemplate
-from langchain.utils.input import get_color_mapping, print_text
+from oplangchain.chains.base import Chain
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.base import BaseLLM
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.utils.input import get_color_mapping, print_text
 
 
 class ModelLaboratory:
     """Experiment with different models."""
 
     def __init__(self, chains: Sequence[Chain], names: Optional[List[str]] = None):
         """Initialize with chains to experiment with.
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/boolean.py` & `oplangchain-0.1.1/oplangchain/output_parsers/boolean.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class BooleanOutputParser(BaseOutputParser[bool]):
     """Parse the output of an LLM call to a boolean."""
 
     true_val: str = "YES"
     """The string value that should be parsed as True."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/combining.py` & `oplangchain-0.1.1/oplangchain/output_parsers/combining.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List
 
 from pydantic import root_validator
 
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class CombiningOutputParser(BaseOutputParser):
     """Combine multiple output parsers into one."""
 
     @property
     def lc_serializable(self) -> bool:
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/datetime.py` & `oplangchain-0.1.1/oplangchain/output_parsers/datetime.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import random
 from datetime import datetime, timedelta
 from typing import List
 
-from langchain.schema import BaseOutputParser, OutputParserException
-from langchain.utils import comma_list
+from oplangchain.schema import BaseOutputParser, OutputParserException
+from oplangchain.utils import comma_list
 
 
 def _generate_random_datetime_strings(
     pattern: str,
     n: int = 3,
     start_date: datetime = datetime(1, 1, 1),
     end_date: datetime = datetime.now() + timedelta(days=3650),
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/enum.py` & `oplangchain-0.1.1/oplangchain/output_parsers/enum.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from enum import Enum
 from typing import Any, Dict, List, Type
 
 from pydantic import root_validator
 
-from langchain.schema import BaseOutputParser, OutputParserException
+from oplangchain.schema import BaseOutputParser, OutputParserException
 
 
 class EnumOutputParser(BaseOutputParser):
     """Parse an output that is one of a set of values."""
 
     enum: Type[Enum]
     """The enum to parse. Its values must be strings."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/fix.py` & `oplangchain-0.1.1/oplangchain/output_parsers/fix.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 from typing import TypeVar
 
-from langchain.chains.llm import LLMChain
-from langchain.output_parsers.prompts import NAIVE_FIX_PROMPT
-from langchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.chains.llm import LLMChain
+from oplangchain.output_parsers.prompts import NAIVE_FIX_PROMPT
+from oplangchain.schema import BaseOutputParser, BasePromptTemplate, OutputParserException
+from oplangchain.schema.language_model import BaseLanguageModel
 
 T = TypeVar("T")
 
 
 class OutputFixingParser(BaseOutputParser[T]):
     """Wraps a parser and tries to fix parsing errors."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/format_instructions.py` & `oplangchain-0.1.1/oplangchain/output_parsers/format_instructions.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/json.py` & `oplangchain-0.1.1/oplangchain/output_parsers/json.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 import json
 import re
 from json import JSONDecodeError
 from typing import Any, List
 
-from langchain.schema import BaseOutputParser, OutputParserException
+from oplangchain.schema import BaseOutputParser, OutputParserException
 
 
 def parse_json_markdown(json_string: str) -> dict:
     """
     Parse a JSON string from a Markdown string.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/list.py` & `oplangchain-0.1.1/oplangchain/output_parsers/list.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 from abc import abstractmethod
 from typing import List
 
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class ListOutputParser(BaseOutputParser[List[str]]):
     """Parse the output of an LLM call to a list."""
 
     @property
     def _type(self) -> str:
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/loading.py` & `oplangchain-0.1.1/oplangchain/output_parsers/loading.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from langchain.output_parsers.regex import RegexParser
+from oplangchain.output_parsers.regex import RegexParser
 
 
 def load_output_parser(config: dict) -> dict:
     """Load an output parser.
 
     Args:
         config: config dict
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/openai_functions.py` & `oplangchain-0.1.1/oplangchain/output_parsers/openai_functions.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 import json
 from typing import Any, Dict, List, Type, Union
 
 from pydantic import BaseModel, root_validator
 
-from langchain.schema import (
+from oplangchain.schema import (
     ChatGeneration,
     Generation,
     OutputParserException,
 )
-from langchain.schema.output_parser import BaseGenerationOutputParser
+from oplangchain.schema.output_parser import BaseGenerationOutputParser
 
 
 class OutputFunctionsParser(BaseGenerationOutputParser[Any]):
     """Parse an output that is one of sets of values."""
 
     args_only: bool = True
     """Whether to only return the arguments to the function call."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/pydantic.py` & `oplangchain-0.1.1/oplangchain/output_parsers/pydantic.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import json
 import re
 from typing import Type, TypeVar
 
 from pydantic import BaseModel, ValidationError
 
-from langchain.output_parsers.format_instructions import PYDANTIC_FORMAT_INSTRUCTIONS
-from langchain.schema import BaseOutputParser, OutputParserException
+from oplangchain.output_parsers.format_instructions import PYDANTIC_FORMAT_INSTRUCTIONS
+from oplangchain.schema import BaseOutputParser, OutputParserException
 
 T = TypeVar("T", bound=BaseModel)
 
 
 class PydanticOutputParser(BaseOutputParser[T]):
     """Parse an output using a pydantic model."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/rail_parser.py` & `oplangchain-0.1.1/oplangchain/output_parsers/rail_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 from typing import Any, Callable, Dict, Optional
 
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class GuardrailsOutputParser(BaseOutputParser):
     """Parse the output of an LLM call using Guardrails."""
 
     guard: Any
     """The Guardrails object."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/regex.py` & `oplangchain-0.1.1/oplangchain/output_parsers/regex.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import re
 from typing import Dict, List, Optional
 
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class RegexParser(BaseOutputParser):
     """Parse the output of an LLM call using a regex."""
 
     @property
     def lc_serializable(self) -> bool:
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/regex_dict.py` & `oplangchain-0.1.1/oplangchain/output_parsers/regex_dict.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import re
 from typing import Dict, Optional
 
-from langchain.schema import BaseOutputParser
+from oplangchain.schema import BaseOutputParser
 
 
 class RegexDictParser(BaseOutputParser):
     """Parse the output of an LLM call into a Dictionary using a regex."""
 
     regex_pattern: str = r"{}:\s?([^.'\n']*)\.?"  # : :meta private:
     """The regex pattern to use to parse the output."""
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/retry.py` & `oplangchain-0.1.1/oplangchain/output_parsers/retry.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 from typing import TypeVar
 
-from langchain.chains.llm import LLMChain
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import (
     BaseOutputParser,
     BasePromptTemplate,
     OutputParserException,
     PromptValue,
 )
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.language_model import BaseLanguageModel
 
 NAIVE_COMPLETION_RETRY = """Prompt:
 {prompt}
 Completion:
 {completion}
 
 Above, the Completion did not satisfy the constraints given in the Prompt.
```

### Comparing `oplangchain-0.1.0/oplangchain/output_parsers/structured.py` & `oplangchain-0.1.1/oplangchain/output_parsers/structured.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Any, List
 
 from pydantic import BaseModel
 
-from langchain.output_parsers.format_instructions import (
+from oplangchain.output_parsers.format_instructions import (
     STRUCTURED_FORMAT_INSTRUCTIONS,
     STRUCTURED_FORMAT_SIMPLE_INSTRUCTIONS,
 )
-from langchain.output_parsers.json import parse_and_check_json_markdown
-from langchain.schema import BaseOutputParser
+from oplangchain.output_parsers.json import parse_and_check_json_markdown
+from oplangchain.schema import BaseOutputParser
 
 line_template = '\t"{name}": {type}  // {description}'
 
 
 class ResponseSchema(BaseModel):
     """A schema for a response from a structured output parser."""
 
@@ -44,15 +44,15 @@
         return cls(response_schemas=response_schemas)
 
     def get_format_instructions(self, only_json: bool = False) -> str:
         """Get format instructions for the output parser.
 
         example:
         ```python
-        from langchain.output_parsers.structured import (
+        from oplangchain.output_parsers.structured import (
             StructuredOutputParser, ResponseSchema
         )
 
         response_schemas = [
             ResponseSchema(
                 name="foo",
                 description="a list of strings",
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/__init__.py` & `oplangchain-0.1.1/oplangchain/prompts/__init__.py`

 * *Files 7% similar despite different names*

```diff
@@ -23,39 +23,39 @@
                                                                       AIMessagePromptTemplate
                                                                       SystemMessagePromptTemplate
 
     PromptValue --> StringPromptValue
                     ChatPromptValue
 
 """  # noqa: E501
-from langchain.prompts.base import StringPromptTemplate
-from langchain.prompts.chat import (
+from oplangchain.prompts.base import StringPromptTemplate
+from oplangchain.prompts.chat import (
     AIMessagePromptTemplate,
     BaseChatPromptTemplate,
     ChatMessagePromptTemplate,
     ChatPromptTemplate,
     HumanMessagePromptTemplate,
     MessagesPlaceholder,
     SystemMessagePromptTemplate,
 )
-from langchain.prompts.example_selector import (
+from oplangchain.prompts.example_selector import (
     LengthBasedExampleSelector,
     MaxMarginalRelevanceExampleSelector,
     NGramOverlapExampleSelector,
     SemanticSimilarityExampleSelector,
 )
-from langchain.prompts.few_shot import (
+from oplangchain.prompts.few_shot import (
     FewShotChatMessagePromptTemplate,
     FewShotPromptTemplate,
 )
-from langchain.prompts.few_shot_with_templates import FewShotPromptWithTemplates
-from langchain.prompts.loading import load_prompt
-from langchain.prompts.pipeline import PipelinePromptTemplate
-from langchain.prompts.prompt import Prompt, PromptTemplate
-from langchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.prompts.few_shot_with_templates import FewShotPromptWithTemplates
+from oplangchain.prompts.loading import load_prompt
+from oplangchain.prompts.pipeline import PipelinePromptTemplate
+from oplangchain.prompts.prompt import Prompt, PromptTemplate
+from oplangchain.schema.prompt_template import BasePromptTemplate
 
 __all__ = [
     "AIMessagePromptTemplate",
     "BaseChatPromptTemplate",
     "BasePromptTemplate",
     "ChatMessagePromptTemplate",
     "ChatPromptTemplate",
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/base.py` & `oplangchain-0.1.1/oplangchain/prompts/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """BasePrompt schema definition."""
 from __future__ import annotations
 
 import warnings
 from abc import ABC
 from typing import Any, Callable, Dict, List, Set
 
-from langchain.formatting import formatter
-from langchain.schema.messages import BaseMessage, HumanMessage
-from langchain.schema.prompt import PromptValue
-from langchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.formatting import formatter
+from oplangchain.schema.messages import BaseMessage, HumanMessage
+from oplangchain.schema.prompt import PromptValue
+from oplangchain.schema.prompt_template import BasePromptTemplate
 
 
 def jinja2_formatter(template: str, **kwargs: Any) -> str:
     """Format a template using jinja2."""
     try:
         from jinja2 import Template
     except ImportError:
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/chat.py` & `oplangchain-0.1.1/oplangchain/prompts/chat.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,22 +3,22 @@
 
 from abc import ABC, abstractmethod
 from pathlib import Path
 from typing import Any, Callable, List, Sequence, Tuple, Type, TypeVar, Union
 
 from pydantic import Field, root_validator
 
-from langchain.load.serializable import Serializable
-from langchain.prompts.base import StringPromptTemplate
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import (
+from oplangchain.load.serializable import Serializable
+from oplangchain.prompts.base import StringPromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import (
     BasePromptTemplate,
     PromptValue,
 )
-from langchain.schema.messages import (
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     HumanMessage,
     SystemMessage,
     get_buffer_string,
 )
@@ -321,15 +321,15 @@
 
     Use to create flexible templated prompts for chat models.
 
     Examples:
 
         .. code-block:: python
 
-            from langchain.prompts import ChatPromptTemplate
+            from oplangchain.prompts import ChatPromptTemplate
 
             template = ChatPromptTemplate.from_messages([
                 ("system", "You are a helpful AI bot. Your name is {name}."),
                 ("human", "Hello, how are you doing?"),
                 ("ai", "I'm doing well, thanks!"),
                 ("human", "{user_input}"),
             ])
@@ -564,15 +564,15 @@
             A new ChatPromptTemplate.
 
 
         Example:
 
             .. code-block:: python
 
-                from langchain.prompts import ChatPromptTemplate
+                from oplangchain.prompts import ChatPromptTemplate
 
                 template = ChatPromptTemplate.from_messages(
                     [
                         ("system", "You are an AI assistant named {name}."),
                         ("human", "Hi I'm {user}"),
                         ("ai", "Hi there, {user}, I'm {name}."),
                         ("human", "{input}"),
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/example_selector/__init__.py` & `oplangchain-0.1.1/oplangchain/prompts/example_selector/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Logic for selecting examples to include in prompts."""
-from langchain.prompts.example_selector.length_based import LengthBasedExampleSelector
-from langchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector
-from langchain.prompts.example_selector.semantic_similarity import (
+from oplangchain.prompts.example_selector.length_based import LengthBasedExampleSelector
+from oplangchain.prompts.example_selector.ngram_overlap import NGramOverlapExampleSelector
+from oplangchain.prompts.example_selector.semantic_similarity import (
     MaxMarginalRelevanceExampleSelector,
     SemanticSimilarityExampleSelector,
 )
 
 __all__ = [
     "LengthBasedExampleSelector",
     "MaxMarginalRelevanceExampleSelector",
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/example_selector/base.py` & `oplangchain-0.1.1/oplangchain/prompts/example_selector/base.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/prompts/example_selector/length_based.py` & `oplangchain-0.1.1/oplangchain/prompts/example_selector/length_based.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Select examples based on length."""
 import re
 from typing import Callable, Dict, List
 
 from pydantic import BaseModel, validator
 
-from langchain.prompts.example_selector.base import BaseExampleSelector
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.example_selector.base import BaseExampleSelector
+from oplangchain.prompts.prompt import PromptTemplate
 
 
 def _get_length_based(text: str) -> int:
     return len(re.split("\n| ", text))
 
 
 class LengthBasedExampleSelector(BaseExampleSelector, BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/example_selector/ngram_overlap.py` & `oplangchain-0.1.1/oplangchain/prompts/example_selector/ngram_overlap.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,16 +4,16 @@
 https://aclanthology.org/P02-1040.pdf
 """
 from typing import Dict, List
 
 import numpy as np
 from pydantic import BaseModel, root_validator
 
-from langchain.prompts.example_selector.base import BaseExampleSelector
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.example_selector.base import BaseExampleSelector
+from oplangchain.prompts.prompt import PromptTemplate
 
 
 def ngram_overlap_score(source: List[str], example: List[str]) -> float:
     """Compute ngram overlap score of source and example as sentence_bleu score.
 
     Use sentence_bleu with method1 smoothing function and auto reweighting.
     Return float value between 0.0 and 1.0 inclusive.
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/example_selector/semantic_similarity.py` & `oplangchain-0.1.1/oplangchain/prompts/example_selector/semantic_similarity.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Example selector that selects examples based on SemanticSimilarity."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Type
 
 from pydantic import BaseModel, Extra
 
-from langchain.embeddings.base import Embeddings
-from langchain.prompts.example_selector.base import BaseExampleSelector
-from langchain.vectorstores.base import VectorStore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.prompts.example_selector.base import BaseExampleSelector
+from oplangchain.vectorstores.base import VectorStore
 
 
 def sorted_values(values: Dict[str, str]) -> List[Any]:
     """Return a list of values in dict sorted by key."""
     return [values[val] for val in sorted(values)]
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/few_shot.py` & `oplangchain-0.1.1/oplangchain/prompts/few_shot.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 """Prompt template that contains few shot examples."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, Union
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.prompts.base import (
+from oplangchain.prompts.base import (
     DEFAULT_FORMATTER_MAPPING,
     StringPromptTemplate,
     check_valid_template,
 )
-from langchain.prompts.chat import BaseChatPromptTemplate, BaseMessagePromptTemplate
-from langchain.prompts.example_selector.base import BaseExampleSelector
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.prompts.chat import BaseChatPromptTemplate, BaseMessagePromptTemplate
+from oplangchain.prompts.example_selector.base import BaseExampleSelector
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 class _FewShotPromptTemplateMixin(BaseModel):
     """Prompt template that contains few shot examples."""
 
     examples: Optional[List[dict]] = None
     """Examples to format into the prompt.
@@ -186,15 +186,15 @@
     Examples:
 
         Prompt template with a fixed list of examples (matching the sample
         conversation above):
 
         .. code-block:: python
 
-            from langchain.prompts import (
+            from oplangchain.prompts import (
                 FewShotChatMessagePromptTemplate,
                 ChatPromptTemplate
             )
 
             examples = [
                 {"input": "2+2", "output": "4"},
                 {"input": "2+3", "output": "5"},
@@ -219,17 +219,17 @@
             )
             final_prompt.format(input="What is 4+4?")
 
         Prompt template with dynamically selected examples:
 
         .. code-block:: python
 
-            from langchain.prompts import SemanticSimilarityExampleSelector
-            from langchain.embeddings import OpenAIEmbeddings
-            from langchain.vectorstores import Chroma
+            from oplangchain.prompts import SemanticSimilarityExampleSelector
+            from oplangchain.embeddings import OpenAIEmbeddings
+            from oplangchain.vectorstores import Chroma
 
             examples = [
                 {"input": "2+2", "output": "4"},
                 {"input": "2+3", "output": "5"},
                 {"input": "2+4", "output": "6"},
                 # ...
             ]
@@ -242,17 +242,17 @@
             vectorstore = Chroma.from_texts(
                 to_vectorize, embeddings, metadatas=examples
             )
             example_selector = SemanticSimilarityExampleSelector(
                 vectorstore=vectorstore
             )
 
-            from langchain.schema import SystemMessage
-            from langchain.prompts import HumanMessagePromptTemplate
-            from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate
+            from oplangchain.schema import SystemMessage
+            from oplangchain.prompts import HumanMessagePromptTemplate
+            from oplangchain.prompts.few_shot import FewShotChatMessagePromptTemplate
 
             few_shot_prompt = FewShotChatMessagePromptTemplate(
                 # Which variable(s) will be passed to the example selector.
                 input_variables=["input"],
                 example_selector=example_selector,
                 # Define how each example will be formatted.
                 # In this case, each example will become 2 messages:
@@ -270,15 +270,15 @@
                 + few_shot_prompt
                 + HumanMessagePromptTemplate.from_template("{input}")
             )
             # Show the prompt
             print(final_prompt.format_messages(input="What's 3+3?"))
 
             # Use within an LLM
-            from langchain.chat_models import ChatAnthropic
+            from oplangchain.chat_models import ChatAnthropic
             chain = final_prompt | ChatAnthropic()
             chain.invoke({"input": "What's 3+3?"})
     """
 
     @property
     def lc_serializable(self) -> bool:
         """Return whether the prompt template is lc_serializable.
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/few_shot_with_templates.py` & `oplangchain-0.1.1/oplangchain/prompts/few_shot_with_templates.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Prompt template that contains few shot examples."""
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.prompts.base import DEFAULT_FORMATTER_MAPPING, StringPromptTemplate
-from langchain.prompts.example_selector.base import BaseExampleSelector
-from langchain.prompts.prompt import PromptTemplate
+from oplangchain.prompts.base import DEFAULT_FORMATTER_MAPPING, StringPromptTemplate
+from oplangchain.prompts.example_selector.base import BaseExampleSelector
+from oplangchain.prompts.prompt import PromptTemplate
 
 
 class FewShotPromptWithTemplates(StringPromptTemplate):
     """Prompt template that contains few shot examples."""
 
     examples: Optional[List[dict]] = None
     """Examples to format into the prompt.
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/loading.py` & `oplangchain-0.1.1/oplangchain/prompts/loading.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 import json
 import logging
 from pathlib import Path
 from typing import Union
 
 import yaml
 
-from langchain.output_parsers.regex import RegexParser
-from langchain.prompts.few_shot import FewShotPromptTemplate
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseLLMOutputParser, BasePromptTemplate, StrOutputParser
-from langchain.utilities.loading import try_load_from_hub
+from oplangchain.output_parsers.regex import RegexParser
+from oplangchain.prompts.few_shot import FewShotPromptTemplate
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseLLMOutputParser, BasePromptTemplate, StrOutputParser
+from oplangchain.utilities.loading import try_load_from_hub
 
 URL_BASE = "https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/"
 logger = logging.getLogger(__name__)
 
 
 def load_prompt_from_config(config: dict) -> BasePromptTemplate:
     """Load prompt from Config Dict."""
@@ -112,15 +112,15 @@
     # Load the template from disk if necessary.
     config = _load_template("template", config)
     config = _load_output_parser(config)
     return PromptTemplate(**config)
 
 
 def load_prompt(path: Union[str, Path]) -> BasePromptTemplate:
-    """Unified method for loading a prompt from LangChainHub or local fs."""
+    """Unified method for loading a prompt from oplangchainHub or local fs."""
     if hub_result := try_load_from_hub(
         path, _load_prompt_from_file, "prompts", {"py", "json", "yaml"}
     ):
         return hub_result
     else:
         return _load_prompt_from_file(path)
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/pipeline.py` & `oplangchain-0.1.1/oplangchain/prompts/pipeline.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, Tuple
 
 from pydantic import root_validator
 
-from langchain.prompts.chat import BaseChatPromptTemplate
-from langchain.schema import BasePromptTemplate, PromptValue
+from oplangchain.prompts.chat import BaseChatPromptTemplate
+from oplangchain.schema import BasePromptTemplate, PromptValue
 
 
 def _get_inputs(inputs: dict, input_variables: List[str]) -> dict:
     return {k: inputs[k] for k in input_variables}
 
 
 class PipelinePromptTemplate(BasePromptTemplate):
```

### Comparing `oplangchain-0.1.0/oplangchain/prompts/prompt.py` & `oplangchain-0.1.1/oplangchain/prompts/prompt.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 from pathlib import Path
 from string import Formatter
 from typing import Any, Dict, List, Optional, Union
 
 from pydantic import root_validator
 
-from langchain.prompts.base import (
+from oplangchain.prompts.base import (
     DEFAULT_FORMATTER_MAPPING,
     StringPromptTemplate,
     _get_jinja2_variables_from_template,
     check_valid_template,
 )
 
 
@@ -23,15 +23,15 @@
 
     The template can be formatted using either f-strings (default) or jinja2 syntax.
 
     Example:
 
         .. code-block:: python
 
-            from langchain import PromptTemplate
+            from oplangchain import PromptTemplate
 
             # Instantiation using from_template (recommended)
             prompt = PromptTemplate.from_template("Say {foo}")
             prompt.format(foo="bar")
 
             # Instantiation using initializer
             prompt = PromptTemplate(input_variables=["foo"], template="Say {foo}")
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/__init__.py` & `oplangchain-0.1.1/oplangchain/retrievers/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -14,52 +14,52 @@
 
 .. code-block::
 
     Document, Serializable, Callbacks,
     CallbackManagerForRetrieverRun, AsyncCallbackManagerForRetrieverRun
 """
 
-from langchain.retrievers.arxiv import ArxivRetriever
-from langchain.retrievers.azure_cognitive_search import AzureCognitiveSearchRetriever
-from langchain.retrievers.bm25 import BM25Retriever
-from langchain.retrievers.chaindesk import ChaindeskRetriever
-from langchain.retrievers.chatgpt_plugin_retriever import ChatGPTPluginRetriever
-from langchain.retrievers.contextual_compression import ContextualCompressionRetriever
-from langchain.retrievers.docarray import DocArrayRetriever
-from langchain.retrievers.elastic_search_bm25 import ElasticSearchBM25Retriever
-from langchain.retrievers.ensemble import EnsembleRetriever
-from langchain.retrievers.google_cloud_enterprise_search import (
+from oplangchain.retrievers.arxiv import ArxivRetriever
+from oplangchain.retrievers.azure_cognitive_search import AzureCognitiveSearchRetriever
+from oplangchain.retrievers.bm25 import BM25Retriever
+from oplangchain.retrievers.chaindesk import ChaindeskRetriever
+from oplangchain.retrievers.chatgpt_plugin_retriever import ChatGPTPluginRetriever
+from oplangchain.retrievers.contextual_compression import ContextualCompressionRetriever
+from oplangchain.retrievers.docarray import DocArrayRetriever
+from oplangchain.retrievers.elastic_search_bm25 import ElasticSearchBM25Retriever
+from oplangchain.retrievers.ensemble import EnsembleRetriever
+from oplangchain.retrievers.google_cloud_enterprise_search import (
     GoogleCloudEnterpriseSearchRetriever,
 )
-from langchain.retrievers.kendra import AmazonKendraRetriever
-from langchain.retrievers.knn import KNNRetriever
-from langchain.retrievers.llama_index import (
+from oplangchain.retrievers.kendra import AmazonKendraRetriever
+from oplangchain.retrievers.knn import KNNRetriever
+from oplangchain.retrievers.llama_index import (
     LlamaIndexGraphRetriever,
     LlamaIndexRetriever,
 )
-from langchain.retrievers.merger_retriever import MergerRetriever
-from langchain.retrievers.metal import MetalRetriever
-from langchain.retrievers.milvus import MilvusRetriever
-from langchain.retrievers.multi_query import MultiQueryRetriever
-from langchain.retrievers.pinecone_hybrid_search import PineconeHybridSearchRetriever
-from langchain.retrievers.pubmed import PubMedRetriever
-from langchain.retrievers.re_phraser import RePhraseQueryRetriever
-from langchain.retrievers.remote_retriever import RemoteLangChainRetriever
-from langchain.retrievers.self_query.base import SelfQueryRetriever
-from langchain.retrievers.svm import SVMRetriever
-from langchain.retrievers.tfidf import TFIDFRetriever
-from langchain.retrievers.time_weighted_retriever import (
+from oplangchain.retrievers.merger_retriever import MergerRetriever
+from oplangchain.retrievers.metal import MetalRetriever
+from oplangchain.retrievers.milvus import MilvusRetriever
+from oplangchain.retrievers.multi_query import MultiQueryRetriever
+from oplangchain.retrievers.pinecone_hybrid_search import PineconeHybridSearchRetriever
+from oplangchain.retrievers.pubmed import PubMedRetriever
+from oplangchain.retrievers.re_phraser import RePhraseQueryRetriever
+from oplangchain.retrievers.remote_retriever import RemoteLangChainRetriever
+from oplangchain.retrievers.self_query.base import SelfQueryRetriever
+from oplangchain.retrievers.svm import SVMRetriever
+from oplangchain.retrievers.tfidf import TFIDFRetriever
+from oplangchain.retrievers.time_weighted_retriever import (
     TimeWeightedVectorStoreRetriever,
 )
-from langchain.retrievers.vespa_retriever import VespaRetriever
-from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever
-from langchain.retrievers.web_research import WebResearchRetriever
-from langchain.retrievers.wikipedia import WikipediaRetriever
-from langchain.retrievers.zep import ZepRetriever
-from langchain.retrievers.zilliz import ZillizRetriever
+from oplangchain.retrievers.vespa_retriever import VespaRetriever
+from oplangchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever
+from oplangchain.retrievers.web_research import WebResearchRetriever
+from oplangchain.retrievers.wikipedia import WikipediaRetriever
+from oplangchain.retrievers.zep import ZepRetriever
+from oplangchain.retrievers.zilliz import ZillizRetriever
 
 __all__ = [
     "AmazonKendraRetriever",
     "ArxivRetriever",
     "AzureCognitiveSearchRetriever",
     "ChatGPTPluginRetriever",
     "ContextualCompressionRetriever",
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/arxiv.py` & `oplangchain-0.1.1/oplangchain/retrievers/pubmed.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 from typing import List
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
-from langchain.utilities.arxiv import ArxivAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.utilities.pupmed import PubMedAPIWrapper
 
 
-class ArxivRetriever(BaseRetriever, ArxivAPIWrapper):
-    """
-    Retriever for Arxiv.
+class PubMedRetriever(BaseRetriever, PubMedAPIWrapper):
+    """Retriever for PubMed API.
 
     It wraps load() to get_relevant_documents().
-    It uses all ArxivAPIWrapper arguments without any change.
+    It uses all PubMedAPIWrapper arguments without any change.
     """
 
     def _get_relevant_documents(
         self, query: str, *, run_manager: CallbackManagerForRetrieverRun
     ) -> List[Document]:
-        return self.load(query=query)
+        return self.load_docs(query=query)
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/azure_cognitive_search.py` & `oplangchain-0.1.1/oplangchain/retrievers/azure_cognitive_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,20 +5,20 @@
 import json
 from typing import Dict, List, Optional
 
 import aiohttp
 import requests
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
-from langchain.utils import get_from_dict_or_env
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.utils import get_from_dict_or_env
 
 
 class AzureCognitiveSearchRetriever(BaseRetriever):
     """Retriever for the Azure Cognitive Search service."""
 
     service_name: str = ""
     """Name of Azure Cognitive Search service"""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/bm25.py` & `oplangchain-0.1.1/oplangchain/retrievers/bm25.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,16 +3,16 @@
 """
 
 
 from __future__ import annotations
 
 from typing import Any, Callable, Dict, Iterable, List, Optional
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
 
 
 def default_preprocessing_func(text: str) -> List[str]:
     return text.split()
 
 
 class BM25Retriever(BaseRetriever):
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/chaindesk.py` & `oplangchain-0.1.1/oplangchain/retrievers/chaindesk.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import Any, List, Optional
 
 import aiohttp
 import requests
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class ChaindeskRetriever(BaseRetriever):
     """Retriever for the Chaindesk API."""
 
     datastore_url: str
     top_k: Optional[int]
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/chatgpt_plugin_retriever.py` & `oplangchain-0.1.1/oplangchain/retrievers/chatgpt_plugin_retriever.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import List, Optional
 
 import aiohttp
 import requests
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class ChatGPTPluginRetriever(BaseRetriever):
     """Retrieves documents from a ChatGPT plugin."""
 
     url: str
     """URL of the ChatGPT plugin."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/contextual_compression.py` & `oplangchain-0.1.1/oplangchain/retrievers/contextual_compression.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import Any, List
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.retrievers.document_compressors.base import (
+from oplangchain.retrievers.document_compressors.base import (
     BaseDocumentCompressor,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class ContextualCompressionRetriever(BaseRetriever):
     """Retriever that wraps a base retriever and compresses the results."""
 
     base_compressor: BaseDocumentCompressor
     """Compressor for compressing retrieved documents."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/databerry.py` & `oplangchain-0.1.1/oplangchain/retrievers/databerry.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import List, Optional
 
 import aiohttp
 import requests
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class DataberryRetriever(BaseRetriever):
     """Retriever for the Databerry API."""
 
     datastore_url: str
     top_k: Optional[int]
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/docarray.py` & `oplangchain-0.1.1/oplangchain/retrievers/docarray.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 from enum import Enum
 from typing import Any, Dict, List, Optional, Union
 
 import numpy as np
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 
 class SearchType(str, Enum):
     """Enumerator of the types of search to perform."""
 
     similarity = "similarity"
     mmr = "mmr"
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/__init__.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-from langchain.retrievers.document_compressors.base import DocumentCompressorPipeline
-from langchain.retrievers.document_compressors.chain_extract import (
+from oplangchain.retrievers.document_compressors.base import DocumentCompressorPipeline
+from oplangchain.retrievers.document_compressors.chain_extract import (
     LLMChainExtractor,
 )
-from langchain.retrievers.document_compressors.chain_filter import (
+from oplangchain.retrievers.document_compressors.chain_filter import (
     LLMChainFilter,
 )
-from langchain.retrievers.document_compressors.cohere_rerank import CohereRerank
-from langchain.retrievers.document_compressors.embeddings_filter import (
+from oplangchain.retrievers.document_compressors.cohere_rerank import CohereRerank
+from oplangchain.retrievers.document_compressors.embeddings_filter import (
     EmbeddingsFilter,
 )
 
 __all__ = [
     "DocumentCompressorPipeline",
     "EmbeddingsFilter",
     "LLMChainExtractor",
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/base.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Interface for retrieved document compressors."""
 from abc import ABC, abstractmethod
 from inspect import signature
 from typing import List, Optional, Sequence, Union
 
 from pydantic import BaseModel
 
-from langchain.callbacks.manager import Callbacks
-from langchain.schema import BaseDocumentTransformer, Document
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.schema import BaseDocumentTransformer, Document
 
 
 class BaseDocumentCompressor(BaseModel, ABC):
     """Base abstraction interface for document compression."""
 
     @abstractmethod
     def compress_documents(
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_extract.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_extract.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 """DocumentFilter that uses an LLM chain to extract the relevant parts of documents."""
 from __future__ import annotations
 
 import asyncio
 from typing import Any, Callable, Dict, Optional, Sequence
 
-from langchain import LLMChain, PromptTemplate
-from langchain.callbacks.manager import Callbacks
-from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
-from langchain.retrievers.document_compressors.chain_extract_prompt import (
+from oplangchain import LLMChain, PromptTemplate
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.retrievers.document_compressors.base import BaseDocumentCompressor
+from oplangchain.retrievers.document_compressors.chain_extract_prompt import (
     prompt_template,
 )
-from langchain.schema import BaseOutputParser, Document
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema import BaseOutputParser, Document
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def default_get_input(query: str, doc: Document) -> Dict[str, Any]:
     """Return the compression chain input."""
     return {"question": query, "context": doc.page_content}
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/chain_filter.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/chain_filter.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Filter that uses an LLM to drop documents that aren't relevant to the query."""
 from typing import Any, Callable, Dict, Optional, Sequence
 
-from langchain import LLMChain, PromptTemplate
-from langchain.callbacks.manager import Callbacks
-from langchain.output_parsers.boolean import BooleanOutputParser
-from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
-from langchain.retrievers.document_compressors.chain_filter_prompt import (
+from oplangchain import LLMChain, PromptTemplate
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.output_parsers.boolean import BooleanOutputParser
+from oplangchain.retrievers.document_compressors.base import BaseDocumentCompressor
+from oplangchain.retrievers.document_compressors.chain_filter_prompt import (
     prompt_template,
 )
-from langchain.schema import BasePromptTemplate, Document
-from langchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema import BasePromptTemplate, Document
+from oplangchain.schema.language_model import BaseLanguageModel
 
 
 def _get_default_chain_prompt() -> PromptTemplate:
     return PromptTemplate(
         template=prompt_template,
         input_variables=["question", "context"],
         output_parser=BooleanOutputParser(),
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/cohere_rerank.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/cohere_rerank.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Dict, Optional, Sequence
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
-from langchain.schema import Document
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.retrievers.document_compressors.base import BaseDocumentCompressor
+from oplangchain.schema import Document
+from oplangchain.utils import get_from_dict_or_env
 
 if TYPE_CHECKING:
     from cohere import Client
 else:
     # We do to avoid pydantic annotation issues when actually instantiating
     # while keeping this import optional
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/document_compressors/embeddings_filter.py` & `oplangchain-0.1.1/oplangchain/retrievers/document_compressors/embeddings_filter.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 from typing import Callable, Dict, Optional, Sequence
 
 import numpy as np
 from pydantic import root_validator
 
-from langchain.callbacks.manager import Callbacks
-from langchain.document_transformers.embeddings_redundant_filter import (
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.document_transformers.embeddings_redundant_filter import (
     _get_embeddings_from_stateful_docs,
     get_stateful_documents,
 )
-from langchain.embeddings.base import Embeddings
-from langchain.retrievers.document_compressors.base import (
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.retrievers.document_compressors.base import (
     BaseDocumentCompressor,
 )
-from langchain.schema import Document
-from langchain.utils.math import cosine_similarity
+from oplangchain.schema import Document
+from oplangchain.utils.math import cosine_similarity
 
 
 class EmbeddingsFilter(BaseDocumentCompressor):
     """Document compressor that uses embeddings to drop documents
     unrelated to the query."""
 
     embeddings: Embeddings
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/elastic_search_bm25.py` & `oplangchain-0.1.1/oplangchain/retrievers/elastic_search_bm25.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Wrapper around Elasticsearch vector database."""
 
 from __future__ import annotations
 
 import uuid
 from typing import Any, Iterable, List
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.docstore.document import Document
-from langchain.schema import BaseRetriever
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BaseRetriever
 
 
 class ElasticSearchBM25Retriever(BaseRetriever):
     """Retriever for the Elasticsearch using BM25 as a retrieval method.
 
     To connect to an Elasticsearch instance that requires login credentials,
     including Elastic Cloud, use the Elasticsearch URL format
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/ensemble.py` & `oplangchain-0.1.1/oplangchain/retrievers/ensemble.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,19 +2,19 @@
 Ensemble retriever that ensemble the results of 
 multiple retrievers by using weighted  Reciprocal Rank Fusion
 """
 from typing import Any, Dict, List
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class EnsembleRetriever(BaseRetriever):
     """
     This class ensemble the results of multiple retrievers by using rank fusion.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/google_cloud_enterprise_search.py` & `oplangchain-0.1.1/oplangchain/retrievers/google_cloud_enterprise_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Retriever wrapper for Google Cloud Enterprise Search on Gen App Builder."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence
 
 from pydantic import Extra, Field, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.utils import get_from_dict_or_env
 
 if TYPE_CHECKING:
     from google.cloud.discoveryengine_v1beta import (
         SearchRequest,
         SearchResult,
         SearchServiceClient,
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/kendra.py` & `oplangchain-0.1.1/oplangchain/retrievers/kendra.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import re
 from abc import ABC, abstractmethod
 from typing import Any, Callable, Dict, List, Literal, Optional, Sequence, Union
 
 from pydantic import BaseModel, Extra, root_validator, validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.docstore.document import Document
-from langchain.schema import BaseRetriever
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BaseRetriever
 
 
 def clean_excerpt(excerpt: str) -> str:
     """Cleans an excerpt from Kendra.
 
     Args:
         excerpt: The excerpt to clean.
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/knn.py` & `oplangchain-0.1.1/oplangchain/retrievers/knn.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 from __future__ import annotations
 
 import concurrent.futures
 from typing import Any, List, Optional
 
 import numpy as np
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
 
 
 def create_index(contexts: List[str], embeddings: Embeddings) -> np.ndarray:
     """
     Create an index of embeddings for a list of contexts.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/llama_index.py` & `oplangchain-0.1.1/oplangchain/retrievers/llama_index.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, Dict, List, cast
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
 
 
 class LlamaIndexRetriever(BaseRetriever):
     """Retriever for the question-answering with sources over
     an LlamaIndex data structure."""
 
     index: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/merger_retriever.py` & `oplangchain-0.1.1/oplangchain/retrievers/merger_retriever.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import List
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class MergerRetriever(BaseRetriever):
     """Retriever that merges the results of multiple retrievers."""
 
     retrievers: List[BaseRetriever]
     """A list of retrievers to merge."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/metal.py` & `oplangchain-0.1.1/oplangchain/retrievers/metal.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Any, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
 
 
 class MetalRetriever(BaseRetriever):
     """Retriever that uses the Metal API."""
 
     client: Any
     """The Metal client to use."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/milvus.py` & `oplangchain-0.1.1/oplangchain/retrievers/milvus.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Milvus Retriever"""
 import warnings
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
-from langchain.vectorstores.milvus import Milvus
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.vectorstores.milvus import Milvus
 
 # TODO: Update to MilvusClient + Hybrid Search when available
 
 
 class MilvusRetriever(BaseRetriever):
     """Retriever that uses the Milvus API."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/multi_query.py` & `oplangchain-0.1.1/oplangchain/retrievers/multi_query.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 import logging
 from typing import List
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.chains.llm import LLMChain
-from langchain.llms.base import BaseLLM
-from langchain.output_parsers.pydantic import PydanticOutputParser
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.base import BaseLLM
+from oplangchain.output_parsers.pydantic import PydanticOutputParser
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseRetriever, Document
 
 logger = logging.getLogger(__name__)
 
 
 class LineList(BaseModel):
     """List of lines."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/pinecone_hybrid_search.py` & `oplangchain-0.1.1/oplangchain/retrievers/pinecone_hybrid_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Taken from: https://docs.pinecone.io/docs/hybrid-search"""
 
 import hashlib
 from typing import Any, Dict, List, Optional
 
 from pydantic import Extra, root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
 
 
 def hash_text(text: str) -> str:
     """Hash a text using SHA256.
 
     Args:
         text: Text to hash.
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/pubmed.py` & `oplangchain-0.1.1/oplangchain/retrievers/wikipedia.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from typing import List
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
-from langchain.utilities.pupmed import PubMedAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
 
 
-class PubMedRetriever(BaseRetriever, PubMedAPIWrapper):
-    """Retriever for PubMed API.
+class WikipediaRetriever(BaseRetriever, WikipediaAPIWrapper):
+    """Retriever for Wikipedia API.
 
     It wraps load() to get_relevant_documents().
-    It uses all PubMedAPIWrapper arguments without any change.
+    It uses all WikipediaAPIWrapper arguments without any change.
     """
 
     def _get_relevant_documents(
         self, query: str, *, run_manager: CallbackManagerForRetrieverRun
     ) -> List[Document]:
-        return self.load_docs(query=query)
+        return self.load(query=query)
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/re_phraser.py` & `oplangchain-0.1.1/oplangchain/retrievers/re_phraser.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 import logging
 from typing import List
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.chains.llm import LLMChain
-from langchain.llms.base import BaseLLM
-from langchain.prompts.prompt import PromptTemplate
-from langchain.schema import BaseRetriever, Document
+from oplangchain.chains.llm import LLMChain
+from oplangchain.llms.base import BaseLLM
+from oplangchain.prompts.prompt import PromptTemplate
+from oplangchain.schema import BaseRetriever, Document
 
 logger = logging.getLogger(__name__)
 
 # Default template
 DEFAULT_TEMPLATE = """You are an assistant tasked with taking a natural language \
 query from a user and converting it into a query for a vectorstore. \
 In this process, you strip out information that is not relevant for \
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/remote_retriever.py` & `oplangchain-0.1.1/oplangchain/retrievers/remote_retriever.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from typing import List, Optional
 
 import aiohttp
 import requests
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 
 class RemoteLangChainRetriever(BaseRetriever):
     """Retriever for remote LangChain API."""
 
     url: str
     """URL of the remote LangChain API."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/base.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Retriever that generates and executes structured queries over its own data source."""
 
 from typing import Any, Dict, List, Optional, Type, cast
 
 from pydantic import BaseModel, Field, root_validator
 
-from langchain import LLMChain
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.chains.query_constructor.base import load_query_constructor_chain
-from langchain.chains.query_constructor.ir import StructuredQuery, Visitor
-from langchain.chains.query_constructor.schema import AttributeInfo
-from langchain.retrievers.self_query.chroma import ChromaTranslator
-from langchain.retrievers.self_query.deeplake import DeepLakeTranslator
-from langchain.retrievers.self_query.myscale import MyScaleTranslator
-from langchain.retrievers.self_query.pinecone import PineconeTranslator
-from langchain.retrievers.self_query.qdrant import QdrantTranslator
-from langchain.retrievers.self_query.weaviate import WeaviateTranslator
-from langchain.schema import BaseRetriever, Document
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.vectorstores import (
+from oplangchain import LLMChain
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.chains.query_constructor.base import load_query_constructor_chain
+from oplangchain.chains.query_constructor.ir import StructuredQuery, Visitor
+from oplangchain.chains.query_constructor.schema import AttributeInfo
+from oplangchain.retrievers.self_query.chroma import ChromaTranslator
+from oplangchain.retrievers.self_query.deeplake import DeepLakeTranslator
+from oplangchain.retrievers.self_query.myscale import MyScaleTranslator
+from oplangchain.retrievers.self_query.pinecone import PineconeTranslator
+from oplangchain.retrievers.self_query.qdrant import QdrantTranslator
+from oplangchain.retrievers.self_query.weaviate import WeaviateTranslator
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.vectorstores import (
     Chroma,
     DeepLake,
     MyScale,
     Pinecone,
     Qdrant,
     VectorStore,
     Weaviate,
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/chroma.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/chroma.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Dict, Tuple, Union
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/deeplake.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/deeplake.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Logic for converting internal query language to a valid Chroma query."""
 from typing import Tuple, Union
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/myscale.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/myscale.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import datetime
 import re
 from typing import Any, Callable, Dict, Tuple
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/pinecone.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/pinecone.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Dict, Tuple, Union
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/qdrant.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/qdrant.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Tuple
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/self_query/weaviate.py` & `oplangchain-0.1.1/oplangchain/retrievers/self_query/weaviate.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Dict, Tuple, Union
 
-from langchain.chains.query_constructor.ir import (
+from oplangchain.chains.query_constructor.ir import (
     Comparator,
     Comparison,
     Operation,
     Operator,
     StructuredQuery,
     Visitor,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/svm.py` & `oplangchain-0.1.1/oplangchain/retrievers/svm.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 import concurrent.futures
 from typing import Any, Iterable, List, Optional
 
 import numpy as np
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
 
 
 def create_index(contexts: List[str], embeddings: Embeddings) -> np.ndarray:
     """
     Create an index of embeddings for a list of contexts.
 
     Args:
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/tfidf.py` & `oplangchain-0.1.1/oplangchain/retrievers/tfidf.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 import pickle
 from pathlib import Path
 from typing import Any, Dict, Iterable, List, Optional
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
 
 
 class TFIDFRetriever(BaseRetriever):
     """TF-IDF Retriever.
 
     Largely based on
     https://github.com/asvskartheek/Text-Retrieval/blob/master/TF-IDF%20Search%20Engine%20(SKLEARN).ipynb
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/time_weighted_retriever.py` & `oplangchain-0.1.1/oplangchain/retrievers/time_weighted_retriever.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import datetime
 from copy import deepcopy
 from typing import Any, Dict, List, Optional, Tuple
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
-from langchain.vectorstores.base import VectorStore
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.vectorstores.base import VectorStore
 
 
 def _get_hours_passed(time: datetime.datetime, ref_time: datetime.datetime) -> float:
     """Get the hours passed between two datetime objects."""
     return (time - ref_time).total_seconds() / 3600
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/vespa_retriever.py` & `oplangchain-0.1.1/oplangchain/retrievers/vespa_retriever.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 import json
 from typing import TYPE_CHECKING, Any, Dict, List, Literal, Optional, Sequence, Union
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
 
 if TYPE_CHECKING:
     from vespa.application import Vespa
 
 
 class VespaRetriever(BaseRetriever):
     """Retriever that uses Vespa."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/weaviate_hybrid_search.py` & `oplangchain-0.1.1/oplangchain/retrievers/weaviate_hybrid_search.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 from typing import Any, Dict, List, Optional, cast
 from uuid import uuid4
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.docstore.document import Document
-from langchain.schema import BaseRetriever
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BaseRetriever
 
 
 class WeaviateHybridSearchRetriever(BaseRetriever):
     """Retriever for the Weaviate's hybrid search."""
 
     client: Any
     """keyword arguments to pass to the Weaviate client."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/web_research.py` & `oplangchain-0.1.1/oplangchain/retrievers/web_research.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 import logging
 import re
 from typing import List, Optional
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.chains import LLMChain
-from langchain.chains.prompt_selector import ConditionalPromptSelector
-from langchain.document_loaders import AsyncHtmlLoader
-from langchain.document_transformers import Html2TextTransformer
-from langchain.llms import LlamaCpp
-from langchain.llms.base import BaseLLM
-from langchain.output_parsers.pydantic import PydanticOutputParser
-from langchain.prompts import BasePromptTemplate, PromptTemplate
-from langchain.schema import BaseRetriever, Document
-from langchain.text_splitter import RecursiveCharacterTextSplitter
-from langchain.utilities import GoogleSearchAPIWrapper
-from langchain.vectorstores.base import VectorStore
+from oplangchain.chains import LLMChain
+from oplangchain.chains.prompt_selector import ConditionalPromptSelector
+from oplangchain.document_loaders import AsyncHtmlLoader
+from oplangchain.document_transformers import Html2TextTransformer
+from oplangchain.llms import LlamaCpp
+from oplangchain.llms.base import BaseLLM
+from oplangchain.output_parsers.pydantic import PydanticOutputParser
+from oplangchain.prompts import BasePromptTemplate, PromptTemplate
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.text_splitter import RecursiveCharacterTextSplitter
+from oplangchain.utilities import GoogleSearchAPIWrapper
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger(__name__)
 
 
 class SearchQueries(BaseModel):
     """Search queries to run to research for the user's goal."""
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/wikipedia.py` & `oplangchain-0.1.1/oplangchain/retrievers/arxiv.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,19 @@
 from typing import List
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.schema import BaseRetriever, Document
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.utilities.arxiv import ArxivAPIWrapper
 
 
-class WikipediaRetriever(BaseRetriever, WikipediaAPIWrapper):
-    """Retriever for Wikipedia API.
+class ArxivRetriever(BaseRetriever, ArxivAPIWrapper):
+    """
+    Retriever for Arxiv.
 
     It wraps load() to get_relevant_documents().
-    It uses all WikipediaAPIWrapper arguments without any change.
+    It uses all ArxivAPIWrapper arguments without any change.
     """
 
     def _get_relevant_documents(
         self, query: str, *, run_manager: CallbackManagerForRetrieverRun
     ) -> List[Document]:
         return self.load(query=query)
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/zep.py` & `oplangchain-0.1.1/oplangchain/retrievers/zep.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.schema import BaseRetriever, Document
+from oplangchain.schema import BaseRetriever, Document
 
 if TYPE_CHECKING:
     from zep_python import MemorySearchResult
 
 
 class ZepRetriever(BaseRetriever):
     """Retriever for the Zep long-term memory store.
```

### Comparing `oplangchain-0.1.0/oplangchain/retrievers/zilliz.py` & `oplangchain-0.1.1/oplangchain/retrievers/zilliz.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import warnings
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForRetrieverRun
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever, Document
-from langchain.vectorstores.zilliz import Zilliz
+from oplangchain.callbacks.manager import CallbackManagerForRetrieverRun
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever, Document
+from oplangchain.vectorstores.zilliz import Zilliz
 
 # TODO: Update to ZillizClient + Hybrid Search when available
 
 
 class ZillizRetriever(BaseRetriever):
     """Retriever for the Zilliz API."""
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/__init__.py` & `oplangchain-0.1.1/oplangchain/schema/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,40 +1,40 @@
 """**Schemas** are the LangChain Base Classes and Interfaces."""
-from langchain.schema.agent import AgentAction, AgentFinish
-from langchain.schema.document import BaseDocumentTransformer, Document
-from langchain.schema.memory import BaseChatMessageHistory, BaseMemory
-from langchain.schema.messages import (
+from oplangchain.schema.agent import AgentAction, AgentFinish
+from oplangchain.schema.document import BaseDocumentTransformer, Document
+from oplangchain.schema.memory import BaseChatMessageHistory, BaseMemory
+from oplangchain.schema.messages import (
     AIMessage,
     BaseMessage,
     ChatMessage,
     FunctionMessage,
     HumanMessage,
     SystemMessage,
     _message_from_dict,
     _message_to_dict,
     get_buffer_string,
     messages_from_dict,
     messages_to_dict,
 )
-from langchain.schema.output import (
+from oplangchain.schema.output import (
     ChatGeneration,
     ChatResult,
     Generation,
     LLMResult,
     RunInfo,
 )
-from langchain.schema.output_parser import (
+from oplangchain.schema.output_parser import (
     BaseLLMOutputParser,
     BaseOutputParser,
     OutputParserException,
     StrOutputParser,
 )
-from langchain.schema.prompt import PromptValue
-from langchain.schema.prompt_template import BasePromptTemplate, format_document
-from langchain.schema.retriever import BaseRetriever
+from oplangchain.schema.prompt import PromptValue
+from oplangchain.schema.prompt_template import BasePromptTemplate, format_document
+from oplangchain.schema.retriever import BaseRetriever
 
 RUN_KEY = "__run"
 Memory = BaseMemory
 
 __all__ = [
     "BaseMemory",
     "BaseChatMessageHistory",
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/agent.py` & `oplangchain-0.1.1/oplangchain/schema/agent.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/schema/document.py` & `oplangchain-0.1.1/oplangchain/schema/document.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from typing import Any, Sequence
 
 from pydantic import Field
 
-from langchain.load.serializable import Serializable
+from oplangchain.load.serializable import Serializable
 
 
 class Document(Serializable):
     """Class for storing a piece of text and associated metadata."""
 
     page_content: str
     """String text."""
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/language_model.py` & `oplangchain-0.1.1/oplangchain/schema/language_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,23 +8,23 @@
     Optional,
     Sequence,
     Set,
     TypeVar,
     Union,
 )
 
-from langchain.load.serializable import Serializable
-from langchain.schema.messages import BaseMessage, get_buffer_string
-from langchain.schema.output import LLMResult
-from langchain.schema.prompt import PromptValue
-from langchain.schema.runnable import Runnable
-from langchain.utils import get_pydantic_field_names
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.schema.output import LLMResult
+from oplangchain.schema.prompt import PromptValue
+from oplangchain.schema.runnable import Runnable
+from oplangchain.utils import get_pydantic_field_names
 
 if TYPE_CHECKING:
-    from langchain.callbacks.manager import Callbacks
+    from oplangchain.callbacks.manager import Callbacks
 
 
 def _get_token_ids_default_method(text: str) -> List[int]:
     """Encode the text into token IDs."""
     # TODO: this method may not be exact.
     # TODO: this method may differ based on model (eg codex).
     try:
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/memory.py` & `oplangchain-0.1.1/oplangchain/schema/memory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from typing import Any, Dict, List
 
-from langchain.load.serializable import Serializable
-from langchain.schema.messages import AIMessage, BaseMessage, HumanMessage
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.messages import AIMessage, BaseMessage, HumanMessage
 
 
 class BaseMemory(Serializable, ABC):
     """Abstract base class for memory in Chains.
 
     Memory refers to state in Chains. Memory can be used to store information about
         past executions of a Chain and inject that information into the inputs of
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/messages.py` & `oplangchain-0.1.1/oplangchain/schema/messages.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from abc import abstractmethod
 from typing import TYPE_CHECKING, Any, Dict, List, Sequence
 
 from pydantic import Field
 
-from langchain.load.serializable import Serializable
+from oplangchain.load.serializable import Serializable
 
 if TYPE_CHECKING:
-    from langchain.prompts.chat import ChatPromptTemplate
+    from oplangchain.prompts.chat import ChatPromptTemplate
 
 
 def get_buffer_string(
     messages: Sequence[BaseMessage], human_prefix: str = "Human", ai_prefix: str = "AI"
 ) -> str:
     """Convert sequence of Messages to strings and concatenate them into one string.
 
@@ -23,15 +23,15 @@
 
     Returns:
         A single string concatenation of all input messages.
 
     Example:
         .. code-block:: python
 
-            from langchain.schema import AIMessage, HumanMessage
+            from oplangchain.schema import AIMessage, HumanMessage
 
             messages = [
                 HumanMessage(content="Hi, how are you?"),
                 AIMessage(content="Good, how are you?"),
             ]
             get_buffer_string(messages)
             # -> "Human: Hi, how are you?\nAI: Good, how are you?"
@@ -77,15 +77,15 @@
 
     @property
     def lc_serializable(self) -> bool:
         """Whether this class is LangChain serializable."""
         return True
 
     def __add__(self, other: Any) -> ChatPromptTemplate:
-        from langchain.prompts.chat import ChatPromptTemplate
+        from oplangchain.prompts.chat import ChatPromptTemplate
 
         prompt = ChatPromptTemplate(messages=[self])
         return prompt + other
 
 
 class BaseMessageChunk(BaseMessage):
     def _merge_kwargs_dict(
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/output.py` & `oplangchain-0.1.1/oplangchain/schema/output.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 
 from copy import deepcopy
 from typing import Any, Dict, List, Optional
 from uuid import UUID
 
 from pydantic import BaseModel, root_validator
 
-from langchain.load.serializable import Serializable
-from langchain.schema.messages import BaseMessage, BaseMessageChunk
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.messages import BaseMessage, BaseMessageChunk
 
 
 class Generation(Serializable):
     """A single text generation output."""
 
     text: str
     """Generated text output."""
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/output_parser.py` & `oplangchain-0.1.1/oplangchain/schema/output_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from typing import Any, Dict, Generic, List, Optional, TypeVar, Union
 
-from langchain.load.serializable import Serializable
-from langchain.schema.messages import BaseMessage
-from langchain.schema.output import ChatGeneration, Generation
-from langchain.schema.prompt import PromptValue
-from langchain.schema.runnable import Runnable, RunnableConfig
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.messages import BaseMessage
+from oplangchain.schema.output import ChatGeneration, Generation
+from oplangchain.schema.prompt import PromptValue
+from oplangchain.schema.runnable import Runnable, RunnableConfig
 
 T = TypeVar("T")
 
 
 class BaseLLMOutputParser(Serializable, Generic[T], ABC):
     """Abstract base class for parsing the outputs of a model."""
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/prompt.py` & `oplangchain-0.1.1/oplangchain/schema/prompt.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from abc import ABC, abstractmethod
 from typing import List
 
-from langchain.load.serializable import Serializable
-from langchain.schema.messages import BaseMessage
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.messages import BaseMessage
 
 
 class PromptValue(Serializable, ABC):
     """Base abstract class for inputs to any language model.
 
     PromptValues can be converted to both LLM (pure text-generation) inputs and
         ChatModel inputs.
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/prompt_template.py` & `oplangchain-0.1.1/oplangchain/schema/prompt_template.py`

 * *Files 6% similar despite different names*

```diff
@@ -4,19 +4,19 @@
 from abc import ABC, abstractmethod
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Mapping, Optional, Union
 
 import yaml
 from pydantic import Field, root_validator
 
-from langchain.load.serializable import Serializable
-from langchain.schema.document import Document
-from langchain.schema.output_parser import BaseOutputParser
-from langchain.schema.prompt import PromptValue
-from langchain.schema.runnable import Runnable, RunnableConfig
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.document import Document
+from oplangchain.schema.output_parser import BaseOutputParser
+from oplangchain.schema.prompt import PromptValue
+from oplangchain.schema.runnable import Runnable, RunnableConfig
 
 
 class BasePromptTemplate(Serializable, Runnable[Dict, PromptValue], ABC):
     """Base class for all prompt templates, returning a prompt."""
 
     input_variables: List[str]
     """A list of the names of the variables the prompt template expects."""
@@ -172,16 +172,16 @@
 
     Returns:
         string of the document formatted.
 
     Example:
         .. code-block:: python
 
-            from langchain.schema import Document
-            from langchain.prompts import PromptTemplate
+            from oplangchain.schema import Document
+            from oplangchain.prompts import PromptTemplate
             doc = Document(page_content="This is a joke", metadata={"page": "1"})
             prompt = PromptTemplate.from_template("Page {page}: {page_content}")
             format_document(doc, prompt)
             >>> "Page 1: This is a joke"
     """
     base_info = {"page_content": doc.page_content, **doc.metadata}
     missing_metadata = set(prompt.input_variables).difference(base_info)
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/retriever.py` & `oplangchain-0.1.1/oplangchain/schema/retriever.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
 import warnings
 from abc import ABC, abstractmethod
 from inspect import signature
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
-from langchain.load.dump import dumpd
-from langchain.load.serializable import Serializable
-from langchain.schema.document import Document
-from langchain.schema.runnable import Runnable, RunnableConfig
+from oplangchain.load.dump import dumpd
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema.document import Document
+from oplangchain.schema.runnable import Runnable, RunnableConfig
 
 if TYPE_CHECKING:
-    from langchain.callbacks.manager import (
+    from oplangchain.callbacks.manager import (
         AsyncCallbackManagerForRetrieverRun,
         CallbackManagerForRetrieverRun,
         Callbacks,
     )
 
 
 class BaseRetriever(Serializable, Runnable[str, List[Document]], ABC):
@@ -160,15 +160,15 @@
                 and passed as arguments to the handlers defined in `callbacks`.
             metadata: Optional metadata associated with the retriever. Defaults to None
                 This metadata will be associated with each call to this retriever,
                 and passed as arguments to the handlers defined in `callbacks`.
         Returns:
             List of relevant documents
         """
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         callback_manager = CallbackManager.configure(
             callbacks,
             None,
             verbose=kwargs.get("verbose", False),
             inheritable_tags=tags,
             local_tags=self.tags,
@@ -216,15 +216,15 @@
                 and passed as arguments to the handlers defined in `callbacks`.
             metadata: Optional metadata associated with the retriever. Defaults to None
                 This metadata will be associated with each call to this retriever,
                 and passed as arguments to the handlers defined in `callbacks`.
         Returns:
             List of relevant documents
         """
-        from langchain.callbacks.manager import AsyncCallbackManager
+        from oplangchain.callbacks.manager import AsyncCallbackManager
 
         callback_manager = AsyncCallbackManager.configure(
             callbacks,
             None,
             verbose=kwargs.get("verbose", False),
             inheritable_tags=tags,
             local_tags=self.tags,
```

### Comparing `oplangchain-0.1.0/oplangchain/schema/runnable.py` & `oplangchain-0.1.1/oplangchain/schema/runnable.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,17 +21,17 @@
     TypeVar,
     Union,
     cast,
 )
 
 from pydantic import Field
 
-from langchain.callbacks.base import BaseCallbackManager, Callbacks
-from langchain.load.dump import dumpd
-from langchain.load.serializable import Serializable
+from oplangchain.callbacks.base import BaseCallbackManager, Callbacks
+from oplangchain.load.dump import dumpd
+from oplangchain.load.serializable import Serializable
 
 
 async def _gated_coro(semaphore: asyncio.Semaphore, coro: Coroutine) -> Any:
     async with semaphore:
         return await coro
 
 
@@ -164,15 +164,15 @@
     def _call_with_config(
         self,
         func: Callable[[Input], Output],
         input: Input,
         config: Optional[RunnableConfig],
         run_type: Optional[str] = None,
     ) -> Output:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         config = config or {}
         callback_manager = CallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             inheritable_tags=config.get("tags"),
             inheritable_metadata=config.get("metadata"),
         )
@@ -215,15 +215,15 @@
 
     @property
     def runnables(self) -> Iterator[Runnable[Input, Output]]:
         yield self.runnable
         yield from self.fallbacks
 
     def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -> Output:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = CallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -258,15 +258,15 @@
             raise ValueError("No error stored at end of fallbacks.")
         run_manager.on_chain_error(first_error)
         raise first_error
 
     async def ainvoke(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> Output:
-        from langchain.callbacks.manager import AsyncCallbackManager
+        from oplangchain.callbacks.manager import AsyncCallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = AsyncCallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -306,15 +306,15 @@
     def batch(
         self,
         inputs: List[Input],
         config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
         *,
         max_concurrency: Optional[int] = None,
     ) -> List[Output]:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         configs = self._get_config_list(config, len(inputs))
         callback_managers = [
             CallbackManager.configure(
                 inheritable_callbacks=config.get("callbacks"),
                 local_callbacks=None,
@@ -368,15 +368,15 @@
     async def abatch(
         self,
         inputs: List[Input],
         config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
         *,
         max_concurrency: Optional[int] = None,
     ) -> List[Output]:
-        from langchain.callbacks.manager import (
+        from oplangchain.callbacks.manager import (
             AsyncCallbackManager,
             AsyncCallbackManagerForChainRun,
         )
 
         # setup callbacks
         configs = self._get_config_list(config, len(inputs))
         callback_managers = [
@@ -489,15 +489,15 @@
             return RunnableSequence(
                 first=_coerce_to_runnable(other),
                 middle=[self.first] + self.middle,
                 last=self.last,
             )
 
     def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -> Output:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = CallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -528,15 +528,15 @@
                 input if isinstance(input, dict) else {"output": input}
             )
             return cast(Output, input)
 
     async def ainvoke(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> Output:
-        from langchain.callbacks.manager import AsyncCallbackManager
+        from oplangchain.callbacks.manager import AsyncCallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = AsyncCallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -571,15 +571,15 @@
     def batch(
         self,
         inputs: List[Input],
         config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
         *,
         max_concurrency: Optional[int] = None,
     ) -> List[Output]:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         configs = self._get_config_list(config, len(inputs))
         callback_managers = [
             CallbackManager.configure(
                 inheritable_callbacks=config.get("callbacks"),
                 local_callbacks=None,
@@ -624,15 +624,15 @@
     async def abatch(
         self,
         inputs: List[Input],
         config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,
         *,
         max_concurrency: Optional[int] = None,
     ) -> List[Output]:
-        from langchain.callbacks.manager import (
+        from oplangchain.callbacks.manager import (
             AsyncCallbackManager,
             AsyncCallbackManagerForChainRun,
         )
 
         # setup callbacks
         configs = self._get_config_list(config, len(inputs))
         callback_managers = [
@@ -684,15 +684,15 @@
                 )
             )
             return cast(List[Output], inputs)
 
     def stream(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> Iterator[Output]:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = CallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -747,15 +747,15 @@
             run_manager.on_chain_end(
                 final if isinstance(final, dict) else {"output": final}
             )
 
     async def astream(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> AsyncIterator[Output]:
-        from langchain.callbacks.manager import AsyncCallbackManager
+        from oplangchain.callbacks.manager import AsyncCallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = AsyncCallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -836,15 +836,15 @@
 
     class Config:
         arbitrary_types_allowed = True
 
     def invoke(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> Dict[str, Any]:
-        from langchain.callbacks.manager import CallbackManager
+        from oplangchain.callbacks.manager import CallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = CallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
@@ -878,15 +878,15 @@
         else:
             run_manager.on_chain_end(output)
             return output
 
     async def ainvoke(
         self, input: Input, config: Optional[RunnableConfig] = None
     ) -> Dict[str, Any]:
-        from langchain.callbacks.manager import AsyncCallbackManager
+        from oplangchain.callbacks.manager import AsyncCallbackManager
 
         # setup callbacks
         config = config or {}
         callback_manager = AsyncCallbackManager.configure(
             inheritable_callbacks=config.get("callbacks"),
             local_callbacks=None,
             verbose=False,
```

### Comparing `oplangchain-0.1.0/oplangchain/server.py` & `oplangchain-0.1.1/oplangchain/server.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/smith/__init__.py` & `oplangchain-0.1.1/oplangchain/smith/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 
 LangSmith helps you evaluate Chains and other language model application components using a number of LangChain evaluators.
 An example of this is shown below, assuming you've created a LangSmith dataset called ``<my_dataset_name>``:
 
 .. code-block:: python
 
     from langsmith import Client
-    from langchain.chat_models import ChatOpenAI
-    from langchain.chains import LLMChain
-    from langchain.smith import RunEvalConfig, run_on_dataset
+    from oplangchain.chat_models import ChatOpenAI
+    from oplangchain.chains import LLMChain
+    from oplangchain.smith import RunEvalConfig, run_on_dataset
 
     # Chains may have memory. Passing in a constructor function lets the
     # evaluation framework avoid cross-contamination between runs.
     def construct_chain():
         llm = ChatOpenAI(temperature=0)
         chain = LLMChain.from_string(
             llm,
@@ -47,15 +47,15 @@
 You can also create custom evaluators by subclassing the
 :class:`StringEvaluator <langchain.evaluation.schema.StringEvaluator>`
 or LangSmith's `RunEvaluator` classes.
 
 .. code-block:: python
 
     from typing import Optional
-    from langchain.evaluation import StringEvaluator
+    from oplangchain.evaluation import StringEvaluator
 
     class MyStringEvaluator(StringEvaluator):
         
         @property
         def requires_input(self) -> bool:
             return False
         
@@ -84,15 +84,15 @@
 
 **Primary Functions**
 
 - :func:`arun_on_dataset <langchain.smith.evaluation.runner_utils.arun_on_dataset>`: Asynchronous function to evaluate a chain, agent, or other LangChain component over a dataset.
 - :func:`run_on_dataset <langchain.smith.evaluation.runner_utils.run_on_dataset>`: Function to evaluate a chain, agent, or other LangChain component over a dataset.
 - :class:`RunEvalConfig <langchain.smith.evaluation.config.RunEvalConfig>`: Class representing the configuration for running evaluation. You can select evaluators by :class:`EvaluatorType <langchain.evaluation.schema.EvaluatorType>` or config, or you can pass in `custom_evaluators`
 """  # noqa: E501
-from langchain.smith.evaluation import (
+from oplangchain.smith.evaluation import (
     RunEvalConfig,
     arun_on_dataset,
     run_on_dataset,
 )
 
 __all__ = [
     "arun_on_dataset",
```

### Comparing `oplangchain-0.1.0/oplangchain/smith/evaluation/__init__.py` & `oplangchain-0.1.1/oplangchain/smith/evaluation/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 For more information on the LangSmith API, see the `LangSmith API documentation <https://docs.smith.langchain.com/docs/>`_.
 
 **Example**
 
 .. code-block:: python
 
     from langsmith import Client
-    from langchain.chat_models import ChatOpenAI
-    from langchain.chains import LLMChain
-    from langchain.smith import EvaluatorType, RunEvalConfig, run_on_dataset
+    from oplangchain.chat_models import ChatOpenAI
+    from oplangchain.chains import LLMChain
+    from oplangchain.smith import EvaluatorType, RunEvalConfig, run_on_dataset
 
     def construct_chain():
         llm = ChatOpenAI(temperature=0)
         chain = LLMChain.from_string(
             llm,
             "What's the answer to {your_input_key}"
         )
@@ -48,21 +48,21 @@
 - ``RunEvalConfig``: Class representing the configuration for running evaluation.
 - ``StringRunEvaluatorChain``: Class representing a string run evaluator chain.
 - ``InputFormatError``: Exception raised when the input format is incorrect.
 
 """  # noqa: E501
 
 
-from langchain.smith.evaluation.config import RunEvalConfig
-from langchain.smith.evaluation.runner_utils import (
+from oplangchain.smith.evaluation.config import RunEvalConfig
+from oplangchain.smith.evaluation.runner_utils import (
     InputFormatError,
     arun_on_dataset,
     run_on_dataset,
 )
-from langchain.smith.evaluation.string_run_evaluator import StringRunEvaluatorChain
+from oplangchain.smith.evaluation.string_run_evaluator import StringRunEvaluatorChain
 
 __all__ = [
     "InputFormatError",
     "arun_on_dataset",
     "run_on_dataset",
     "StringRunEvaluatorChain",
     "RunEvalConfig",
```

### Comparing `oplangchain-0.1.0/oplangchain/smith/evaluation/config.py` & `oplangchain-0.1.1/oplangchain/smith/evaluation/config.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """Configuration for run evaluators."""
 
 from typing import Any, Dict, List, Optional, Union
 
 from langsmith import RunEvaluator
 from pydantic import BaseModel, Field
 
-from langchain.embeddings.base import Embeddings
-from langchain.evaluation.criteria.eval_chain import CRITERIA_TYPE
-from langchain.evaluation.embedding_distance.base import (
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.evaluation.criteria.eval_chain import CRITERIA_TYPE
+from oplangchain.evaluation.embedding_distance.base import (
     EmbeddingDistance as EmbeddingDistanceEnum,
 )
-from langchain.evaluation.schema import EvaluatorType, StringEvaluator
-from langchain.evaluation.string_distance.base import (
+from oplangchain.evaluation.schema import EvaluatorType, StringEvaluator
+from oplangchain.evaluation.string_distance.base import (
     StringDistance as StringDistanceEnum,
 )
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.prompt_template import BasePromptTemplate
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.prompt_template import BasePromptTemplate
 
 
 class EvalConfig(BaseModel):
     """Configuration for a given run evaluator.
 
     Parameters
     ----------
```

### Comparing `oplangchain-0.1.0/oplangchain/smith/evaluation/runner_utils.py` & `oplangchain-0.1.1/oplangchain/smith/evaluation/runner_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,29 +23,29 @@
     cast,
 )
 from urllib.parse import urlparse, urlunparse
 
 from langsmith import Client, RunEvaluator
 from langsmith.schemas import Dataset, DataType, Example
 
-from langchain.callbacks.base import BaseCallbackHandler
-from langchain.callbacks.manager import Callbacks
-from langchain.callbacks.tracers.base import BaseTracer
-from langchain.callbacks.tracers.evaluation import EvaluatorCallbackHandler
-from langchain.callbacks.tracers.langchain import LangChainTracer
-from langchain.chains.base import Chain
-from langchain.chat_models.openai import ChatOpenAI
-from langchain.evaluation.loading import load_evaluator
-from langchain.evaluation.schema import EvaluatorType, StringEvaluator
-from langchain.schema import ChatResult, LLMResult
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.schema.messages import BaseMessage, messages_from_dict
-from langchain.schema.runnable import Runnable, RunnableConfig, RunnableLambda
-from langchain.smith.evaluation.config import EvalConfig, RunEvalConfig
-from langchain.smith.evaluation.string_run_evaluator import StringRunEvaluatorChain
+from oplangchain.callbacks.base import BaseCallbackHandler
+from oplangchain.callbacks.manager import Callbacks
+from oplangchain.callbacks.tracers.base import BaseTracer
+from oplangchain.callbacks.tracers.evaluation import EvaluatorCallbackHandler
+from oplangchain.callbacks.tracers.langchain import LangChainTracer
+from oplangchain.chains.base import Chain
+from oplangchain.chat_models.openai import ChatOpenAI
+from oplangchain.evaluation.loading import load_evaluator
+from oplangchain.evaluation.schema import EvaluatorType, StringEvaluator
+from oplangchain.schema import ChatResult, LLMResult
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.schema.messages import BaseMessage, messages_from_dict
+from oplangchain.schema.runnable import Runnable, RunnableConfig, RunnableLambda
+from oplangchain.smith.evaluation.config import EvalConfig, RunEvalConfig
+from oplangchain.smith.evaluation.string_run_evaluator import StringRunEvaluatorChain
 
 logger = logging.getLogger(__name__)
 
 MODEL_OR_CHAIN_FACTORY = Union[
     Callable[[], Union[Chain, Runnable]],
     BaseLanguageModel,
     Callable[[dict], Any],
@@ -1180,17 +1180,17 @@
 
     Examples
     --------
 
     .. code-block:: python
 
         from langsmith import Client
-        from langchain.chat_models import ChatOpenAI
-        from langchain.chains import LLMChain
-        from langchain.smith import RunEvalConfig, arun_on_dataset
+        from oplangchain.chat_models import ChatOpenAI
+        from oplangchain.chains import LLMChain
+        from oplangchain.smith import RunEvalConfig, arun_on_dataset
 
         # Chains may have memory. Passing in a constructor function lets the
         # evaluation framework avoid cross-contamination between runs.
         def construct_chain():
             llm = ChatOpenAI(temperature=0)
             chain = LLMChain.from_string(
                 llm,
@@ -1221,15 +1221,15 @@
     You can also create custom evaluators by subclassing the
     :class:`StringEvaluator <langchain.evaluation.schema.StringEvaluator>`
     or LangSmith's `RunEvaluator` classes.
 
     .. code-block:: python
 
         from typing import Optional
-        from langchain.evaluation import StringEvaluator
+        from oplangchain.evaluation import StringEvaluator
 
         class MyStringEvaluator(StringEvaluator):
 
             @property
             def requires_input(self) -> bool:
                 return False
 
@@ -1324,17 +1324,17 @@
 
     Examples
     --------
 
     .. code-block:: python
 
         from langsmith import Client
-        from langchain.chat_models import ChatOpenAI
-        from langchain.chains import LLMChain
-        from langchain.smith import RunEvalConfig, run_on_dataset
+        from oplangchain.chat_models import ChatOpenAI
+        from oplangchain.chains import LLMChain
+        from oplangchain.smith import RunEvalConfig, run_on_dataset
 
         # Chains may have memory. Passing in a constructor function lets the
         # evaluation framework avoid cross-contamination between runs.
         def construct_chain():
             llm = ChatOpenAI(temperature=0)
             chain = LLMChain.from_string(
                 llm,
@@ -1365,15 +1365,15 @@
     You can also create custom evaluators by subclassing the
     :class:`StringEvaluator <langchain.evaluation.schema.StringEvaluator>`
     or LangSmith's `RunEvaluator` classes.
 
     .. code-block:: python
 
         from typing import Optional
-        from langchain.evaluation import StringEvaluator
+        from oplangchain.evaluation import StringEvaluator
 
         class MyStringEvaluator(StringEvaluator):
 
             @property
             def requires_input(self) -> bool:
                 return False
```

### Comparing `oplangchain-0.1.0/oplangchain/smith/evaluation/string_run_evaluator.py` & `oplangchain-0.1.1/oplangchain/smith/evaluation/string_run_evaluator.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,25 +3,25 @@
 
 from abc import abstractmethod
 from typing import Any, Dict, List, Optional
 
 from langsmith import EvaluationResult, RunEvaluator
 from langsmith.schemas import DataType, Example, Run
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForChainRun,
     CallbackManagerForChainRun,
 )
-from langchain.chains.base import Chain
-from langchain.evaluation.schema import StringEvaluator
-from langchain.load.dump import dumpd
-from langchain.load.load import load
-from langchain.load.serializable import Serializable
-from langchain.schema import RUN_KEY, messages_from_dict
-from langchain.schema.messages import BaseMessage, get_buffer_string
+from oplangchain.chains.base import Chain
+from oplangchain.evaluation.schema import StringEvaluator
+from oplangchain.load.dump import dumpd
+from oplangchain.load.load import load
+from oplangchain.load.serializable import Serializable
+from oplangchain.schema import RUN_KEY, messages_from_dict
+from oplangchain.schema.messages import BaseMessage, get_buffer_string
 
 
 def _get_messages_from_run_dict(messages: List[dict]) -> List[BaseMessage]:
     if not messages:
         return []
     first_message = messages[0]
     if "lc" in first_message:
```

### Comparing `oplangchain-0.1.0/oplangchain/text_splitter.py` & `oplangchain-0.1.1/oplangchain/text_splitter.py`

 * *Files 0% similar despite different names*

```diff
@@ -42,16 +42,16 @@
     Type,
     TypedDict,
     TypeVar,
     Union,
     cast,
 )
 
-from langchain.docstore.document import Document
-from langchain.schema import BaseDocumentTransformer
+from oplangchain.docstore.document import Document
+from oplangchain.schema import BaseDocumentTransformer
 
 logger = logging.getLogger(__name__)
 
 TS = TypeVar("TS", bound="TextSplitter")
 
 
 def _make_spacy_pipeline_for_splitting(pipeline: str) -> Any:  # avoid importing spacy
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -13,113 +13,113 @@
 **Main helpers:**
 
 .. code-block::
 
     CallbackManagerForToolRun, AsyncCallbackManagerForToolRun
 """
 
-from langchain.tools.arxiv.tool import ArxivQueryRun
-from langchain.tools.azure_cognitive_services import (
+from oplangchain.tools.arxiv.tool import ArxivQueryRun
+from oplangchain.tools.azure_cognitive_services import (
     AzureCogsFormRecognizerTool,
     AzureCogsImageAnalysisTool,
     AzureCogsSpeech2TextTool,
     AzureCogsText2SpeechTool,
 )
-from langchain.tools.base import BaseTool, StructuredTool, Tool, tool
-from langchain.tools.bing_search.tool import BingSearchResults, BingSearchRun
-from langchain.tools.brave_search.tool import BraveSearch
-from langchain.tools.convert_to_openai import format_tool_to_openai_function
-from langchain.tools.ddg_search.tool import DuckDuckGoSearchResults, DuckDuckGoSearchRun
-from langchain.tools.file_management import (
+from oplangchain.tools.base import BaseTool, StructuredTool, Tool, tool
+from oplangchain.tools.bing_search.tool import BingSearchResults, BingSearchRun
+from oplangchain.tools.brave_search.tool import BraveSearch
+from oplangchain.tools.convert_to_openai import format_tool_to_openai_function
+from oplangchain.tools.ddg_search.tool import DuckDuckGoSearchResults, DuckDuckGoSearchRun
+from oplangchain.tools.file_management import (
     CopyFileTool,
     DeleteFileTool,
     FileSearchTool,
     ListDirectoryTool,
     MoveFileTool,
     ReadFileTool,
     WriteFileTool,
 )
-from langchain.tools.gmail import (
+from oplangchain.tools.gmail import (
     GmailCreateDraft,
     GmailGetMessage,
     GmailGetThread,
     GmailSearch,
     GmailSendMessage,
 )
-from langchain.tools.google_places.tool import GooglePlacesTool
-from langchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun
-from langchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun
-from langchain.tools.graphql.tool import BaseGraphQLTool
-from langchain.tools.human.tool import HumanInputRun
-from langchain.tools.ifttt import IFTTTWebhook
-from langchain.tools.interaction.tool import StdInInquireTool
-from langchain.tools.jira.tool import JiraAction
-from langchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool
-from langchain.tools.metaphor_search import MetaphorSearchResults
-from langchain.tools.office365.create_draft_message import O365CreateDraftMessage
-from langchain.tools.office365.events_search import O365SearchEvents
-from langchain.tools.office365.messages_search import O365SearchEmails
-from langchain.tools.office365.send_event import O365SendEvent
-from langchain.tools.office365.send_message import O365SendMessage
-from langchain.tools.office365.utils import authenticate
-from langchain.tools.openapi.utils.api_models import APIOperation
-from langchain.tools.openapi.utils.openapi_utils import OpenAPISpec
-from langchain.tools.openweathermap.tool import OpenWeatherMapQueryRun
-from langchain.tools.playwright import (
+from oplangchain.tools.google_places.tool import GooglePlacesTool
+from oplangchain.tools.google_search.tool import GoogleSearchResults, GoogleSearchRun
+from oplangchain.tools.google_serper.tool import GoogleSerperResults, GoogleSerperRun
+from oplangchain.tools.graphql.tool import BaseGraphQLTool
+from oplangchain.tools.human.tool import HumanInputRun
+from oplangchain.tools.ifttt import IFTTTWebhook
+from oplangchain.tools.interaction.tool import StdInInquireTool
+from oplangchain.tools.jira.tool import JiraAction
+from oplangchain.tools.json.tool import JsonGetValueTool, JsonListKeysTool
+from oplangchain.tools.metaphor_search import MetaphorSearchResults
+from oplangchain.tools.office365.create_draft_message import O365CreateDraftMessage
+from oplangchain.tools.office365.events_search import O365SearchEvents
+from oplangchain.tools.office365.messages_search import O365SearchEmails
+from oplangchain.tools.office365.send_event import O365SendEvent
+from oplangchain.tools.office365.send_message import O365SendMessage
+from oplangchain.tools.office365.utils import authenticate
+from oplangchain.tools.openapi.utils.api_models import APIOperation
+from oplangchain.tools.openapi.utils.openapi_utils import OpenAPISpec
+from oplangchain.tools.openweathermap.tool import OpenWeatherMapQueryRun
+from oplangchain.tools.playwright import (
     ClickTool,
     CurrentWebPageTool,
     ExtractHyperlinksTool,
     ExtractTextTool,
     GetElementsTool,
     NavigateBackTool,
     NavigateTool,
 )
-from langchain.tools.plugin import AIPluginTool
-from langchain.tools.powerbi.tool import (
+from oplangchain.tools.plugin import AIPluginTool
+from oplangchain.tools.powerbi.tool import (
     InfoPowerBITool,
     ListPowerBITool,
     QueryPowerBITool,
 )
-from langchain.tools.pubmed.tool import PubmedQueryRun
-from langchain.tools.python.tool import PythonAstREPLTool, PythonREPLTool
-from langchain.tools.requests.tool import (
+from oplangchain.tools.pubmed.tool import PubmedQueryRun
+from oplangchain.tools.python.tool import PythonAstREPLTool, PythonREPLTool
+from oplangchain.tools.requests.tool import (
     BaseRequestsTool,
     RequestsDeleteTool,
     RequestsGetTool,
     RequestsPatchTool,
     RequestsPostTool,
     RequestsPutTool,
 )
-from langchain.tools.scenexplain.tool import SceneXplainTool
-from langchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun
-from langchain.tools.shell.tool import ShellTool
-from langchain.tools.sleep.tool import SleepTool
-from langchain.tools.spark_sql.tool import (
+from oplangchain.tools.scenexplain.tool import SceneXplainTool
+from oplangchain.tools.searx_search.tool import SearxSearchResults, SearxSearchRun
+from oplangchain.tools.shell.tool import ShellTool
+from oplangchain.tools.sleep.tool import SleepTool
+from oplangchain.tools.spark_sql.tool import (
     BaseSparkSQLTool,
     InfoSparkSQLTool,
     ListSparkSQLTool,
     QueryCheckerTool,
     QuerySparkSQLTool,
 )
-from langchain.tools.sql_database.tool import (
+from oplangchain.tools.sql_database.tool import (
     BaseSQLDatabaseTool,
     InfoSQLDatabaseTool,
     ListSQLDatabaseTool,
     QuerySQLCheckerTool,
     QuerySQLDataBaseTool,
 )
-from langchain.tools.steamship_image_generation import SteamshipImageGenerationTool
-from langchain.tools.vectorstore.tool import (
+from oplangchain.tools.steamship_image_generation import SteamshipImageGenerationTool
+from oplangchain.tools.vectorstore.tool import (
     VectorStoreQATool,
     VectorStoreQAWithSourcesTool,
 )
-from langchain.tools.wikipedia.tool import WikipediaQueryRun
-from langchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun
-from langchain.tools.youtube.search import YouTubeSearchTool
-from langchain.tools.zapier.tool import ZapierNLAListActions, ZapierNLARunAction
+from oplangchain.tools.wikipedia.tool import WikipediaQueryRun
+from oplangchain.tools.wolfram_alpha.tool import WolframAlphaQueryRun
+from oplangchain.tools.youtube.search import YouTubeSearchTool
+from oplangchain.tools.zapier.tool import ZapierNLAListActions, ZapierNLARunAction
 
 __all__ = [
     "AIPluginTool",
     "APIOperation",
     "ArxivQueryRun",
     "AzureCogsFormRecognizerTool",
     "AzureCogsImageAnalysisTool",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/amadeus/closest_airport.py` & `oplangchain-0.1.1/oplangchain/tools/amadeus/closest_airport.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.chains import LLMChain
-from langchain.chat_models import ChatOpenAI
-from langchain.tools.amadeus.base import AmadeusBaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.chains import LLMChain
+from oplangchain.chat_models import ChatOpenAI
+from oplangchain.tools.amadeus.base import AmadeusBaseTool
 
 
 class ClosestAirportSchema(BaseModel):
     """Schema for the AmadeusClosestAirport tool."""
 
     location: str = Field(
         description=(
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/amadeus/flight_search.py` & `oplangchain-0.1.1/oplangchain/tools/amadeus/flight_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import logging
 from datetime import datetime as dt
 from typing import Dict, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.amadeus.base import AmadeusBaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.amadeus.base import AmadeusBaseTool
 
 logger = logging.getLogger(__name__)
 
 
 class FlightSearchSchema(BaseModel):
     """Schema for the AmadeusFlightSearch tool."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/amadeus/utils.py` & `oplangchain-0.1.1/oplangchain/tools/amadeus/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/arxiv/tool.py` & `oplangchain-0.1.1/oplangchain/tools/arxiv/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Tool for the Arxiv API."""
 
 from typing import Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.arxiv import ArxivAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.arxiv import ArxivAPIWrapper
 
 
 class ArxivQueryRun(BaseTool):
     """Tool that searches the Arxiv API."""
 
     name = "arxiv"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Azure Cognitive Services Tools."""
 
-from langchain.tools.azure_cognitive_services.form_recognizer import (
+from oplangchain.tools.azure_cognitive_services.form_recognizer import (
     AzureCogsFormRecognizerTool,
 )
-from langchain.tools.azure_cognitive_services.image_analysis import (
+from oplangchain.tools.azure_cognitive_services.image_analysis import (
     AzureCogsImageAnalysisTool,
 )
-from langchain.tools.azure_cognitive_services.speech2text import (
+from oplangchain.tools.azure_cognitive_services.speech2text import (
     AzureCogsSpeech2TextTool,
 )
-from langchain.tools.azure_cognitive_services.text2speech import (
+from oplangchain.tools.azure_cognitive_services.text2speech import (
     AzureCogsText2SpeechTool,
 )
 
 __all__ = [
     "AzureCogsImageAnalysisTool",
     "AzureCogsFormRecognizerTool",
     "AzureCogsSpeech2TextTool",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/form_recognizer.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/form_recognizer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 import logging
 from typing import Any, Dict, List, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.azure_cognitive_services.utils import detect_file_src_type
-from langchain.tools.base import BaseTool
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.azure_cognitive_services.utils import detect_file_src_type
+from oplangchain.tools.base import BaseTool
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class AzureCogsFormRecognizerTool(BaseTool):
     """Tool that queries the Azure Cognitive Services Form Recognizer API.
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/image_analysis.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/image_analysis.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 import logging
 from typing import Any, Dict, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.azure_cognitive_services.utils import detect_file_src_type
-from langchain.tools.base import BaseTool
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.azure_cognitive_services.utils import detect_file_src_type
+from oplangchain.tools.base import BaseTool
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class AzureCogsImageAnalysisTool(BaseTool):
     """Tool that queries the Azure Cognitive Services Image Analysis API.
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/speech2text.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/speech2text.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 
 import logging
 import time
 from typing import Any, Dict, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.azure_cognitive_services.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.azure_cognitive_services.utils import (
     detect_file_src_type,
     download_audio_from_url,
 )
-from langchain.tools.base import BaseTool
-from langchain.utils import get_from_dict_or_env
+from oplangchain.tools.base import BaseTool
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class AzureCogsSpeech2TextTool(BaseTool):
     """Tool that queries the Azure Cognitive Services Speech2Text API.
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/text2speech.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/text2speech.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,17 +2,17 @@
 
 import logging
 import tempfile
 from typing import Any, Dict, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utils import get_from_dict_or_env
 
 logger = logging.getLogger(__name__)
 
 
 class AzureCogsText2SpeechTool(BaseTool):
     """Tool that queries the Azure Cognitive Services Text2Speech API.
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/azure_cognitive_services/utils.py` & `oplangchain-0.1.1/oplangchain/tools/azure_cognitive_services/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/base.py` & `oplangchain-0.1.1/oplangchain/tools/base.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,23 +14,23 @@
     Field,
     create_model,
     root_validator,
     validate_arguments,
 )
 from pydantic.main import ModelMetaclass
 
-from langchain.callbacks.base import BaseCallbackManager
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.base import BaseCallbackManager
+from oplangchain.callbacks.manager import (
     AsyncCallbackManager,
     AsyncCallbackManagerForToolRun,
     CallbackManager,
     CallbackManagerForToolRun,
     Callbacks,
 )
-from langchain.schema.runnable import Runnable, RunnableConfig
+from oplangchain.schema.runnable import Runnable, RunnableConfig
 
 
 class SchemaAnnotationError(TypeError):
     """Raised when 'args_schema' is missing or has an incorrect type annotation."""
 
 
 class ToolMetaclass(ModelMetaclass):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/bing_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/bing_search/tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Tool for the Bing search API."""
 
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.bing_search import BingSearchAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.bing_search import BingSearchAPIWrapper
 
 
 class BingSearchRun(BaseTool):
     """Tool that queries the Bing search API."""
 
     name = "bing_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/brave_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/brave_search/tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import Any, Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.brave_search import BraveSearchWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.brave_search import BraveSearchWrapper
 
 
 class BraveSearch(BaseTool):
     """Tool that queries the BraveSearch."""
 
     name = "brave_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/convert_to_openai.py` & `oplangchain-0.1.1/oplangchain/tools/convert_to_openai.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import TypedDict
 
-from langchain.tools import BaseTool, StructuredTool
+from oplangchain.tools import BaseTool, StructuredTool
 
 
 class FunctionDescription(TypedDict):
     """Representation of a callable function to the OpenAI API."""
 
     name: str
     """The name of the function."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/dataforseo_api_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/dataforseo_api_search/tool.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Tool for the DataForSeo SERP API."""
 
 from typing import Optional
 
 from pydantic.fields import Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
-from langchain.utilities.dataforseo_api_search import DataForSeoAPIWrapper
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.dataforseo_api_search import DataForSeoAPIWrapper
 
 
 class DataForSeoAPISearchRun(BaseTool):
     """Tool that queries the DataForSeo Google search API."""
 
     name = "dataforseo_api_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/ddg_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/ddg_search/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Tool for the DuckDuckGo search API."""
 
 import warnings
 from typing import Any, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
 
 
 class DuckDuckGoSearchRun(BaseTool):
     """Tool that queries the DuckDuckGo search API."""
 
     name = "duckduckgo_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/__init__.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """File Management Tools."""
 
-from langchain.tools.file_management.copy import CopyFileTool
-from langchain.tools.file_management.delete import DeleteFileTool
-from langchain.tools.file_management.file_search import FileSearchTool
-from langchain.tools.file_management.list_dir import ListDirectoryTool
-from langchain.tools.file_management.move import MoveFileTool
-from langchain.tools.file_management.read import ReadFileTool
-from langchain.tools.file_management.write import WriteFileTool
+from oplangchain.tools.file_management.copy import CopyFileTool
+from oplangchain.tools.file_management.delete import DeleteFileTool
+from oplangchain.tools.file_management.file_search import FileSearchTool
+from oplangchain.tools.file_management.list_dir import ListDirectoryTool
+from oplangchain.tools.file_management.move import MoveFileTool
+from oplangchain.tools.file_management.read import ReadFileTool
+from oplangchain.tools.file_management.write import WriteFileTool
 
 __all__ = [
     "CopyFileTool",
     "DeleteFileTool",
     "FileSearchTool",
     "MoveFileTool",
     "ReadFileTool",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/copy.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/copy.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import shutil
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class FileCopyInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/delete.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/delete.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import os
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class FileDeleteInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/file_search.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/file_search.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import fnmatch
 import os
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class FileSearchInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/list_dir.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/list_dir.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import os
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class DirectoryListingInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/move.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/move.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import shutil
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class FileMoveInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/read.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/read.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class ReadFileInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/utils.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/file_management/write.py` & `oplangchain-0.1.1/oplangchain/tools/file_management/write.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.tools.file_management.utils import (
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.file_management.utils import (
     INVALID_PATH_TEMPLATE,
     BaseFileToolMixin,
     FileValidationError,
 )
 
 
 class WriteFileInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/github/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/github/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/__init__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Gmail tools."""
 
-from langchain.tools.gmail.create_draft import GmailCreateDraft
-from langchain.tools.gmail.get_message import GmailGetMessage
-from langchain.tools.gmail.get_thread import GmailGetThread
-from langchain.tools.gmail.search import GmailSearch
-from langchain.tools.gmail.send_message import GmailSendMessage
-from langchain.tools.gmail.utils import get_gmail_credentials
+from oplangchain.tools.gmail.create_draft import GmailCreateDraft
+from oplangchain.tools.gmail.get_message import GmailGetMessage
+from oplangchain.tools.gmail.get_thread import GmailGetThread
+from oplangchain.tools.gmail.search import GmailSearch
+from oplangchain.tools.gmail.send_message import GmailSendMessage
+from oplangchain.tools.gmail.utils import get_gmail_credentials
 
 __all__ = [
     "GmailCreateDraft",
     "GmailSendMessage",
     "GmailSearch",
     "GmailGetMessage",
     "GmailGetThread",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/base.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/base.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Base class for Gmail tools."""
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
 from pydantic import Field
 
-from langchain.tools.base import BaseTool
-from langchain.tools.gmail.utils import build_resource_service
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.gmail.utils import build_resource_service
 
 if TYPE_CHECKING:
     # This is for linting and IDE typehints
     from googleapiclient.discovery import Resource
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/create_draft.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/create_draft.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 import base64
 from email.message import EmailMessage
 from typing import List, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.gmail.base import GmailBaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.gmail.base import GmailBaseTool
 
 
 class CreateDraftSchema(BaseModel):
     """Input for CreateDraftTool."""
 
     message: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/get_message.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/get_message.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import base64
 import email
 from typing import Dict, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.gmail.base import GmailBaseTool
-from langchain.tools.gmail.utils import clean_email_body
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.gmail.base import GmailBaseTool
+from oplangchain.tools.gmail.utils import clean_email_body
 
 
 class SearchArgsSchema(BaseModel):
     """Input for GetMessageTool."""
 
     message_id: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/get_thread.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/get_thread.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import Dict, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.gmail.base import GmailBaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.gmail.base import GmailBaseTool
 
 
 class GetThreadSchema(BaseModel):
     """Input for GetMessageTool."""
 
     # From https://support.google.com/mail/answer/7190?hl=en
     thread_id: str = Field(
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/search.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/search.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 import base64
 import email
 from enum import Enum
 from typing import Any, Dict, List, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.gmail.base import GmailBaseTool
-from langchain.tools.gmail.utils import clean_email_body
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.gmail.base import GmailBaseTool
+from oplangchain.tools.gmail.utils import clean_email_body
 
 
 class Resource(str, Enum):
     """Enumerator of Resources to search."""
 
     THREADS = "threads"
     MESSAGES = "messages"
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/send_message.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/send_message.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 import base64
 from email.mime.multipart import MIMEMultipart
 from email.mime.text import MIMEText
 from typing import Any, Dict, List, Optional, Union
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.gmail.base import GmailBaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.gmail.base import GmailBaseTool
 
 
 class SendMessageSchema(BaseModel):
     """Input for SendMessageTool."""
 
     message: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/gmail/utils.py` & `oplangchain-0.1.1/oplangchain/tools/gmail/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/golden_query/tool.py` & `oplangchain-0.1.1/oplangchain/tools/golden_query/tool.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Tool for the Golden API."""
 
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.golden_query import GoldenQueryAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.golden_query import GoldenQueryAPIWrapper
 
 
 class GoldenQueryRun(BaseTool):
     """Tool that adds the capability to query using the Golden API and get back JSON."""
 
     name = "Golden Query"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/google_places/tool.py` & `oplangchain-0.1.1/oplangchain/tools/google_places/tool.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Tool for the Google search API."""
 
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.google_places_api import GooglePlacesAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.google_places_api import GooglePlacesAPIWrapper
 
 
 class GooglePlacesSchema(BaseModel):
     """Input for GooglePlacesTool."""
 
     query: str = Field(..., description="Query for google maps")
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/google_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/google_search/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Tool for the Google search API."""
 
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.google_search import GoogleSearchAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.google_search import GoogleSearchAPIWrapper
 
 
 class GoogleSearchRun(BaseTool):
     """Tool that queries the Google search API."""
 
     name = "google_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/graphql/tool.py` & `oplangchain-0.1.1/oplangchain/tools/graphql/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import json
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.graphql import GraphQLAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.graphql import GraphQLAPIWrapper
 
 
 class BaseGraphQLTool(BaseTool):
     """Base tool for querying a GraphQL API."""
 
     graphql_wrapper: GraphQLAPIWrapper
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/human/tool.py` & `oplangchain-0.1.1/oplangchain/tools/human/tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Tool for asking human input."""
 
 from typing import Callable, Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
 
 
 def _print_func(text: str) -> None:
     print("\n")
     print(text)
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/ifttt.py` & `oplangchain-0.1.1/oplangchain/tools/ifttt.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,16 +32,16 @@
 - Copy the IFTTT key value from there. The URL is of the form
 https://maker.ifttt.com/use/YOUR_IFTTT_KEY. Grab the YOUR_IFTTT_KEY value.
 """
 from typing import Optional
 
 import requests
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
 
 
 class IFTTTWebhook(BaseTool):
     """IFTTT Webhook.
 
     Args:
         name: name of the tool
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/jira/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/jira/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/jira/tool.py` & `oplangchain-0.1.1/oplangchain/tools/jira/tool.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,19 +7,19 @@
     JIRA_API_TOKEN
     JIRA_USERNAME
     JIRA_INSTANCE_URL
 
 Below is a sample script that uses the Jira tool:
 
 ```python
-from langchain.agents import AgentType
-from langchain.agents import initialize_agent
-from langchain.agents.agent_toolkits.jira.toolkit import JiraToolkit
-from langchain.llms import OpenAI
-from langchain.utilities.jira import JiraAPIWrapper
+from oplangchain.agents import AgentType
+from oplangchain.agents import initialize_agent
+from oplangchain.agents.agent_toolkits.jira.toolkit import JiraToolkit
+from oplangchain.llms import OpenAI
+from oplangchain.utilities.jira import JiraAPIWrapper
 
 llm = OpenAI(temperature=0)
 jira = JiraAPIWrapper()
 toolkit = JiraToolkit.from_jira_api_wrapper(jira)
 agent = initialize_agent(
     toolkit.get_tools(),
     llm,
@@ -28,17 +28,17 @@
 )
 ```
 """
 from typing import Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.jira import JiraAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.jira import JiraAPIWrapper
 
 
 class JiraAction(BaseTool):
     """Tool that queries the Atlassian Jira API."""
 
     api_wrapper: JiraAPIWrapper = Field(default_factory=JiraAPIWrapper)
     mode: str
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/json/tool.py` & `oplangchain-0.1.1/oplangchain/tools/json/tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,19 +5,19 @@
 import json
 import re
 from pathlib import Path
 from typing import Dict, List, Optional, Union
 
 from pydantic import BaseModel
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 
 def _parse_input(text: str) -> List[Union[str, int]]:
     """Parse input of the form data["key1"][0]["key2"] into a list of keys."""
     _res = re.findall(r"\[.*?]", text)
     # strip the brackets and quotes, convert to int if possible
     res = [i[1:-1].replace('"', "") for i in _res]
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/metaphor_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/metaphor_search/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Tool for the Metaphor search API."""
 
 from typing import Dict, List, Optional, Union
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
-from langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
 
 
 class MetaphorSearchResults(BaseTool):
     """Tool that queries the Metaphor Search API and gets back json."""
 
     name = "metaphor_search_results_json"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/multion/create_session.py` & `oplangchain-0.1.1/oplangchain/tools/multion/create_session.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import TYPE_CHECKING, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
 
 if TYPE_CHECKING:
     # This is for linting and IDE typehints
     import multion
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/multion/update_session.py` & `oplangchain-0.1.1/oplangchain/tools/multion/update_session.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import TYPE_CHECKING, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
 
 if TYPE_CHECKING:
     # This is for linting and IDE typehints
     import multion
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/nuclia/tool.py` & `oplangchain-0.1.1/oplangchain/tools/nuclia/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,19 +14,19 @@
 import mimetypes
 import os
 from typing import Any, Dict, Optional, Type, Union
 
 import requests
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 logger = logging.getLogger(__name__)
 
 
 class NUASchema(BaseModel):
     action: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/office365/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """O365 tools."""
 
-from langchain.tools.office365.create_draft_message import O365CreateDraftMessage
-from langchain.tools.office365.events_search import O365SearchEvents
-from langchain.tools.office365.messages_search import O365SearchEmails
-from langchain.tools.office365.send_event import O365SendEvent
-from langchain.tools.office365.send_message import O365SendMessage
-from langchain.tools.office365.utils import authenticate
+from oplangchain.tools.office365.create_draft_message import O365CreateDraftMessage
+from oplangchain.tools.office365.events_search import O365SearchEvents
+from oplangchain.tools.office365.messages_search import O365SearchEmails
+from oplangchain.tools.office365.send_event import O365SendEvent
+from oplangchain.tools.office365.send_message import O365SendMessage
+from oplangchain.tools.office365.utils import authenticate
 
 __all__ = [
     "O365SearchEmails",
     "O365SearchEvents",
     "O365CreateDraftMessage",
     "O365SendMessage",
     "O365SendEvent",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/create_draft_message.py` & `oplangchain-0.1.1/oplangchain/tools/office365/create_draft_message.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import List, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.office365.base import O365BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.office365.base import O365BaseTool
 
 
 class CreateDraftMessageSchema(BaseModel):
     """Input for SendMessageTool."""
 
     body: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/events_search.py` & `oplangchain-0.1.1/oplangchain/tools/office365/events_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 """
 
 from datetime import datetime as dt
 from typing import Any, Dict, List, Optional, Type
 
 from pydantic import BaseModel, Extra, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.office365.base import O365BaseTool
-from langchain.tools.office365.utils import clean_body
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.office365.base import O365BaseTool
+from oplangchain.tools.office365.utils import clean_body
 
 
 class SearchEventsInput(BaseModel):
     """Input for SearchEmails Tool."""
 
     """From https://learn.microsoft.com/en-us/graph/search-query-parameter"""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/messages_search.py` & `oplangchain-0.1.1/oplangchain/tools/office365/messages_search.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,17 +4,17 @@
 https://learn.microsoft.com/en-us/graph/auth/
 """
 
 from typing import Any, Dict, List, Optional, Type
 
 from pydantic import BaseModel, Extra, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.office365.base import O365BaseTool
-from langchain.tools.office365.utils import clean_body
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.office365.base import O365BaseTool
+from oplangchain.tools.office365.utils import clean_body
 
 
 class SearchEmailsInput(BaseModel):
     """Input for SearchEmails Tool."""
 
     """From https://learn.microsoft.com/en-us/graph/search-query-parameter"""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/send_event.py` & `oplangchain-0.1.1/oplangchain/tools/office365/send_event.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 """
 
 from datetime import datetime as dt
 from typing import List, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.office365.base import O365BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.office365.base import O365BaseTool
 
 
 class SendEventSchema(BaseModel):
     """Input for CreateEvent Tool."""
 
     body: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/send_message.py` & `oplangchain-0.1.1/oplangchain/tools/office365/send_message.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from typing import List, Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.office365.base import O365BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.office365.base import O365BaseTool
 
 
 class SendMessageSchema(BaseModel):
     """Input for SendMessageTool."""
 
     body: str = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/office365/utils.py` & `oplangchain-0.1.1/oplangchain/tools/office365/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/openapi/utils/api_models.py` & `oplangchain-0.1.1/oplangchain/tools/openapi/utils/api_models.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import logging
 from enum import Enum
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Type, Union
 
 from openapi_schema_pydantic import MediaType, Parameter, Reference, RequestBody, Schema
 from pydantic import BaseModel, Field
 
-from langchain.tools.openapi.utils.openapi_utils import HTTPVerb, OpenAPISpec
+from oplangchain.tools.openapi.utils.openapi_utils import HTTPVerb, OpenAPISpec
 
 logger = logging.getLogger(__name__)
 PRIMITIVE_TYPES = {
     "integer": int,
     "number": float,
     "string": str,
     "boolean": bool,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/openweathermap/tool.py` & `oplangchain-0.1.1/oplangchain/tools/openweathermap/tool.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Tool for the OpenWeatherMap API."""
 
 from typing import Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities import OpenWeatherMapAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities import OpenWeatherMapAPIWrapper
 
 
 class OpenWeatherMapQueryRun(BaseTool):
     """Tool that queries the OpenWeatherMap API."""
 
     api_wrapper: OpenWeatherMapAPIWrapper = Field(
         default_factory=OpenWeatherMapAPIWrapper
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/__init__.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/__init__.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Browser tools and toolkit."""
 
-from langchain.tools.playwright.click import ClickTool
-from langchain.tools.playwright.current_page import CurrentWebPageTool
-from langchain.tools.playwright.extract_hyperlinks import ExtractHyperlinksTool
-from langchain.tools.playwright.extract_text import ExtractTextTool
-from langchain.tools.playwright.get_elements import GetElementsTool
-from langchain.tools.playwright.navigate import NavigateTool
-from langchain.tools.playwright.navigate_back import NavigateBackTool
+from oplangchain.tools.playwright.click import ClickTool
+from oplangchain.tools.playwright.current_page import CurrentWebPageTool
+from oplangchain.tools.playwright.extract_hyperlinks import ExtractHyperlinksTool
+from oplangchain.tools.playwright.extract_text import ExtractTextTool
+from oplangchain.tools.playwright.get_elements import GetElementsTool
+from oplangchain.tools.playwright.navigate import NavigateTool
+from oplangchain.tools.playwright.navigate_back import NavigateBackTool
 
 __all__ = [
     "NavigateTool",
     "NavigateBackTool",
     "ExtractTextTool",
     "ExtractHyperlinksTool",
     "GetElementsTool",
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/base.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/base.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Optional, Tuple, Type
 
 from pydantic import root_validator
 
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 if TYPE_CHECKING:
     from playwright.async_api import Browser as AsyncBrowser
     from playwright.sync_api import Browser as SyncBrowser
 else:
     try:
         # We do this so pydantic can resolve the types when instantiating
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/click.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/click.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import (
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import (
     aget_current_page,
     get_current_page,
 )
 
 
 class ClickToolInput(BaseModel):
     """Input for ClickTool."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/current_page.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/current_page.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Optional, Type
 
 from pydantic import BaseModel
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import aget_current_page, get_current_page
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import aget_current_page, get_current_page
 
 
 class CurrentWebPageTool(BaseBrowserTool):
     """Tool for getting the URL of the current webpage."""
 
     name: str = "current_webpage"
     description: str = "Returns the URL of the current page"
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/extract_hyperlinks.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/extract_hyperlinks.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import json
 from typing import TYPE_CHECKING, Any, Optional, Type
 
 from pydantic import BaseModel, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import aget_current_page, get_current_page
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import aget_current_page, get_current_page
 
 if TYPE_CHECKING:
     pass
 
 
 class ExtractHyperlinksToolInput(BaseModel):
     """Input for ExtractHyperlinksTool."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/extract_text.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/extract_text.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Optional, Type
 
 from pydantic import BaseModel, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import aget_current_page, get_current_page
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import aget_current_page, get_current_page
 
 
 class ExtractTextTool(BaseBrowserTool):
     """Tool for extracting all the text on the current webpage."""
 
     name: str = "extract_text"
     description: str = "Extract all the text on the current webpage"
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/get_elements.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/get_elements.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import json
 from typing import TYPE_CHECKING, List, Optional, Sequence, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import aget_current_page, get_current_page
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import aget_current_page, get_current_page
 
 if TYPE_CHECKING:
     from playwright.async_api import Page as AsyncPage
     from playwright.sync_api import Page as SyncPage
 
 
 class GetElementsToolInput(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/navigate.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/navigate.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import (
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import (
     aget_current_page,
     get_current_page,
 )
 
 
 class NavigateToolInput(BaseModel):
     """Input for NavigateToolInput."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/navigate_back.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/navigate_back.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 from typing import Optional, Type
 
 from pydantic import BaseModel
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.playwright.base import BaseBrowserTool
-from langchain.tools.playwright.utils import (
+from oplangchain.tools.playwright.base import BaseBrowserTool
+from oplangchain.tools.playwright.utils import (
     aget_current_page,
     get_current_page,
 )
 
 
 class NavigateBackTool(BaseBrowserTool):
     """Navigate back to the previous page in the browser history."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/playwright/utils.py` & `oplangchain-0.1.1/oplangchain/tools/playwright/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/plugin.py` & `oplangchain-0.1.1/oplangchain/tools/plugin.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 import json
 from typing import Optional, Type
 
 import requests
 import yaml
 from pydantic import BaseModel
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 
 class ApiConfig(BaseModel):
     """API Configuration."""
 
     type: str
     url: str
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/powerbi/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/powerbi/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/powerbi/tool.py` & `oplangchain-0.1.1/oplangchain/tools/powerbi/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Tools for interacting with a Power BI dataset."""
 import logging
 from time import perf_counter
 from typing import Any, Dict, Optional, Tuple
 
 from pydantic import Field, validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.chains.llm import LLMChain
-from langchain.chat_models.openai import _import_tiktoken
-from langchain.tools.base import BaseTool
-from langchain.tools.powerbi.prompt import (
+from oplangchain.chains.llm import LLMChain
+from oplangchain.chat_models.openai import _import_tiktoken
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.powerbi.prompt import (
     BAD_REQUEST_RESPONSE,
     DEFAULT_FEWSHOT_EXAMPLES,
     RETRY_RESPONSE,
 )
-from langchain.utilities.powerbi import PowerBIDataset, json_to_md
+from oplangchain.utilities.powerbi import PowerBIDataset, json_to_md
 
 logger = logging.getLogger(__name__)
 
 
 class QueryPowerBITool(BaseTool):
     """Tool for querying a Power BI Dataset."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/pubmed/tool.py` & `oplangchain-0.1.1/oplangchain/tools/pubmed/tool.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Tool for the Pubmed API."""
 
 from typing import Optional
 
 from pydantic import Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.pupmed import PubMedAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.pupmed import PubMedAPIWrapper
 
 
 class PubmedQueryRun(BaseTool):
     """Tool that searches the PubMed API."""
 
     name = "PubMed"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/python/tool.py` & `oplangchain-0.1.1/oplangchain/tools/python/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,20 +6,20 @@
 import sys
 from contextlib import redirect_stdout
 from io import StringIO
 from typing import Any, Dict, Optional
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
-from langchain.utilities import PythonREPL
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities import PythonREPL
 
 
 def _get_default_python_repl() -> PythonREPL:
     return PythonREPL(_globals=globals(), _locals=None)
 
 
 def sanitize_input(query: str) -> str:
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/requests/tool.py` & `oplangchain-0.1.1/oplangchain/tools/requests/tool.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 # flake8: noqa
 """Tools for making requests to an API endpoint."""
 import json
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
 
-from langchain.utilities.requests import TextRequestsWrapper
-from langchain.tools.base import BaseTool
+from oplangchain.utilities.requests import TextRequestsWrapper
+from oplangchain.tools.base import BaseTool
 
 
 def _parse_input(text: str) -> Dict[str, Any]:
     """Parse the json string into a dict."""
     return json.loads(text)
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/scenexplain/tool.py` & `oplangchain-0.1.1/oplangchain/tools/scenexplain/tool.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Tool for the SceneXplain API."""
 from typing import Optional
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.scenexplain import SceneXplainAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.scenexplain import SceneXplainAPIWrapper
 
 
 class SceneXplainInput(BaseModel):
     """Input for SceneXplain."""
 
     query: str = Field(..., description="The link to the image to explain")
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/searx_search/tool.py` & `oplangchain-0.1.1/oplangchain/tools/searx_search/tool.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 """Tool for the SearxNG search API."""
 from typing import Optional
 
 from pydantic import Extra
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool, Field
-from langchain.utilities.searx_search import SearxSearchWrapper
+from oplangchain.tools.base import BaseTool, Field
+from oplangchain.utilities.searx_search import SearxSearchWrapper
 
 
 class SearxSearchRun(BaseTool):
     """Tool that queries a Searx instance."""
 
     name = "searx_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/shell/tool.py` & `oplangchain-0.1.1/oplangchain/tools/shell/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 import asyncio
 import platform
 import warnings
 from typing import List, Optional, Type, Union
 
 from pydantic import BaseModel, Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
-from langchain.utilities.bash import BashProcess
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.bash import BashProcess
 
 
 class ShellInput(BaseModel):
     """Commands for the Bash Shell tool."""
 
     commands: Union[str, List[str]] = Field(
         ...,
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/sleep/tool.py` & `oplangchain-0.1.1/oplangchain/tools/sleep/tool.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 """Tool for agent to sleep."""
 from asyncio import sleep as asleep
 from time import sleep
 from typing import Optional, Type
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
+from oplangchain.tools.base import BaseTool
 
 
 class SleepInput(BaseModel):
     """Input for CopyFileTool."""
 
     sleep_time: int = Field(..., description="Time to sleep in seconds")
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/spark_sql/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/spark_sql/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/spark_sql/tool.py` & `oplangchain-0.1.1/oplangchain/tools/sql_database/tool.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,135 +1,137 @@
 # flake8: noqa
-"""Tools for interacting with Spark SQL."""
+"""Tools for interacting with a SQL database."""
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.callbacks.manager import (
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.chains.llm import LLMChain
-from langchain.prompts import PromptTemplate
-from langchain.utilities.spark_sql import SparkSQL
-from langchain.tools.base import BaseTool
-from langchain.tools.spark_sql.prompt import QUERY_CHECKER
+from oplangchain.chains.llm import LLMChain
+from oplangchain.prompts import PromptTemplate
+from oplangchain.utilities.sql_database import SQLDatabase
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.sql_database.prompt import QUERY_CHECKER
 
 
-class BaseSparkSQLTool(BaseModel):
-    """Base tool for interacting with Spark SQL."""
+class BaseSQLDatabaseTool(BaseModel):
+    """Base tool for interacting with a SQL database."""
 
-    db: SparkSQL = Field(exclude=True)
+    db: SQLDatabase = Field(exclude=True)
 
     # Override BaseTool.Config to appease mypy
     # See https://github.com/pydantic/pydantic/issues/4173
     class Config(BaseTool.Config):
         """Configuration for this pydantic object."""
 
         arbitrary_types_allowed = True
         extra = Extra.forbid
 
 
-class QuerySparkSQLTool(BaseSparkSQLTool, BaseTool):
-    """Tool for querying a Spark SQL."""
+class QuerySQLDataBaseTool(BaseSQLDatabaseTool, BaseTool):
+    """Tool for querying a SQL database."""
 
-    name = "query_sql_db"
+    name = "sql_db_query"
     description = """
-    Input to this tool is a detailed and correct SQL query, output is a result from the Spark SQL.
+    Input to this tool is a detailed and correct SQL query, output is a result from the database.
     If the query is not correct, an error message will be returned.
     If an error is returned, rewrite the query, check the query, and try again.
     """
 
     def _run(
         self,
         query: str,
         run_manager: Optional[CallbackManagerForToolRun] = None,
     ) -> str:
         """Execute the query, return the results or an error message."""
         return self.db.run_no_throw(query)
 
 
-class InfoSparkSQLTool(BaseSparkSQLTool, BaseTool):
-    """Tool for getting metadata about a Spark SQL."""
+class InfoSQLDatabaseTool(BaseSQLDatabaseTool, BaseTool):
+    """Tool for getting metadata about a SQL database."""
 
-    name = "schema_sql_db"
+    name = "sql_db_schema"
     description = """
-    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.
-    Be sure that the tables actually exist by calling list_tables_sql_db first!
+    Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables.    
 
     Example Input: "table1, table2, table3"
     """
 
     def _run(
         self,
         table_names: str,
         run_manager: Optional[CallbackManagerForToolRun] = None,
     ) -> str:
         """Get the schema for tables in a comma-separated list."""
         return self.db.get_table_info_no_throw(table_names.split(", "))
 
 
-class ListSparkSQLTool(BaseSparkSQLTool, BaseTool):
+class ListSQLDatabaseTool(BaseSQLDatabaseTool, BaseTool):
     """Tool for getting tables names."""
 
-    name = "list_tables_sql_db"
-    description = "Input is an empty string, output is a comma separated list of tables in the Spark SQL."
+    name = "sql_db_list_tables"
+    description = "Input is an empty string, output is a comma separated list of tables in the database."
 
     def _run(
         self,
         tool_input: str = "",
         run_manager: Optional[CallbackManagerForToolRun] = None,
     ) -> str:
         """Get the schema for a specific table."""
         return ", ".join(self.db.get_usable_table_names())
 
 
-class QueryCheckerTool(BaseSparkSQLTool, BaseTool):
+class QuerySQLCheckerTool(BaseSQLDatabaseTool, BaseTool):
     """Use an LLM to check if a query is correct.
     Adapted from https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/"""
 
     template: str = QUERY_CHECKER
     llm: BaseLanguageModel
     llm_chain: LLMChain = Field(init=False)
-    name = "query_checker_sql_db"
+    name = "sql_db_query_checker"
     description = """
     Use this tool to double check if your query is correct before executing it.
     Always use this tool before executing a query with query_sql_db!
     """
 
     @root_validator(pre=True)
     def initialize_llm_chain(cls, values: Dict[str, Any]) -> Dict[str, Any]:
         if "llm_chain" not in values:
             values["llm_chain"] = LLMChain(
                 llm=values.get("llm"),
                 prompt=PromptTemplate(
-                    template=QUERY_CHECKER, input_variables=["query"]
+                    template=QUERY_CHECKER, input_variables=["query", "dialect"]
                 ),
             )
 
-        if values["llm_chain"].prompt.input_variables != ["query"]:
+        if values["llm_chain"].prompt.input_variables != ["query", "dialect"]:
             raise ValueError(
-                "LLM chain for QueryCheckerTool need to use ['query'] as input_variables "
-                "for the embedded prompt"
+                "LLM chain for QueryCheckerTool must have input variables ['query', 'dialect']"
             )
 
         return values
 
     def _run(
         self,
         query: str,
         run_manager: Optional[CallbackManagerForToolRun] = None,
     ) -> str:
         """Use the LLM to check the query."""
         return self.llm_chain.predict(
-            query=query, callbacks=run_manager.get_child() if run_manager else None
+            query=query,
+            dialect=self.db.dialect,
+            callbacks=run_manager.get_child() if run_manager else None,
         )
 
     async def _arun(
         self,
         query: str,
         run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
     ) -> str:
         return await self.llm_chain.apredict(
-            query=query, callbacks=run_manager.get_child() if run_manager else None
+            query=query,
+            dialect=self.db.dialect,
+            callbacks=run_manager.get_child() if run_manager else None,
         )
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/sql_database/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/sql_database/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/steamship_image_generation/tool.py` & `oplangchain-0.1.1/oplangchain/tools/steamship_image_generation/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,18 +14,18 @@
 from __future__ import annotations
 
 from enum import Enum
 from typing import TYPE_CHECKING, Dict, Optional
 
 from pydantic import root_validator
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools import BaseTool
-from langchain.tools.steamship_image_generation.utils import make_image_public
-from langchain.utils import get_from_dict_or_env
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools import BaseTool
+from oplangchain.tools.steamship_image_generation.utils import make_image_public
+from oplangchain.utils import get_from_dict_or_env
 
 if TYPE_CHECKING:
     from steamship import Steamship
 
 
 class ModelName(str, Enum):
     """Supported Image Models for generation."""
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/steamship_image_generation/utils.py` & `oplangchain-0.1.1/oplangchain/tools/steamship_image_generation/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/vectorstore/tool.py` & `oplangchain-0.1.1/oplangchain/tools/vectorstore/tool.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 """Tools for interacting with vectorstores."""
 
 import json
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Field
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain
-from langchain.llms.openai import OpenAI
-from langchain.schema.language_model import BaseLanguageModel
-from langchain.tools.base import BaseTool
-from langchain.vectorstores.base import VectorStore
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.chains import RetrievalQA, RetrievalQAWithSourcesChain
+from oplangchain.llms.openai import OpenAI
+from oplangchain.schema.language_model import BaseLanguageModel
+from oplangchain.tools.base import BaseTool
+from oplangchain.vectorstores.base import VectorStore
 
 
 class BaseVectorStoreTool(BaseModel):
     """Base class for tools that use a VectorStore."""
 
     vectorstore: VectorStore = Field(exclude=True)
     llm: BaseLanguageModel = Field(default_factory=lambda: OpenAI(temperature=0))
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/wikipedia/tool.py` & `oplangchain-0.1.1/oplangchain/tools/wikipedia/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Tool for the Wikipedia API."""
 
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
 
 
 class WikipediaQueryRun(BaseTool):
     """Tool that searches the Wikipedia API."""
 
     name = "Wikipedia"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/wolfram_alpha/tool.py` & `oplangchain-0.1.1/oplangchain/tools/wolfram_alpha/tool.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Tool for the Wolfram Alpha API."""
 
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools.base import BaseTool
-from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools.base import BaseTool
+from oplangchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
 
 
 class WolframAlphaQueryRun(BaseTool):
     """Tool that queries using the Wolfram Alpha SDK."""
 
     name = "wolfram_alpha"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/youtube/search.py` & `oplangchain-0.1.1/oplangchain/tools/youtube/search.py`

 * *Files 7% similar despite different names*

```diff
@@ -7,16 +7,16 @@
  - the first part contains a person name
  - and the second(optional) a number that is the
     maximum number of video results to return
  """
 import json
 from typing import Optional
 
-from langchain.callbacks.manager import CallbackManagerForToolRun
-from langchain.tools import BaseTool
+from oplangchain.callbacks.manager import CallbackManagerForToolRun
+from oplangchain.tools import BaseTool
 
 
 class YouTubeSearchTool(BaseTool):
     """Tool that queries YouTube."""
 
     name = "youtube_search"
     description = (
```

### Comparing `oplangchain-0.1.0/oplangchain/tools/zapier/prompt.py` & `oplangchain-0.1.1/oplangchain/tools/zapier/prompt.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/tools/zapier/tool.py` & `oplangchain-0.1.1/oplangchain/tools/zapier/tool.py`

 * *Files 4% similar despite different names*

```diff
@@ -41,18 +41,18 @@
 
 # get from https://platform.openai.com/
 os.environ["OPENAI_API_KEY"] = os.environ.get("OPENAI_API_KEY", "")
 
 # get from https://nla.zapier.com/docs/authentication/
 os.environ["ZAPIER_NLA_API_KEY"] = os.environ.get("ZAPIER_NLA_API_KEY", "")
 
-from langchain.llms import OpenAI
-from langchain.agents import initialize_agent
-from langchain.agents.agent_toolkits import ZapierToolkit
-from langchain.utilities.zapier import ZapierNLAWrapper
+from oplangchain.llms import OpenAI
+from oplangchain.agents import initialize_agent
+from oplangchain.agents.agent_toolkits import ZapierToolkit
+from oplangchain.utilities.zapier import ZapierNLAWrapper
 
 ## step 0. expose gmail 'find email' and slack 'send channel message' actions
 
 # first go here, log in, expose (enable) the two actions:
 #    https://nla.zapier.com/demo/start
 #    -- for this example, can leave all fields "Have AI guess"
 # in an oauth scenario, you'd get your own <provider> id (instead of 'demo')
@@ -77,21 +77,21 @@
 ```
 
 """
 from typing import Any, Dict, Optional
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForToolRun,
     CallbackManagerForToolRun,
 )
-from langchain.tools.base import BaseTool
-from langchain.tools.zapier.prompt import BASE_ZAPIER_TOOL_PROMPT
-from langchain.utilities.zapier import ZapierNLAWrapper
+from oplangchain.tools.base import BaseTool
+from oplangchain.tools.zapier.prompt import BASE_ZAPIER_TOOL_PROMPT
+from oplangchain.utilities.zapier import ZapierNLAWrapper
 
 
 class ZapierNLARunAction(BaseTool):
     """
     Args:
         action_id: a specific action ID (from list actions) of the action to execute
             (the set api_key must be associated with the action owner)
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/__init__.py` & `oplangchain-0.1.1/oplangchain/utilities/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,42 +1,42 @@
 """**Utilities** are the integrations with third-part systems and packages.
 
 Other LangChain classes use **Utilities** to interact with third-part systems
 and packages.
 """
-from langchain.utilities.arxiv import ArxivAPIWrapper
-from langchain.utilities.awslambda import LambdaWrapper
-from langchain.utilities.bash import BashProcess
-from langchain.utilities.bibtex import BibtexparserWrapper
-from langchain.utilities.bing_search import BingSearchAPIWrapper
-from langchain.utilities.brave_search import BraveSearchWrapper
-from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
-from langchain.utilities.golden_query import GoldenQueryAPIWrapper
-from langchain.utilities.google_places_api import GooglePlacesAPIWrapper
-from langchain.utilities.google_search import GoogleSearchAPIWrapper
-from langchain.utilities.google_serper import GoogleSerperAPIWrapper
-from langchain.utilities.graphql import GraphQLAPIWrapper
-from langchain.utilities.jira import JiraAPIWrapper
-from langchain.utilities.max_compute import MaxComputeAPIWrapper
-from langchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
-from langchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
-from langchain.utilities.portkey import Portkey
-from langchain.utilities.powerbi import PowerBIDataset
-from langchain.utilities.pupmed import PubMedAPIWrapper
-from langchain.utilities.python import PythonREPL
-from langchain.utilities.requests import Requests, RequestsWrapper, TextRequestsWrapper
-from langchain.utilities.scenexplain import SceneXplainAPIWrapper
-from langchain.utilities.searx_search import SearxSearchWrapper
-from langchain.utilities.serpapi import SerpAPIWrapper
-from langchain.utilities.spark_sql import SparkSQL
-from langchain.utilities.sql_database import SQLDatabase
-from langchain.utilities.twilio import TwilioAPIWrapper
-from langchain.utilities.wikipedia import WikipediaAPIWrapper
-from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
-from langchain.utilities.zapier import ZapierNLAWrapper
+from oplangchain.utilities.arxiv import ArxivAPIWrapper
+from oplangchain.utilities.awslambda import LambdaWrapper
+from oplangchain.utilities.bash import BashProcess
+from oplangchain.utilities.bibtex import BibtexparserWrapper
+from oplangchain.utilities.bing_search import BingSearchAPIWrapper
+from oplangchain.utilities.brave_search import BraveSearchWrapper
+from oplangchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper
+from oplangchain.utilities.golden_query import GoldenQueryAPIWrapper
+from oplangchain.utilities.google_places_api import GooglePlacesAPIWrapper
+from oplangchain.utilities.google_search import GoogleSearchAPIWrapper
+from oplangchain.utilities.google_serper import GoogleSerperAPIWrapper
+from oplangchain.utilities.graphql import GraphQLAPIWrapper
+from oplangchain.utilities.jira import JiraAPIWrapper
+from oplangchain.utilities.max_compute import MaxComputeAPIWrapper
+from oplangchain.utilities.metaphor_search import MetaphorSearchAPIWrapper
+from oplangchain.utilities.openweathermap import OpenWeatherMapAPIWrapper
+from oplangchain.utilities.portkey import Portkey
+from oplangchain.utilities.powerbi import PowerBIDataset
+from oplangchain.utilities.pupmed import PubMedAPIWrapper
+from oplangchain.utilities.python import PythonREPL
+from oplangchain.utilities.requests import Requests, RequestsWrapper, TextRequestsWrapper
+from oplangchain.utilities.scenexplain import SceneXplainAPIWrapper
+from oplangchain.utilities.searx_search import SearxSearchWrapper
+from oplangchain.utilities.serpapi import SerpAPIWrapper
+from oplangchain.utilities.spark_sql import SparkSQL
+from oplangchain.utilities.sql_database import SQLDatabase
+from oplangchain.utilities.twilio import TwilioAPIWrapper
+from oplangchain.utilities.wikipedia import WikipediaAPIWrapper
+from oplangchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper
+from oplangchain.utilities.zapier import ZapierNLAWrapper
 
 __all__ = [
     "ArxivAPIWrapper",
     "BashProcess",
     "BibtexparserWrapper",
     "BingSearchAPIWrapper",
     "BraveSearchWrapper",
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/arxiv.py` & `oplangchain-0.1.1/oplangchain/utilities/arxiv.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Util that calls Arxiv."""
 import logging
 import os
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, root_validator
 
-from langchain.schema import Document
+from oplangchain.schema import Document
 
 logger = logging.getLogger(__name__)
 
 
 class ArxivAPIWrapper(BaseModel):
     """Wrapper around ArxivAPI.
 
@@ -32,15 +32,15 @@
             authors and summary.
         doc_content_chars_max: an optional cut limit for the length of a document's
             content
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities.arxiv import ArxivAPIWrapper
+            from oplangchain.utilities.arxiv import ArxivAPIWrapper
             arxiv = ArxivAPIWrapper(
                 top_k_results = 3,
                 ARXIV_MAX_QUERY_LENGTH = 300,
                 load_max_docs = 3,
                 load_all_available_meta = False,
                 doc_content_chars_max = 40000
             )
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/awslambda.py` & `oplangchain-0.1.1/oplangchain/utilities/awslambda.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/bash.py` & `oplangchain-0.1.1/oplangchain/utilities/bash.py`

 * *Files 0% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     on Windows systems, as pexpect makes use of
     Unix pseudoterminals (ptys). MacOS and Linux
     are okay.
 
     Example:
         .. code-block:: python
 
-        from langchain.utilities.bash import BashProcess
+        from oplangchain.utilities.bash import BashProcess
             bash = BashProcess(
                 strip_newlines = False,
                 return_err_output = False,
                 persistent = False
             )
             bash.run('echo \'hello world\'')
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/bibtex.py` & `oplangchain-0.1.1/oplangchain/utilities/bibtex.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/bing_search.py` & `oplangchain-0.1.1/oplangchain/utilities/bing_search.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 https://levelup.gitconnected.com/api-tutorial-how-to-use-bing-web-search-api-in-python-4165d5592a7e
 """
 from typing import Dict, List
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class BingSearchAPIWrapper(BaseModel):
     """Wrapper for Bing Search API.
 
     In order to set this up, follow instructions at:
     https://levelup.gitconnected.com/api-tutorial-how-to-use-bing-web-search-api-in-python-4165d5592a7e
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/brave_search.py` & `oplangchain-0.1.1/oplangchain/utilities/brave_search.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 import json
 from typing import List
 
 import requests
 from pydantic import BaseModel, Field
 
-from langchain.schema import Document
+from oplangchain.schema import Document
 
 
 class BraveSearchWrapper(BaseModel):
     """Wrapper around the Brave search engine."""
 
     api_key: str
     """The API key to use for the Brave search engine."""
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/dataforseo_api_search.py` & `oplangchain-0.1.1/oplangchain/utilities/dataforseo_api_search.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from typing import Dict, Optional
 from urllib.parse import quote
 
 import aiohttp
 import requests
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class DataForSeoAPIWrapper(BaseModel):
     """Wrapper around the DataForSeo API."""
 
     class Config:
         """Configuration for this pydantic object."""
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/duckduckgo_search.py` & `oplangchain-0.1.1/oplangchain/utilities/duckduckgo_search.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/github.py` & `oplangchain-0.1.1/oplangchain/utilities/github.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 from __future__ import annotations
 
 import json
 from typing import TYPE_CHECKING, Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 if TYPE_CHECKING:
     from github.Issue import Issue
 
 
 class GitHubAPIWrapper(BaseModel):
     """Wrapper for GitHub API."""
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/golden_query.py` & `oplangchain-0.1.1/oplangchain/utilities/golden_query.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Util that calls Golden."""
 import json
 from typing import Dict, Optional
 
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 GOLDEN_BASE_URL = "https://golden.com"
 GOLDEN_TIMEOUT = 5000
 
 
 class GoldenQueryAPIWrapper(BaseModel):
     """Wrapper for Golden.
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/google_places_api.py` & `oplangchain-0.1.1/oplangchain/utilities/google_places_api.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 """
 
 import logging
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class GooglePlacesAPIWrapper(BaseModel):
     """Wrapper around Google Places API.
 
     To use, you should have the ``googlemaps`` python package installed,
      **an API key for the google maps platform**,
@@ -21,15 +21,15 @@
     By default, this will return the all the results on the input query.
      You can use the top_k_results argument to limit the number of results.
 
     Example:
         .. code-block:: python
 
 
-            from langchain import GooglePlacesAPIWrapper
+            from oplangchain import GooglePlacesAPIWrapper
             gplaceapi = GooglePlacesAPIWrapper()
     """
 
     gplaces_api_key: Optional[str] = None
     google_map_client: Any  #: :meta private:
     top_k_results: Optional[int] = None
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/google_search.py` & `oplangchain-0.1.1/oplangchain/utilities/google_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Util that calls Google Search."""
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class GoogleSearchAPIWrapper(BaseModel):
     """Wrapper for Google Search API.
 
     Adapted from: Instructions adapted from https://stackoverflow.com/questions/
     37083058/
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/google_serper.py` & `oplangchain-0.1.1/oplangchain/utilities/google_serper.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,30 +3,30 @@
 
 import aiohttp
 import requests
 from pydantic.class_validators import root_validator
 from pydantic.main import BaseModel
 from typing_extensions import Literal
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class GoogleSerperAPIWrapper(BaseModel):
     """Wrapper around the Serper.dev Google Search API.
 
     You can create a free API key at https://serper.dev.
 
     To use, you should have the environment variable ``SERPER_API_KEY``
     set with your API key, or pass `serper_api_key` as a named parameter
     to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain import GoogleSerperAPIWrapper
+            from oplangchain import GoogleSerperAPIWrapper
             google_serper = GoogleSerperAPIWrapper()
     """
 
     k: int = 10
     gl: str = "us"
     hl: str = "en"
     # "places" and "images" is available from Serper but not implemented in the
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/graphql.py` & `oplangchain-0.1.1/oplangchain/utilities/graphql.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/jira.py` & `oplangchain-0.1.1/oplangchain/utilities/jira.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Util that calls Jira."""
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 # TODO: think about error handling, more specific api specs, and jql/project limits
 class JiraAPIWrapper(BaseModel):
     """Wrapper for Jira API."""
 
     jira: Any  #: :meta private:
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/loading.py` & `oplangchain-0.1.1/oplangchain/utilities/loading.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-"""Utilities for loading configurations from langchain-hub."""
+"""Utilities for loading configurations from oplangchain-hub."""
 
 import os
 import re
 import tempfile
 from pathlib import Path, PurePosixPath
 from typing import Any, Callable, Optional, Set, TypeVar, Union
 from urllib.parse import urljoin
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/max_compute.py` & `oplangchain-0.1.1/oplangchain/utilities/max_compute.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING, Iterator, List, Optional
 
-from langchain.utils import get_from_env
+from oplangchain.utils import get_from_env
 
 if TYPE_CHECKING:
     from odps import ODPS
 
 
 class MaxComputeAPIWrapper:
     """Interface for querying Alibaba Cloud MaxCompute tables."""
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/metaphor_search.py` & `oplangchain-0.1.1/oplangchain/utilities/metaphor_search.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import json
 from typing import Dict, List, Optional
 
 import aiohttp
 import requests
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 METAPHOR_API_URL = "https://api.metaphor.systems"
 
 
 class MetaphorSearchAPIWrapper(BaseModel):
     """Wrapper for Metaphor Search API."""
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/openapi.py` & `oplangchain-0.1.1/oplangchain/utilities/openapi.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/openweathermap.py` & `oplangchain-0.1.1/oplangchain/utilities/openweathermap.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Util that calls OpenWeatherMap using PyOWM."""
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class OpenWeatherMapAPIWrapper(BaseModel):
     """Wrapper for OpenWeatherMap API using PyOWM.
 
     Docs for using:
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/portkey.py` & `oplangchain-0.1.1/oplangchain/utilities/portkey.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/powerbi.py` & `oplangchain-0.1.1/oplangchain/utilities/powerbi.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/pupmed.py` & `oplangchain-0.1.1/oplangchain/utilities/pupmed.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 import time
 import urllib.error
 import urllib.request
 from typing import List
 
 from pydantic import BaseModel
 
-from langchain.schema import Document
+from oplangchain.schema import Document
 
 logger = logging.getLogger(__name__)
 
 
 class PubMedAPIWrapper(BaseModel):
     """
     Wrapper around PubMed API.
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/python.py` & `oplangchain-0.1.1/oplangchain/utilities/python.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/redis.py` & `oplangchain-0.1.1/oplangchain/utilities/redis.py`

 * *Files 5% similar despite different names*

```diff
@@ -24,15 +24,15 @@
     an and ValueError raised otherwise
 
     To use, you should have the ``redis`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities.redis import get_client
+            from oplangchain.utilities.redis import get_client
             redis_client = get_client(
                 redis_url="redis://username:password@localhost:6379"
                 index_name="my-index",
                 embedding_function=embeddings.embed_query,
             )
 
     To use a redis replication setup with multiple redis server and redis sentinels
@@ -44,15 +44,15 @@
     An optional username or password is used for booth connections to the rediserver
     and the sentinel, different passwords for server and sentinel are not supported.
     And as another constraint only one sentinel instance can be given:
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities.redis import get_client
+            from oplangchain.utilities.redis import get_client
             redis_client = get_client(
                 redis_url="redis+sentinel://username:password@sentinelhost:26379/mymaster/0"
                 index_name="my-index",
                 embedding_function=embeddings.embed_query,
             )
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/requests.py` & `oplangchain-0.1.1/oplangchain/utilities/requests.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/scenexplain.py` & `oplangchain-0.1.1/oplangchain/utilities/scenexplain.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 - Navigate to the API Access page (https://scenex.jina.ai/api) and create a new API key.
 """
 from typing import Dict
 
 import requests
 from pydantic import BaseModel, BaseSettings, Field, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class SceneXplainAPIWrapper(BaseSettings, BaseModel):
     """Wrapper for SceneXplain API.
 
     In order to set this up, you need API key for the SceneXplain API.
     You can obtain a key by following the steps below.
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/searx_search.py` & `oplangchain-0.1.1/oplangchain/utilities/searx_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 or exporting the environment variable SEARX_HOST.
 Note: this is the only required parameter.
 
 Then create a searx search instance like this:
 
     .. code-block:: python
 
-        from langchain.utilities import SearxSearchWrapper
+        from oplangchain.utilities import SearxSearchWrapper
 
         # when the host starts with `http` SSL is disabled and the connection
         # is assumed to be on a private network
         searx_host='http://self.hosted'
 
         search = SearxSearchWrapper(searx_host=searx_host)
 
@@ -130,15 +130,15 @@
 import json
 from typing import Any, Dict, List, Optional
 
 import aiohttp
 import requests
 from pydantic import BaseModel, Extra, Field, PrivateAttr, root_validator, validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 def _get_default_params() -> dict:
     return {"language": "en", "format": "json"}
 
 
 class SearxResults(dict):
@@ -179,21 +179,21 @@
     In some situations you might want to disable SSL verification, for example
     if you are running searx locally. You can do this by passing the named parameter
     ``unsecure``. You can also pass the host url scheme as ``http`` to disable SSL.
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities import SearxSearchWrapper
+            from oplangchain.utilities import SearxSearchWrapper
             searx = SearxSearchWrapper(searx_host="http://localhost:8888")
 
     Example with SSL disabled:
         .. code-block:: python
 
-            from langchain.utilities import SearxSearchWrapper
+            from oplangchain.utilities import SearxSearchWrapper
             # note the unsecure parameter is not needed if you pass the url scheme as
             # http
             searx = SearxSearchWrapper(searx_host="http://localhost:8888",
                                                     unsecure=True)
 
 
     """
@@ -326,15 +326,15 @@
 
 
         Example:
             This will make a query to the qwant engine:
 
             .. code-block:: python
 
-                from langchain.utilities import SearxSearchWrapper
+                from oplangchain.utilities import SearxSearchWrapper
                 searx = SearxSearchWrapper(searx_host="http://my.searx.host")
                 searx.run("what is the weather in France ?", engine="qwant")
 
                 # the same result can be achieved using the `!` syntax of searx
                 # to select the engine using `query_suffix`
                 searx.run("what is the weather in France ?", query_suffix="!qwant")
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/serpapi.py` & `oplangchain-0.1.1/oplangchain/utilities/serpapi.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 import os
 import sys
 from typing import Any, Dict, Optional, Tuple
 
 import aiohttp
 from pydantic import BaseModel, Extra, Field, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class HiddenPrints:
     """Context manager to hide prints."""
 
     def __enter__(self) -> None:
         """Open file to pipe stdout to."""
@@ -32,15 +32,15 @@
     To use, you should have the ``google-search-results`` python package installed,
     and the environment variable ``SERPAPI_API_KEY`` set with your API key, or pass
     `serpapi_api_key` as a named parameter to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities import SerpAPIWrapper
+            from oplangchain.utilities import SerpAPIWrapper
             serpapi = SerpAPIWrapper()
     """
 
     search_engine: Any  #: :meta private:
     params: dict = Field(
         default={
             "engine": "google",
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/spark_sql.py` & `oplangchain-0.1.1/oplangchain/utilities/spark_sql.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/sql_database.py` & `oplangchain-0.1.1/oplangchain/utilities/sql_database.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 
 import sqlalchemy
 from sqlalchemy import MetaData, Table, create_engine, inspect, select, text
 from sqlalchemy.engine import Engine
 from sqlalchemy.exc import ProgrammingError, SQLAlchemyError
 from sqlalchemy.schema import CreateTable
 
-from langchain.utils import get_from_env
+from oplangchain.utils import get_from_env
 
 
 def _format_index(index: sqlalchemy.engine.interfaces.ReflectedIndex) -> str:
     return (
         f'Name: {index["name"]}, Unique: {index["unique"]},'
         f' Columns: {str(index["column_names"])}'
     )
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/twilio.py` & `oplangchain-0.1.1/oplangchain/utilities/twilio.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 """Util that calls Twilio."""
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class TwilioAPIWrapper(BaseModel):
     """Messaging Client using Twilio.
 
     To use, you should have the ``twilio`` python package installed,
     and the environment variables ``TWILIO_ACCOUNT_SID``, ``TWILIO_AUTH_TOKEN``, and
     ``TWILIO_FROM_NUMBER``, or pass `account_sid`, `auth_token`, and `from_number` as
     named parameters to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain.utilities.twilio import TwilioAPIWrapper
+            from oplangchain.utilities.twilio import TwilioAPIWrapper
             twilio = TwilioAPIWrapper(
                 account_sid="ACxxx",
                 auth_token="xxx",
                 from_number="+10123456789"
             )
             twilio.run('test', '+12484345508')
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/vertexai.py` & `oplangchain-0.1.1/oplangchain/utilities/vertexai.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utilities/wikipedia.py` & `oplangchain-0.1.1/oplangchain/utilities/wikipedia.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Util that calls Wikipedia."""
 import logging
 from typing import Any, Dict, List, Optional
 
 from pydantic import BaseModel, root_validator
 
-from langchain.schema import Document
+from oplangchain.schema import Document
 
 logger = logging.getLogger(__name__)
 
 WIKIPEDIA_MAX_QUERY_LENGTH = 300
 
 
 class WikipediaAPIWrapper(BaseModel):
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/wolfram_alpha.py` & `oplangchain-0.1.1/oplangchain/utilities/wolfram_alpha.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """Util that calls WolframAlpha."""
 from typing import Any, Dict, Optional
 
 from pydantic import BaseModel, Extra, root_validator
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class WolframAlphaAPIWrapper(BaseModel):
     """Wrapper for Wolfram Alpha.
 
     Docs for using:
```

### Comparing `oplangchain-0.1.0/oplangchain/utilities/zapier.py` & `oplangchain-0.1.1/oplangchain/utilities/zapier.py`

 * *Files 0% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 from typing import Any, Dict, List, Optional
 
 import aiohttp
 import requests
 from pydantic import BaseModel, Extra, root_validator
 from requests import Request, Session
 
-from langchain.utils import get_from_dict_or_env
+from oplangchain.utils import get_from_dict_or_env
 
 
 class ZapierNLAWrapper(BaseModel):
     """Wrapper for Zapier NLA.
 
     Full docs here: https://nla.zapier.com/start/
```

### Comparing `oplangchain-0.1.0/oplangchain/utils/__init__.py` & `oplangchain-0.1.1/oplangchain/utils/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 """
 **Utility functions** for LangChain.
 
 These functions do not depend on any other LangChain module.
 """
 
-from langchain.utils.env import get_from_dict_or_env, get_from_env
-from langchain.utils.formatting import StrictFormatter, formatter
-from langchain.utils.input import (
+from oplangchain.utils.env import get_from_dict_or_env, get_from_env
+from oplangchain.utils.formatting import StrictFormatter, formatter
+from oplangchain.utils.input import (
     get_bolded_text,
     get_color_mapping,
     get_colored_text,
     print_text,
 )
-from langchain.utils.math import cosine_similarity, cosine_similarity_top_k
-from langchain.utils.strings import comma_list, stringify_dict, stringify_value
-from langchain.utils.utils import (
+from oplangchain.utils.math import cosine_similarity, cosine_similarity_top_k
+from oplangchain.utils.strings import comma_list, stringify_dict, stringify_value
+from oplangchain.utils.utils import (
     check_package_version,
     get_pydantic_field_names,
     guard_import,
     mock_now,
     raise_for_status_with_text,
     xor_args,
 )
```

### Comparing `oplangchain-0.1.0/oplangchain/utils/env.py` & `oplangchain-0.1.1/oplangchain/utils/env.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utils/formatting.py` & `oplangchain-0.1.1/oplangchain/utils/formatting.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utils/input.py` & `oplangchain-0.1.1/oplangchain/utils/input.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utils/math.py` & `oplangchain-0.1.1/oplangchain/utils/math.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utils/strings.py` & `oplangchain-0.1.1/oplangchain/utils/strings.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/utils/utils.py` & `oplangchain-0.1.1/oplangchain/utils/utils.py`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/__init__.py` & `oplangchain-0.1.1/oplangchain/vectorstores/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,61 +14,61 @@
 
 **Main helpers:**
 
 .. code-block::
 
     Embeddings, Document
 """  # noqa: E501
-from langchain.vectorstores.alibabacloud_opensearch import (
+from oplangchain.vectorstores.alibabacloud_opensearch import (
     AlibabaCloudOpenSearch,
     AlibabaCloudOpenSearchSettings,
 )
-from langchain.vectorstores.analyticdb import AnalyticDB
-from langchain.vectorstores.annoy import Annoy
-from langchain.vectorstores.atlas import AtlasDB
-from langchain.vectorstores.awadb import AwaDB
-from langchain.vectorstores.azuresearch import AzureSearch
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.cassandra import Cassandra
-from langchain.vectorstores.chroma import Chroma
-from langchain.vectorstores.clarifai import Clarifai
-from langchain.vectorstores.clickhouse import Clickhouse, ClickhouseSettings
-from langchain.vectorstores.deeplake import DeepLake
-from langchain.vectorstores.docarray import DocArrayHnswSearch, DocArrayInMemorySearch
-from langchain.vectorstores.elastic_vector_search import (
+from oplangchain.vectorstores.analyticdb import AnalyticDB
+from oplangchain.vectorstores.annoy import Annoy
+from oplangchain.vectorstores.atlas import AtlasDB
+from oplangchain.vectorstores.awadb import AwaDB
+from oplangchain.vectorstores.azuresearch import AzureSearch
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.cassandra import Cassandra
+from oplangchain.vectorstores.chroma import Chroma
+from oplangchain.vectorstores.clarifai import Clarifai
+from oplangchain.vectorstores.clickhouse import Clickhouse, ClickhouseSettings
+from oplangchain.vectorstores.deeplake import DeepLake
+from oplangchain.vectorstores.docarray import DocArrayHnswSearch, DocArrayInMemorySearch
+from oplangchain.vectorstores.elastic_vector_search import (
     ElasticKnnSearch,
     ElasticVectorSearch,
 )
-from langchain.vectorstores.faiss import FAISS
-from langchain.vectorstores.hologres import Hologres
-from langchain.vectorstores.lancedb import LanceDB
-from langchain.vectorstores.marqo import Marqo
-from langchain.vectorstores.matching_engine import MatchingEngine
-from langchain.vectorstores.meilisearch import Meilisearch
-from langchain.vectorstores.milvus import Milvus
-from langchain.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch
-from langchain.vectorstores.myscale import MyScale, MyScaleSettings
-from langchain.vectorstores.opensearch_vector_search import OpenSearchVectorSearch
-from langchain.vectorstores.pgembedding import PGEmbedding
-from langchain.vectorstores.pgvector import PGVector
-from langchain.vectorstores.pinecone import Pinecone
-from langchain.vectorstores.qdrant import Qdrant
-from langchain.vectorstores.redis import Redis
-from langchain.vectorstores.rocksetdb import Rockset
-from langchain.vectorstores.scann import ScaNN
-from langchain.vectorstores.singlestoredb import SingleStoreDB
-from langchain.vectorstores.sklearn import SKLearnVectorStore
-from langchain.vectorstores.starrocks import StarRocks
-from langchain.vectorstores.supabase import SupabaseVectorStore
-from langchain.vectorstores.tair import Tair
-from langchain.vectorstores.tigris import Tigris
-from langchain.vectorstores.typesense import Typesense
-from langchain.vectorstores.vectara import Vectara
-from langchain.vectorstores.weaviate import Weaviate
-from langchain.vectorstores.zilliz import Zilliz
+from oplangchain.vectorstores.faiss import FAISS
+from oplangchain.vectorstores.hologres import Hologres
+from oplangchain.vectorstores.lancedb import LanceDB
+from oplangchain.vectorstores.marqo import Marqo
+from oplangchain.vectorstores.matching_engine import MatchingEngine
+from oplangchain.vectorstores.meilisearch import Meilisearch
+from oplangchain.vectorstores.milvus import Milvus
+from oplangchain.vectorstores.mongodb_atlas import MongoDBAtlasVectorSearch
+from oplangchain.vectorstores.myscale import MyScale, MyScaleSettings
+from oplangchain.vectorstores.opensearch_vector_search import OpenSearchVectorSearch
+from oplangchain.vectorstores.pgembedding import PGEmbedding
+from oplangchain.vectorstores.pgvector import PGVector
+from oplangchain.vectorstores.pinecone import Pinecone
+from oplangchain.vectorstores.qdrant import Qdrant
+from oplangchain.vectorstores.redis import Redis
+from oplangchain.vectorstores.rocksetdb import Rockset
+from oplangchain.vectorstores.scann import ScaNN
+from oplangchain.vectorstores.singlestoredb import SingleStoreDB
+from oplangchain.vectorstores.sklearn import SKLearnVectorStore
+from oplangchain.vectorstores.starrocks import StarRocks
+from oplangchain.vectorstores.supabase import SupabaseVectorStore
+from oplangchain.vectorstores.tair import Tair
+from oplangchain.vectorstores.tigris import Tigris
+from oplangchain.vectorstores.typesense import Typesense
+from oplangchain.vectorstores.vectara import Vectara
+from oplangchain.vectorstores.weaviate import Weaviate
+from oplangchain.vectorstores.zilliz import Zilliz
 
 __all__ = [
     "AlibabaCloudOpenSearch",
     "AlibabaCloudOpenSearchSettings",
     "AnalyticDB",
     "Annoy",
     "AtlasDB",
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/_pgvector_data_models.py` & `oplangchain-0.1.1/oplangchain/vectorstores/_pgvector_data_models.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from typing import Optional, Tuple
 
 import sqlalchemy
 from pgvector.sqlalchemy import Vector
 from sqlalchemy.dialects.postgresql import JSON, UUID
 from sqlalchemy.orm import Session, relationship
 
-from langchain.vectorstores.pgvector import BaseModel
+from oplangchain.vectorstores.pgvector import BaseModel
 
 
 class CollectionStore(BaseModel):
     __tablename__ = "langchain_pg_collection"
 
     name = sqlalchemy.Column(sqlalchemy.String)
     cmetadata = sqlalchemy.Column(JSON)
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/alibabacloud_opensearch.py` & `oplangchain-0.1.1/oplangchain/vectorstores/alibabacloud_opensearch.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 import json
 import logging
 import numbers
 from hashlib import sha1
 from typing import Any, Dict, Iterable, List, Optional, Tuple
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import Document
-from langchain.vectorstores.base import VectorStore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import Document
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger()
 
 
 class AlibabaCloudOpenSearchSettings:
     """Opensearch Client Configuration
     Attribute:
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/analyticdb.py` & `oplangchain-0.1.1/oplangchain/vectorstores/analyticdb.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 from sqlalchemy.dialects.postgresql import ARRAY, JSON, TEXT
 
 try:
     from sqlalchemy.orm import declarative_base
 except ImportError:
     from sqlalchemy.ext.declarative import declarative_base
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 _LANGCHAIN_DEFAULT_EMBEDDING_DIM = 1536
 _LANGCHAIN_DEFAULT_COLLECTION_NAME = "langchain_document"
 
 Base = declarative_base()  # type: Any
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/annoy.py` & `oplangchain-0.1.1/oplangchain/vectorstores/annoy.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,20 +6,20 @@
 import uuid
 from configparser import ConfigParser
 from pathlib import Path
 from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple
 
 import numpy as np
 
-from langchain.docstore.base import Docstore
-from langchain.docstore.document import Document
-from langchain.docstore.in_memory import InMemoryDocstore
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.base import Docstore
+from oplangchain.docstore.document import Document
+from oplangchain.docstore.in_memory import InMemoryDocstore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 INDEX_METRICS = frozenset(["angular", "euclidean", "manhattan", "hamming", "dot"])
 DEFAULT_METRIC = "angular"
 
 
 def dependable_annoy_import() -> Any:
     """Import annoy if available, otherwise raise error."""
@@ -37,15 +37,15 @@
     """Wrapper around Annoy vector database.
 
     To use, you should have the ``annoy`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain import Annoy
+            from oplangchain import Annoy
             db = Annoy(embedding_function, index, docstore, index_to_docstore_id)
 
     """
 
     def __init__(
         self,
         embedding_function: Callable,
@@ -347,16 +347,16 @@
             3. Initializes the Annoy database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Annoy
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Annoy
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 index = Annoy.from_texts(texts, embeddings)
         """
         embeddings = embedding.embed_documents(texts)
         return cls.__from(
             texts, embeddings, embedding, metadatas, metric, trees, n_jobs, **kwargs
         )
@@ -387,16 +387,16 @@
             2. Initializes the Annoy database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Annoy
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Annoy
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 text_embeddings = embeddings.embed_documents(texts)
                 text_embedding_pairs = list(zip(texts, text_embeddings))
                 db = Annoy.from_embeddings(text_embedding_pairs, embeddings)
         """
         texts = [t[0] for t in text_embeddings]
         embeddings = [t[1] for t in text_embeddings]
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/atlas.py` & `oplangchain-0.1.1/oplangchain/vectorstores/atlas.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,31 +3,31 @@
 
 import logging
 import uuid
 from typing import Any, Iterable, List, Optional, Type
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger(__name__)
 
 
 class AtlasDB(VectorStore):
     """Wrapper around Atlas: Nomic's neural database and rhizomatic instrument.
 
     To use, you should have the ``nomic`` python package installed.
 
     Example:
         .. code-block:: python
 
-                from langchain.vectorstores import AtlasDB
-                from langchain.embeddings.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import AtlasDB
+                from oplangchain.embeddings.openai import OpenAIEmbeddings
 
                 embeddings = OpenAIEmbeddings()
                 vectorstore = AtlasDB("my_project", embeddings.embed_query)
     """
 
     _ATLAS_DEFAULT_ID_FIELD = "atlas_id"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/awadb.py` & `oplangchain-0.1.1/oplangchain/vectorstores/awadb.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 
 import logging
 import uuid
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Set, Tuple, Type
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     import awadb
 
 logger = logging.getLogger()
 DEFAULT_TOPN = 4
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/azuresearch.py` & `oplangchain-0.1.1/oplangchain/vectorstores/azuresearch.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,23 +16,23 @@
     Tuple,
     Type,
 )
 
 import numpy as np
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever
-from langchain.utils import get_from_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever
+from oplangchain.utils import get_from_env
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger()
 
 if TYPE_CHECKING:
     from azure.search.documents import SearchClient
     from azure.search.documents.indexes.models import (
         ScoringProfile,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/base.py` & `oplangchain-0.1.1/oplangchain/vectorstores/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,21 +20,21 @@
     Tuple,
     Type,
     TypeVar,
 )
 
 from pydantic import Field, root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.schema import BaseRetriever
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import BaseRetriever
 
 logger = logging.getLogger(__name__)
 
 VST = TypeVar("VST", bound="VectorStore")
 
 
 class VectorStore(ABC):
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/cassandra.py` & `oplangchain-0.1.1/oplangchain/vectorstores/cassandra.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,33 +6,33 @@
 from typing import Any, Callable, Iterable, List, Optional, Tuple, Type, TypeVar
 
 import numpy as np
 
 if typing.TYPE_CHECKING:
     from cassandra.cluster import Session
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 CVST = TypeVar("CVST", bound="Cassandra")
 
 
 class Cassandra(VectorStore):
     """Wrapper around Cassandra embeddings platform.
 
     There is no notion of a default table name, since each embedding
     function implies its own vector dimension, which is part of the schema.
 
     Example:
         .. code-block:: python
 
-                from langchain.vectorstores import Cassandra
-                from langchain.embeddings.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import Cassandra
+                from oplangchain.embeddings.openai import OpenAIEmbeddings
 
                 embeddings = OpenAIEmbeddings()
                 session = ...
                 keyspace = 'my_keyspace'
                 vectorstore = Cassandra(embeddings, session, keyspace, 'my_doc_archive')
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/chroma.py` & `oplangchain-0.1.1/oplangchain/vectorstores/chroma.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,19 +13,19 @@
     Optional,
     Tuple,
     Type,
 )
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import xor_args
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import xor_args
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     import chromadb
     import chromadb.config
     from chromadb.api.types import ID, OneOrMany, Where, WhereDocument
 
 logger = logging.getLogger()
@@ -53,16 +53,16 @@
     """Wrapper around ChromaDB embeddings platform.
 
     To use, you should have the ``chromadb`` python package installed.
 
     Example:
         .. code-block:: python
 
-                from langchain.vectorstores import Chroma
-                from langchain.embeddings.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import Chroma
+                from oplangchain.embeddings.openai import OpenAIEmbeddings
 
                 embeddings = OpenAIEmbeddings()
                 vectorstore = Chroma("langchain_store", embeddings)
     """
 
     _LANGCHAIN_DEFAULT_COLLECTION_NAME = "langchain"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/clarifai.py` & `oplangchain-0.1.1/oplangchain/vectorstores/clarifai.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,31 +3,31 @@
 import logging
 import os
 import traceback
 from typing import Any, Iterable, List, Optional, Tuple
 
 import requests
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger(__name__)
 
 
 class Clarifai(VectorStore):
     """Wrapper around Clarifai AI platform's vector store.
 
     To use, you should have the ``clarifai`` python package installed.
 
     Example:
         .. code-block:: python
 
-                from langchain.vectorstores import Clarifai
-                from langchain.embeddings.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import Clarifai
+                from oplangchain.embeddings.openai import OpenAIEmbeddings
 
                 embeddings = OpenAIEmbeddings()
                 vectorstore = Clarifai("langchain_store", embeddings.embed_query)
     """
 
     def __init__(
         self,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/clickhouse.py` & `oplangchain-0.1.1/oplangchain/vectorstores/clickhouse.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 import logging
 from hashlib import sha1
 from threading import Thread
 from typing import Any, Dict, Iterable, List, Optional, Tuple, Union
 
 from pydantic import BaseSettings
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger()
 
 
 def has_mul_sub_str(s: str, *args: Any) -> bool:
     """
     Check if a string contains multiple substrings.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/deeplake.py` & `oplangchain-0.1.1/oplangchain/vectorstores/deeplake.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,18 +11,18 @@
     from deeplake.core.fast_forwarding import version_compare
     from deeplake.core.vectorstore import DeepLakeVectorStore
 
     _DEEPLAKE_INSTALLED = True
 except ImportError:
     _DEEPLAKE_INSTALLED = False
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 logger = logging.getLogger(__name__)
 
 
 class DeepLake(VectorStore):
     """Wrapper around Deep Lake, a data lake for deep learning applications.
 
@@ -39,16 +39,16 @@
         to fine-tune your own LLM models.
 
     To use, you should have the ``deeplake`` python package installed.
 
     Example:
         .. code-block:: python
 
-                from langchain.vectorstores import DeepLake
-                from langchain.embeddings.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import DeepLake
+                from oplangchain.embeddings.openai import OpenAIEmbeddings
 
                 embeddings = OpenAIEmbeddings()
                 vectorstore = DeepLake("langchain_store", embeddings.embed_query)
     """
 
     _LANGCHAIN_DEFAULT_DEEPLAKE_PATH = "./deeplake/"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/docarray/base.py` & `oplangchain-0.1.1/oplangchain/vectorstores/docarray/base.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from abc import ABC
 from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Tuple, Type
 
 import numpy as np
 from pydantic import Field
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import Document
-from langchain.vectorstores import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import Document
+from oplangchain.vectorstores import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     from docarray import BaseDoc
     from docarray.index.abstract import BaseDocIndex
 
 
 def _check_docarray_import() -> None:
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/docarray/hnsw.py` & `oplangchain-0.1.1/oplangchain/vectorstores/docarray/hnsw.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Wrapper around Hnswlib store."""
 from __future__ import annotations
 
 from typing import Any, List, Literal, Optional
 
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.docarray.base import (
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.docarray.base import (
     DocArrayIndex,
     _check_docarray_import,
 )
 
 
 class DocArrayHnswSearch(DocArrayIndex):
     """Wrapper around HnswLib storage.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/docarray/in_memory.py` & `oplangchain-0.1.1/oplangchain/vectorstores/docarray/in_memory.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Wrapper around in-memory storage."""
 from __future__ import annotations
 
 from typing import Any, Dict, List, Literal, Optional
 
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.docarray.base import (
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.docarray.base import (
     DocArrayIndex,
     _check_docarray_import,
 )
 
 
 class DocArrayInMemorySearch(DocArrayIndex):
     """Wrapper around in-memory storage for exact search.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/elastic_vector_search.py` & `oplangchain-0.1.1/oplangchain/vectorstores/elastic_vector_search.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,18 +11,18 @@
     List,
     Mapping,
     Optional,
     Tuple,
     Union,
 )
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
     from elasticsearch import Elasticsearch
 
 
 def _default_text_mapping(dim: int) -> Dict:
     return {
@@ -63,16 +63,16 @@
     To connect to an Elasticsearch instance that does not require
     login credentials, pass the Elasticsearch URL and index name along with the
     embedding object to the constructor.
 
     Example:
         .. code-block:: python
 
-            from langchain import ElasticVectorSearch
-            from langchain.embeddings import OpenAIEmbeddings
+            from oplangchain import ElasticVectorSearch
+            from oplangchain.embeddings import OpenAIEmbeddings
 
             embedding = OpenAIEmbeddings()
             elastic_vector_search = ElasticVectorSearch(
                 elasticsearch_url="http://localhost:9200",
                 index_name="test_index",
                 embedding=embedding
             )
@@ -99,16 +99,16 @@
 
     The format for Elastic Cloud URLs is
     https://username:password@cluster_id.region_id.gcp.cloud.es.io:9243.
 
     Example:
         .. code-block:: python
 
-            from langchain import ElasticVectorSearch
-            from langchain.embeddings import OpenAIEmbeddings
+            from oplangchain import ElasticVectorSearch
+            from oplangchain.embeddings import OpenAIEmbeddings
 
             embedding = OpenAIEmbeddings()
 
             elastic_host = "cluster_id.region_id.gcp.cloud.es.io"
             elasticsearch_url = f"https://username:password@{elastic_host}:9243"
             elastic_vector_search = ElasticVectorSearch(
                 elasticsearch_url=elasticsearch_url,
@@ -278,16 +278,16 @@
             3. Adds the documents to the newly created Elasticsearch index.
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import ElasticVectorSearch
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import ElasticVectorSearch
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 elastic_vector_search = ElasticVectorSearch.from_texts(
                     texts,
                     embeddings,
                     elasticsearch_url="http://localhost:9200"
                 )
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/faiss.py` & `oplangchain-0.1.1/oplangchain/vectorstores/faiss.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,20 +7,20 @@
 import uuid
 import warnings
 from pathlib import Path
 from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple
 
 import numpy as np
 
-from langchain.docstore.base import AddableMixin, Docstore
-from langchain.docstore.document import Document
-from langchain.docstore.in_memory import InMemoryDocstore
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import DistanceStrategy, maximal_marginal_relevance
+from oplangchain.docstore.base import AddableMixin, Docstore
+from oplangchain.docstore.document import Document
+from oplangchain.docstore.in_memory import InMemoryDocstore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import DistanceStrategy, maximal_marginal_relevance
 
 
 def dependable_faiss_import(no_avx2: Optional[bool] = None) -> Any:
     """
     Import faiss if available, otherwise raise error.
     If FAISS_NO_AVX2 environment variable is set, it will be considered
     to load FAISS with no AVX2 optimization.
@@ -50,15 +50,15 @@
     """Wrapper around FAISS vector database.
 
     To use, you should have the ``faiss`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain import FAISS
+            from oplangchain import FAISS
             faiss = FAISS(embedding_function, index, docstore, index_to_docstore_id)
 
     """
 
     def __init__(
         self,
         embedding_function: Callable,
@@ -595,16 +595,16 @@
             3. Initializes the FAISS database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import FAISS
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import FAISS
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 faiss = FAISS.from_texts(texts, embeddings)
         """
         embeddings = embedding.embed_documents(texts)
         return cls.__from(
             texts,
             embeddings,
@@ -631,16 +631,16 @@
             3. Initializes the FAISS database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import FAISS
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import FAISS
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 text_embeddings = embeddings.embed_documents(texts)
                 text_embedding_pairs = list(zip(texts, text_embeddings))
                 faiss = FAISS.from_embeddings(text_embedding_pairs, embeddings)
         """
         texts = [t[0] for t in text_embeddings]
         embeddings = [t[1] for t in text_embeddings]
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/hologres.py` & `oplangchain-0.1.1/oplangchain/vectorstores/hologres.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,18 +2,18 @@
 from __future__ import annotations
 
 import json
 import logging
 import uuid
 from typing import Any, Dict, Iterable, List, Optional, Tuple, Type
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 ADA_TOKEN_COUNT = 1536
 _LANGCHAIN_DEFAULT_TABLE_NAME = "langchain_pg_embedding"
 
 
 class HologresWrapper:
     def __init__(self, connection_string: str, ndims: int, table_name: str) -> None:
@@ -390,16 +390,16 @@
         Postgres connection string is required
         "Either pass it as a parameter
         or set the HOLOGRES_CONNECTION_STRING environment variable.
 
         Example:
             .. code-block:: python
 
-                from langchain import Hologres
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Hologres
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 text_embeddings = embeddings.embed_documents(texts)
                 text_embedding_pairs = list(zip(texts, text_embeddings))
                 faiss = Hologres.from_embeddings(text_embedding_pairs, embeddings)
         """
         texts = [t[0] for t in text_embeddings]
         embeddings = [t[1] for t in text_embeddings]
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/lancedb.py` & `oplangchain-0.1.1/oplangchain/vectorstores/lancedb.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 """Wrapper around LanceDB vector database"""
 from __future__ import annotations
 
 import uuid
 from typing import Any, Iterable, List, Optional
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 
 class LanceDB(VectorStore):
     """Wrapper around LanceDB vector database.
 
     To use, you should have ``lancedb`` python package installed.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/marqo.py` & `oplangchain-0.1.1/oplangchain/vectorstores/marqo.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,17 +12,17 @@
     List,
     Optional,
     Tuple,
     Type,
     Union,
 )
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
     import marqo
 
 
 class Marqo(VectorStore):
     """Wrapper around Marqo database.
@@ -40,15 +40,15 @@
     To use, you should have the `marqo` python package installed, you can do this with
     `pip install marqo`.
 
     Example:
         .. code-block:: python
 
             import marqo
-            from langchain.vectorstores import Marqo
+            from oplangchain.vectorstores import Marqo
             client = marqo.Client(url=os.environ["MARQO_URL"], ...)
             vectorstore = Marqo(client, index_name)
 
     """
 
     def __init__(
         self,
@@ -392,15 +392,15 @@
 
         To know the ids of your documents with this approach you will need to include
         them in under the key "_id" in your metadatas for each text
 
         Example:
         .. code-block:: python
 
-                from langchain.vectorstores import Marqo
+                from oplangchain.vectorstores import Marqo
 
                 datastore = Marqo(texts=['text'], index_name='my-first-index',
                 url='http://localhost:8882')
 
         Args:
             texts (List[str]): A list of texts to index into marqo upon creation.
             embedding (Any, optional): Embeddings (not required). Defaults to None.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/matching_engine.py` & `oplangchain-0.1.1/oplangchain/vectorstores/matching_engine.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 
 import json
 import logging
 import time
 import uuid
 from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Type
 
-from langchain.docstore.document import Document
-from langchain.embeddings import TensorflowHubEmbeddings
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings import TensorflowHubEmbeddings
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
     from google.cloud import storage
     from google.cloud.aiplatform import MatchingEngineIndex, MatchingEngineIndexEndpoint
     from google.oauth2.service_account import Credentials
 
 logger = logging.getLogger()
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/meilisearch.py` & `oplangchain-0.1.1/oplangchain/vectorstores/meilisearch.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Wrapper around Meilisearch vector database."""
 from __future__ import annotations
 
 import uuid
 from typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, Tuple, Type
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_env
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
     from meilisearch import Client
 
 
 def _create_client(
     client: Optional[Client] = None,
@@ -55,16 +55,16 @@
 
     See the following documentation for how to run a Meilisearch instance:
     https://www.meilisearch.com/docs/learn/getting_started/quick_start.
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import Meilisearch
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import Meilisearch
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
             import meilisearch
 
             # api_key is optional; provide it if your meilisearch instance requires it
             client = meilisearch.Client(url='http://127.0.0.1:7700', api_key='***')
             embeddings = OpenAIEmbeddings()
             vectorstore = Meilisearch(
                 embedding=embeddings,
@@ -278,16 +278,16 @@
             2. Adds the documents to a provided Meilisearch index.
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Meilisearch
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Meilisearch
+                from oplangchain.embeddings import OpenAIEmbeddings
                 import meilisearch
 
                 # The environment should be the one specified next to the API key
                 # in your Meilisearch console
                 client = meilisearch.Client(url='http://127.0.0.1:7700', api_key='***')
                 embeddings = OpenAIEmbeddings()
                 docsearch = Meilisearch.from_texts(
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/milvus.py` & `oplangchain-0.1.1/oplangchain/vectorstores/milvus.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,18 +3,18 @@
 
 import logging
 from typing import Any, Iterable, List, Optional, Tuple, Union
 from uuid import uuid4
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 logger = logging.getLogger(__name__)
 
 DEFAULT_MILVUS_CONNECTION = {
     "host": "localhost",
     "port": "19530",
     "user": "",
@@ -79,16 +79,16 @@
         server_pem_path (str): If use tls one-way authentication, need to
             write the server.pem path.
         server_name (str): If use tls, need to write the common name.
 
     Example:
         .. code-block:: python
 
-        from langchain import Milvus
-        from langchain.embeddings import OpenAIEmbeddings
+        from oplangchain import Milvus
+        from oplangchain.embeddings import OpenAIEmbeddings
 
         embedding = OpenAIEmbeddings()
         # Connect to a milvus instance on localhost
         milvus_store = Milvus(
             embedding_function = Embeddings,
             collection_name = "LangChainCollection",
             drop_old = True,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/mongodb_atlas.py` & `oplangchain-0.1.1/oplangchain/vectorstores/mongodb_atlas.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,18 +12,18 @@
     Tuple,
     TypeVar,
     Union,
 )
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     from pymongo.collection import Collection
 
 MongoDBDocumentType = TypeVar("MongoDBDocumentType", bound=Dict[str, Any])
 
 logger = logging.getLogger(__name__)
@@ -38,16 +38,16 @@
     - the ``pymongo`` python package installed
     - a connection string associated with a MongoDB Atlas Cluster having deployed an
         Atlas Search index
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import MongoDBAtlasVectorSearch
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import MongoDBAtlasVectorSearch
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
             from pymongo import MongoClient
 
             mongo_client = MongoClient("<YOUR-CONNECTION-STRING>")
             collection = mongo_client["<db_name>"]["<collection_name>"]
             embeddings = OpenAIEmbeddings()
             vectorstore = MongoDBAtlasVectorSearch(collection, embeddings)
     """
@@ -316,16 +316,16 @@
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
                 from pymongo import MongoClient
 
-                from langchain.vectorstores import MongoDBAtlasVectorSearch
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import MongoDBAtlasVectorSearch
+                from oplangchain.embeddings import OpenAIEmbeddings
 
                 mongo_client = MongoClient("<YOUR-CONNECTION-STRING>")
                 collection = mongo_client["<db_name>"]["<collection_name>"]
                 embeddings = OpenAIEmbeddings()
                 vectorstore = MongoDBAtlasVectorSearch.from_texts(
                     texts,
                     embeddings,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/myscale.py` & `oplangchain-0.1.1/oplangchain/vectorstores/myscale.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,17 +5,17 @@
 import logging
 from hashlib import sha1
 from threading import Thread
 from typing import Any, Dict, Iterable, List, Optional, Tuple
 
 from pydantic import BaseSettings
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger()
 
 
 def has_mul_sub_str(s: str, *args: Any) -> bool:
     """
     Check if a string contains multiple substrings.
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/opensearch_vector_search.py` & `oplangchain-0.1.1/oplangchain/vectorstores/opensearch_vector_search.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 
 import uuid
 import warnings
 from typing import Any, Dict, Iterable, List, Optional, Tuple
 
 import numpy as np
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import Document
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import Document
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 IMPORT_OPENSEARCH_PY_ERROR = (
     "Could not import OpenSearch. Please install it with `pip install opensearch-py`."
 )
 SCRIPT_SCORING_SEARCH = "script_scoring"
 PAINLESS_SCRIPTING_SEARCH = "painless_scripting"
 MATCH_ALL_QUERY = {"match_all": {}}  # type: Dict
@@ -316,15 +316,15 @@
 
 class OpenSearchVectorSearch(VectorStore):
     """Wrapper around OpenSearch as a vector database.
 
     Example:
         .. code-block:: python
 
-            from langchain import OpenSearchVectorSearch
+            from oplangchain import OpenSearchVectorSearch
             opensearch_vector_search = OpenSearchVectorSearch(
                 "http://localhost:9200",
                 "embeddings",
                 embedding_function
             )
 
     """
@@ -667,16 +667,16 @@
         **kwargs: Any,
     ) -> OpenSearchVectorSearch:
         """Construct OpenSearchVectorSearch wrapper from raw documents.
 
         Example:
             .. code-block:: python
 
-                from langchain import OpenSearchVectorSearch
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import OpenSearchVectorSearch
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 opensearch_vector_search = OpenSearchVectorSearch.from_texts(
                     texts,
                     embeddings,
                     opensearch_url="http://localhost:9200"
                 )
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/pgembedding.py` & `oplangchain-0.1.1/oplangchain/vectorstores/pgembedding.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,18 +6,18 @@
 from typing import Any, Dict, Iterable, List, Optional, Tuple, Type
 
 import sqlalchemy
 from sqlalchemy import func
 from sqlalchemy.dialects.postgresql import JSON, UUID
 from sqlalchemy.orm import Session, declarative_base, relationship
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 Base = declarative_base()  # type: Any
 
 
 ADA_TOKEN_COUNT = 1536
 _LANGCHAIN_DEFAULT_COLLECTION_NAME = "langchain"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/pgvector.py` & `oplangchain-0.1.1/oplangchain/vectorstores/pgvector.py`

 * *Files 4% similar despite different names*

```diff
@@ -16,21 +16,21 @@
     Type,
 )
 
 import sqlalchemy
 from sqlalchemy.dialects.postgresql import UUID
 from sqlalchemy.orm import Session, declarative_base
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
-    from langchain.vectorstores._pgvector_data_models import CollectionStore
+    from oplangchain.vectorstores._pgvector_data_models import CollectionStore
 
 
 class DistanceStrategy(str, enum.Enum):
     """Enumerator of the Distance strategies."""
 
     EUCLIDEAN = "l2"
     COSINE = "cosine"
@@ -66,16 +66,16 @@
         distance_strategy: The distance strategy to use. (default: COSINE)
         pre_delete_collection: If True, will delete the collection if it exists.
             (default: False). Useful for testing.
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import PGVector
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import PGVector
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
 
             CONNECTION_STRING = "postgresql+psycopg2://hwc@localhost:5432/test3"
             COLLECTION_NAME = "state_of_the_union_test"
             embeddings = OpenAIEmbeddings()
             vectorestore = PGVector.from_documents(
                 embedding=embeddings,
                 documents=docs,
@@ -111,15 +111,15 @@
         self,
     ) -> None:
         """
         Initialize the store.
         """
         self._conn = self.connect()
         # self.create_vector_extension()
-        from langchain.vectorstores._pgvector_data_models import (
+        from oplangchain.vectorstores._pgvector_data_models import (
             CollectionStore,
             EmbeddingStore,
         )
 
         self.CollectionStore = CollectionStore
         self.EmbeddingStore = EmbeddingStore
         self.create_tables_if_not_exists()
@@ -465,16 +465,16 @@
         Postgres connection string is required
         "Either pass it as a parameter
         or set the PGVECTOR_CONNECTION_STRING environment variable.
 
         Example:
             .. code-block:: python
 
-                from langchain import PGVector
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import PGVector
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 text_embeddings = embeddings.embed_documents(texts)
                 text_embedding_pairs = list(zip(texts, text_embeddings))
                 faiss = PGVector.from_embeddings(text_embedding_pairs, embeddings)
         """
         texts = [t[0] for t in text_embeddings]
         embeddings = [t[1] for t in text_embeddings]
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/pinecone.py` & `oplangchain-0.1.1/oplangchain/vectorstores/pinecone.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,32 +3,32 @@
 
 import logging
 import uuid
 from typing import Any, Callable, Iterable, List, Optional, Tuple
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import DistanceStrategy, maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import DistanceStrategy, maximal_marginal_relevance
 
 logger = logging.getLogger(__name__)
 
 
 class Pinecone(VectorStore):
     """Wrapper around Pinecone vector database.
 
     To use, you should have the ``pinecone-client`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import Pinecone
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import Pinecone
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
             import pinecone
 
             # The environment should be the one specified next to the API key
             # in your Pinecone console
             pinecone.init(api_key="***", environment="...")
             index = pinecone.Index("langchain-demo")
             embeddings = OpenAIEmbeddings()
@@ -291,16 +291,16 @@
             2. Adds the documents to a provided Pinecone index
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Pinecone
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Pinecone
+                from oplangchain.embeddings import OpenAIEmbeddings
                 import pinecone
 
                 # The environment should be the one specified next to the API key
                 # in your Pinecone console
                 pinecone.init(api_key="***", environment="...")
                 embeddings = OpenAIEmbeddings()
                 pinecone = Pinecone.from_texts(
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/qdrant.py` & `oplangchain-0.1.1/oplangchain/vectorstores/qdrant.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,18 +20,18 @@
     Tuple,
     Type,
     Union,
 )
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     from qdrant_client import grpc  # noqa
     from qdrant_client.conversions import common_types
     from qdrant_client.http import models as rest
 
     DictFilter = Dict[str, Union[str, int, bool, dict, list]]
@@ -71,15 +71,15 @@
 
     To use you should have the ``qdrant-client`` package installed.
 
     Example:
         .. code-block:: python
 
             from qdrant_client import QdrantClient
-            from langchain import Qdrant
+            from oplangchain import Qdrant
 
             client = QdrantClient()
             collection_name = "MyCollection"
             qdrant = Qdrant(client, collection_name, embedding_function)
     """
 
     CONTENT_KEY = "page_content"
@@ -1079,16 +1079,16 @@
         3. Adds the text embeddings to the Qdrant database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Qdrant
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Qdrant
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 qdrant = Qdrant.from_texts(texts, embeddings, "localhost")
         """
         qdrant = cls._construct_instance(
             texts,
             embedding,
             location,
@@ -1255,16 +1255,16 @@
         3. Adds the text embeddings to the Qdrant database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import Qdrant
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import Qdrant
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 qdrant = await Qdrant.afrom_texts(texts, embeddings, "localhost")
         """
         qdrant = cls._construct_instance(
             texts,
             embedding,
             location,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/redis.py` & `oplangchain-0.1.1/oplangchain/vectorstores/redis.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,23 +18,23 @@
     Tuple,
     Type,
 )
 
 import numpy as np
 from pydantic import root_validator
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utilities.redis import get_client
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore, VectorStoreRetriever
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utilities.redis import get_client
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore, VectorStoreRetriever
 
 logger = logging.getLogger(__name__)
 
 if TYPE_CHECKING:
     from redis.client import Redis as RedisType
     from redis.commands.search.query import Query
 
@@ -99,16 +99,16 @@
     """Wrapper around Redis vector database.
 
     To use, you should have the ``redis`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import Redis
-            from langchain.embeddings import OpenAIEmbeddings
+            from oplangchain.vectorstores import Redis
+            from oplangchain.embeddings import OpenAIEmbeddings
 
             embeddings = OpenAIEmbeddings()
             vectorstore = Redis(
                 redis_url="redis://username:password@localhost:6379"
                 index_name="my-index",
                 embedding_function=embeddings.embed_query,
             )
@@ -389,16 +389,16 @@
         4. Returns the keys of the newly created documents.
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain.vectorstores import Redis
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import Redis
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 redisearch, keys = RediSearch.from_texts_return_keys(
                     texts,
                     embeddings,
                     redis_url="redis://username:password@localhost:6379"
                 )
         """
@@ -452,16 +452,16 @@
         3. Adds the documents to the newly created Redis index.
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain.vectorstores import Redis
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import Redis
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 redisearch = RediSearch.from_texts(
                     texts,
                     embeddings,
                     redis_url="redis://username:password@localhost:6379"
                 )
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/rocksetdb.py` & `oplangchain-0.1.1/oplangchain/vectorstores/rocksetdb.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 """Wrapper around Rockset vector database."""
 from __future__ import annotations
 
 import logging
 from enum import Enum
 from typing import Any, Iterable, List, Optional, Tuple
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger(__name__)
 
 
 class Rockset(VectorStore):
     """Wrapper arpund Rockset vector database.
 
@@ -23,16 +23,16 @@
     See: https://rockset.com/blog/introducing-vector-search-on-rockset/ for more details
 
     Everything below assumes `commons` Rockset workspace.
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import Rockset
-            from langchain.embeddings.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import Rockset
+            from oplangchain.embeddings.openai import OpenAIEmbeddings
             import rockset
 
             # Make sure you use the right host (region) for your Rockset instance
             # and APIKEY has both read-write access to your collection.
 
             rs = rockset.RocksetClient(host=rockset.Regions.use1a1, api_key="***")
             collection_name = "langchain_demo"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/scann.py` & `oplangchain-0.1.1/oplangchain/vectorstores/scann.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,20 +5,20 @@
 import pickle
 import uuid
 from pathlib import Path
 from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple
 
 import numpy as np
 
-from langchain.docstore.base import AddableMixin, Docstore
-from langchain.docstore.document import Document
-from langchain.docstore.in_memory import InMemoryDocstore
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import DistanceStrategy
+from oplangchain.docstore.base import AddableMixin, Docstore
+from oplangchain.docstore.document import Document
+from oplangchain.docstore.in_memory import InMemoryDocstore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import DistanceStrategy
 
 
 def normalize(x: np.ndarray) -> np.ndarray:
     x /= np.clip(np.linalg.norm(x, axis=-1, keepdims=True), 1e-12, None)
     return x
 
 
@@ -40,16 +40,16 @@
     """Wrapper around ScaNN vector database.
 
     To use, you should have the ``scann`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embeddings import HuggingFaceEmbeddings
-            from langchain.vectorstores import ScaNN
+            from oplangchain.embeddings import HuggingFaceEmbeddings
+            from oplangchain.vectorstores import ScaNN
 
             db = ScaNN.from_texts(
                 ['foo', 'bar', 'barz', 'qux'],
                 HuggingFaceEmbeddings())
             db.similarity_search('foo?', k=1)
     """
 
@@ -378,16 +378,16 @@
             3. Initializes the ScaNN database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import ScaNN
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import ScaNN
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 scann = ScaNN.from_texts(texts, embeddings)
         """
         embeddings = embedding.embed_documents(texts)
         return cls.__from(
             texts,
             embeddings,
@@ -414,16 +414,16 @@
             3. Initializes the ScaNN database
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain import ScaNN
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain import ScaNN
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 text_embeddings = embeddings.embed_documents(texts)
                 text_embedding_pairs = list(zip(texts, text_embeddings))
                 scann = ScaNN.from_embeddings(text_embedding_pairs, embeddings)
         """
         texts = [t[0] for t in text_embeddings]
         embeddings = [t[1] for t in text_embeddings]
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/singlestoredb.py` & `oplangchain-0.1.1/oplangchain/vectorstores/singlestoredb.py`

 * *Files 2% similar despite different names*

```diff
@@ -13,22 +13,22 @@
     Optional,
     Tuple,
     Type,
 )
 
 from sqlalchemy.pool import QueuePool
 
-from langchain.callbacks.manager import (
+from oplangchain.callbacks.manager import (
     AsyncCallbackManagerForRetrieverRun,
     CallbackManagerForRetrieverRun,
 )
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore, VectorStoreRetriever
-from langchain.vectorstores.utils import DistanceStrategy
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore, VectorStoreRetriever
+from oplangchain.vectorstores.utils import DistanceStrategy
 
 DEFAULT_DISTANCE_STRATEGY = DistanceStrategy.DOT_PRODUCT
 
 ORDERING_DIRECTIVE: dict = {
     DistanceStrategy.EUCLIDEAN_DISTANCE: "",
     DistanceStrategy.DOT_PRODUCT: "DESC",
 }
@@ -144,28 +144,28 @@
                 results_type.
 
         Examples:
             Basic Usage:
 
             .. code-block:: python
 
-                from langchain.embeddings import OpenAIEmbeddings
-                from langchain.vectorstores import SingleStoreDB
+                from oplangchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import SingleStoreDB
 
                 vectorstore = SingleStoreDB(
                     OpenAIEmbeddings(),
                     host="https://user:password@127.0.0.1:3306/database"
                 )
 
             Advanced Usage:
 
             .. code-block:: python
 
-                from langchain.embeddings import OpenAIEmbeddings
-                from langchain.vectorstores import SingleStoreDB
+                from oplangchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import SingleStoreDB
 
                 vectorstore = SingleStoreDB(
                     OpenAIEmbeddings(),
                     distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,
                     host="127.0.0.1",
                     port=3306,
                     user="user",
@@ -176,16 +176,16 @@
                     timeout=60,
                 )
 
             Using environment variables:
 
             .. code-block:: python
 
-                from langchain.embeddings import OpenAIEmbeddings
-                from langchain.vectorstores import SingleStoreDB
+                from oplangchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import SingleStoreDB
 
                 os.environ['SINGLESTOREDB_URL'] = 'me:p455w0rd@s2-host.com/my_db'
                 vectorstore = SingleStoreDB(OpenAIEmbeddings())
         """
 
         self.embedding = embedding
         self.distance_strategy = distance_strategy
@@ -302,16 +302,16 @@
             filter (dict): A dictionary of metadata fields and values to filter by.
 
         Returns:
             List[Document]: A list of documents that are most similar to the query text.
 
         Examples:
             .. code-block:: python
-                from langchain.vectorstores import SingleStoreDB
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import SingleStoreDB
+                from oplangchain.embeddings import OpenAIEmbeddings
                 s2 = SingleStoreDB.from_documents(
                     docs,
                     OpenAIEmbeddings(),
                     host="username:password@localhost:3306/database"
                 )
                 s2.similarity_search("query text", 1,
                     {"metadata_field": "metadata_value"})
@@ -416,16 +416,16 @@
         This is a user-friendly interface that:
             1. Embeds documents.
             2. Creates a new table for the embeddings in SingleStoreDB.
             3. Adds the documents to the newly created table.
         This is intended to be a quick way to get started.
         Example:
             .. code-block:: python
-                from langchain.vectorstores import SingleStoreDB
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores import SingleStoreDB
+                from oplangchain.embeddings import OpenAIEmbeddings
                 s2 = SingleStoreDB.from_texts(
                     texts,
                     OpenAIEmbeddings(),
                     host="username:password@localhost:3306/database"
                 )
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/sklearn.py` & `oplangchain-0.1.1/oplangchain/vectorstores/sklearn.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,19 +6,19 @@
 import json
 import math
 import os
 from abc import ABC, abstractmethod
 from typing import Any, Dict, Iterable, List, Literal, Optional, Tuple, Type
 from uuid import uuid4
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import guard_import
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import guard_import
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 DEFAULT_K = 4  # Number of Documents to return.
 DEFAULT_FETCH_K = 20  # Number of Documents to initially fetch during MMR search.
 
 
 class BaseSerializer(ABC):
     """Abstract base class for saving and loading data."""
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/starrocks.py` & `oplangchain-0.1.1/oplangchain/vectorstores/starrocks.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,17 +6,17 @@
 import logging
 from hashlib import sha1
 from threading import Thread
 from typing import Any, Dict, Iterable, List, Optional, Tuple
 
 from pydantic import BaseSettings
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger()
 DEBUG = False
 
 
 def has_mul_sub_str(s: str, *args: Any) -> bool:
     """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/supabase.py` & `oplangchain-0.1.1/oplangchain/vectorstores/supabase.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,18 +12,18 @@
     Tuple,
     Type,
     Union,
 )
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 if TYPE_CHECKING:
     import supabase
 
 
 class SupabaseVectorStore(VectorStore):
     """VectorStore for a Supabase postgres database. Assumes you have the `pgvector`
@@ -39,17 +39,17 @@
     below on modifying the `match_documents` function to return matched embeddings.
 
 
     Examples:
 
     .. code-block:: python
 
-        from langchain.embeddings.openai import OpenAIEmbeddings
-        from langchain.schema import Document
-        from langchain.vectorstores import SupabaseVectorStore
+        from oplangchain.embeddings.openai import OpenAIEmbeddings
+        from oplangchain.schema import Document
+        from oplangchain.vectorstores import SupabaseVectorStore
         from supabase.client import create_client
 
         docs = [
             Document(page_content="foo", metadata={"id": 1}),
         ]
         embeddings = OpenAIEmbeddings()
         supabase_client = create_client("my_supabase_url", "my_supabase_key")
@@ -61,16 +61,16 @@
             query_name="match_documents",
         )
 
     To load from an existing table:
 
     .. code-block:: python
 
-        from langchain.embeddings.openai import OpenAIEmbeddings
-        from langchain.vectorstores import SupabaseVectorStore
+        from oplangchain.embeddings.openai import OpenAIEmbeddings
+        from oplangchain.vectorstores import SupabaseVectorStore
         from supabase.client import create_client
 
 
         embeddings = OpenAIEmbeddings()
         supabase_client = create_client("my_supabase_url", "my_supabase_key")
         vector_store = SupabaseVectorStore(
             client=supabase_client,
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/tair.py` & `oplangchain-0.1.1/oplangchain/vectorstores/tair.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,18 +2,18 @@
 from __future__ import annotations
 
 import json
 import logging
 import uuid
 from typing import Any, Iterable, List, Optional, Type
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
 
 logger = logging.getLogger(__name__)
 
 
 def _uuid_key() -> str:
     return uuid.uuid4().hex
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/tigris.py` & `oplangchain-0.1.1/oplangchain/vectorstores/tigris.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 from __future__ import annotations
 
 import itertools
 from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Tuple
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import Document
-from langchain.vectorstores import VectorStore
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import Document
+from oplangchain.vectorstores import VectorStore
 
 if TYPE_CHECKING:
     from tigrisdb import TigrisClient
     from tigrisdb import VectorStore as TigrisVectorStore
     from tigrisdb.types.filters import Filter as TigrisFilter
     from tigrisdb.types.vector import Document as TigrisDocument
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/typesense.py` & `oplangchain-0.1.1/oplangchain/vectorstores/typesense.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 """Wrapper around Typesense vector search"""
 from __future__ import annotations
 
 import uuid
 from typing import TYPE_CHECKING, Any, Iterable, List, Optional, Tuple, Union
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_env
-from langchain.vectorstores.base import VectorStore
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_env
+from oplangchain.vectorstores.base import VectorStore
 
 if TYPE_CHECKING:
     from typesense.client import Client
     from typesense.collection import Collection
 
 
 class Typesense(VectorStore):
     """Wrapper around Typesense vector search.
 
     To use, you should have the ``typesense`` python package installed.
 
     Example:
         .. code-block:: python
 
-            from langchain.embedding.openai import OpenAIEmbeddings
-            from langchain.vectorstores import Typesense
+            from oplangchain.embedding.openai import OpenAIEmbeddings
+            from oplangchain.vectorstores import Typesense
             import typesense
 
             node = {
                 "host": "localhost",  # For Typesense Cloud use xxx.a1.typesense.net
                 "port": "8108",       # For Typesense Cloud use 443
                 "protocol": "http"    # For Typesense Cloud use https
             }
@@ -209,16 +209,16 @@
         **kwargs: Any,
     ) -> Typesense:
         """Initialize Typesense directly from client parameters.
 
         Example:
             .. code-block:: python
 
-                from langchain.embedding.openai import OpenAIEmbeddings
-                from langchain.vectorstores import Typesense
+                from oplangchain.embedding.openai import OpenAIEmbeddings
+                from oplangchain.vectorstores import Typesense
 
                 # Pass in typesense_api_key as kwarg or set env var "TYPESENSE_API_KEY".
                 vectorstore = Typesense(
                     OpenAIEmbeddings(),
                     host="localhost",
                     port="8108",
                     protocol="http",
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/utils.py` & `oplangchain-0.1.1/oplangchain/vectorstores/utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Utility functions for working with vectors and vectorstores."""
 
 from enum import Enum
 from typing import List
 
 import numpy as np
 
-from langchain.utils.math import cosine_similarity
+from oplangchain.utils.math import cosine_similarity
 
 
 class DistanceStrategy(str, Enum):
     """Enumerator of the Distance strategies for calculating distances
     between vectors."""
 
     EUCLIDEAN_DISTANCE = "EUCLIDEAN_DISTANCE"
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/vectara.py` & `oplangchain-0.1.1/oplangchain/vectorstores/vectara.py`

 * *Files 0% similar despite different names*

```diff
@@ -6,30 +6,30 @@
 import os
 from hashlib import md5
 from typing import Any, Iterable, List, Optional, Tuple, Type
 
 import requests
 from pydantic import Field
 
-from langchain.embeddings.base import Embeddings
-from langchain.schema import Document
-from langchain.vectorstores.base import VectorStore, VectorStoreRetriever
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.schema import Document
+from oplangchain.vectorstores.base import VectorStore, VectorStoreRetriever
 
 logger = logging.getLogger(__name__)
 
 
 class Vectara(VectorStore):
     """Implementation of Vector Store using Vectara.
 
      See (https://vectara.com).
 
     Example:
         .. code-block:: python
 
-            from langchain.vectorstores import Vectara
+            from oplangchain.vectorstores import Vectara
 
             vectorstore = Vectara(
                 vectara_customer_id=vectara_customer_id,
                 vectara_corpus_id=vectara_corpus_id,
                 vectara_api_key=vectara_api_key
             )
     """
@@ -361,15 +361,15 @@
         **kwargs: Any,
     ) -> Vectara:
         """Construct Vectara wrapper from raw documents.
         This is intended to be a quick way to get started.
         Example:
             .. code-block:: python
 
-                from langchain import Vectara
+                from oplangchain import Vectara
                 vectara = Vectara.from_texts(
                     texts,
                     vectara_customer_id=customer_id,
                     vectara_corpus_id=corpus_id,
                     vectara_api_key=api_key,
                 )
         """
@@ -389,15 +389,15 @@
         **kwargs: Any,
     ) -> Vectara:
         """Construct Vectara wrapper from raw documents.
         This is intended to be a quick way to get started.
         Example:
             .. code-block:: python
 
-                from langchain import Vectara
+                from oplangchain import Vectara
                 vectara = Vectara.from_files(
                     files_list,
                     vectara_customer_id=customer_id,
                     vectara_corpus_id=corpus_id,
                     vectara_api_key=api_key,
                 )
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/weaviate.py` & `oplangchain-0.1.1/oplangchain/vectorstores/weaviate.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,19 +3,19 @@
 
 import datetime
 from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type
 from uuid import uuid4
 
 import numpy as np
 
-from langchain.docstore.document import Document
-from langchain.embeddings.base import Embeddings
-from langchain.utils import get_from_dict_or_env
-from langchain.vectorstores.base import VectorStore
-from langchain.vectorstores.utils import maximal_marginal_relevance
+from oplangchain.docstore.document import Document
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.utils import get_from_dict_or_env
+from oplangchain.vectorstores.base import VectorStore
+from oplangchain.vectorstores.utils import maximal_marginal_relevance
 
 
 def _default_schema(index_name: str) -> Dict:
     return {
         "class": index_name,
         "properties": [
             {
@@ -74,15 +74,15 @@
 
     To use, you should have the ``weaviate-client`` python package installed.
 
     Example:
         .. code-block:: python
 
             import weaviate
-            from langchain.vectorstores import Weaviate
+            from oplangchain.vectorstores import Weaviate
             client = weaviate.Client(url=os.environ["WEAVIATE_URL"], ...)
             weaviate = Weaviate(client, index_name, text_key)
 
     """
 
     def __init__(
         self,
@@ -388,16 +388,16 @@
             3. Adds the documents to the newly created Weaviate index.
 
         This is intended to be a quick way to get started.
 
         Example:
             .. code-block:: python
 
-                from langchain.vectorstores.weaviate import Weaviate
-                from langchain.embeddings import OpenAIEmbeddings
+                from oplangchain.vectorstores.weaviate import Weaviate
+                from oplangchain.embeddings import OpenAIEmbeddings
                 embeddings = OpenAIEmbeddings()
                 weaviate = Weaviate.from_texts(
                     texts,
                     embeddings,
                     weaviate_url="http://localhost:8080"
                 )
         """
```

### Comparing `oplangchain-0.1.0/oplangchain/vectorstores/zilliz.py` & `oplangchain-0.1.1/oplangchain/vectorstores/zilliz.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from __future__ import annotations
 
 import logging
 from typing import Any, List, Optional
 
-from langchain.embeddings.base import Embeddings
-from langchain.vectorstores.milvus import Milvus
+from oplangchain.embeddings.base import Embeddings
+from oplangchain.vectorstores.milvus import Milvus
 
 logger = logging.getLogger(__name__)
 
 
 class Zilliz(Milvus):
     """Initialize wrapper around the Zilliz vector database.
 
@@ -62,16 +62,16 @@
         server_pem_path (str): If use tls one-way authentication, need to
             write the server.pem path.
         server_name (str): If use tls, need to write the common name.
 
     Example:
         .. code-block:: python
 
-        from langchain import Zilliz
-        from langchain.embeddings import OpenAIEmbeddings
+        from oplangchain import Zilliz
+        from oplangchain.embeddings import OpenAIEmbeddings
 
         embedding = OpenAIEmbeddings()
         # Connect to a Zilliz instance
         milvus_store = Milvus(
             embedding_function = embedding,
             collection_name = "LangChainCollection",
             connection_args = {
```

### Comparing `oplangchain-0.1.0/pyproject.toml` & `oplangchain-0.1.1/pyproject.toml`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 [tool.poetry]
 name = "oplangchain"
-version = "0.1.0"
-description = "langchain modified for OpenPlugin"
+version = "0.1.1"
+description = "Building applications with LLMs through composability"
 authors = []
 license = "MIT"
 readme = "README.md"
 repository = "https://www.github.com/hwchase17/langchain"
 
 [tool.poetry.scripts]
 langchain-server = "langchain.server:main"
```

### Comparing `oplangchain-0.1.0/README.md` & `oplangchain-0.1.1/README.md`

 * *Files identical despite different names*

### Comparing `oplangchain-0.1.0/PKG-INFO` & `oplangchain-0.1.1/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 Metadata-Version: 2.1
 Name: oplangchain
-Version: 0.1.0
-Summary: langchain modified for OpenPlugin
+Version: 0.1.1
+Summary: Building applications with LLMs through composability
 Home-page: https://www.github.com/hwchase17/langchain
 License: MIT
 Requires-Python: >=3.8.1,<4.0
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
```

