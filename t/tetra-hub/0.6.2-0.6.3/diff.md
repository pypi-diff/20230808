# Comparing `tmp/tetra_hub-0.6.2-py3-none-any.whl.zip` & `tmp/tetra_hub-0.6.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,23 +1,25 @@
-Zip file size: 56265 bytes, number of entries: 21
--rw-r--r--  2.0 unx      271 b- defN 23-Jul-27 18:29 tetra_hub/__init__.py
--rw-r--r--  2.0 unx     3656 b- defN 23-Jul-27 18:29 tetra_hub/_cli.py
--rw-r--r--  2.0 unx       22 b- defN 23-Jul-27 18:29 tetra_hub/_version.py
--rw-r--r--  2.0 unx     4095 b- defN 23-Jul-27 18:29 tetra_hub/api_status_codes.py
--rw-r--r--  2.0 unx    86869 b- defN 23-Jul-27 18:29 tetra_hub/client.py
--rw-r--r--  2.0 unx      928 b- defN 23-Jul-27 18:29 tetra_hub/hub.py
--rw-r--r--  2.0 unx    21639 b- defN 23-Jul-27 18:31 tetra_hub/public_api_pb2.py
--rw-r--r--  2.0 unx    86066 b- defN 23-Jul-27 18:31 tetra_hub/public_api_pb2.pyi
--rw-r--r--  2.0 unx    46337 b- defN 23-Jul-27 18:29 tetra_hub/public_rest_api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-27 18:29 tetra_hub/py.typed
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-27 18:29 tetra_hub/test/__init__.py
--rw-r--r--  2.0 unx     1586 b- defN 23-Jul-27 18:29 tetra_hub/test/test_cli.py
--rw-r--r--  2.0 unx     3727 b- defN 23-Jul-27 18:29 tetra_hub/test/test_client.py
--rw-r--r--  2.0 unx      601 b- defN 23-Jul-27 18:29 tetra_hub/test/test_public_rest_api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-27 18:29 tetra_hub/util/__init__.py
--rw-r--r--  2.0 unx     3887 b- defN 23-Jul-27 18:29 tetra_hub/util/dataset_entries_converters.py
--rw-r--r--  2.0 unx     2688 b- defN 23-Jul-27 18:31 tetra_hub-0.6.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jul-27 18:31 tetra_hub-0.6.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       51 b- defN 23-Jul-27 18:31 tetra_hub-0.6.2.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Jul-27 18:31 tetra_hub-0.6.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1718 b- defN 23-Jul-27 18:31 tetra_hub-0.6.2.dist-info/RECORD
-21 files, 264243 bytes uncompressed, 53465 bytes compressed:  79.8%
+Zip file size: 60525 bytes, number of entries: 23
+-rw-r--r--  2.0 unx      271 b- defN 23-Aug-08 00:34 tetra_hub/__init__.py
+-rw-r--r--  2.0 unx     3656 b- defN 23-Aug-08 00:34 tetra_hub/_cli.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Aug-08 00:34 tetra_hub/_version.py
+-rw-r--r--  2.0 unx     4095 b- defN 23-Aug-08 00:34 tetra_hub/api_status_codes.py
+-rw-r--r--  2.0 unx    89325 b- defN 23-Aug-08 00:34 tetra_hub/client.py
+-rw-r--r--  2.0 unx      928 b- defN 23-Aug-08 00:34 tetra_hub/hub.py
+-rw-r--r--  2.0 unx    21681 b- defN 23-Aug-08 00:36 tetra_hub/public_api_pb2.py
+-rw-r--r--  2.0 unx    86165 b- defN 23-Aug-08 00:36 tetra_hub/public_api_pb2.pyi
+-rw-r--r--  2.0 unx    48616 b- defN 23-Aug-08 00:34 tetra_hub/public_rest_api.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Aug-08 00:34 tetra_hub/py.typed
+-rw-r--r--  2.0 unx        0 b- defN 23-Aug-08 00:34 tetra_hub/test/__init__.py
+-rw-r--r--  2.0 unx     1586 b- defN 23-Aug-08 00:34 tetra_hub/test/test_cli.py
+-rw-r--r--  2.0 unx     5932 b- defN 23-Aug-08 00:34 tetra_hub/test/test_client.py
+-rw-r--r--  2.0 unx      601 b- defN 23-Aug-08 00:34 tetra_hub/test/test_public_rest_api.py
+-rw-r--r--  2.0 unx     5062 b- defN 23-Aug-08 00:34 tetra_hub/test/test_zipped_model.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Aug-08 00:34 tetra_hub/util/__init__.py
+-rw-r--r--  2.0 unx     3887 b- defN 23-Aug-08 00:34 tetra_hub/util/dataset_entries_converters.py
+-rw-r--r--  2.0 unx     4933 b- defN 23-Aug-08 00:34 tetra_hub/util/zipped_model.py
+-rw-r--r--  2.0 unx     2688 b- defN 23-Aug-08 00:36 tetra_hub-0.6.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Aug-08 00:36 tetra_hub-0.6.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       51 b- defN 23-Aug-08 00:36 tetra_hub-0.6.3.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Aug-08 00:36 tetra_hub-0.6.3.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1897 b- defN 23-Aug-08 00:36 tetra_hub-0.6.3.dist-info/RECORD
+23 files, 281498 bytes uncompressed, 57443 bytes compressed:  79.6%
```

## zipnote {}

```diff
@@ -36,29 +36,35 @@
 
 Filename: tetra_hub/test/test_client.py
 Comment: 
 
 Filename: tetra_hub/test/test_public_rest_api.py
 Comment: 
 
+Filename: tetra_hub/test/test_zipped_model.py
+Comment: 
+
 Filename: tetra_hub/util/__init__.py
 Comment: 
 
 Filename: tetra_hub/util/dataset_entries_converters.py
 Comment: 
 
-Filename: tetra_hub-0.6.2.dist-info/METADATA
+Filename: tetra_hub/util/zipped_model.py
+Comment: 
+
+Filename: tetra_hub-0.6.3.dist-info/METADATA
 Comment: 
 
-Filename: tetra_hub-0.6.2.dist-info/WHEEL
+Filename: tetra_hub-0.6.3.dist-info/WHEEL
 Comment: 
 
-Filename: tetra_hub-0.6.2.dist-info/entry_points.txt
+Filename: tetra_hub-0.6.3.dist-info/entry_points.txt
 Comment: 
 
-Filename: tetra_hub-0.6.2.dist-info/top_level.txt
+Filename: tetra_hub-0.6.3.dist-info/top_level.txt
 Comment: 
 
-Filename: tetra_hub-0.6.2.dist-info/RECORD
+Filename: tetra_hub-0.6.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tetra_hub/_version.py

```diff
@@ -1 +1 @@
-__version__ = "0.6.2"
+__version__ = "0.6.3"
```

## tetra_hub/client.py

```diff
@@ -37,14 +37,19 @@
 from . import public_api_pb2 as api_pb
 from . import public_rest_api as api
 from .public_rest_api import APIException, ClientConfig, DatasetEntries, InputSpecs
 from .util.dataset_entries_converters import (
     dataset_entries_to_h5,
     h5_to_dataset_entries,
 )
+from .util.zipped_model import (
+    SUPPORTED_ZIPPED_MODEL_ASSETS,
+    make_zipped_model_compatible,
+    zip_model,
+)
 
 if TYPE_CHECKING:
     # Evaluate to False in general. Only import to resolve Sphinx autodoc
     # typehints forward declaration warnings
     import coremltools
     import torch
 
@@ -190,81 +195,103 @@
     return SourceModelType(model_type)
 
 
 def _is_in_zip(zip: ZipFile, filename: str) -> bool:
     return filename in zip.namelist()
 
 
-def _assert_is_valid_zipped_mlmodelc(filepath: str) -> None:
-    # Valid if any of the files exists:
-    #  1. <filepath>/assemble.json
-    #  2. <filepath>/foo.mlmodelc/assemble.json
-    #  3. <filepath>/model.espresso.net
-    #  4. <filepath>/model0/model.espresso.net
-    #  5. <filepath>/foo.mlmodelc/model.espresso.net
-    #  6. <filepath>/foo.mlmodelc/model0/model.espresso.net
+def _assert_is_valid_zipped_model(filepath: str) -> None:
+    # Valid if one of following is true:
+    # 1. has mlpackage
+    #    <filepath>/foo.mlpackage/
+    # 2. has one of following file (valid .mlmodelc)
+    #   a. <filepath>/foo.mlmodelc/assemble.json
+    #   b. <filepath>/foo.mlmodelc/model.espresso.net
+    #   c. <filepath>/foo.mlmodelc/model0/model.espresso.net
     with ZipFile(filepath, "r") as zippedModel:
+        zippedNames = zippedModel.namelist()
+        if len([dname for dname in zippedNames if dname.endswith(".mlpackage/")]) == 1:
+            # Is a valid mlpackage zipped model
+            return
+
+        # Check if it's a valid mlmodelc zipped model
         # Find .mlmodelc directory
         mlmodelc_dir = None
-        for fname in zippedModel.namelist():
-            if fname.endswith(".mlmodelc/"):
-                mlmodelc_dir = fname
-                break
-
-        # Check for assembly instructions, which may produce an espresso.net file, but
-        # may only exist at the root of the model.
-        if _is_in_zip(zippedModel, ASSEMBLE_JSON_FILE):
-            return
 
-        if mlmodelc_dir is not None:
-            if _is_in_zip(zippedModel, os.path.join(mlmodelc_dir, ASSEMBLE_JSON_FILE)):
-                return
+        all_mlmodelc_dir = [
+            fname for fname in zippedNames if fname.endswith(".mlmodelc/")
+        ]
+        if len(all_mlmodelc_dir) == 1:
+            mlmodelc_dir = all_mlmodelc_dir[0]
 
-        if _is_in_zip(zippedModel, ESPRESSO_NET_FILE):
-            return
-        if _is_in_zip(zippedModel, os.path.join("model0", ESPRESSO_NET_FILE)):
-            return
+        if mlmodelc_dir is None:
+            raise UserError(
+                "Incorrect zipped model .zip provided."
+                " Must have one root level `*.mlmodelc` or `*.mlpackage` directory."
+            )
 
+        # Case 2. a): <filepath>/foo.mlmodelc/assemble.json
+        if _is_in_zip(zippedModel, os.path.join(mlmodelc_dir, ASSEMBLE_JSON_FILE)):
+            return
         # Search in the .mlmodelc directory
-        if mlmodelc_dir is not None:
-            if _is_in_zip(zippedModel, os.path.join(mlmodelc_dir, ESPRESSO_NET_FILE)):
-                return
-            if _is_in_zip(
-                zippedModel, os.path.join(mlmodelc_dir, "model0", ESPRESSO_NET_FILE)
-            ):
-                return
+        # Case 2. b): <filepath>/foo.mlmodelc/model.espresso.net
+        if _is_in_zip(zippedModel, os.path.join(mlmodelc_dir, ESPRESSO_NET_FILE)):
+            return
+        # Case 2. c): <filepath>/foo.mlmodelc/model0/model.espresso.net
+        if _is_in_zip(
+            zippedModel, os.path.join(mlmodelc_dir, "model0", ESPRESSO_NET_FILE)
+        ):
+            return
 
-        # No match in each of the 4 types.
+        # No match in each of the 3 supported types
         raise UserError(
             f"Incorrect mlmodelc.zip provided. Neither {ESPRESSO_NET_FILE} nor {ASSEMBLE_JSON_FILE} found."
         )
 
 
-def _zip_mlmodelc_if_needed(source_path: str, archive_path: str) -> str:
+def _make_zipped_model_compatible(
+    source_path: str, archive_path: str, model_ext: str
+) -> str:
     """
     If source_path is a directory, zip it up.
+    If source_path is a zip, ensure only one model asset is present in zip.
 
     Parameters
     ----------
     source_path:
         A mlmodelc.zip archive or mlmodelc directory.
     archive_path:
         Path of archive to create if source path is a directory.
 
     Returns
     -------
     mlmodelc_archive_path :
         Path to a mlmodelc.zip file containing.
+
+    Raises
+    ------
+    UserError
+        if source_path is a directory and not pointing to .mlmodelc directory
+    UserError
+        if provided zipped archive has no or more than one model asset at base path
     """
+
     if os.path.isdir(source_path):
-        archive_base_name = Path(archive_path).with_suffix("")
-        return shutil.make_archive(
-            str(archive_base_name), format="zip", root_dir=source_path
+        if not source_path.endswith(model_ext):
+            raise UserError(
+                f"Provided source path must point to {model_ext} dir. "
+                f"Provided {source_path}."
+            )
+
+        return zip_model(
+            str(Path(archive_path).with_suffix("")),
+            source_path,
         )
-    return source_path
+    # Make existing archived model compatible with hub
+    return make_zipped_model_compatible(source_path, archive_path)
 
 
 ## ERROR HANDLING ##
 class Error(Exception):
     """
     Base class for all exceptions explicitly thrown by the API.
 
@@ -570,14 +597,15 @@
     UNRECOGNIZED_MODEL_TYPE = api_pb.ModelType.MODEL_TYPE_UNSPECIFIED
     TORCHSCRIPT = api_pb.ModelType.MODEL_TYPE_TORCHSCRIPT
     MLMODEL = api_pb.ModelType.MODEL_TYPE_MLMODEL
     TFLITE = api_pb.ModelType.MODEL_TYPE_TFLITE
     MLMODELC = api_pb.ModelType.MODEL_TYPE_MLMODELC
     ONNX = api_pb.ModelType.MODEL_TYPE_ONNX
     ORT = api_pb.ModelType.MODEL_TYPE_ORT
+    MLPACKAGE = api_pb.ModelType.MODEL_TYPE_MLPACKAGE
 
 
 class Model:
     """
     Neural network model object.
 
     A model should not be constructed directly. It is constructed by the hub client
@@ -649,14 +677,19 @@
                         "platform. Specify `filename` to download to disk."
                     )
                 elif self.model_type == SourceModelType.MLMODELC:
                     raise UserError(
                         "Cannot load a compiled Core ML (.mlmodelc) into memory. "
                         "Please specify a filename to download it to disk without loading it."
                     )
+                elif self.model_type == SourceModelType.MLPACKAGE:
+                    raise UserError(
+                        "Cannot load a Core ML MLPackage (.mlpackage) into memory. "
+                        "Please specify a filename to download it to disk without loading it."
+                    )
 
                 # delete=False to be compatible with Windows
                 with tempfile.NamedTemporaryFile(delete=False) as file:
                     download_file = file.name
                 # Close the file to avoid double-open on Windows
 
             download_file = _api_call(
@@ -768,27 +801,41 @@
         _, suffix = os.path.splitext(path)
         if suffix in [".pt", ".pth"]:
             return SourceModelType.TORCHSCRIPT
         elif suffix == ".mlmodel":
             return SourceModelType.MLMODEL
         elif suffix == ".tflite":
             return SourceModelType.TFLITE
-        elif suffix == ".mlmodelc" or str(model).endswith(".mlmodelc.zip"):
+        elif suffix == ".mlmodelc":
             return SourceModelType.MLMODELC
         elif suffix == ".onnx":
             return SourceModelType.ONNX
         elif suffix == ".ort":
             return SourceModelType.ORT
-        else:
-            raise UserError(
-                rf"Unsupported model type for {model}. The following types are supported {error_message}"
-            )
+        elif suffix == ".mlpackage":
+            return SourceModelType.MLPACKAGE
+        elif suffix == ".zip":
+            model_non_zip_path = Path(model).with_suffix("")
+            if model_non_zip_path.suffix in SUPPORTED_ZIPPED_MODEL_ASSETS:
+                return _determine_model_type(Path(model).with_suffix(""))
+        raise UserError(
+            rf"Unsupported model type for {model}. The following types are supported {error_message}"
+        )
     elif type(model).__name__ in {"TopLevelTracedModule", "RecursiveScriptModule"}:
         return SourceModelType.TORCHSCRIPT
     elif type(model).__name__ == "MLModel":
+        import coremltools
+
+        assert isinstance(model, coremltools.models.model.MLModel)
+
+        # MLModel distinguishes NeuralNetwork and MLPackage format
+        # with following field
+        # https://github.com/apple/coremltools/blob/d52d536a399011933c6faf23d8fa19bcf79c5dca/coremltools/models/model.py#L360
+        if model.is_package:
+            return SourceModelType.MLPACKAGE
         return SourceModelType.MLMODEL
     elif isinstance(model, bytes) and model[4:8] == b"TFL3":
         return SourceModelType.TFLITE
     elif type(model).__name__ == "ModelProto":
         return SourceModelType.ONNX
     elif isinstance(model, bytes) and model[4:8] == b"ORTM":
         return SourceModelType.ORT
@@ -810,14 +857,16 @@
         suffix = ".tflite"
     elif type == SourceModelType.MLMODELC:
         suffix = ".mlmodelc.zip"
     elif type == SourceModelType.ONNX:
         suffix = ".onnx"
     elif type == SourceModelType.ORT:
         suffix = ".ort"
+    elif type == SourceModelType.MLPACKAGE:
+        suffix = ".mlpackage.zip"
     else:
         raise RuntimeError(f"Unsupported model type: {type}")
     return suffix
 
 
 ## JOBS ##
 
@@ -1851,45 +1900,56 @@
             file_path_to_upload = model_tempfile.name
 
         model_name: str | None = None
         if isinstance(model, (str, Path)):
             file_path_to_upload = str(model)
             model_name = os.path.basename(file_path_to_upload)
             model = None
-            if model_type == SourceModelType.MLMODELC:
-                file_path_to_upload = _zip_mlmodelc_if_needed(
-                    file_path_to_upload, model_tempfile.name
+            if (
+                model_type == SourceModelType.MLMODELC
+                or model_type == SourceModelType.MLPACKAGE
+            ):
+                # .mlmodelc and .mlpackage are directory based assets.
+                # Ensure we upload these as zipped model.
+                assert suffix.endswith(".zip")
+                model_suffix = suffix.rsplit(".", 1)[0]
+                file_path_to_upload = _make_zipped_model_compatible(
+                    file_path_to_upload, model_tempfile.name, model_suffix
                 )
-                _assert_is_valid_zipped_mlmodelc(file_path_to_upload)
+                _assert_is_valid_zipped_model(file_path_to_upload)
         elif model_type == SourceModelType.TORCHSCRIPT:
             import torch
 
             torch.jit.save(model, file_path_to_upload)
             model_name = model.original_name
         elif model_type == SourceModelType.MLMODEL:
             model.save(file_path_to_upload)
-            # TODO: Figure out a better default name for MLModel instances
             model_name = "MLModel"
         elif model_type == SourceModelType.TFLITE:
             with open(file_path_to_upload, "wb") as f:
                 f.write(model)
-            # TODO: Figure out a better default name for TFLite instances
             model_name = "TFLite"
         elif model_type == SourceModelType.ONNX:
             import onnx
 
             onnx.save(model, file_path_to_upload)
-            # TODO: Figure out a better default name for ONNX instances
             model_name = "ONNX"
         elif model_type == SourceModelType.ORT:
             import onnx
 
             onnx.save(model, file_path_to_upload)
-            # TODO: Figure out a better default name for ORT instances
             model_name = "ORT"
+        elif model_type == SourceModelType.MLPACKAGE:
+            with tempfile.TemporaryDirectory() as tempdir:
+                mlpackage_path = os.path.join(tempdir, "model.mlpackage")
+                model.save(mlpackage_path)
+                zipped_model_path = zip_model(tempdir, mlpackage_path)
+                shutil.copy(zipped_model_path, file_path_to_upload)
+
+            model_name = "MLPackage"
 
         model_name = name or model_name
         res_pb = _api_call(
             api.create_and_upload_model,
             self.config,
             file_path_to_upload,
             name=model_name,
@@ -2460,15 +2520,15 @@
 
             # Submit validation job
             job = hub.submit_validation_job(ml_model,
                                device=hub.Device("Apple iPhone 11", "14.0"),
                                name="squeeze_net (1, 3, 227, 227)",
                                inputs=dict(image=[input_tensor]))
 
-        For more examples, see :ref:`examples`.
+        For more examples, see :ref:`hub_examples`.
         """
 
         # Determine the model type
         model_type = _determine_model_type(model)
         if model_type == SourceModelType.TORCHSCRIPT:
             raise UserError("TorchScript models cannot be used for validation.")
 
@@ -2578,15 +2638,15 @@
 
             model = hub.upload_model(pt_model)
 
             job = hub.submit_profile_job(model, device=hub.Device("Apple iPhone 11", "14.0"),
                                          name="mobilenet (1, 3, 224, 224)",
                                          input_shapes=dict(x=input_shapes))
 
-        For more examples, see :ref:`examples`.
+        For more examples, see :ref:`hub_examples`.
         """
         # Determine the model type
         model_type = _determine_model_type(model)
         devices = self._check_devices(device, model_type)
         self._check_input_specs(model_type=model_type, input_specs=input_shapes)
         model = self._upload_model(model, model_type=model_type)
         tensor_type_list_pb = api.utils.input_shapes_to_tensor_type_list_pb(
```

## tetra_hub/public_api_pb2.py

```diff
@@ -10,15 +10,15 @@
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1atetra_hub/public_api.proto\x12\rtetra_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x9e\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x38\n\x06\x66ields\x18\x03 \x03(\x0b\x32(.tetra_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"I\n\x08UserList\x12\"\n\x05users\x18\x01 \x03(\x0b\x32\x13.tetra_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"V\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12(\n\x07members\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.UserList\"6\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\"O\n\nDeviceList\x12&\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x15.tetra_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xd4\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_complete\"R\n\x0b\x44\x61tasetList\x12(\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12)\n\x05\x64type\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.TensorDtype\"O\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x19.tetra_hub.api.TensorType\"D\n\x13NamedTensorTypeList\x12-\n\x05types\x18\x01 \x03(\x0b\x32\x1e.tetra_hub.api.NamedTensorType\"\xc2\x02\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x31\n\nmodel_type\x18\x05 \x01(\x0e\x32\x18.tetra_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_complete\"L\n\tModelList\x12$\n\x06models\x18\x01 \x03(\x0b\x32\x14.tetra_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xa3\x07\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12#\n\x05model\x18\x04 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12%\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12<\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32\".tetra_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12\'\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12/\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x14.tetra_hub.api.ModelH\x03\x88\x01\x01\x12\x38\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x14.tetra_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x12\x35\n\x11last_updated_time\x18\x14 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x15 \x01(\tH\x06\x88\x01\x01\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_url\"\xb2\x04\n\rValidationJob\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12#\n\x05model\x18\x03 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12%\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12\'\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\t\x12\x35\n\x11last_updated_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x0e \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0c\n\n_admin_url\"v\n\x03Job\x12\x30\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x19.tetra_hub.api.ProfileJobH\x00\x12\x36\n\x0evalidation_job\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ValidationJobH\x00\x42\x05\n\x03job\"T\n\x0eProfileJobList\x12\'\n\x04jobs\x18\x01 \x03(\x0b\x32\x19.tetra_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"Z\n\x11ValidationJobList\x12*\n\x04jobs\x18\x01 \x03(\x0b\x32\x1c.tetra_hub.api.ValidationJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\x07JobList\x12 \n\x04jobs\x18\x01 \x03(\x0b\x32\x12.tetra_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"j\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x32\n\x07profile\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"K\n\x13ValidationJobResult\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\"\x99\x01\n\tJobResult\x12=\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1f.tetra_hub.api.ProfileJobResultH\x00\x12\x43\n\x15validation_job_result\x18\x02 \x01(\x0b\x32\".tetra_hub.api.ValidationJobResultH\x00\x42\x08\n\x06result\"\xf4\x02\n\x08VizGraph\x12/\n\ngraph_type\x18\x01 \x01(\x0e\x32\x1b.tetra_hub.api.VizGraphType\x12-\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x1a.tetra_hub.api.VizSubgraph\x12;\n\nparameters\x18\x04 \x03(\x0b\x32\'.tetra_hub.api.VizGraph.ParametersEntry\x12\x35\n\x07tensors\x18\x05 \x03(\x0b\x32$.tetra_hub.api.VizGraph.TensorsEntry\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\x1aH\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\'\n\x05value\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensor:\x02\x38\x01\"B\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12%\n\x05nodes\x18\x02 \x03(\x0b\x32\x16.tetra_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x8c\x02\n\tVizTensor\x12&\n\x05\x64type\x18\x02 \x01(\x0e\x32\x17.tetra_hub.api.VizDtype\x12&\n\x05shape\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.VizShape\x12<\n\nparameters\x18\x04 \x03(\x0b\x32(.tetra_hub.api.VizTensor.ParametersEntry\x12%\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x17.tetra_hub.api.VizValue\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\"\x90\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12:\n\nattributes\x18\x07 \x03(\x0b\x32&.tetra_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aN\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12*\n\x05value\x18\x02 \x01(\x0b\x32\x1b.tetra_hub.api.VizAttribute:\x02\x38\x01\"\xe0\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x39\n\x0bstring_list\x18\x06 \x01(\x0b\x32\".tetra_hub.api.VizValue.StringListH\x00\x12;\n\x0cinteger_list\x18\x07 \x01(\x0b\x32#.tetra_hub.api.VizValue.IntegerListH\x00\x12\x37\n\nfloat_list\x18\x08 \x01(\x0b\x32!.tetra_hub.api.VizValue.FloatListH\x00\x12\x35\n\tbool_list\x18\t \x01(\x0b\x32 .tetra_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"l\n\x0cVizAttribute\x12(\n\x05value\x18\x01 \x01(\x0b\x32\x17.tetra_hub.api.VizValueH\x00\x12*\n\x06tensor\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\x9d\x02\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x12\x1d\n\x15\x64\x65legate_reported_ops\x18\t \x03(\tB\x11\n\x0f_execution_timeB\r\n\x0b_segment_id\"\xb1\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"\xef\x0b\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12\x31\n\rlayer_details\x18\x04 \x03(\x0b\x32\x1a.tetra_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x45\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12G\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12G\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12G\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x35\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1c.tetra_hub.api.SegmentDetail\x1aY\n\x0bMemoryUsage\x12&\n\x08increase\x18\x01 \x01(\x0b\x32\x14.tetra_hub.api.Range\x12\"\n\x04peak\x18\x02 \x01(\x0b\x32\x14.tetra_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory*\xd7\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1e\n\x1aJOB_STATE_VALIDATING_MODEL\x10P*\xa4\x01\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01\x12\x16\n\x12TENSOR_DTYPE_INT32\x10\x02\x12\x16\n\x12TENSOR_DTYPE_INT64\x10\x03\x12\x15\n\x11TENSOR_DTYPE_INT8\x10\x04\x12\x16\n\x12TENSOR_DTYPE_UINT8\x10\x05*\xe4\x01\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05\x12\x13\n\x0fMODEL_TYPE_ONNX\x10\x06\x12\x12\n\x0eMODEL_TYPE_ORT\x10\x07*T\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x16\n\x12JOB_TYPE_PROFILING\x10\x01\x12\x17\n\x13JOB_TYPE_VALIDATION\x10\x02*\xb4\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n\x12\x17\n\x13VIZ_GRAPH_TYPE_ONNX\x10\x0b\x12\x16\n\x12VIZ_GRAPH_TYPE_ORT\x10\x0c*\xa4\x05\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x16\n\x12VIZ_DTYPE_BFLOAT16\x10\x10\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1atetra_hub/public_api.proto\x12\rtetra_hub.api\x1a\x1fgoogle/protobuf/timestamp.proto\"\x9a\x01\n\x14\x43reateUpdateResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x31\n\rcreation_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x65xpiration_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\"0\n\x0f\x46ileDownloadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x10\n\x08\x66ilename\x18\x02 \x01(\t\"\x9e\x01\n\rFileUploadURL\x12\x0b\n\x03url\x18\x01 \x01(\t\x12\x17\n\x0f\x66ile_field_name\x18\x02 \x01(\t\x12\x38\n\x06\x66ields\x18\x03 \x03(\x0b\x32(.tetra_hub.api.FileUploadURL.FieldsEntry\x1a-\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"v\n\x04User\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x12\n\nfirst_name\x18\x02 \x01(\t\x12\x11\n\tlast_name\x18\x03 \x01(\t\x12\r\n\x05\x65mail\x18\x04 \x01(\t\x12\x12\n\x05token\x18\x05 \x01(\tH\x00\x88\x01\x01\x12\x0e\n\x06org_id\x18\x06 \x01(\x04\x42\x08\n\x06_token\"I\n\x08UserList\x12\"\n\x05users\x18\x01 \x03(\x0b\x32\x13.tetra_hub.api.User\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"@\n\x12UserChangePassword\x12\x14\n\x0cold_password\x18\x01 \x01(\t\x12\x14\n\x0cnew_password\x18\x02 \x01(\t\"V\n\x0cOrganization\x12\x0e\n\x06org_id\x18\x01 \x01(\x04\x12\x0c\n\x04name\x18\x02 \x01(\t\x12(\n\x07members\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.UserList\"6\n\x06\x44\x65vice\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02os\x18\x02 \x01(\t\x12\x12\n\nattributes\x18\x03 \x03(\t\"O\n\nDeviceList\x12&\n\x07\x64\x65vices\x18\x01 \x03(\x0b\x32\x15.tetra_hub.api.Device\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xd4\x02\n\x07\x44\x61taset\x12\x17\n\ndataset_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x38\n\x0f\x65xpiration_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\r\n\x0b_dataset_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\x12\n\x10_expiration_timeB\x17\n\x15_file_upload_complete\"R\n\x0b\x44\x61tasetList\x12(\n\x08\x64\x61tasets\x18\x01 \x03(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\nTensorType\x12\r\n\x05shape\x18\x01 \x03(\x04\x12)\n\x05\x64type\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.TensorDtype\"O\n\x0fNamedTensorType\x12\x0c\n\x04name\x18\x01 \x01(\t\x12.\n\x0btensor_type\x18\x02 \x01(\x0b\x32\x19.tetra_hub.api.TensorType\"D\n\x13NamedTensorTypeList\x12-\n\x05types\x18\x01 \x03(\x0b\x32\x1e.tetra_hub.api.NamedTensorType\"\xc2\x02\n\x05Model\x12\x15\n\x08model_id\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\'\n\x05owner\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.UserH\x01\x88\x01\x01\x12\x11\n\x04name\x18\x03 \x01(\tH\x02\x88\x01\x01\x12\x36\n\rcreation_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampH\x03\x88\x01\x01\x12\x31\n\nmodel_type\x18\x05 \x01(\x0e\x32\x18.tetra_hub.api.ModelTypeH\x04\x88\x01\x01\x12!\n\x14\x66ile_upload_complete\x18\x06 \x01(\x08H\x05\x88\x01\x01\x42\x0b\n\t_model_idB\x08\n\x06_ownerB\x07\n\x05_nameB\x10\n\x0e_creation_timeB\r\n\x0b_model_typeB\x17\n\x15_file_upload_complete\"L\n\tModelList\x12$\n\x06models\x18\x01 \x03(\x0b\x32\x14.tetra_hub.api.Model\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"\xa3\x07\n\nProfileJob\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12\x0f\n\x07user_id\x18\x03 \x01(\x04\x12#\n\x05model\x18\x04 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12%\n\x06\x64\x65vice\x18\x06 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12<\n\x10tensor_type_list\x18\x07 \x01(\x0b\x32\".tetra_hub.api.NamedTensorTypeList\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x65xecution_time\x18\x0b \x01(\x04H\x00\x88\x01\x01\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0c \x01(\tH\x01\x88\x01\x01\x12\x1e\n\x11peak_memory_usage\x18\r \x01(\x04H\x02\x88\x01\x01\x12\x0c\n\x04name\x18\x0e \x01(\t\x12\x0f\n\x07options\x18\x0f \x01(\t\x12\'\n\x07\x64\x61taset\x18\x10 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12/\n\x0ctarget_model\x18\x11 \x01(\x0b\x32\x14.tetra_hub.api.ModelH\x03\x88\x01\x01\x12\x38\n\x15\x65xecution_peak_memory\x18\x12 \x01(\x0b\x32\x14.tetra_hub.api.RangeH\x04\x88\x01\x01\x12\x19\n\x0chas_vizgraph\x18\x13 \x01(\x08H\x05\x88\x01\x01\x12\x35\n\x11last_updated_time\x18\x14 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x15 \x01(\tH\x06\x88\x01\x01\x42\x11\n\x0f_execution_timeB\x11\n\x0f_failure_reasonB\x14\n\x12_peak_memory_usageB\x0f\n\r_target_modelB\x18\n\x16_execution_peak_memoryB\x0f\n\r_has_vizgraphB\x0c\n\n_admin_url\"\xb2\x04\n\rValidationJob\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12!\n\x04user\x18\x02 \x01(\x0b\x32\x13.tetra_hub.api.User\x12#\n\x05model\x18\x03 \x01(\x0b\x32\x14.tetra_hub.api.Model\x12%\n\x06\x64\x65vice\x18\x04 \x01(\x0b\x32\x15.tetra_hub.api.Device\x12*\n\tjob_state\x18\x05 \x01(\x0e\x32\x17.tetra_hub.api.JobState\x12\x0c\n\x04name\x18\x06 \x01(\t\x12\'\n\x07\x64\x61taset\x18\x07 \x01(\x0b\x32\x16.tetra_hub.api.Dataset\x12\x31\n\rcreation_time\x18\x08 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12.\n\nstart_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x33\n\x0f\x63ompletion_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x1b\n\x0e\x66\x61ilure_reason\x18\x0b \x01(\tH\x00\x88\x01\x01\x12\x0f\n\x07options\x18\x0c \x01(\t\x12\x35\n\x11last_updated_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x16\n\tadmin_url\x18\x0e \x01(\tH\x01\x88\x01\x01\x42\x11\n\x0f_failure_reasonB\x0c\n\n_admin_url\"v\n\x03Job\x12\x30\n\x0bprofile_job\x18\x01 \x01(\x0b\x32\x19.tetra_hub.api.ProfileJobH\x00\x12\x36\n\x0evalidation_job\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ValidationJobH\x00\x42\x05\n\x03job\"T\n\x0eProfileJobList\x12\'\n\x04jobs\x18\x01 \x03(\x0b\x32\x19.tetra_hub.api.ProfileJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"Z\n\x11ValidationJobList\x12*\n\x04jobs\x18\x01 \x03(\x0b\x32\x1c.tetra_hub.api.ValidationJob\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"F\n\x07JobList\x12 \n\x04jobs\x18\x01 \x03(\x0b\x32\x12.tetra_hub.api.Job\x12\x19\n\x11total_query_count\x18\x02 \x01(\x04\"j\n\x10ProfileJobResult\x12\x16\n\x0eprofile_job_id\x18\x01 \x01(\t\x12\x32\n\x07profile\x18\x02 \x01(\x0b\x32\x1c.tetra_hub.api.ProfileDetailH\x00\x88\x01\x01\x42\n\n\x08_profile\"K\n\x13ValidationJobResult\x12\x19\n\x11validation_job_id\x18\x01 \x01(\t\x12\x19\n\x11output_dataset_id\x18\x02 \x01(\t\"\x99\x01\n\tJobResult\x12=\n\x12profile_job_result\x18\x01 \x01(\x0b\x32\x1f.tetra_hub.api.ProfileJobResultH\x00\x12\x43\n\x15validation_job_result\x18\x02 \x01(\x0b\x32\".tetra_hub.api.ValidationJobResultH\x00\x42\x08\n\x06result\"\xf4\x02\n\x08VizGraph\x12/\n\ngraph_type\x18\x01 \x01(\x0e\x32\x1b.tetra_hub.api.VizGraphType\x12-\n\tsubgraphs\x18\x03 \x03(\x0b\x32\x1a.tetra_hub.api.VizSubgraph\x12;\n\nparameters\x18\x04 \x03(\x0b\x32\'.tetra_hub.api.VizGraph.ParametersEntry\x12\x35\n\x07tensors\x18\x05 \x03(\x0b\x32$.tetra_hub.api.VizGraph.TensorsEntry\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\x1aH\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\'\n\x05value\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensor:\x02\x38\x01\"B\n\x0bVizSubgraph\x12\x0c\n\x04name\x18\x01 \x01(\t\x12%\n\x05nodes\x18\x02 \x03(\x0b\x32\x16.tetra_hub.api.VizNode\"\x17\n\x08VizShape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\"\x8c\x02\n\tVizTensor\x12&\n\x05\x64type\x18\x02 \x01(\x0e\x32\x17.tetra_hub.api.VizDtype\x12&\n\x05shape\x18\x03 \x01(\x0b\x32\x17.tetra_hub.api.VizShape\x12<\n\nparameters\x18\x04 \x03(\x0b\x32(.tetra_hub.api.VizTensor.ParametersEntry\x12%\n\x04\x64\x61ta\x18\x05 \x01(\x0b\x32\x17.tetra_hub.api.VizValue\x1aJ\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tetra_hub.api.VizValue:\x02\x38\x01\"\x90\x02\n\x07VizNode\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06inputs\x18\x03 \x03(\t\x12\x0f\n\x07outputs\x18\x04 \x03(\t\x12\x12\n\ninput_keys\x18\x05 \x03(\t\x12\x13\n\x0boutput_keys\x18\x06 \x03(\t\x12:\n\nattributes\x18\x07 \x03(\x0b\x32&.tetra_hub.api.VizNode.AttributesEntry\x12\x10\n\x08subgraph\x18\x08 \x01(\x03\x1aN\n\x0f\x41ttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12*\n\x05value\x18\x02 \x01(\x0b\x32\x1b.tetra_hub.api.VizAttribute:\x02\x38\x01\"\xe0\x03\n\x08VizValue\x12\x17\n\rliteral_value\x18\x01 \x01(\tH\x00\x12\x16\n\x0cstring_value\x18\x02 \x01(\tH\x00\x12\x17\n\rinteger_value\x18\x03 \x01(\x03H\x00\x12\x15\n\x0b\x66loat_value\x18\x04 \x01(\x02H\x00\x12\x14\n\nbool_value\x18\x05 \x01(\x08H\x00\x12\x39\n\x0bstring_list\x18\x06 \x01(\x0b\x32\".tetra_hub.api.VizValue.StringListH\x00\x12;\n\x0cinteger_list\x18\x07 \x01(\x0b\x32#.tetra_hub.api.VizValue.IntegerListH\x00\x12\x37\n\nfloat_list\x18\x08 \x01(\x0b\x32!.tetra_hub.api.VizValue.FloatListH\x00\x12\x35\n\tbool_list\x18\t \x01(\x0b\x32 .tetra_hub.api.VizValue.BoolListH\x00\x1a\x1a\n\nStringList\x12\x0c\n\x04list\x18\x01 \x03(\t\x1a\x1b\n\x0bIntegerList\x12\x0c\n\x04list\x18\x01 \x03(\x03\x1a\x19\n\tFloatList\x12\x0c\n\x04list\x18\x01 \x03(\x02\x1a\x18\n\x08\x42oolList\x12\x0c\n\x04list\x18\x01 \x03(\x08\x42\x07\n\x05value\"l\n\x0cVizAttribute\x12(\n\x05value\x18\x01 \x01(\x0b\x32\x17.tetra_hub.api.VizValueH\x00\x12*\n\x06tensor\x18\x02 \x01(\x0b\x32\x18.tetra_hub.api.VizTensorH\x00\x42\x06\n\x04type\"\x9d\x02\n\x0bLayerDetail\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x17\n\x0flayer_type_name\x18\x03 \x01(\t\x12\n\n\x02id\x18\x04 \x01(\t\x12\x15\n\rdelegate_name\x18\x05 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x06 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x07 \x01(\x04H\x00\x88\x01\x01\x12\x17\n\nsegment_id\x18\x08 \x01(\tH\x01\x88\x01\x01\x12\x1d\n\x15\x64\x65legate_reported_ops\x18\t \x03(\tB\x11\n\x0f_execution_timeB\r\n\x0b_segment_id\"\xb1\x01\n\rSegmentDetail\x12\n\n\x02id\x18\x01 \x01(\t\x12\x30\n\x0c\x63ompute_unit\x18\x02 \x01(\x0e\x32\x1a.tetra_hub.api.ComputeUnit\x12\x15\n\rdelegate_name\x18\x03 \x01(\t\x12\x1b\n\x13\x64\x65legate_extra_info\x18\x04 \x01(\t\x12\x1b\n\x0e\x65xecution_time\x18\x05 \x01(\x04H\x00\x88\x01\x01\x42\x11\n\x0f_execution_time\"%\n\x05Range\x12\r\n\x05lower\x18\x01 \x01(\x04\x12\r\n\x05upper\x18\x02 \x01(\x04\"\xef\x0b\n\rProfileDetail\x12\x16\n\x0e\x65xecution_time\x18\x01 \x01(\x04\x12\x19\n\x11peak_memory_usage\x18\x02 \x01(\x04\x12\x16\n\tload_time\x18\x03 \x01(\x04H\x00\x88\x01\x01\x12\x31\n\rlayer_details\x18\x04 \x03(\x0b\x32\x1a.tetra_hub.api.LayerDetail\x12\x15\n\rmajor_version\x18\x05 \x01(\x04\x12\x15\n\rminor_version\x18\x06 \x01(\x04\x12#\n\x1b\x61\x66ter_cold_load_peak_memory\x18\x07 \x01(\x04\x12!\n\x19\x61\x66ter_compile_peak_memory\x18\x08 \x01(\x04\x12#\n\x1b\x61\x66ter_execution_peak_memory\x18\t \x01(\x04\x12#\n\x1b\x61\x66ter_warm_load_peak_memory\x18\n \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_cold_load_current_memory\x18\x0b \x01(\x04\x12$\n\x1c\x62\x65\x66ore_cold_load_peak_memory\x18\x0c \x01(\x04\x12%\n\x1d\x62\x65\x66ore_compile_current_memory\x18\r \x01(\x04\x12\"\n\x1a\x62\x65\x66ore_compile_peak_memory\x18\x0e \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_execution_current_memory\x18\x0f \x01(\x04\x12$\n\x1c\x62\x65\x66ore_execution_peak_memory\x18\x10 \x01(\x04\x12\'\n\x1f\x62\x65\x66ore_warm_load_current_memory\x18\x11 \x01(\x04\x12$\n\x1c\x62\x65\x66ore_warm_load_peak_memory\x18\x12 \x01(\x04\x12\x16\n\x0e\x63old_load_time\x18\x13 \x01(\x04\x12\x14\n\x0c\x63ompile_time\x18\x14 \x01(\x04\x12\x16\n\x0ewarm_load_time\x18\x15 \x01(\x04\x12&\n\x1e\x61\x66ter_cold_load_current_memory\x18\x16 \x01(\x04\x12&\n\x1e\x61\x66ter_warm_load_current_memory\x18\x17 \x01(\x04\x12$\n\x1c\x61\x66ter_compile_current_memory\x18\x18 \x01(\x04\x12&\n\x1e\x61\x66ter_execution_current_memory\x18\x19 \x01(\x04\x12\x45\n\x0e\x63ompile_memory\x18\x1a \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x01\x88\x01\x01\x12G\n\x10\x63old_load_memory\x18\x1b \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x02\x88\x01\x01\x12G\n\x10warm_load_memory\x18\x1c \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x03\x88\x01\x01\x12G\n\x10\x65xecution_memory\x18\x1d \x01(\x0b\x32(.tetra_hub.api.ProfileDetail.MemoryUsageH\x04\x88\x01\x01\x12\x19\n\x11\x61ll_compile_times\x18\x1e \x03(\x04\x12\x1b\n\x13\x61ll_cold_load_times\x18\x1f \x03(\x04\x12\x1b\n\x13\x61ll_warm_load_times\x18  \x03(\x04\x12\x1b\n\x13\x61ll_execution_times\x18! \x03(\x04\x12\x35\n\x0fsegment_details\x18\" \x03(\x0b\x32\x1c.tetra_hub.api.SegmentDetail\x1aY\n\x0bMemoryUsage\x12&\n\x08increase\x18\x01 \x01(\x0b\x32\x14.tetra_hub.api.Range\x12\"\n\x04peak\x18\x02 \x01(\x0b\x32\x14.tetra_hub.api.RangeB\x0c\n\n_load_timeB\x11\n\x0f_compile_memoryB\x13\n\x11_cold_load_memoryB\x13\n\x11_warm_load_memoryB\x13\n\x11_execution_memory*\xd7\x01\n\x08JobState\x12\x19\n\x15JOB_STATE_UNSPECIFIED\x10\x00\x12\x12\n\x0eJOB_STATE_DONE\x10\n\x12\x14\n\x10JOB_STATE_FAILED\x10\x1e\x12\x1e\n\x1aJOB_STATE_OPTIMIZING_MODEL\x10\x32\x12!\n\x1dJOB_STATE_PROVISIONING_DEVICE\x10<\x12#\n\x1fJOB_STATE_MEASURING_PERFORMANCE\x10\x46\x12\x1e\n\x1aJOB_STATE_VALIDATING_MODEL\x10P*\xa4\x01\n\x0bTensorDtype\x12\x1c\n\x18TENSOR_DTYPE_UNSPECIFIED\x10\x00\x12\x18\n\x14TENSOR_DTYPE_FLOAT32\x10\x01\x12\x16\n\x12TENSOR_DTYPE_INT32\x10\x02\x12\x16\n\x12TENSOR_DTYPE_INT64\x10\x03\x12\x15\n\x11TENSOR_DTYPE_INT8\x10\x04\x12\x16\n\x12TENSOR_DTYPE_UINT8\x10\x05*\xfe\x01\n\tModelType\x12\x1a\n\x16MODEL_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16MODEL_TYPE_TORCHSCRIPT\x10\x01\x12\x16\n\x12MODEL_TYPE_MLMODEL\x10\x02\x12.\n*MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT\x10\x03\x12\x15\n\x11MODEL_TYPE_TFLITE\x10\x04\x12\x17\n\x13MODEL_TYPE_MLMODELC\x10\x05\x12\x13\n\x0fMODEL_TYPE_ONNX\x10\x06\x12\x12\n\x0eMODEL_TYPE_ORT\x10\x07\x12\x18\n\x14MODEL_TYPE_MLPACKAGE\x10\x08*T\n\x07JobType\x12\x18\n\x14JOB_TYPE_UNSPECIFIED\x10\x00\x12\x16\n\x12JOB_TYPE_PROFILING\x10\x01\x12\x17\n\x13JOB_TYPE_VALIDATION\x10\x02*\xb4\x01\n\x0cVizGraphType\x12\x1e\n\x1aVIZ_GRAPH_TYPE_UNSPECIFIED\x10\x00\x12\x1a\n\x16VIZ_GRAPH_TYPE_MLMODEL\x10\x01\x12\x1c\n\x18VIZ_GRAPH_TYPE_MLPROGRAM\x10\x02\x12\x19\n\x15VIZ_GRAPH_TYPE_TFLITE\x10\n\x12\x17\n\x13VIZ_GRAPH_TYPE_ONNX\x10\x0b\x12\x16\n\x12VIZ_GRAPH_TYPE_ORT\x10\x0c*\xa4\x05\n\x08VizDtype\x12\x19\n\x15VIZ_DTYPE_UNSPECIFIED\x10\x00\x12\x15\n\x11VIZ_DTYPE_FLOAT16\x10\x01\x12\x15\n\x11VIZ_DTYPE_FLOAT32\x10\x02\x12\x15\n\x11VIZ_DTYPE_FLOAT64\x10\x03\x12\x13\n\x0fVIZ_DTYPE_UINT8\x10\x04\x12\x12\n\x0eVIZ_DTYPE_INT8\x10\x05\x12\x14\n\x10VIZ_DTYPE_UINT16\x10\x06\x12\x13\n\x0fVIZ_DTYPE_INT16\x10\x07\x12\x14\n\x10VIZ_DTYPE_UINT32\x10\x08\x12\x13\n\x0fVIZ_DTYPE_INT32\x10\t\x12\x14\n\x10VIZ_DTYPE_UINT64\x10\n\x12\x13\n\x0fVIZ_DTYPE_INT64\x10\x0b\x12\x17\n\x13VIZ_DTYPE_COMPLEX64\x10\x0c\x12\x18\n\x14VIZ_DTYPE_COMPLEX128\x10\r\x12\x14\n\x10VIZ_DTYPE_STRING\x10\x0e\x12\x12\n\x0eVIZ_DTYPE_BOOL\x10\x0f\x12\x16\n\x12VIZ_DTYPE_BFLOAT16\x10\x10\x12\x13\n\x0fVIZ_DTYPE_UINT1\x10\x32\x12\x13\n\x0fVIZ_DTYPE_UINT2\x10\x33\x12\x13\n\x0fVIZ_DTYPE_UINT3\x10\x34\x12\x13\n\x0fVIZ_DTYPE_UINT4\x10\x35\x12\x13\n\x0fVIZ_DTYPE_UINT5\x10\x36\x12\x13\n\x0fVIZ_DTYPE_UINT6\x10\x37\x12\x13\n\x0fVIZ_DTYPE_UINT7\x10\x38\x12#\n\x1fVIZ_DTYPE_DICT_INT64_TO_FLOAT64\x10\x64\x12$\n VIZ_DTYPE_DICT_STRING_TO_FLOAT64\x10\x65\x12\x1d\n\x19VIZ_DTYPE_TFLITE_RESOURCE\x10n\x12\x1c\n\x18VIZ_DTYPE_TFLITE_VARIANT\x10o*m\n\x0b\x43omputeUnit\x12\x1c\n\x18\x43OMPUTE_UNIT_UNSPECIFIED\x10\x00\x12\x14\n\x10\x43OMPUTE_UNIT_CPU\x10\x01\x12\x14\n\x10\x43OMPUTE_UNIT_GPU\x10\x02\x12\x14\n\x10\x43OMPUTE_UNIT_NPU\x10\x03\x62\x06proto3')
 
 _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
 _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tetra_hub.public_api_pb2', globals())
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _FILEUPLOADURL_FIELDSENTRY._options = None
@@ -32,23 +32,23 @@
   _VIZNODE_ATTRIBUTESENTRY._options = None
   _VIZNODE_ATTRIBUTESENTRY._serialized_options = b'8\001'
   _JOBSTATE._serialized_start=7832
   _JOBSTATE._serialized_end=8047
   _TENSORDTYPE._serialized_start=8050
   _TENSORDTYPE._serialized_end=8214
   _MODELTYPE._serialized_start=8217
-  _MODELTYPE._serialized_end=8445
-  _JOBTYPE._serialized_start=8447
-  _JOBTYPE._serialized_end=8531
-  _VIZGRAPHTYPE._serialized_start=8534
-  _VIZGRAPHTYPE._serialized_end=8714
-  _VIZDTYPE._serialized_start=8717
-  _VIZDTYPE._serialized_end=9393
-  _COMPUTEUNIT._serialized_start=9395
-  _COMPUTEUNIT._serialized_end=9504
+  _MODELTYPE._serialized_end=8471
+  _JOBTYPE._serialized_start=8473
+  _JOBTYPE._serialized_end=8557
+  _VIZGRAPHTYPE._serialized_start=8560
+  _VIZGRAPHTYPE._serialized_end=8740
+  _VIZDTYPE._serialized_start=8743
+  _VIZDTYPE._serialized_end=9419
+  _COMPUTEUNIT._serialized_start=9421
+  _COMPUTEUNIT._serialized_end=9530
   _CREATEUPDATERESPONSE._serialized_start=79
   _CREATEUPDATERESPONSE._serialized_end=233
   _FILEDOWNLOADURL._serialized_start=235
   _FILEDOWNLOADURL._serialized_end=283
   _FILEUPLOADURL._serialized_start=286
   _FILEUPLOADURL._serialized_end=444
   _FILEUPLOADURL_FIELDSENTRY._serialized_start=399
```

## tetra_hub/public_api_pb2.pyi

```diff
@@ -92,14 +92,15 @@
     MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT: _ModelType.ValueType  # 3
     """unused"""
 
     MODEL_TYPE_TFLITE: _ModelType.ValueType  # 4
     MODEL_TYPE_MLMODELC: _ModelType.ValueType  # 5
     MODEL_TYPE_ONNX: _ModelType.ValueType  # 6
     MODEL_TYPE_ORT: _ModelType.ValueType  # 7
+    MODEL_TYPE_MLPACKAGE: _ModelType.ValueType  # 8
 class ModelType(_ModelType, metaclass=_ModelTypeEnumTypeWrapper):
     """-------------
     /models
     -------------
 
     """
     pass
@@ -112,14 +113,15 @@
 MODEL_TYPE_DEPRECATED_UNTRACED_TORCHSCRIPT: ModelType.ValueType  # 3
 """unused"""
 
 MODEL_TYPE_TFLITE: ModelType.ValueType  # 4
 MODEL_TYPE_MLMODELC: ModelType.ValueType  # 5
 MODEL_TYPE_ONNX: ModelType.ValueType  # 6
 MODEL_TYPE_ORT: ModelType.ValueType  # 7
+MODEL_TYPE_MLPACKAGE: ModelType.ValueType  # 8
 global___ModelType = ModelType
 
 
 class _JobType:
     ValueType = typing.NewType('ValueType', builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 class _JobTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_JobType.ValueType], builtins.type):
```

## tetra_hub/public_rest_api.py

```diff
@@ -373,32 +373,36 @@
                 input_names_match[i] = True
                 if input_tensor_spec != input_spec:
                     return False
     return all(input_names_match)
 
 
 def _download_file(
-    url: str, filename: str, dst_path: str, verbose: bool, extract_model: bool = False
+    url: str,
+    filename: str,
+    dst_path: str,
+    verbose: bool,
+    extract_if_zipped: bool = False,
 ) -> str:
     dst_path = os.path.expanduser(dst_path)  # Expand ~ to user home in path.
 
-    # Unzip model only if extract_model is set and uploaded model is zipped.
-    model_to_be_extracted = extract_model and filename.endswith(".zip")
+    # Unzip file only if extract_if_zipped is set and uploaded file is zipped.
+    file_to_be_extracted = extract_if_zipped and filename.endswith(".zip")
 
     # If no filename is provided, use the filename given to us by the parent
     if os.path.isdir(dst_path):
         dst_path = os.path.join(dst_path, filename)
 
         # Append numerical suffix to the filename if the dst file already exists.
         dst_path, filename = _get_unique_path(dst_path)
 
         # Remove .zip extension from destination path
-        if model_to_be_extracted:
+        if file_to_be_extracted:
             dst_path = os.path.splitext(dst_path)[0]
-    elif model_to_be_extracted:
+    elif file_to_be_extracted:
         raise ValueError(
             "Model cannot be extracted to a file. Please provide a directory path."
         )
 
     # Verify dst parent dir exists. The same error thrown by open() called
     # below would include the model name, which is confusing.
     parent_dir = os.path.dirname(dst_path)
@@ -429,15 +433,15 @@
                 tmp_dst_path = os.path.join(tmpdir, os.path.basename(dst_path))
                 with open(tmp_dst_path, "wb") as fd:
                     for data in response.iter_content(block_size):
                         written_data = fd.write(data)
                         if progress_bar:
                             progress_bar.update(written_data)
 
-                if model_to_be_extracted:
+                if file_to_be_extracted:
                     with ZipFile(tmp_dst_path, "r") as zippedModel:
                         zippedModel.extractall(dst_path)
                     os.remove(tmp_dst_path)
                 else:
                     # Cannot use os.rename, whose doc string states: "On
                     # Windows, if dst exists a FileExistsError is always
                     # raised." `dst_path` is always created by
@@ -1430,14 +1434,88 @@
     url = utils.api_url(config, "models", model_id, "download")
     header = utils.auth_header(config)
     return utils.response_as_protobuf(
         requests.get(url, headers=header), api_pb.FileDownloadURL
     )
 
 
+def _download_model(
+    url: str,
+    filename: str,
+    dst_path: str,
+    verbose: bool,
+    extract_if_zipped: bool = False,
+):
+    """
+    Download model at provided destination path and return path to the model
+
+    Parameters
+    ----------
+    url : str
+        Model URL to download
+    filename : str
+        File name of model to download
+    dst_path : str
+        Destination path to download model to
+    verbose: bool
+        Enable logs
+    extract_if_zipped: bool
+        If set true, extracts zipped model into provided `dst_path`
+
+    Returns
+    -------
+    model_path : str
+        Path to the saved model file/directory.
+
+    Raises
+    ------
+        ValueError
+            if zipped model does not have single base level directory.
+        ValueError
+            if zipped model is being extracted to a file.
+    """
+    extract_zipped_model = extract_if_zipped and filename.endswith(".zip")
+    with tempfile.TemporaryDirectory() as tmpdir:
+        # If not extracting zipped model,
+        # download model at expected destination path itself.
+        model_path = utils.download_file(
+            url,
+            filename,
+            tmpdir if extract_zipped_model else dst_path,
+            verbose,
+            extract_if_zipped,
+        )
+
+        if not extract_zipped_model:
+            return model_path
+
+        if not os.path.isdir(dst_path):
+            raise ValueError(
+                "Model cannot be extracted to a file. Please provide a directory path."
+            )
+
+        # Move extracted model from temporary path to destination path
+        dst_path = os.path.join(dst_path, os.path.basename(model_path))
+        dst_path, _ = _get_unique_path(dst_path)
+
+        # get_unique_path creates an empty file.
+        if os.path.exists(dst_path) and os.path.isfile(dst_path):
+            os.remove(dst_path)
+
+        unzipped_model_content = os.listdir(model_path)
+        if len(unzipped_model_content) != 1:
+            raise ValueError("Extracted model must contain a single base model asset.")
+
+        # Point to base model directory
+        model_path = os.path.join(model_path, unzipped_model_content[0])
+
+        shutil.copytree(model_path, dst_path)
+        return dst_path
+
+
 def download_model(
     config: ClientConfig,
     model_id: str,
     file_path: str,
     verbose: bool | None = None,
     extract_model: bool = False,
 ) -> str:
@@ -1451,24 +1529,24 @@
     model_id : str
         Model ID.
     file_path : str
         file location to store model to
 
     Returns
     -------
-    file_path : str
-        Path to the saved file.
+    model_path : str
+        Path to the saved model file/directory.
 
     Raises
     ------
     APIException
         Raised if request has failed.
     """
     response = download_model_info(config, model_id)
-    return utils.download_file(
+    return _download_model(
         response.url,
         response.filename,
         file_path,
         verbose if verbose is not None else config.verbose,
         extract_model,
     )
 
@@ -1486,29 +1564,29 @@
     job_id : str
         Job ID.
     file_path : str
         file location to store compiled model to
 
     Returns
     -------
-    file_path : str
-        Path to the saved file.
+    model_path : str
+        Path to the saved model file/directory.
 
     Raises
     ------
     APIException
         Raised if request has failed.
     """
     # fetch compiled model
     url = utils.api_url(config, "jobs", job_id, "download_compiled_model")
     header = utils.auth_header(config)
     response = utils.response_as_protobuf(
         requests.get(url, headers=header), api_pb.FileDownloadURL
     )
-    return utils.download_file(
+    return _download_model(
         response.url,
         response.filename,
         file_path,
         verbose if verbose is not None else config.verbose,
     )
```

## tetra_hub/test/test_client.py

```diff
@@ -1,97 +1,153 @@
+import os
 import shutil
 import tempfile
 from pathlib import Path
 
 import pytest
 
 from tetra_hub.client import (
     UserError,
-    _assert_is_valid_zipped_mlmodelc,
-    _zip_mlmodelc_if_needed,
+    _assert_is_valid_zipped_model,
+    _make_zipped_model_compatible,
 )
 
 
-def create_sample_mlmodelc(modelDir: Path):
+def create_sample_mlmodelc(modelDir: Path, include_assemble_json: bool = False):
     Path(modelDir).mkdir(parents=True)
     Path(modelDir / "model.espresso.net").touch()
     Path(modelDir / "model.espresso.shape").touch()
     Path(modelDir / "model.espresso.weights").touch()
+    if include_assemble_json:
+        Path(modelDir / "assemble.json").touch()
 
 
 def test_valid_zipped_mlmodelc():
-    #  1. <filepath>/model.espresso.net or
-    #  2. <filepath>/model0/model.espresso.net in case of pipeline model
-    #  3. <filepath>/foo.mlmodelc/model.espresso.net or
-    #  4. <filepath>/foo.mlmodelc/model0/model.espresso.net in case of pipeline model
+    #  1. <filepath>/foo.mlmodelc/assemble.json in case of pipeline model
+    #  2. <filepath>/foo.mlmodelc/model.espresso.net or
+    #  3. <filepath>/foo.mlmodelc/model0/model.espresso.net in case of pipeline model
 
-    # Case 1 and 3:
+    mlmodelc_name = "myModel.mlmodelc"
+    # Case 1:
     with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
-        modelDir = Path(baseDir) / "myModel.mlmodelc"
+        modelDir = Path(baseDir) / mlmodelc_name
+        create_sample_mlmodelc(modelDir, include_assemble_json=True)
 
-        create_sample_mlmodelc(modelDir)
-        # Case 1
         zipPath = Path(baseDir) / "my_model_archive"
-        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir=modelDir)
-        _assert_is_valid_zipped_mlmodelc(f"{zipPath}.zip")
+        shutil.make_archive(
+            str(zipPath), "zip", root_dir=baseDir, base_dir=mlmodelc_name
+        )
+        _assert_is_valid_zipped_model(f"{zipPath}.zip")
 
-        # Case 3
-        zipPath = Path(baseDir) / "my_model_archive_flat"
-        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir=baseDir)
-        _assert_is_valid_zipped_mlmodelc(f"{zipPath}.zip")
+    # Case 2
+    with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
+        modelDir = Path(baseDir) / mlmodelc_name
+        create_sample_mlmodelc(modelDir)
 
-    # Case 2 and 4:
+        zipPath = Path(baseDir) / "my_model_archive"
+        shutil.make_archive(
+            str(zipPath), "zip", root_dir=baseDir, base_dir=mlmodelc_name
+        )
+        _assert_is_valid_zipped_model(f"{zipPath}.zip")
+
+    # Case 3
     with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
         modelDir = Path(baseDir) / "myModel.mlmodelc"
         pipelinePath = Path(modelDir) / "model0"
         create_sample_mlmodelc(pipelinePath)
 
-        # Case 2
         zipPath = Path(baseDir) / "my_model_archive"
-        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir=modelDir)
-        _assert_is_valid_zipped_mlmodelc(f"{zipPath}.zip")
+        shutil.make_archive(
+            str(zipPath), "zip", root_dir=baseDir, base_dir=mlmodelc_name
+        )
+        _assert_is_valid_zipped_model(f"{zipPath}.zip")
 
-        # Case 4
-        zipPath = Path(baseDir) / "my_model_archive_flat"
-        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir=baseDir)
-        _assert_is_valid_zipped_mlmodelc(f"{zipPath}.zip")
+    # Unsupported: model.espresso.net / assemble.json present
+    # with flat directory structure i.e. model.zip -> model.espresso.net
+    with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
+        modelDir = Path(baseDir) / mlmodelc_name
+        create_sample_mlmodelc(modelDir, include_assemble_json=True)
+
+        zipPath = Path(baseDir) / "my_model_archive"
+        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir="./")
+        with pytest.raises(UserError):
+            _assert_is_valid_zipped_model(f"{zipPath}.zip")
 
+    # Valid .mlmodelc within zip with no model.espresso.net/assemble.json
     with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
         # Make an invalid model
-        modelDir = Path(baseDir) / "myModel.mlmodelc"
+        modelDir = Path(baseDir) / mlmodelc_name
         Path(modelDir).mkdir()
         Path(modelDir / "bad_file").touch()
 
         # Check that this fails
         zipPath = Path(baseDir) / "my_model_archive"
-        shutil.make_archive(str(zipPath), "zip", root_dir=modelDir, base_dir=baseDir)
+        shutil.make_archive(
+            str(zipPath), "zip", root_dir=baseDir, base_dir=mlmodelc_name
+        )
         with pytest.raises(UserError):
-            _assert_is_valid_zipped_mlmodelc(f"{zipPath}.zip")
+            _assert_is_valid_zipped_model(f"{zipPath}.zip")
 
 
-def test_zip_mlmodelc_if_needed_does_not_zip_zip():
+def test_valid_zipped_mlpackage():
+    # <dirpath>/foo.mlpackage/ in case of zipped mlpackage
+
+    mlpackage_name = "myModel.mlpackage"
+    with tempfile.TemporaryDirectory(suffix="baseDir") as baseDir:
+        modelDir = Path(baseDir) / mlpackage_name
+        os.makedirs(modelDir)
+
+        zipPath = Path(baseDir) / "my_model_archive"
+        shutil.make_archive(
+            str(zipPath), "zip", root_dir=baseDir, base_dir=mlpackage_name
+        )
+        _assert_is_valid_zipped_model(f"{zipPath}.zip")
+
+
+def test_make_mlmodelc_compatible_zip_does_not_zip_zip():
+    model_name = "myModel.mlmodelc"
     with tempfile.TemporaryDirectory(suffix="baseDir") as base_dir:
-        model_dir = Path(base_dir) / "myModel.mlmodelc"
+        model_dir = Path(base_dir) / model_name
         create_sample_mlmodelc(model_dir)
 
         zip_base_path = Path(base_dir) / "my_model_archive"
         zip_path = shutil.make_archive(
-            str(zip_base_path), "zip", root_dir=model_dir, base_dir=model_dir
+            str(zip_base_path), "zip", root_dir=base_dir, base_dir=model_name
         )
 
         with tempfile.NamedTemporaryFile(suffix=".mlmodelc.zip") as model_zip_tempfile:
-            mlmodelc_zip_path = _zip_mlmodelc_if_needed(
-                zip_path, model_zip_tempfile.name
+            mlmodelc_zip_path = _make_zipped_model_compatible(
+                zip_path, model_zip_tempfile.name, ".mlmodelc"
             )
             assert mlmodelc_zip_path == zip_path
 
 
-def test_zip_mlmodelc_if_needed_zips_dir():
+def test_make_mlmodelc_compatible_zip_zips_dir():
     with tempfile.TemporaryDirectory(suffix="baseDir") as base_dir:
         model_dir = Path(base_dir) / "myModel.mlmodelc"
         create_sample_mlmodelc(model_dir)
-        with tempfile.NamedTemporaryFile(suffix=".mlmodelc.zip") as model_zip_tempfile:
-            zipfile_path = _zip_mlmodelc_if_needed(
-                str(model_dir), model_zip_tempfile.name
+
+        model_output_path = str(Path(base_dir, "output_model_dir"))
+        os.makedirs(model_output_path)
+        zipfile_path = _make_zipped_model_compatible(
+            str(model_dir), model_output_path, ".mlmodelc"
+        )
+        assert zipfile_path == os.path.join(model_output_path, "myModel.mlmodelc.zip")
+        _assert_is_valid_zipped_model(zipfile_path)
+
+
+def test_make_mlmodelc_compatible_zip_zips_dir_removing_additional_dirs():
+    with tempfile.TemporaryDirectory(suffix="baseDir") as base_dir:
+        model_dir = Path(base_dir) / "myModel.mlmodelc"
+        create_sample_mlmodelc(model_dir)
+        Path(os.path.join(base_dir, "__MACOS__")).mkdir(parents=True)
+        Path(os.path.join(base_dir, "some_random_file")).touch()
+
+        zipped_file_path = shutil.make_archive(
+            os.path.join(base_dir, "test_model.mlmodelc"), "zip", root_dir=base_dir
+        )
+        with tempfile.TemporaryDirectory() as tmp_dir:
+            zipfile_path = _make_zipped_model_compatible(
+                zipped_file_path, tmp_dir, ".mlmodelc"
             )
-            assert zipfile_path == model_zip_tempfile.name
-            _assert_is_valid_zipped_mlmodelc(zipfile_path)
+            assert zipfile_path == str(os.path.join(tmp_dir, "myModel.mlmodelc.zip"))
+            _assert_is_valid_zipped_model(zipfile_path)
```

## Comparing `tetra_hub-0.6.2.dist-info/METADATA` & `tetra_hub-0.6.3.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tetra-hub
-Version: 0.6.2
+Version: 0.6.3
 Summary: Python API for Tetra Hub.
 Home-page: https://tetra.ai/
 Author: Tetra Intelligence Systems Inc.
 Author-email: support@tetra.ai
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Development Status :: 2 - Pre-Alpha
```

## Comparing `tetra_hub-0.6.2.dist-info/RECORD` & `tetra_hub-0.6.3.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,23 @@
 tetra_hub/__init__.py,sha256=dypPlGFcYRNv21nwydpRPuw0Fut0_MlCs_OIRHhPc8Y,271
 tetra_hub/_cli.py,sha256=S9uy8GZNdknLcAQquAl4ehimiQu7yS2CTO-pAn8kMcs,3656
-tetra_hub/_version.py,sha256=jFlbxEJFS0G44LE-yXXVSwXACA1J_NyYDk5E20_2zpc,22
+tetra_hub/_version.py,sha256=zYiFHqR7JwbvdK9dvKrh-RTNfUqjHUwC4CTcFAPVYLc,22
 tetra_hub/api_status_codes.py,sha256=1Bo8lC_zSjBEz-bkEEZY8qfhrVRC-CfVOtVS77JOLGQ,4095
-tetra_hub/client.py,sha256=2X1ElNpkXSIQerygXNjslwHKHSiw9nCnPg7bgENzam0,86869
+tetra_hub/client.py,sha256=l1MgSLlrM07gpo1VRBGfpTJnPy_RdEhZ-8TnCOuPaiE,89325
 tetra_hub/hub.py,sha256=jyfgYyrkqcgOkSHYqlKKKf4efIMyEJEkCDoR6jCEhOQ,928
-tetra_hub/public_api_pb2.py,sha256=PtmIrUPpKAA8roNl0EtUq8nHpx27eReFpgX2jLx-l8w,21639
-tetra_hub/public_api_pb2.pyi,sha256=UKuMk9qC6eAQ8Bm9WygdBVAGAReBMcYCgNuOPDHNt34,86066
-tetra_hub/public_rest_api.py,sha256=NHu8Gcr0dT-W_skpZJjvIIPautXokb8jL0gIW9NQfHs,46337
+tetra_hub/public_api_pb2.py,sha256=n8MCtf9TugLaHWmSJzqqDsjNcB6TkEFDaKDimEDdxZQ,21681
+tetra_hub/public_api_pb2.pyi,sha256=qKXtkoAE3aKnR2i28SiHtUM0CDO3mcQ5hC4QgfruqP0,86165
+tetra_hub/public_rest_api.py,sha256=hzz_hn7m-ANvoc3hARR7vEtzx_WSIFGYifmlyml_3XY,48616
 tetra_hub/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tetra_hub/test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tetra_hub/test/test_cli.py,sha256=b84r92p0AR63M_w1WxpV9rkvCopdzKmXDt6cn2VFZ6A,1586
-tetra_hub/test/test_client.py,sha256=WawrN2qogNCYJt4F3Rv8GUTHS4A2dR7nuARx-IYZx1g,3727
+tetra_hub/test/test_client.py,sha256=VKZZFbOMst9Qs389trO1wpKEANYfoK4RdZqgzF70wc4,5932
 tetra_hub/test/test_public_rest_api.py,sha256=v_BjT53XOP9TZNFufWytEZb16cFKm9z90Oms9A0AEhY,601
+tetra_hub/test/test_zipped_model.py,sha256=YabM0hFtoGOVALeZYzSUj4NQ7qNwsSgHShPXIRplIN8,5062
 tetra_hub/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tetra_hub/util/dataset_entries_converters.py,sha256=203V0O7NXA3ZCUUB9EB1oyaMViJwJfjfUYresCW9Ikk,3887
-tetra_hub-0.6.2.dist-info/METADATA,sha256=783DPyeWNGEZ6nUiTnmSYIZFuWMpDoJif_TrazGq8ek,2688
-tetra_hub-0.6.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-tetra_hub-0.6.2.dist-info/entry_points.txt,sha256=EuYMlBUJNBh51LZtTvw4XSjrMuOHZsq23X8CtQvzCb4,51
-tetra_hub-0.6.2.dist-info/top_level.txt,sha256=cVzWAT5ht1JM3K_TxfxGQcVyvGQZGaJw_ddkLgN8ulY,10
-tetra_hub-0.6.2.dist-info/RECORD,,
+tetra_hub/util/zipped_model.py,sha256=GCVX2cXNrWgawZ5SfQS53-Q2mp_tNTq9tuF2CslYtRc,4933
+tetra_hub-0.6.3.dist-info/METADATA,sha256=zAh_A6eE-epKZ_cfb5v99YJWUlnq98To6kmzkctULiU,2688
+tetra_hub-0.6.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+tetra_hub-0.6.3.dist-info/entry_points.txt,sha256=EuYMlBUJNBh51LZtTvw4XSjrMuOHZsq23X8CtQvzCb4,51
+tetra_hub-0.6.3.dist-info/top_level.txt,sha256=cVzWAT5ht1JM3K_TxfxGQcVyvGQZGaJw_ddkLgN8ulY,10
+tetra_hub-0.6.3.dist-info/RECORD,,
```

